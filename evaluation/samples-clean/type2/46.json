{
  "code": "def update_state(\n      self, y_true: Dict[str, tf.Tensor], y_pred: Dict[str, tf.Tensor]\n  ):\n    # (batch_size, num_detections, 4) in absolute coordinates.\n    detection_boxes = tf.cast(y_pred['detection_boxes'], tf.float32)\n    # (batch_size, num_detections)\n    detection_classes = tf.cast(y_pred['detection_classes'], tf.int32)\n    # (batch_size, num_detections)\n    detection_scores = tf.cast(y_pred['detection_scores'], tf.float32)\n    # (batch_size, num_gts, 4) in absolute coordinates.\n    gt_boxes = tf.cast(y_true['boxes'], tf.float32)\n    # (batch_size, num_gts)\n    gt_classes = tf.cast(y_true['classes'], tf.int32)\n    # (batch_size, num_gts)\n    if 'is_crowds' in y_true:\n      gt_is_crowd = tf.cast(y_true['is_crowds'], tf.bool)\n    else:\n      gt_is_crowd = tf.zeros_like(gt_classes, dtype=tf.bool)\n\n    image_scale = tf.tile(y_true['image_info'][:, 2:3, :], multiples=[1, 1, 2])\n    detection_boxes = detection_boxes / tf.cast(\n        image_scale, dtype=detection_boxes.dtype\n    )\n\n    # Step 1: Computes IoUs between the detections and the non-crowd ground\n    # truths and IoAs between the detections and the crowd ground truths.\n    if not self._use_masks:\n      # (batch_size, num_detections, num_gts)\n      detection_to_gt_ious = box_ops.bbox_overlap(detection_boxes, gt_boxes)\n      detection_to_gt_ioas = box_ops.bbox_intersection_over_area(\n          detection_boxes, gt_boxes\n      )\n    else:\n      # Use outer boxes to generate the masks if available.\n      if 'detection_outer_boxes' in y_pred:\n        detection_boxes = tf.cast(y_pred['detection_outer_boxes'], tf.float32)\n\n      # (batch_size, num_detections, mask_height, mask_width)\n      detection_masks = tf.cast(y_pred['detection_masks'], tf.float32)\n      # (batch_size, num_gts, gt_mask_height, gt_mask_width)\n      gt_masks = tf.cast(y_true['masks'], tf.float32)\n\n      num_detections = detection_boxes.get_shape()[1]\n      # (batch_size, num_detections + num_gts, 4)\n      all_boxes = _shift_and_rescale_boxes(\n          tf.concat([detection_boxes, gt_boxes], axis=1),\n          self._mask_output_boundary,\n      )\n      detection_boxes = all_boxes[:, :num_detections, :]\n      gt_boxes = all_boxes[:, num_detections:, :]\n      # (batch_size, num_detections, num_gts)\n      detection_to_gt_ious, detection_to_gt_ioas = (\n          mask_ops.instance_masks_overlap(\n              detection_boxes,\n              detection_masks,\n              gt_boxes,\n              gt_masks,\n              output_size=self._mask_output_boundary,\n          )\n      )\n    # (batch_size, num_detections, num_gts)\n    detection_to_gt_ious = tf.where(\n        gt_is_crowd[:, tf.newaxis, :], 0.0, detection_to_gt_ious\n    )\n    detection_to_crowd_ioas = tf.where(\n        gt_is_crowd[:, tf.newaxis, :], detection_to_gt_ioas, 0.0\n    )\n\n    # Step 2: counts true positives grouped by IoU thresholds, classes and\n    # confidence bins.\n\n    # (batch_size, num_detections, num_iou_thresholds)\n    detection_is_tp, _ = self._matching_algorithm(\n        detection_to_gt_ious, detection_classes, detection_scores, gt_classes\n    )\n    # (batch_size * num_detections,)\n    flattened_binned_confidence = tf.reshape(\n        tf.cast(detection_scores * self._num_confidence_bins, tf.int32), [-1]\n    )\n    # (batch_size * num_detections, num_confidence_bins + 1)\n    flattened_binned_confidence_one_hot = tf.one_hot(\n        flattened_binned_confidence, self._num_confidence_bins + 1, axis=1\n    )\n    # (num_iou_thresholds, num_classes, num_confidence_bins + 1)\n    tp_count = _count_detection_type(\n        detection_is_tp,\n        detection_classes,\n        flattened_binned_confidence_one_hot,\n        self._num_classes,\n    )\n\n    # Step 3: Counts false positives grouped by IoU thresholds, classes and\n    # confidence bins.\n    # False positive: detection is not true positive (see above) and not part of\n    # the crowd ground truth with the same class.\n\n    # (batch_size, num_detections, num_gts, num_iou_thresholds)\n    detection_matches_crowd = (\n        (detection_to_crowd_ioas[..., tf.newaxis] > self._iou_thresholds)\n        & (\n            detection_classes[:, :, tf.newaxis, tf.newaxis]\n            == gt_classes[:, tf.newaxis, :, tf.newaxis]\n        )\n        & (detection_classes[:, :, tf.newaxis, tf.newaxis] > 0)\n    )\n    # (batch_size, num_detections, num_iou_thresholds)\n    detection_matches_any_crowd = tf.reduce_any(\n        detection_matches_crowd & ~detection_is_tp[:, :, tf.newaxis, :], axis=2\n    )\n    detection_is_fp = ~detection_is_tp & ~detection_matches_any_crowd\n    # (num_iou_thresholds, num_classes, num_confidence_bins + 1)\n    fp_count = _count_detection_type(\n        detection_is_fp,\n        detection_classes,\n        flattened_binned_confidence_one_hot,\n        self._num_classes,\n    )\n\n    # Step 4: Counts non-crowd groundtruths grouped by classes.\n    # (num_classes, )\n    gt_count = tf.reduce_sum(\n        tf.one_hot(\n            tf.where(gt_is_crowd, -1, gt_classes), self._num_classes, axis=-1\n        ),\n        axis=[0, 1],\n    )\n    # Clears the count of class 0 (background).\n    gt_count *= 1.0 - tf.eye(1, self._num_classes, dtype=gt_count.dtype)[0]\n\n    # Accumulates the variables.\n    self.fp_count.assign_add(tf.cast(fp_count, self.fp_count.dtype))\n    self.tp_count.assign_add(tf.cast(tp_count, self.tp_count.dtype))\n    self.gt_count.assign_add(tf.cast(gt_count, self.gt_count.dtype))\ndef instance_masks_overlap(\n    boxes: tf.Tensor,\n    masks: tf.Tensor,\n    gt_boxes: tf.Tensor,\n    gt_masks: tf.Tensor,\n    output_size: List[int],\n    mask_binarize_threshold: float = 0.5,\n) -> Tuple[tf.Tensor, tf.Tensor]:\n  \"\"\"Calculates the IoUs and IoAs between the detection masks and the ground truth masks.\n\n  IoU: intersection over union.\n  IoA: intersection over the area of the detection masks.\n\n  Args:\n    boxes: a tensor with a shape of [batch_size, N, 4]. The last dimension is\n      the pixel coordinates in [ymin, xmin, ymax, xmax] form.\n    masks: a float tensor with a shape of [batch_size, N, mask_height,\n      mask_width] representing the instance masks w.r.t. the `boxes`.\n    gt_boxes: a tensor with a shape of [batch_size, M, 4]. The last dimension is\n      the pixel coordinates in [ymin, xmin, ymax, xmax] form.\n    gt_masks: a float tensor with a shape of [batch_size, M, gt_mask_height,\n      gt_mask_width] representing the instance masks w.r.t. the `gt_boxes`.\n    output_size: two integers that represent the height and width of the output\n      masks.\n    mask_binarize_threshold: a float representing the threshold for binarizing\n      mask values. Default value is 0.5.\n\n  Returns:\n    iou: a tensor with as a shape of [batch_size, N, M].\n  \"\"\"\n  _, num_detections, mask_height, mask_width = masks.get_shape().as_list()\n  _, num_gts, gt_mask_height, gt_mask_width = gt_masks.get_shape().as_list()\n  output_height, output_width = output_size\n\n  masks = tf.where(masks < 0, tf.zeros_like(masks), masks)\n  gt_masks = tf.where(gt_masks < 0, tf.zeros_like(gt_masks), gt_masks)\n\n  pasted_masks = tf.reshape(\n      spatial_transform_ops.bilinear_resize_to_bbox(\n          tf.reshape(masks, [-1, mask_height, mask_width]),\n          tf.reshape(boxes, [-1, 4]),\n          output_size,\n      ),\n      shape=[-1, num_detections, output_height, output_width],\n  )\n  pasted_gt_masks = tf.reshape(\n      spatial_transform_ops.bilinear_resize_to_bbox(\n          tf.reshape(gt_masks, [-1, gt_mask_height, gt_mask_width]),\n          tf.reshape(gt_boxes, [-1, 4]),\n          output_size,\n      ),\n      shape=[-1, num_gts, output_height, output_width],\n  )\n  # (batch_size, num_detections, output_height * output_width)\n  flattened_binary_masks = tf.reshape(\n      pasted_masks > mask_binarize_threshold,\n      [-1, num_detections, output_height * output_width],\n  )\n  # (batch_size, num_gts, output_height * output_width)\n  flattened_gt_binary_masks = tf.reshape(\n      pasted_gt_masks > mask_binarize_threshold,\n      [-1, num_gts, output_height * output_width],\n  )\n  # (batch_size, output_height * output_width, num_gts)\n  flattened_gt_binary_masks = tf.transpose(flattened_gt_binary_masks, [0, 2, 1])\n\n  flattened_binary_masks = tf.cast(flattened_binary_masks, tf.float32)\n  flattened_gt_binary_masks = tf.cast(flattened_gt_binary_masks, tf.float32)\n\n  # (batch_size, num_detections, num_gts)\n  intersection = tf.matmul(flattened_binary_masks, flattened_gt_binary_masks)\n  detection_area = tf.reduce_sum(flattened_binary_masks, axis=-1, keepdims=True)\n  gt_area = tf.reduce_sum(flattened_gt_binary_masks, axis=-2, keepdims=True)\n  union = detection_area + gt_area - intersection\n  return tf.math.divide_no_nan(intersection, union), tf.math.divide_no_nan(\n      intersection, detection_area\n  )",
  "smell": [
    {
      "smell_id": 2,
      "line_no": 58,
      "description": "The values of an argument hold inconsistent types in different function calls."
    }
  ]
}
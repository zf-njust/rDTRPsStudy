{
  "code": "def test_all(self, strategy, training):\n    tf.keras.backend.set_image_data_format('channels_last')\n    num_classes = 2\n\n    h, w, c = 8, 8, 2\n    n, p, d = 2, 3, 4\n    image_size = [h, w]\n    pillars_size = [n, p, d]\n    indices_size = [n, 2]\n    attribute_heads = [{'name': 'heading', 'type': 'regression', 'size': 1}]\n\n    min_level = 1\n    max_level = 2\n\n    anchor_sizes = [(1.1, 1.1)]\n    num_anchors_per_location = len(anchor_sizes)\n\n    global_batch_size = 4\n    num_replicas = tf.distribute.get_strategy().num_replicas_in_sync\n    batch_size = int(global_batch_size / num_replicas)\n    pillars = tf.keras.Input(shape=pillars_size, batch_size=batch_size)\n    indices = tf.keras.Input(\n        shape=indices_size, batch_size=batch_size, dtype=tf.int32)\n    image_shape = tf.tile(tf.expand_dims([h, w], axis=0), [batch_size, 1])\n    max_num_detections = 4\n\n    # Test model creation.\n    with strategy.scope():\n      anchor_boxes = utils.generate_anchors(min_level,\n                                            max_level,\n                                            image_size,\n                                            anchor_sizes)\n      for l in anchor_boxes:\n        anchor_boxes[l] = tf.tile(\n            tf.expand_dims(anchor_boxes[l], axis=0), [batch_size, 1, 1, 1])\n\n      featurizer = featurizers.Featurizer(\n          image_size=image_size,\n          pillars_size=pillars_size,\n          train_batch_size=batch_size,\n          eval_batch_size=batch_size,\n          num_blocks=3,\n          num_channels=c\n      )\n      image = featurizer(pillars, indices, training)\n      backbone = backbones.Backbone(\n          input_specs=featurizer.output_specs,\n          min_level=min_level,\n          max_level=max_level,\n          num_convs=3\n      )\n      encoded_feats = backbone(image)\n      decoder = decoders.Decoder(\n          input_specs=backbone.output_specs)\n      decoded_feats = decoder(encoded_feats)\n      head = heads.SSDHead(\n          num_classes=num_classes,\n          num_anchors_per_location=num_anchors_per_location,\n          num_params_per_anchor=4,\n          attribute_heads=attribute_heads,\n          min_level=min_level,\n          max_level=max_level\n      )\n      _ = head(decoded_feats)\n      generator = detection_generator.MultilevelDetectionGenerator(\n          max_num_detections=max_num_detections,\n          nms_version='v1',\n          use_cpu_nms=True,\n          soft_nms_sigma=0.1)\n      model = models.PointPillarsModel(\n          featurizer=featurizer,\n          backbone=backbone,\n          decoder=decoder,\n          head=head,\n          detection_generator=generator,\n          min_level=min_level,\n          max_level=max_level,\n          image_size=image_size,\n          anchor_sizes=anchor_sizes)\n      outputs = model(\n          pillars,\n          indices,\n          image_shape,\n          anchor_boxes,\n          training)\n\n    # Test training and evaluation.\n    if training:\n      cls_outputs = outputs['cls_outputs']\n      box_outputs = outputs['box_outputs']\n      for level in range(min_level, max_level+1):\n        self.assertIn(str(level), cls_outputs)\n        self.assertIn(str(level), box_outputs)\n        self.assertAllEqual([\n            batch_size,\n            h // 2**level,\n            w // 2**level,\n            num_classes * num_anchors_per_location\n        ], cls_outputs[str(level)].shape)\n        self.assertAllEqual([\n            batch_size,\n            h // 2**level,\n            w // 2**level,\n            4 * num_anchors_per_location\n        ], box_outputs[str(level)].shape)\n        att_outputs = outputs['attribute_outputs']\n        self.assertLen(att_outputs, 1)\n        self.assertIn('heading', att_outputs)\n        self.assertAllEqual([\n            batch_size,\n            h // 2**level,\n            w // 2**level,\n            1 * num_anchors_per_location\n        ], att_outputs['heading'][str(level)].shape)\n    else:\n      self.assertIn('boxes', outputs)\n      self.assertIn('scores', outputs)\n      self.assertIn('classes', outputs)\n      self.assertIn('num_detections', outputs)\n      self.assertAllEqual([\n          batch_size,\n      ], outputs['num_detections'].shape)\n      self.assertAllEqual([batch_size, max_num_detections, 4],\n                          outputs['boxes'].shape)\n      self.assertAllEqual([batch_size, max_num_detections],\n                          outputs['scores'].shape)\n      self.assertAllEqual([batch_size, max_num_detections],\n                          outputs['classes'].shape)\n      self.assertIn('attributes', outputs)\n      self.assertAllEqual(\n          [batch_size, max_num_detections, 1],\n          outputs['attributes']['heading'].shape)\n\n    # Test serialization.\n    config = model.get_config()\n    new_model = models.PointPillarsModel.from_config(config)\n    _ = new_model.to_json()\n    self.assertAllEqual(model.get_config(), new_model.get_config())\n  def __init__(\n      self,\n      image_size: Tuple[int, int],\n      pillars_size: Tuple[int, int, int],\n      train_batch_size: int,\n      eval_batch_size: int,\n      num_blocks: int,\n      num_channels: int,\n      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,\n      **kwargs):\n    \"\"\"Initialize the featurizer.\n\n    Args:\n      image_size: A [int, int] tuple to define the [H, W] of BEV image.\n      pillars_size: A [int, int, int] tuple to define the [P, N, D] of pillars.\n      train_batch_size: An `int` training batch size per replica.\n      eval_batch_size: An `int` evaluation batch size per replica.\n      num_blocks: An `int` number of blocks for extracting features.\n      num_channels: An `int` number channels of the BEV image.\n      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for\n        block layers. Default to None.\n      **kwargs: Additional keyword arguments to be passed.\n    \"\"\"\n    super(Featurizer, self).__init__(**kwargs)",
  "smell": [
    {
      "smell_id": 2,
      "line_no": 39,
      "description": "The values of an argument hold inconsistent types in different function calls."
    }
  ]
}
{
  "code": "def __init__(self,\n               filters=1,\n               kernel_size=(1, 1),\n               strides=(1, 1),\n               padding='same',\n               dilation_rate=(1, 1),\n               kernel_initializer='VarianceScaling',\n               bias_initializer='zeros',\n               bias_regularizer=None,\n               kernel_regularizer=None,\n               use_separable_conv=False,\n               use_bn=True,\n               use_sync_bn=False,\n               norm_momentum=0.99,\n               norm_epsilon=0.001,\n               activation='leaky',\n               leaky_alpha=0.1,\n               **kwargs):\n    \"\"\"ConvBN initializer.\n\n    Args:\n      filters: integer for output depth, or the number of features to learn.\n      kernel_size: integer or tuple for the shape of the weight matrix or kernel\n        to learn.\n      strides: integer of tuple how much to move the kernel after each kernel\n        use.\n      padding: string 'valid' or 'same', if same, then pad the image, else do\n        not.\n      dilation_rate: tuple to indicate how much to modulate kernel weights and\n        how many pixels in a feature map to skip.\n      kernel_initializer: string to indicate which function to use to initialize\n        weights.\n      bias_initializer: string to indicate which function to use to initialize\n        bias.\n      bias_regularizer: string to indicate which function to use to regularizer\n        bias.\n      kernel_regularizer: string to indicate which function to use to\n        regularizer weights.\n      use_separable_conv: `bool` wether to use separable convs.\n      use_bn: boolean for whether to use batch normalization.\n      use_sync_bn: boolean for whether sync batch normalization statistics\n        of all batch norm layers to the models global statistics\n        (across all input batches).\n      norm_momentum: float for moment to use for batch normalization.\n      norm_epsilon: float for batch normalization epsilon.\n      activation: string or None for activation function to use in layer,\n        if None activation is replaced by linear.\n      leaky_alpha: float to use as alpha if activation function is leaky.\n      **kwargs: Keyword Arguments.\n    \"\"\"\n\n    # convolution params\n    self._filters = filters\n    self._kernel_size = kernel_size\n    self._strides = strides\n    self._padding = padding\n    self._dilation_rate = dilation_rate\n\n    if kernel_initializer == 'VarianceScaling':\n      # to match pytorch initialization method\n      self._kernel_initializer = tf.keras.initializers.VarianceScaling(\n          scale=1 / 3, mode='fan_in', distribution='uniform')\n    else:\n      self._kernel_initializer = kernel_initializer\n\n    self._bias_initializer = bias_initializer\n    self._kernel_regularizer = kernel_regularizer\n\n    self._bias_regularizer = bias_regularizer\n\n    # batch normalization params\n    self._use_bn = use_bn\n    self._use_separable_conv = use_separable_conv\n    self._use_sync_bn = use_sync_bn\n    self._norm_momentum = norm_momentum\n    self._norm_epsilon = norm_epsilon\n\n    ksize = self._kernel_size\n    if not isinstance(ksize, List) and not isinstance(ksize, Tuple):\n      ksize = [ksize]\n    if use_separable_conv and not all([a == 1 for a in ksize]):\n      self._conv_base = tf.keras.layers.SeparableConv2D\n    else:\n      self._conv_base = tf.keras.layers.Conv2D\n\n    self._bn_base = tf.keras.layers.BatchNormalization\n\n    if tf.keras.backend.image_data_format() == 'channels_last':\n      # format: (batch_size, height, width, channels)\n      self._bn_axis = -1\n    else:\n      # format: (batch_size, channels, width, height)\n      self._bn_axis = 1\n\n    # activation params\n    self._activation = activation\n    self._leaky_alpha = leaky_alpha\n    self._fuse = False\n\n    super().__init__(**kwargs)\ndef isinstance(x, A_tuple): # real signature unknown; restored from __doc__\n    \"\"\"\n    Return whether an object is an instance of a class or of a subclass thereof.\n    \n    A tuple, as in ``isinstance(x, (A, B, ...))``, may be given as the target to\n    check against. This is equivalent to ``isinstance(x, A) or isinstance(x, B)\n    or ...`` etc.\n    \"\"\"\n    pass",
  "smell": [
    {
      "smell_id": 2,
      "line_no": 79,
      "description": "The values of an argument hold inconsistent types in different function calls."
    }
  ]
}
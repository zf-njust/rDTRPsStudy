{
  "code": "def fetch_mldata(dataname, target_name='label', data_name='data',\n                 transpose_data=True, data_home=None):\n    \"\"\"Fetch an mldata.org data set\n\n    If the file does not exist yet, it is downloaded from mldata.org .\n\n    mldata.org does not have an enforced convention for storing data or\n    naming the columns in a data set. The default behavior of this function\n    works well with the most common cases:\n\n      1) data values are stored in the column 'data', and target values in the\n         column 'label'\n      2) alternatively, the first column stores target values, and the second\n         data values\n      3) the data array is stored as `n_features x n_samples` , and thus needs\n         to be transposed to match the `sklearn` standard\n\n    Keyword arguments allow to adapt these defaults to specific data sets\n    (see parameters `target_name`, `data_name`, `transpose_data`, and\n    the examples below).\n\n    mldata.org data sets may have multiple columns, which are stored in the\n    Bunch object with their original name.\n\n    Parameters\n    ----------\n\n    dataname:\n        Name of the data set on mldata.org,\n        e.g.: \"leukemia\", \"Whistler Daily Snowfall\", etc.\n        The raw name is automatically converted to a mldata.org URL .\n\n    target_name: optional, default: 'label'\n        Name or index of the column containing the target values.\n\n    data_name: optional, default: 'data'\n        Name or index of the column containing the data.\n\n    transpose_data: optional, default: True\n        If True, transpose the downloaded data array.\n\n    data_home: optional, default: None\n        Specify another download and cache folder for the data sets. By default\n        all scikit learn data is stored in '~/scikit_learn_data' subfolders.\n\n    Returns\n    -------\n\n    data : Bunch\n        Dictionary-like object, the interesting attributes are:\n        'data', the data to learn, 'target', the classification labels,\n        'DESCR', the full description of the dataset, and\n        'COL_NAMES', the original names of the dataset columns.\n\n    Examples\n    --------\n    Load the 'iris' dataset from mldata.org:\n\n    >>> from sklearn.datasets.mldata import fetch_mldata\n    >>> import tempfile\n    >>> test_data_home = tempfile.mkdtemp()\n\n    >>> iris = fetch_mldata('iris', data_home=test_data_home)\n    >>> iris.target.shape\n    (150,)\n    >>> iris.data.shape\n    (150, 4)\n\n    Load the 'leukemia' dataset from mldata.org, which needs to be transposed\n    to respects the sklearn axes convention:\n\n    >>> leuk = fetch_mldata('leukemia', transpose_data=True,\n    ...                     data_home=test_data_home)\n    >>> leuk.data.shape\n    (72, 7129)\n\n    Load an alternative 'iris' dataset, which has different names for the\n    columns:\n\n    >>> iris2 = fetch_mldata('datasets-UCI iris', target_name=1,\n    ...                      data_name=0, data_home=test_data_home)\n    >>> iris3 = fetch_mldata('datasets-UCI iris',\n    ...                      target_name='class', data_name='double0',\n    ...                      data_home=test_data_home)\n\n    >>> import shutil\n    >>> shutil.rmtree(test_data_home)\n    \"\"\"\n\n    # normalize dataset name\n    dataname = mldata_filename(dataname)\n\n    # check if this data set has been already downloaded\n    data_home = get_data_home(data_home=data_home)\n    data_home = join(data_home, 'mldata')\n    if not exists(data_home):\n        os.makedirs(data_home)\n\n    matlab_name = dataname + '.mat'\n    filename = join(data_home, matlab_name)\n\n    # if the file does not exist, download it\n    if not exists(filename):\n        urlname = MLDATA_BASE_URL % quote(dataname)\n        try:\n            mldata_url = urlopen(urlname)\n        except HTTPError as e:\n            if e.code == 404:\n                e.msg = \"Dataset '%s' not found on mldata.org.\" % dataname\n            raise\n        # store Matlab file\n        try:\n            with open(filename, 'w+b') as matlab_file:\n                copyfileobj(mldata_url, matlab_file)\n        except:\n            os.remove(filename)\n            raise\n        mldata_url.close()\n\n    # load dataset matlab file\n    with open(filename, 'rb') as matlab_file:\n        matlab_dict = io.loadmat(matlab_file, struct_as_record=True)\n\n    # -- extract data from matlab_dict\n\n    # flatten column names\n    col_names = [str(descr[0])\n                 for descr in matlab_dict['mldata_descr_ordering'][0]]\n\n    # if target or data names are indices, transform then into names\n    if isinstance(target_name, numbers.Integral):\n        target_name = col_names[target_name]\n    if isinstance(data_name, numbers.Integral):\n        data_name = col_names[data_name]\n\n    # rules for making sense of the mldata.org data format\n    # (earlier ones have priority):\n    # 1) there is only one array => it is \"data\"\n    # 2) there are multiple arrays\n    #    a) copy all columns in the bunch, using their column name\n    #    b) if there is a column called `target_name`, set \"target\" to it,\n    #        otherwise set \"target\" to first column\n    #    c) if there is a column called `data_name`, set \"data\" to it,\n    #        otherwise set \"data\" to second column\n\n    dataset = {'DESCR': 'mldata.org dataset: %s' % dataname,\n               'COL_NAMES': col_names}\n\n    # 1) there is only one array => it is considered data\n    if len(col_names) == 1:\n        data_name = col_names[0]\n        dataset['data'] = matlab_dict[data_name]\n    # 2) there are multiple arrays\n    else:\n        for name in col_names:\n            dataset[name] = matlab_dict[name]\n\n        if target_name in col_names:\n            del dataset[target_name]\n            dataset['target'] = matlab_dict[target_name]\n        else:\n            del dataset[col_names[0]]\n            dataset['target'] = matlab_dict[col_names[0]]\n\n        if data_name in col_names:\n            del dataset[data_name]\n            dataset['data'] = matlab_dict[data_name]\n        else:\n            del dataset[col_names[1]]\n            dataset['data'] = matlab_dict[col_names[1]]\n\n    # set axes to sklearn conventions\n    if transpose_data:\n        dataset['data'] = dataset['data'].T\n    if 'target' in dataset:\n        if not sp.sparse.issparse(dataset['target']):\n            dataset['target'] = dataset['target'].squeeze()\n\n    return Bunch(**dataset)",
  "smell": [
    {
      "smell_id": 4,
      "line_no": 166,
      "description": "The element is deleted from a container by a dynamically determined index."
    }
  ]
}
{
  "code": "def _update(self):\n        # Throttle autoscaling updates to this interval to avoid exceeding\n        # rate limits on API calls.\n        if time.time() - self.last_update_time < self.update_interval_s:\n            return\n\n        self.last_update_time = time.time()\n        num_pending = self.num_launches_pending.value\n        nodes = self.workers()\n        logger.info(self.info_string(nodes))\n        self.load_metrics.prune_active_ips(\n            [self.provider.internal_ip(node_id) for node_id in nodes])\n        target_workers = self.target_num_workers()\n\n        # Terminate any idle or out of date nodes\n        last_used = self.load_metrics.last_used_time_by_ip\n        horizon = time.time() - (60 * self.config[\"idle_timeout_minutes\"])\n        num_terminated = 0\n        for node_id in nodes:\n            node_ip = self.provider.internal_ip(node_id)\n            if node_ip in last_used and last_used[node_ip] < horizon and \\\n                    len(nodes) - num_terminated > target_workers:\n                num_terminated += 1\n                logger.info(\"StandardAutoscaler: Terminating idle node: \"\n                            \"{}\".format(node_id))\n                self.provider.terminate_node(node_id)\n            elif not self.launch_config_ok(node_id):\n                num_terminated += 1\n                logger.info(\"StandardAutoscaler: Terminating outdated node: \"\n                            \"{}\".format(node_id))\n                self.provider.terminate_node(node_id)\n        if num_terminated > 0:\n            nodes = self.workers()\n            logger.info(self.info_string(nodes))\n\n        # Terminate nodes if there are too many\n        num_terminated = 0\n        while len(nodes) > self.config[\"max_workers\"]:\n            num_terminated += 1\n            logger.info(\"StandardAutoscaler: Terminating unneeded node: \"\n                        \"{}\".format(nodes[-1]))\n            self.provider.terminate_node(nodes[-1])\n            nodes = nodes[:-1]\n        if num_terminated > 0:\n            nodes = self.workers()\n            logger.info(self.info_string(nodes))\n\n        # Launch new nodes if needed\n        num_workers = len(nodes) + num_pending\n        if num_workers < target_workers:\n            max_allowed = min(self.max_launch_batch,\n                              self.max_concurrent_launches - num_pending)\n            num_launches = min(max_allowed, target_workers - num_workers)\n            self.launch_new_node(num_launches)\n            logger.info(self.info_string())\n\n        # Process any completed updates\n        completed = []\n        for node_id, updater in self.updaters.items():\n            if not updater.is_alive():\n                completed.append(node_id)\n        if completed:\n            for node_id in completed:\n                if self.updaters[node_id].exitcode == 0:\n                    self.num_successful_updates[node_id] += 1\n                else:\n                    self.num_failed_updates[node_id] += 1\n                del self.updaters[node_id]\n            # Mark the node as active to prevent the node recovery logic\n            # immediately trying to restart Ray on the new node.\n            self.load_metrics.mark_active(self.provider.internal_ip(node_id))\n            nodes = self.workers()\n            logger.info(self.info_string(nodes))\n\n        # Update nodes with out-of-date files\n        for node_id in nodes:\n            self.update_if_needed(node_id)\n\n        # Attempt to recover unhealthy nodes\n        for node_id in nodes:\n            self.recover_if_needed(node_id)",
  "smell": [
    {
      "smell_id": 4,
      "line_no": 68,
      "description": "The element is deleted from a container by a dynamically determined index."
    }
  ]
}
{
  "code": "def get_tokens_unprocessed(self, text=None, context=None):\n        \"\"\"\n        Split ``text`` into (tokentype, text) pairs.\n        If ``context`` is given, use this lexer context instead.\n        \"\"\"\n        tokendefs = self._tokens\n        if not context:\n            ctx = LexerContext(text, 0)\n            statetokens = tokendefs['root']\n        else:\n            ctx = context\n            statetokens = tokendefs[ctx.stack[-1]]\n            text = ctx.text\n        while 1:\n            for rexmatch, action, new_state in statetokens:\n                m = rexmatch(text, ctx.pos, ctx.end)\n                if m:\n                    if action is not None:\n                        if type(action) is _TokenType:\n                            yield ctx.pos, action, m.group()\n                            ctx.pos = m.end()\n                        else:\n                            yield from action(self, m, ctx)\n                            if not new_state:\n                                # altered the state stack?\n                                statetokens = tokendefs[ctx.stack[-1]]\n                    # CAUTION: callback must set ctx.pos!\n                    if new_state is not None:\n                        # state transition\n                        if isinstance(new_state, tuple):\n                            for state in new_state:\n                                if state == '#pop':\n                                    if len(ctx.stack) > 1:\n                                        ctx.stack.pop()\n                                elif state == '#push':\n                                    ctx.stack.append(ctx.stack[-1])\n                                else:\n                                    ctx.stack.append(state)\n                        elif isinstance(new_state, int):\n                            # see RegexLexer for why this check is made\n                            if abs(new_state) >= len(ctx.stack):\n                                del ctx.stack[1:]\n                            else:\n                                del ctx.stack[new_state:]\n                        elif new_state == '#push':\n                            ctx.stack.append(ctx.stack[-1])\n                        else:\n                            assert False, \"wrong state def: %r\" % new_state\n                        statetokens = tokendefs[ctx.stack[-1]]\n                    break\n            else:\n                try:\n                    if ctx.pos >= ctx.end:\n                        break\n                    if text[ctx.pos] == '\\n':\n                        # at EOL, reset state to \"root\"\n                        ctx.stack = ['root']\n                        statetokens = tokendefs['root']\n                        yield ctx.pos, Text, '\\n'\n                        ctx.pos += 1\n                        continue\n                    yield ctx.pos, Error, text[ctx.pos]\n                    ctx.pos += 1\n                except IndexError:\n                    break",
  "smell": [
    {
      "smell_id": 4,
      "line_no": 44,
      "description": "The element is deleted from a container by a dynamically determined index."
    }
  ]
}
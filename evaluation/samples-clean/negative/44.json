{
    "code": "def extract_global_descriptors_from_list(net, images, image_size,\n                                         bounding_boxes=None, scales=[1.],\n                                         multi_scale_power=1., print_freq=10):\n  \"\"\"Extracting global descriptors from a list of images.\n\n  Args:\n    net: Model object, network for the forward pass.\n    images: Absolute image paths as strings.\n    image_size: Integer, defines the maximum size of longer image side.\n    bounding_boxes: List of (x1,y1,x2,y2) tuples to crop the query images.\n    scales: List of float scales.\n    multi_scale_power: Float, multi-scale normalization power parameter.\n    print_freq: Printing frequency for debugging.\n\n  Returns:\n    descriptors: Global descriptors for the input images.\n  \"\"\"\n  # Creating dataset loader.\n  data = generic_dataset.ImagesFromList(root='', image_paths=images,\n                                        imsize=image_size,\n                                        bounding_boxes=bounding_boxes)\n\n  def _data_gen():\n    return (inst for inst in data)\n\n  loader = tf.data.Dataset.from_generator(_data_gen, output_types=(tf.float32))\n  loader = loader.batch(1)\n\n  # Extracting vectors.\n  descriptors = tf.zeros((0, net.meta['outputdim']))\n  for i, input in enumerate(loader):\n    if len(scales) == 1 and scales[0] == 1:\n      descriptors = tf.concat([descriptors, net(input)], 0)\n    else:\n      descriptors = tf.concat(\n              [descriptors, extract_multi_scale_descriptor(\n                      net, input, scales, multi_scale_power)], 0)\n\n    if (i + 1) % print_freq == 0 or (i + 1) == len(images):\n      global_features_utils.debug_and_log(\n              '\\r>>>> {}/{} done...'.format((i + 1), len(images)),\n              debug_on_the_same_line=True)\n  global_features_utils.debug_and_log('', log=False)\n\n  descriptors = tf.transpose(descriptors, perm=[1, 0])\n  return descriptors",
    "smell": []
}
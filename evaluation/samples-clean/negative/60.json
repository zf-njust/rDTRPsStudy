{
    "code": "def create_input_fn(runner_config, mode, drop_remainder):\n  \"\"\"Returns an input function to use in the instantiation of tf.estimator.*.\"\"\"\n\n  def _post_processor(features, batch_size):\n    \"\"\"Post process the data to a form expected by model_fn.\"\"\"\n    data_processor = getattr(sys.modules[__name__], runner_config[\"dataset\"])\n    text, label = data_processor(features, runner_config)\n    model_config = runner_config[\"model_config\"]\n    if \"max_seq_len\" in model_config:\n      max_seq_len = model_config[\"max_seq_len\"]\n      logging.info(\"Truncating text to have at most %d tokens\", max_seq_len)\n      text = misc_utils.random_substr(text, max_seq_len)\n    text = tf.reshape(text, [batch_size])\n    num_classes = len(model_config[\"labels\"])\n    label = tf.reshape(label, [batch_size, num_classes])\n    prxlayer = projection_layers.ProjectionLayer(model_config, mode)\n    projection, seq_length = prxlayer(text)\n    gbst_max_token_len = max_seq_len\n    if \"gbst_max_token_len\" in model_config:\n      gbst_max_token_len = model_config[\"gbst_max_token_len\"]\n    byte_int = tftext.ByteSplitter().split(text).to_tensor(\n        default_value=0, shape=[batch_size, gbst_max_token_len])\n    token_ids = tf.cast(byte_int, tf.int32)\n    token_len = tf.strings.length(text)\n    mask = tf.cast(\n        tf.sequence_mask(token_len, maxlen=gbst_max_token_len), tf.int32)\n    mask *= 3\n    token_ids += mask\n    return {\n        \"projection\": projection,\n        \"seq_length\": seq_length,\n        \"token_ids\": token_ids,\n        \"token_len\": token_len,\n        \"label\": label\n    }\n\n  def _input_fn(params):\n    \"\"\"Method to be used for reading the data.\"\"\"\n    assert mode != tf_estimator.ModeKeys.PREDICT\n    split = \"train\" if mode == tf_estimator.ModeKeys.TRAIN else \"test\"\n    ds = tfds.load(runner_config[\"dataset\"], split=split)\n    ds = ds.batch(params[\"batch_size\"], drop_remainder=drop_remainder)\n    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    ds = ds.shuffle(buffer_size=100)\n    ds = ds.repeat(count=1 if mode == tf_estimator.ModeKeys.EVAL else None)\n    ds = ds.map(\n        functools.partial(_post_processor, batch_size=params[\"batch_size\"]),\n        num_parallel_calls=tf.data.experimental.AUTOTUNE,\n        deterministic=False)\n    return ds\n\n  return _input_fn",
    "smell": []
}
{
    "code": "def tumblr_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    if re.match(r'https?://\\d+\\.media\\.tumblr\\.com/', url):\n        universal_download(url, output_dir, merge=merge, info_only=info_only)\n        return\n\n    import ssl\n    ssl_context = request.HTTPSHandler(context=ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)) # server requires TLS v1.2\n    cookie_handler = request.HTTPCookieProcessor()\n    opener = request.build_opener(ssl_context, cookie_handler)\n    request.install_opener(opener)\n\n    page = get_html(url)\n    form_key = match1(page, r'id=\"tumblr_form_key\" content=\"([^\"]+)\"')\n    if form_key is not None:\n        # bypass GDPR consent page\n        referer = 'https://www.tumblr.com/privacy/consent?redirect=%s' % parse.quote_plus(url)\n        post_content('https://www.tumblr.com/svc/privacy/consent',\n                     headers={\n                         'Content-Type': 'application/json',\n                         'User-Agent': fake_headers['User-Agent'],\n                         'Referer': referer,\n                         'X-tumblr-form-key': form_key,\n                         'X-Requested-With': 'XMLHttpRequest'\n                     },\n                     post_data_raw='{\"eu_resident\":true,\"gdpr_is_acceptable_age\":true,\"gdpr_consent_core\":true,\"gdpr_consent_first_party_ads\":true,\"gdpr_consent_third_party_ads\":true,\"gdpr_consent_search_history\":true,\"redirect_to\":\"%s\",\"gdpr_reconsent\":false}' % url)\n        page = get_html(url, faker=True)\n\n    html = parse.unquote(page).replace('\\/', '/')\n    feed = r1(r'<meta property=\"og:type\" content=\"tumblr-feed:(\\w+)\" />', html)\n\n    if feed in ['photo', 'photoset', 'entry'] or feed is None:\n        # try to extract photos\n        page_title = r1(r'<meta name=\"description\" content=\"([^\"\\n]+)', html) or \\\n                     r1(r'<meta property=\"og:description\" content=\"([^\"\\n]+)', html) or \\\n                     r1(r'<title>([^<\\n]*)', html)\n        urls = re.findall(r'(https?://[^;\"&]+/tumblr_[^;\"&]+_\\d+\\.jpg)', html) +\\\n               re.findall(r'(https?://[^;\"&]+/tumblr_[^;\"&]+_\\d+\\.png)', html) +\\\n               re.findall(r'(https?://[^;\"&]+/tumblr_[^;\"&]+_\\d+\\.gif)', html) +\\\n               re.findall(r'(https?://\\d+\\.media\\.tumblr\\.com/[^;\"&]+/s\\d+x\\d+/[^;\"&]+\\.jpg)', html) +\\\n               re.findall(r'(https?://\\d+\\.media\\.tumblr\\.com/[^;\"&]+/s\\d+x\\d+/[^;\"&]+\\.png)', html) +\\\n               re.findall(r'(https?://\\d+\\.media\\.tumblr\\.com/[^;\"&]+/s\\d+x\\d+/[^;\"&]+\\.gif)', html)\n\n        tuggles = {}\n        for url in urls:\n            if url.endswith('.gif'):\n                hd_url = url\n            elif url.endswith('.jpg'):\n                hd_url = url  # FIXME: decide actual quality # r1(r'(.+)_\\d+\\.jpg$', url) + '_1280.jpg'\n            elif url.endswith('.png'):\n                hd_url = url  # FIXME: decide actual quality # r1(r'(.+)_\\d+\\.png$', url) + '_1280.png'\n            else:\n                continue\n            filename = parse.unquote(hd_url.split('/')[-1])\n            title = '.'.join(filename.split('.')[:-1])\n            tumblr_id = r1(r'^tumblr_(.+)_\\d+$', title) or title\n            try:\n                quality = int(r1(r'^tumblr_.+_(\\d+)$', title))\n            except:\n                quality = int(r1(r'/s(\\d+)x\\d+/', hd_url))\n            ext = filename.split('.')[-1]\n\n            try:\n                size = int(get_head(hd_url)['Content-Length'])\n                if tumblr_id not in tuggles or tuggles[tumblr_id]['quality'] < quality:\n                    tuggles[tumblr_id] = {\n                        'title': title,\n                        'url': hd_url,\n                        'quality': quality,\n                        'ext': ext,\n                        'size': size,\n                    }\n            except: pass\n\n        if tuggles:\n            size = sum([tuggles[t]['size'] for t in tuggles])\n            print_info(site_info, page_title, None, size)\n\n            if not info_only:\n                for t in tuggles:\n                    title = tuggles[t]['title']\n                    ext = tuggles[t]['ext']\n                    size = tuggles[t]['size']\n                    url = tuggles[t]['url']\n                    print_info(site_info, title, ext, size)\n                    download_urls([url], title, ext, size,\n                                  output_dir=output_dir)\n            return\n\n    # feed == 'audio' or feed == 'video' or feed is None\n    # try to extract video / audio\n    real_url = r1(r'source src=\\\\x22([^\\\\]+)\\\\', html)\n    if not real_url:\n        real_url = r1(r'audio_file=([^&]+)&', html)\n        if real_url:\n            real_url = real_url + '?plead=please-dont-download-this-or-our-lawyers-wont-let-us-host-audio'\n    if not real_url:\n        real_url = r1(r'<source src=\"([^\"]*)\"', html)\n    if not real_url:\n        iframe_url = r1(r'<[^>]+tumblr_video_container[^>]+><iframe[^>]+src=[\\'\"]([^\\'\"]*)[\\'\"]', html)\n\n        if iframe_url is None:\n            universal_download(url, output_dir, merge=merge, info_only=info_only, **kwargs)\n            return\n\n        if iframe_url:\n            iframe_html = get_content(iframe_url, headers=fake_headers)\n            real_url = r1(r'<video[^>]*>[\\n ]*<source[^>]+src=[\\'\"]([^\\'\"]*)[\\'\"]', iframe_html)\n        else:\n            iframe_url = r1(r'<iframe[^>]+src=[\\'\"]([^\\'\"]*)[\\'\"]', html)\n            if iframe_url[:2] == '//': iframe_url = 'http:' + iframe_url\n            if re.search(r'player\\.vimeo\\.com', iframe_url):\n                vimeo_download(iframe_url, output_dir, merge=merge, info_only=info_only,\n                               referer='http://tumblr.com/', **kwargs)\n                return\n            elif re.search(r'dailymotion\\.com', iframe_url):\n                dailymotion_download(iframe_url, output_dir, merge=merge, info_only=info_only, **kwargs)\n                return\n            elif re.search(r'vine\\.co', iframe_url):\n                vine_download(iframe_url, output_dir, merge=merge, info_only=info_only, **kwargs)\n                return\n            else:\n                iframe_html = get_content(iframe_url)\n                real_url = r1(r'<source src=\"([^\"]*)\"', iframe_html)\n\n    title = unescape_html(r1(r'<meta property=\"og:title\" content=\"([^\"]*)\" />', html) or\n        r1(r'<meta property=\"og:description\" content=\"([^\"]*)\" />', html) or\n        r1(r'<title>([^<\\n]*)', html) or url.split(\"/\")[4]).replace('\\n', '')\n\n    # this is better\n    vcode = r1(r'tumblr_(\\w+)', real_url)\n    real_url = 'https://vt.media.tumblr.com/tumblr_%s.mp4' % vcode\n\n    type, ext, size = url_info(real_url, faker=True)\n\n    print_info(site_info, title, type, size)\n    if not info_only:\n        download_urls([real_url], title, ext, size, output_dir, merge=merge)",
    "smell": []
}
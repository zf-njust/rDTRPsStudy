{
    "code": "def get_argument_list() -> list[dict[str, T.Any]]:\n        \"\"\" Put the arguments in a list so that they are accessible from both argparse and gui \"\"\"\n        argument_list = []\n        argument_list.append(dict(\n            opts=(\"-m\", \"--model-dir\"),\n            action=DirFullPaths,\n            dest=\"model_dir\",\n            required=True,\n            help=_(\"Model directory. A directory containing the model you wish to perform an \"\n                   \"action on.\")))\n        argument_list.append(dict(\n            opts=(\"-j\", \"--job\"),\n            action=Radio,\n            type=str,\n            choices=(\"inference\", \"nan-scan\", \"restore\"),\n            required=True,\n            help=_(\"R|Choose which action you want to perform.\"\n                   \"\\nL|'inference' - Create an inference only copy of the model. Strips any \"\n                   \"layers from the model which are only required for training. NB: This is for \"\n                   \"exporting the model for use in external applications. Inference generated \"\n                   \"models cannot be used within Faceswap. See the 'format' option for specifying \"\n                   \"the model output format.\"\n                   \"\\nL|'nan-scan' - Scan the model file for NaNs or Infs (invalid data).\"\n                   \"\\nL|'restore' - Restore a model from backup.\")))\n        argument_list.append(dict(\n            opts=(\"-f\", \"--format\"),\n            action=Radio,\n            type=str,\n            choices=(\"h5\", \"saved-model\"),\n            default=\"h5\",\n            group=_(\"inference\"),\n            help=_(\"R|The format to save the model as. Note: Only used for 'inference' job.\"\n                   \"\\nL|'h5' - Standard Keras H5 format. Does not store any custom layer \"\n                   \"information. Layers will need to be loaded from Faceswap to use.\"\n                   \"\\nL|'saved-model' - Tensorflow's Saved Model format. Contains all information \"\n                   \"required to load the model outside of Faceswap.\")))\n        argument_list.append(dict(\n            opts=(\"-s\", \"--swap-model\"),\n            action=\"store_true\",\n            dest=\"swap_model\",\n            default=False,\n            group=_(\"inference\"),\n            help=_(\"Only used for 'inference' job. Generate the inference model for B -> A \"\n                   \"instead of A -> B.\")))\n        return argument_list",
    "smell": []
}
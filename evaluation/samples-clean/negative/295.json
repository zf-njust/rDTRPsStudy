{
    "code": "def main(unused_argv=None):\n  with tf.Graph().as_default():\n    # Force all input processing onto CPU in order to reserve the GPU for the\n    # forward inference and back-propagation.\n    device = '/cpu:0' if not FLAGS.ps_tasks else '/job:worker/cpu:0'\n    with tf.device(tf.train.replica_device_setter(FLAGS.ps_tasks,\n                                                  worker_device=device)):\n      inputs, _ = image_utils.imagenet_inputs(FLAGS.batch_size,\n                                              FLAGS.image_size)\n      # Load style images and select one at random (for each graph execution, a\n      # new random selection occurs)\n      _, style_labels, style_gram_matrices = image_utils.style_image_inputs(\n          os.path.expanduser(FLAGS.style_dataset_file),\n          batch_size=FLAGS.batch_size, image_size=FLAGS.image_size,\n          square_crop=True, shuffle=True)\n\n    with tf.device(tf.train.replica_device_setter(FLAGS.ps_tasks)):\n      # Process style and weight flags\n      num_styles = FLAGS.num_styles\n      if FLAGS.style_coefficients is None:\n        style_coefficients = [1.0 for _ in range(num_styles)]\n      else:\n        style_coefficients = ast.literal_eval(FLAGS.style_coefficients)\n      if len(style_coefficients) != num_styles:\n        raise ValueError(\n            'number of style coefficients differs from number of styles')\n      content_weights = ast.literal_eval(FLAGS.content_weights)\n      style_weights = ast.literal_eval(FLAGS.style_weights)\n\n      # Rescale style weights dynamically based on the current style image\n      style_coefficient = tf.gather(\n          tf.constant(style_coefficients), style_labels)\n      style_weights = dict((key, style_coefficient * value)\n                           for key, value in style_weights.items())\n\n      # Define the model\n      stylized_inputs = model.transform(\n          inputs,\n          alpha=FLAGS.alpha,\n          normalizer_params={\n              'labels': style_labels,\n              'num_categories': num_styles,\n              'center': True,\n              'scale': True\n          })\n\n      # Compute losses.\n      total_loss, loss_dict = learning.total_loss(\n          inputs, stylized_inputs, style_gram_matrices, content_weights,\n          style_weights)\n      for key, value in loss_dict.items():\n        tf.summary.scalar(key, value)\n\n      instance_norm_vars = [var for var in slim.get_variables('transformer')\n                            if 'InstanceNorm' in var.name]\n      other_vars = [var for var in slim.get_variables('transformer')\n                    if 'InstanceNorm' not in var.name]\n\n      # Function to restore VGG16 parameters.\n      init_fn_vgg = slim.assign_from_checkpoint_fn(vgg.checkpoint_file(),\n                                                   slim.get_variables('vgg_16'))\n\n      # Function to restore N-styles parameters.\n      init_fn_n_styles = slim.assign_from_checkpoint_fn(\n          os.path.expanduser(FLAGS.checkpoint), other_vars)\n\n      def init_fn(session):\n        init_fn_vgg(session)\n        init_fn_n_styles(session)\n\n      # Set up training.\n      optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)\n      train_op = slim.learning.create_train_op(\n          total_loss, optimizer, clip_gradient_norm=FLAGS.clip_gradient_norm,\n          variables_to_train=instance_norm_vars, summarize_gradients=False)\n\n      # Run training.\n      slim.learning.train(\n          train_op=train_op,\n          logdir=os.path.expanduser(FLAGS.train_dir),\n          master=FLAGS.master,\n          is_chief=FLAGS.task == 0,\n          number_of_steps=FLAGS.train_steps,\n          init_fn=init_fn,\n          save_summaries_secs=FLAGS.save_summaries_secs,\n          save_interval_secs=FLAGS.save_interval_secs)",
    "smell": []
}
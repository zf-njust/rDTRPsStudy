{
    "code": "def __init__(\n      self,\n      filters: int,\n      kernel_size: Union[int, Sequence[int]],\n      strides: Union[int, Sequence[int]] = 1,\n      depthwise: bool = False,\n      causal: bool = False,\n      use_bias: bool = False,\n      kernel_initializer: tf.keras.initializers.Initializer = 'HeNormal',\n      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] =\n      tf.keras.regularizers.L2(KERNEL_WEIGHT_DECAY),\n      use_batch_norm: bool = True,\n      batch_norm_layer: tf.keras.layers.Layer =\n      tf.keras.layers.BatchNormalization,\n      batch_norm_momentum: float = 0.99,\n      batch_norm_epsilon: float = 1e-3,\n      use_sync_bn: bool = False,\n      activation: Optional[Any] = None,\n      conv_type: str = '3d',\n      use_buffered_input: bool = False,  # pytype: disable=annotation-type-mismatch  # typed-keras\n      **kwargs):\n    \"\"\"Initializes a conv block.\n\n    Args:\n      filters: filters for the conv operation.\n      kernel_size: kernel size for the conv operation.\n      strides: strides for the conv operation.\n      depthwise: if True, use DepthwiseConv2D instead of Conv2D\n      causal: if True, use causal mode for the conv operation.\n      use_bias: use bias for the conv operation.\n      kernel_initializer: kernel initializer for the conv operation.\n      kernel_regularizer: kernel regularizer for the conv operation.\n      use_batch_norm: if True, apply batch norm after the conv operation.\n      batch_norm_layer: class to use for batch norm, if applied.\n      batch_norm_momentum: momentum of the batch norm operation, if applied.\n      batch_norm_epsilon: epsilon of the batch norm operation, if applied.\n      use_sync_bn: if True, use synchronized batch normalization.\n      activation: activation after the conv and batch norm operations.\n      conv_type: '3d', '2plus1d', or '3d_2plus1d'. '3d' uses the default 3D\n          ops. '2plus1d' split any 3D ops into two sequential 2D ops with their\n          own batch norm and activation. '3d_2plus1d' is like '2plus1d', but\n          uses two sequential 3D ops instead.\n      use_buffered_input: if True, the input is expected to be padded\n          beforehand. In effect, calling this layer will use 'valid' padding on\n          the temporal dimension to simulate 'causal' padding.\n      **kwargs: keyword arguments to be passed to this layer.\n\n    Returns:\n      A output tensor of the ConvBlock operation.\n    \"\"\"\n\n    super(ConvBlock, self).__init__(**kwargs)\n\n    kernel_size = normalize_tuple(kernel_size, 3, 'kernel_size')\n    strides = normalize_tuple(strides, 3, 'strides')\n\n    self._filters = filters\n    self._kernel_size = kernel_size\n    self._strides = strides\n    self._depthwise = depthwise\n    self._causal = causal\n    self._use_bias = use_bias\n    self._kernel_initializer = kernel_initializer\n    self._kernel_regularizer = kernel_regularizer\n    self._use_batch_norm = use_batch_norm\n    self._batch_norm_layer = batch_norm_layer\n    self._batch_norm_momentum = batch_norm_momentum\n    self._batch_norm_epsilon = batch_norm_epsilon\n    self._use_sync_bn = use_sync_bn\n    self._activation = activation\n    self._conv_type = conv_type\n    self._use_buffered_input = use_buffered_input\n\n    if activation is not None:\n      self._activation_layer = tf_utils.get_activation(\n          activation, use_keras_layer=True)\n    else:\n      self._activation_layer = None\n\n    self._groups = None",
    "smell": []
}
{
    "code": "def main(unused_argv):\n  if not tf.gfile.IsDirectory(FLAGS.train_dir):\n    tf.gfile.MakeDirs(FLAGS.train_dir)\n\n  cfg, cfg_summary = get_named_config(FLAGS.model_cfg,\n                                      FLAGS.model_cfg_overrides)\n  with tf.gfile.Open(os.path.join(FLAGS.train_dir, \"cfg.txt\"), \"w\") as f:\n    f.write(cfg_summary)\n\n  # Load data\n  with tf.name_scope(\"loader\"):\n    feat_dict = load_noteseqs(\n        FLAGS.dataset_fp,\n        cfg.train_batch_size,\n        cfg.train_seq_len,\n        max_discrete_times=cfg.data_max_discrete_times,\n        max_discrete_velocities=cfg.data_max_discrete_velocities,\n        augment_stretch_bounds=cfg.train_augment_stretch_bounds,\n        augment_transpose_bounds=cfg.train_augment_transpose_bounds,\n        randomize_chord_order=cfg.data_randomize_chord_order,\n        repeat=True)\n\n  # Summarize data\n  tf.summary.image(\n      \"piano_roll\",\n      util.discrete_to_piano_roll(util.demidify(feat_dict[\"midi_pitches\"]), 88))\n\n  # Build model\n  with tf.variable_scope(\"phero_model\"):\n    model_dict = build_genie_model(\n        feat_dict,\n        cfg,\n        cfg.train_batch_size,\n        cfg.train_seq_len,\n        is_training=True)\n\n  # Summarize quantized step embeddings\n  if cfg.stp_emb_vq:\n    tf.summary.scalar(\"codebook_perplexity\",\n                      model_dict[\"stp_emb_vq_codebook_ppl\"])\n    tf.summary.image(\n        \"genie\",\n        util.discrete_to_piano_roll(\n            model_dict[\"stp_emb_vq_discrete\"],\n            cfg.stp_emb_vq_codebook_size,\n            dilation=max(1, 88 // cfg.stp_emb_vq_codebook_size)))\n    tf.summary.scalar(\"loss_vqvae\", model_dict[\"stp_emb_vq_loss\"])\n\n  # Summarize integer-quantized step embeddings\n  if cfg.stp_emb_iq:\n    tf.summary.scalar(\"discrete_perplexity\",\n                      model_dict[\"stp_emb_iq_discrete_ppl\"])\n    tf.summary.scalar(\"iq_valid_p\", model_dict[\"stp_emb_iq_valid_p\"])\n    tf.summary.image(\n        \"genie\",\n        util.discrete_to_piano_roll(\n            model_dict[\"stp_emb_iq_discrete\"],\n            cfg.stp_emb_iq_nbins,\n            dilation=max(1, 88 // cfg.stp_emb_iq_nbins)))\n    tf.summary.scalar(\"loss_iq_range\", model_dict[\"stp_emb_iq_range_penalty\"])\n    tf.summary.scalar(\"loss_iq_contour\",\n                      model_dict[\"stp_emb_iq_contour_penalty\"])\n    tf.summary.scalar(\"loss_iq_deviate\",\n                      model_dict[\"stp_emb_iq_deviate_penalty\"])\n\n  if cfg.stp_emb_vq or cfg.stp_emb_iq:\n    tf.summary.scalar(\"contour_violation\", model_dict[\"contour_violation\"])\n    tf.summary.scalar(\"deviate_violation\", model_dict[\"deviate_violation\"])\n\n  # Summarize VAE sequence embeddings\n  if cfg.seq_emb_vae:\n    tf.summary.scalar(\"loss_kl\", model_dict[\"seq_emb_vae_kl\"])\n\n  # Summarize output\n  tf.summary.image(\n      \"decoder_scores\",\n      util.discrete_to_piano_roll(model_dict[\"dec_recons_scores\"], 88))\n  tf.summary.image(\n      \"decoder_preds\",\n      util.discrete_to_piano_roll(model_dict[\"dec_recons_preds\"], 88))\n  if cfg.dec_pred_velocity:\n    tf.summary.scalar(\"loss_recons_velocity\",\n                      model_dict[\"dec_recons_velocity_loss\"])\n    tf.summary.scalar(\"ppl_recons_velocity\",\n                      tf.exp(model_dict[\"dec_recons_velocity_loss\"]))\n\n  # Reconstruction loss\n  tf.summary.scalar(\"loss_recons\", model_dict[\"dec_recons_loss\"])\n  tf.summary.scalar(\"ppl_recons\", tf.exp(model_dict[\"dec_recons_loss\"]))\n\n  # Build hybrid loss\n  loss = model_dict[\"dec_recons_loss\"]\n  if cfg.stp_emb_vq and cfg.train_loss_vq_err_scalar > 0:\n    loss += (cfg.train_loss_vq_err_scalar * model_dict[\"stp_emb_vq_loss\"])\n  if cfg.stp_emb_iq and cfg.train_loss_iq_range_scalar > 0:\n    loss += (\n        cfg.train_loss_iq_range_scalar * model_dict[\"stp_emb_iq_range_penalty\"])\n  if cfg.stp_emb_iq and cfg.train_loss_iq_contour_scalar > 0:\n    loss += (\n        cfg.train_loss_iq_contour_scalar *\n        model_dict[\"stp_emb_iq_contour_penalty\"])\n  if cfg.stp_emb_iq and cfg.train_loss_iq_deviate_scalar > 0:\n    loss += (\n        cfg.train_loss_iq_deviate_scalar *\n        model_dict[\"stp_emb_iq_deviate_penalty\"])\n  if cfg.seq_emb_vae and cfg.train_loss_vae_kl_scalar > 0:\n    loss += (cfg.train_loss_vae_kl_scalar * model_dict[\"seq_emb_vae_kl\"])\n  if cfg.dec_pred_velocity:\n    loss += model_dict[\"dec_recons_velocity_loss\"]\n  tf.summary.scalar(\"loss\", loss)\n\n  # Construct optimizer\n  opt = tf.train.AdamOptimizer(learning_rate=cfg.train_lr)\n  train_op = opt.minimize(\n      loss, global_step=tf.train.get_or_create_global_step())\n\n  # Train\n  with tf.train.MonitoredTrainingSession(\n      checkpoint_dir=FLAGS.train_dir,\n      save_checkpoint_secs=600,\n      save_summaries_secs=FLAGS.summary_every_nsecs) as sess:\n    while True:\n      sess.run(train_op)",
    "smell": []
}
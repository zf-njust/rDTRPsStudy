{
    "code": "def get_best_anchor(y_true,\n                    anchors,\n                    stride,\n                    width=1,\n                    height=1,\n                    iou_thresh=0.25,\n                    best_match_only=False,\n                    use_tie_breaker=True):\n  \"\"\"Get the correct anchor that is assoiciated with each box using IOU.\n\n  Args:\n    y_true: tf.Tensor[] for the list of bounding boxes in the yolo format.\n    anchors: list or tensor for the anchor boxes to be used in prediction found\n      via Kmeans.\n    stride: `int` stride for the anchors.\n    width: int for the image width.\n    height: int for the image height.\n    iou_thresh: `float` the minimum iou threshold to use for selecting boxes for\n      each level.\n    best_match_only: `bool` if the box only has one match and it is less than\n      the iou threshold, when set to True, this match will be dropped as no\n      anchors can be linked to it.\n    use_tie_breaker: `bool` if there is many anchors for a given box, then\n      attempt to use all of them, if False, only the first matching box will be\n      used.\n  Returns:\n    tf.Tensor: y_true with the anchor associated with each ground truth box\n      known\n  \"\"\"\n  with tf.name_scope('get_best_anchor'):\n    width = tf.cast(width, dtype=tf.float32)\n    height = tf.cast(height, dtype=tf.float32)\n    scaler = tf.convert_to_tensor([width, height])\n\n    # scale to levels houts width and height\n    true_wh = tf.cast(y_true[..., 2:4], dtype=tf.float32) * scaler\n\n    # scale down from large anchor to small anchor type\n    anchors = tf.cast(anchors, dtype=tf.float32) / stride\n\n    k = tf.shape(anchors)[0]\n\n    anchors = tf.concat([tf.zeros_like(anchors), anchors], axis=-1)\n    truth_comp = tf.concat([tf.zeros_like(true_wh), true_wh], axis=-1)\n\n    if iou_thresh >= 1.0:\n      anchors = tf.expand_dims(anchors, axis=-2)\n      truth_comp = tf.expand_dims(truth_comp, axis=-3)\n\n      aspect = truth_comp[..., 2:4] / anchors[..., 2:4]\n      aspect = tf.where(tf.math.is_nan(aspect), tf.zeros_like(aspect), aspect)\n      aspect = tf.maximum(aspect, 1 / aspect)\n      aspect = tf.where(tf.math.is_nan(aspect), tf.zeros_like(aspect), aspect)\n      aspect = tf.reduce_max(aspect, axis=-1)\n\n      values, indexes = tf.math.top_k(\n          tf.transpose(-aspect, perm=[1, 0]),\n          k=tf.cast(k, dtype=tf.int32),\n          sorted=True)\n      values = -values\n      ind_mask = tf.cast(values < iou_thresh, dtype=indexes.dtype)\n    else:\n      truth_comp = box_ops.xcycwh_to_yxyx(truth_comp)\n      anchors = box_ops.xcycwh_to_yxyx(anchors)\n      iou_raw = box_ops.aggregated_comparitive_iou(\n          truth_comp,\n          anchors,\n          iou_type=3,\n      )\n      values, indexes = tf.math.top_k(\n          iou_raw, k=tf.cast(k, dtype=tf.int32), sorted=True)\n      ind_mask = tf.cast(values >= iou_thresh, dtype=indexes.dtype)\n\n    # pad the indexs such that all values less than the thresh are -1\n    # add one, multiply the mask to zeros all the bad locations\n    # subtract 1 makeing all the bad locations 0.\n    if best_match_only:\n      iou_index = ((indexes[..., 0:] + 1) * ind_mask[..., 0:]) - 1\n    elif use_tie_breaker:\n      iou_index = tf.concat([\n          tf.expand_dims(indexes[..., 0], axis=-1),\n          ((indexes[..., 1:] + 1) * ind_mask[..., 1:]) - 1\n      ],\n                            axis=-1)\n    else:\n      iou_index = tf.concat([\n          tf.expand_dims(indexes[..., 0], axis=-1),\n          tf.zeros_like(indexes[..., 1:]) - 1\n      ],\n                            axis=-1)\n\n  return tf.cast(iou_index, dtype=tf.float32), tf.cast(values, dtype=tf.float32)",
    "smell": []
}
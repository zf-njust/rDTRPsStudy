{
    "code": "def _convert_single_example(example, max_seq_length, tokenizer):\n  \"\"\"Converts an `InputExample` instance to a `tf.train.Example` instance.\"\"\"\n  tokens = [\"[CLS]\"]\n  tokens.extend(example.words)\n  tokens.append(\"[SEP]\")\n  input_ids = tokenizer.convert_tokens_to_ids(tokens)\n  label_ids = [_PADDING_LABEL_ID]\n  label_ids.extend(example.label_ids)\n  label_ids.append(_PADDING_LABEL_ID)\n\n  segment_ids = [0] * len(input_ids)\n  input_mask = [1] * len(input_ids)\n\n  # Pad up to the sequence length.\n  while len(input_ids) < max_seq_length:\n    input_ids.append(0)\n    input_mask.append(0)\n    segment_ids.append(0)\n    label_ids.append(_PADDING_LABEL_ID)\n\n  def create_int_feature(values):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n\n  features = collections.OrderedDict()\n  features[\"input_ids\"] = create_int_feature(input_ids)\n  features[\"input_mask\"] = create_int_feature(input_mask)\n  features[\"segment_ids\"] = create_int_feature(segment_ids)\n  features[\"label_ids\"] = create_int_feature(label_ids)\n  features[\"sentence_id\"] = create_int_feature([example.sentence_id])\n  features[\"sub_sentence_id\"] = create_int_feature([example.sub_sentence_id])\n\n  tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n  return tf_example",
    "smell": []
}
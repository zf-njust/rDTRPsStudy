{
    "code": "def get_norm(norm, out_channels):\n    \"\"\"\n    Args:\n        norm (str or callable): either one of BN, SyncBN, FrozenBN, GN;\n            or a callable that takes a channel number and returns\n            the normalization layer as a nn.Module.\n\n    Returns:\n        nn.Module or None: the normalization layer\n    \"\"\"\n    if norm is None:\n        return None\n    if isinstance(norm, str):\n        if len(norm) == 0:\n            return None\n        norm = {\n            \"BN\": BatchNorm2d,\n            # Fixed in https://github.com/pytorch/pytorch/pull/36382\n            \"SyncBN\": NaiveSyncBatchNorm if env.TORCH_VERSION <= (1, 5) else nn.SyncBatchNorm,\n            \"FrozenBN\": FrozenBatchNorm2d,\n            \"GN\": lambda channels: nn.GroupNorm(32, channels),\n            # for debugging:\n            \"nnSyncBN\": nn.SyncBatchNorm,\n            \"naiveSyncBN\": NaiveSyncBatchNorm,\n            # expose stats_mode N as an option to caller, required for zero-len inputs\n            \"naiveSyncBN_N\": lambda channels: NaiveSyncBatchNorm(channels, stats_mode=\"N\"),\n            \"LN\": lambda channels: LayerNorm(channels),\n        }[norm]\n    return norm(out_channels)",
    "smell": []
}
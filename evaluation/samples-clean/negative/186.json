{
    "code": "def main(_):\n  assert FLAGS.train_dir, '`train_dir` is missing.'\n  if FLAGS.task == 0:\n    tf.gfile.MakeDirs(FLAGS.train_dir)\n  if FLAGS.pipeline_config_path:\n    configs = config_util.get_configs_from_pipeline_file(\n        FLAGS.pipeline_config_path)\n    if FLAGS.task == 0:\n      tf.gfile.Copy(\n          FLAGS.pipeline_config_path,\n          os.path.join(FLAGS.train_dir, 'pipeline.config'),\n          overwrite=True)\n  else:\n    configs = config_util.get_configs_from_multiple_files(\n        model_config_path=FLAGS.model_config_path,\n        train_config_path=FLAGS.train_config_path,\n        train_input_config_path=FLAGS.input_config_path)\n    if FLAGS.task == 0:\n      for name, config in [('model.config', FLAGS.model_config_path),\n                           ('train.config', FLAGS.train_config_path),\n                           ('input.config', FLAGS.input_config_path)]:\n        tf.gfile.Copy(\n            config, os.path.join(FLAGS.train_dir, name), overwrite=True)\n\n  model_config = configs['model']\n  lstm_config = configs['lstm_model']\n  train_config = configs['train_config']\n  input_config = configs['train_input_config']\n\n  model_fn = functools.partial(\n      model_builder.build,\n      model_config=model_config,\n      lstm_config=lstm_config,\n      is_training=True)\n\n  def get_next(config, model_config, lstm_config, unroll_length):\n    data_augmentation_options = [\n        preprocessor_builder.build(step)\n        for step in train_config.data_augmentation_options\n    ]\n    return seq_dataset_builder.build(\n        config,\n        model_config,\n        lstm_config,\n        unroll_length,\n        data_augmentation_options,\n        batch_size=train_config.batch_size)\n\n  create_input_dict_fn = functools.partial(get_next, input_config, model_config,\n                                           lstm_config,\n                                           lstm_config.train_unroll_length)\n\n  env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n  cluster_data = env.get('cluster', None)\n  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n  task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n  task_info = type('TaskSpec', (object,), task_data)\n\n  # Parameters for a single worker.\n  ps_tasks = 0\n  worker_replicas = 1\n  worker_job_name = 'lonely_worker'\n  task = 0\n  is_chief = True\n  master = ''\n\n  if cluster_data and 'worker' in cluster_data:\n    # Number of total worker replicas include \"worker\"s and the \"master\".\n    worker_replicas = len(cluster_data['worker']) + 1\n  if cluster_data and 'ps' in cluster_data:\n    ps_tasks = len(cluster_data['ps'])\n\n  if worker_replicas > 1 and ps_tasks < 1:\n    raise ValueError('At least 1 ps task is needed for distributed training.')\n\n  if worker_replicas >= 1 and ps_tasks > 0:\n    # Set up distributed training.\n    server = tf.train.Server(\n        tf.train.ClusterSpec(cluster),\n        protocol='grpc',\n        job_name=task_info.type,\n        task_index=task_info.index)\n    if task_info.type == 'ps':\n      server.join()\n      return\n\n    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n    task = task_info.index\n    is_chief = (task_info.type == 'master')\n    master = server.target\n\n  trainer.train(create_input_dict_fn, model_fn, train_config, master, task,\n                FLAGS.num_clones, worker_replicas, FLAGS.clone_on_cpu, ps_tasks,\n                worker_job_name, is_chief, FLAGS.train_dir)",
    "smell": []
}
{
    "code": "def _runif_reasons(\n    *,\n    min_cuda_gpus: int = 0,\n    min_torch: Optional[str] = None,\n    max_torch: Optional[str] = None,\n    min_python: Optional[str] = None,\n    bf16_cuda: bool = False,\n    tpu: bool = False,\n    mps: Optional[bool] = None,\n    skip_windows: bool = False,\n    standalone: bool = False,\n    deepspeed: bool = False,\n    dynamo: bool = False,\n) -> Tuple[List[str], Dict[str, bool]]:\n    \"\"\"Construct reasons for pytest skipif.\n\n    Args:\n        min_cuda_gpus: Require this number of gpus and that the ``PL_RUN_CUDA_TESTS=1`` environment variable is set.\n        min_torch: Require that PyTorch is greater or equal than this version.\n        max_torch: Require that PyTorch is less than this version.\n        min_python: Require that Python is greater or equal than this version.\n        bf16_cuda: Require that CUDA device supports bf16.\n        tpu: Require that TPU is available.\n        mps: If True: Require that MPS (Apple Silicon) is available,\n            if False: Explicitly Require that MPS is not available\n        skip_windows: Skip for Windows platform.\n        standalone: Mark the test as standalone, our CI will run it in a separate process.\n            This requires that the ``PL_RUN_STANDALONE_TESTS=1`` environment variable is set.\n        deepspeed: Require that microsoft/DeepSpeed is installed.\n        dynamo: Require that `torch.dynamo` is supported.\n    \"\"\"\n    reasons = []\n    kwargs = {}  # used in conftest.py::pytest_collection_modifyitems\n\n    if min_cuda_gpus:\n        if num_cuda_devices() < min_cuda_gpus:\n            reasons.append(f\"GPUs>={min_cuda_gpus}\")\n        kwargs[\"min_cuda_gpus\"] = True\n\n    # set use_base_version for nightly support\n    if min_torch and compare_version(\"torch\", operator.lt, min_torch, use_base_version=True):\n        reasons.append(f\"torch>={min_torch}, {torch.__version__} installed\")\n\n    # set use_base_version for nightly support\n    if max_torch and compare_version(\"torch\", operator.ge, max_torch, use_base_version=True):\n        reasons.append(f\"torch<{max_torch}, {torch.__version__} installed\")\n\n    if min_python:\n        py_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n        if Version(py_version) < Version(min_python):\n            reasons.append(f\"python>={min_python}\")\n\n    if bf16_cuda:\n        try:\n            cond = not (torch.cuda.is_available() and torch.cuda.is_bf16_supported())\n        except (AssertionError, RuntimeError) as ex:\n            # AssertionError: Torch not compiled with CUDA enabled\n            # RuntimeError: Found no NVIDIA driver on your system.\n            is_unrelated = \"Found no NVIDIA driver\" not in str(ex) or \"Torch not compiled with CUDA\" not in str(ex)\n            if is_unrelated:\n                raise ex\n            cond = True\n        if cond:\n            reasons.append(\"CUDA device bf16\")\n\n    if skip_windows and sys.platform == \"win32\":\n        reasons.append(\"unimplemented on Windows\")\n\n    if tpu:\n        if not XLAAccelerator.is_available():\n            reasons.append(\"TPU\")\n        kwargs[\"tpu\"] = True\n\n    if mps is not None:\n        if mps and not MPSAccelerator.is_available():\n            reasons.append(\"MPS\")\n        elif not mps and MPSAccelerator.is_available():\n            reasons.append(\"not MPS\")\n\n    if standalone:\n        if os.getenv(\"PL_RUN_STANDALONE_TESTS\", \"0\") != \"1\":\n            reasons.append(\"Standalone execution\")\n        kwargs[\"standalone\"] = True\n\n    if deepspeed and not _DEEPSPEED_AVAILABLE:\n        reasons.append(\"Deepspeed\")\n\n    if dynamo:\n        if _TORCH_GREATER_EQUAL_2_1:\n            from torch._dynamo.eval_frame import is_dynamo_supported\n\n            cond = not is_dynamo_supported()\n        else:\n            cond = sys.platform == \"win32\" or sys.version_info >= (3, 11)\n        # set use_base_version for nightly support\n        cond |= compare_version(\"torch\", operator.lt, \"2.0.0\", use_base_version=True)\n        if cond:\n            reasons.append(\"torch.dynamo\")\n\n    return reasons, kwargs",
    "smell": []
}
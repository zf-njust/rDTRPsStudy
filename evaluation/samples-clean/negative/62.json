{
    "code": "def on_train_start(self, trainer: \"pl.Trainer\", *args: Any, **kwargs: Any) -> None:\n        \"\"\"Called before training, determines unique names for all lr schedulers in the case of multiple of the\n        same type or in the case of multiple parameter groups.\n\n        Raises:\n            MisconfigurationException:\n                If ``Trainer`` has no ``logger``.\n        \"\"\"\n        if not trainer.loggers:\n            raise MisconfigurationException(\n                \"Cannot use `LearningRateMonitor` callback with `Trainer` that has no logger.\"\n            )\n\n        if self.log_momentum:\n\n            def _check_no_key(key: str) -> bool:\n                if trainer.lr_scheduler_configs:\n                    return any(\n                        key not in config.scheduler.optimizer.defaults for config in trainer.lr_scheduler_configs\n                    )\n\n                return any(key not in optimizer.defaults for optimizer in trainer.optimizers)\n\n            if _check_no_key(\"momentum\") and _check_no_key(\"betas\"):\n                rank_zero_warn(\n                    \"You have set log_momentum=True, but some optimizers do not\"\n                    \" have momentum. This will log a value 0 for the momentum.\",\n                    category=RuntimeWarning,\n                )\n\n        # Find names for schedulers\n        names: List[List[str]] = []\n        (\n            sched_hparam_keys,\n            optimizers_with_scheduler,\n            optimizers_with_scheduler_types,\n        ) = self._find_names_from_schedulers(trainer.lr_scheduler_configs)\n        names.extend(sched_hparam_keys)\n\n        # Find names for leftover optimizers\n        optimizer_hparam_keys, _ = self._find_names_from_optimizers(\n            trainer.optimizers,\n            seen_optimizers=optimizers_with_scheduler,\n            seen_optimizer_types=optimizers_with_scheduler_types,\n        )\n        names.extend(optimizer_hparam_keys)\n\n        # Initialize for storing values\n        names_flatten = list(itertools.chain.from_iterable(names))\n        self.lrs = {name: [] for name in names_flatten}\n        self.last_momentum_values = {name + \"-momentum\": None for name in names_flatten}",
    "smell": []
}
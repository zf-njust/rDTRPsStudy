{
    "code": "def on_initialize(self):\n        device_config = nn.getCurrentDeviceConfig()\n        devices = device_config.devices\n        self.model_data_format = \"NCHW\" if len(devices) != 0 and not self.is_debug() else \"NHWC\"\n        nn.initialize(data_format=self.model_data_format)\n        tf = nn.tf\n\n        resolution = self.resolution = 96\n        self.face_type = FaceType.FULL\n        ae_dims = 128\n        e_dims = 64\n        d_dims = 64\n        d_mask_dims = 16\n        self.pretrain = False\n        self.pretrain_just_disabled = False\n\n        masked_training = True\n\n        models_opt_on_gpu = len(devices) >= 1 and all([dev.total_mem_gb >= 4 for dev in devices])\n        models_opt_device = nn.tf_default_device_name if models_opt_on_gpu and self.is_training else '/CPU:0'\n        optimizer_vars_on_cpu = models_opt_device=='/CPU:0'\n\n        input_ch = 3\n        bgr_shape = nn.get4Dshape(resolution,resolution,input_ch)\n        mask_shape = nn.get4Dshape(resolution,resolution,1)\n\n        self.model_filename_list = []\n        \n        model_archi = nn.DeepFakeArchi(resolution, opts='ud')\n\n        with tf.device ('/CPU:0'):\n            #Place holders on CPU\n            self.warped_src = tf.placeholder (nn.floatx, bgr_shape)\n            self.warped_dst = tf.placeholder (nn.floatx, bgr_shape)\n\n            self.target_src = tf.placeholder (nn.floatx, bgr_shape)\n            self.target_dst = tf.placeholder (nn.floatx, bgr_shape)\n\n            self.target_srcm = tf.placeholder (nn.floatx, mask_shape)\n            self.target_dstm = tf.placeholder (nn.floatx, mask_shape)\n\n        # Initializing model classes\n        with tf.device (models_opt_device):\n            self.encoder = model_archi.Encoder(in_ch=input_ch, e_ch=e_dims, name='encoder')\n            encoder_out_ch = self.encoder.get_out_ch()*self.encoder.get_out_res(resolution)**2\n\n            self.inter = model_archi.Inter (in_ch=encoder_out_ch, ae_ch=ae_dims, ae_out_ch=ae_dims, name='inter')\n            inter_out_ch = self.inter.get_out_ch()\n\n            self.decoder_src = model_archi.Decoder(in_ch=inter_out_ch, d_ch=d_dims, d_mask_ch=d_mask_dims, name='decoder_src')\n            self.decoder_dst = model_archi.Decoder(in_ch=inter_out_ch, d_ch=d_dims, d_mask_ch=d_mask_dims, name='decoder_dst')\n\n            self.model_filename_list += [ [self.encoder,     'encoder.npy'    ],\n                                          [self.inter,       'inter.npy'      ],\n                                          [self.decoder_src, 'decoder_src.npy'],\n                                          [self.decoder_dst, 'decoder_dst.npy']  ]\n\n            if self.is_training:\n                self.src_dst_trainable_weights = self.encoder.get_weights() + self.inter.get_weights() + self.decoder_src.get_weights() + self.decoder_dst.get_weights()\n\n                # Initialize optimizers\n                self.src_dst_opt = nn.RMSprop(lr=2e-4, lr_dropout=0.3, name='src_dst_opt')\n                self.src_dst_opt.initialize_variables(self.src_dst_trainable_weights, vars_on_cpu=optimizer_vars_on_cpu )\n                self.model_filename_list += [ (self.src_dst_opt, 'src_dst_opt.npy') ]\n\n        if self.is_training:\n            # Adjust batch size for multiple GPU\n            gpu_count = max(1, len(devices) )\n            bs_per_gpu = max(1, 4 // gpu_count)\n            self.set_batch_size( gpu_count*bs_per_gpu)\n\n            # Compute losses per GPU\n            gpu_pred_src_src_list = []\n            gpu_pred_dst_dst_list = []\n            gpu_pred_src_dst_list = []\n            gpu_pred_src_srcm_list = []\n            gpu_pred_dst_dstm_list = []\n            gpu_pred_src_dstm_list = []\n\n            gpu_src_losses = []\n            gpu_dst_losses = []\n            gpu_src_dst_loss_gvs = []\n            \n            for gpu_id in range(gpu_count):\n                with tf.device( f'/{devices[gpu_id].tf_dev_type}:{gpu_id}' if len(devices) != 0 else f'/CPU:0' ):\n                    batch_slice = slice( gpu_id*bs_per_gpu, (gpu_id+1)*bs_per_gpu )\n                    with tf.device(f'/CPU:0'):\n                        # slice on CPU, otherwise all batch data will be transfered to GPU first\n                        gpu_warped_src   = self.warped_src [batch_slice,:,:,:]\n                        gpu_warped_dst   = self.warped_dst [batch_slice,:,:,:]\n                        gpu_target_src   = self.target_src [batch_slice,:,:,:]\n                        gpu_target_dst   = self.target_dst [batch_slice,:,:,:]\n                        gpu_target_srcm  = self.target_srcm[batch_slice,:,:,:]\n                        gpu_target_dstm  = self.target_dstm[batch_slice,:,:,:]\n\n                    # process model tensors\n                    gpu_src_code     = self.inter(self.encoder(gpu_warped_src))\n                    gpu_dst_code     = self.inter(self.encoder(gpu_warped_dst))\n                    gpu_pred_src_src, gpu_pred_src_srcm = self.decoder_src(gpu_src_code)\n                    gpu_pred_dst_dst, gpu_pred_dst_dstm = self.decoder_dst(gpu_dst_code)\n                    gpu_pred_src_dst, gpu_pred_src_dstm = self.decoder_src(gpu_dst_code)\n\n                    gpu_pred_src_src_list.append(gpu_pred_src_src)\n                    gpu_pred_dst_dst_list.append(gpu_pred_dst_dst)\n                    gpu_pred_src_dst_list.append(gpu_pred_src_dst)\n\n                    gpu_pred_src_srcm_list.append(gpu_pred_src_srcm)\n                    gpu_pred_dst_dstm_list.append(gpu_pred_dst_dstm)\n                    gpu_pred_src_dstm_list.append(gpu_pred_src_dstm)\n\n                    gpu_target_srcm_blur = nn.gaussian_blur(gpu_target_srcm,  max(1, resolution // 32) )\n                    gpu_target_dstm_blur = nn.gaussian_blur(gpu_target_dstm,  max(1, resolution // 32) )\n\n                    gpu_target_dst_masked      = gpu_target_dst*gpu_target_dstm_blur\n                    gpu_target_dst_anti_masked = gpu_target_dst*(1.0 - gpu_target_dstm_blur)\n\n                    gpu_target_src_masked_opt  = gpu_target_src*gpu_target_srcm_blur if masked_training else gpu_target_src\n                    gpu_target_dst_masked_opt = gpu_target_dst_masked if masked_training else gpu_target_dst\n\n                    gpu_pred_src_src_masked_opt = gpu_pred_src_src*gpu_target_srcm_blur if masked_training else gpu_pred_src_src\n                    gpu_pred_dst_dst_masked_opt = gpu_pred_dst_dst*gpu_target_dstm_blur if masked_training else gpu_pred_dst_dst\n\n                    gpu_psd_target_dst_masked = gpu_pred_src_dst*gpu_target_dstm_blur\n                    gpu_psd_target_dst_anti_masked = gpu_pred_src_dst*(1.0 - gpu_target_dstm_blur)\n\n                    gpu_src_loss =  tf.reduce_mean ( 10*nn.dssim(gpu_target_src_masked_opt, gpu_pred_src_src_masked_opt, max_val=1.0, filter_size=int(resolution/11.6)), axis=[1])\n                    gpu_src_loss += tf.reduce_mean ( 10*tf.square ( gpu_target_src_masked_opt - gpu_pred_src_src_masked_opt ), axis=[1,2,3])\n                    gpu_src_loss += tf.reduce_mean ( 10*tf.square( gpu_target_srcm - gpu_pred_src_srcm ),axis=[1,2,3] )\n\n                    gpu_dst_loss  = tf.reduce_mean ( 10*nn.dssim(gpu_target_dst_masked_opt, gpu_pred_dst_dst_masked_opt, max_val=1.0, filter_size=int(resolution/11.6) ), axis=[1])\n                    gpu_dst_loss += tf.reduce_mean ( 10*tf.square(  gpu_target_dst_masked_opt- gpu_pred_dst_dst_masked_opt ), axis=[1,2,3])\n                    gpu_dst_loss += tf.reduce_mean ( 10*tf.square( gpu_target_dstm - gpu_pred_dst_dstm ),axis=[1,2,3] )\n\n                    gpu_src_losses += [gpu_src_loss]\n                    gpu_dst_losses += [gpu_dst_loss]\n\n                    gpu_G_loss = gpu_src_loss + gpu_dst_loss\n                    gpu_src_dst_loss_gvs += [ nn.gradients ( gpu_G_loss, self.src_dst_trainable_weights ) ]\n\n\n            # Average losses and gradients, and create optimizer update ops\n            with tf.device (models_opt_device):\n                pred_src_src  = nn.concat(gpu_pred_src_src_list, 0)\n                pred_dst_dst  = nn.concat(gpu_pred_dst_dst_list, 0)\n                pred_src_dst  = nn.concat(gpu_pred_src_dst_list, 0)\n                pred_src_srcm = nn.concat(gpu_pred_src_srcm_list, 0)\n                pred_dst_dstm = nn.concat(gpu_pred_dst_dstm_list, 0)\n                pred_src_dstm = nn.concat(gpu_pred_src_dstm_list, 0)\n\n                src_loss = nn.average_tensor_list(gpu_src_losses)\n                dst_loss = nn.average_tensor_list(gpu_dst_losses)\n                src_dst_loss_gv = nn.average_gv_list (gpu_src_dst_loss_gvs)\n                src_dst_loss_gv_op = self.src_dst_opt.get_update_op (src_dst_loss_gv)\n\n            # Initializing training and view functions\n            def src_dst_train(warped_src, target_src, target_srcm, \\\n                              warped_dst, target_dst, target_dstm):\n                s, d, _ = nn.tf_sess.run ( [ src_loss, dst_loss, src_dst_loss_gv_op],\n                                            feed_dict={self.warped_src :warped_src,\n                                                       self.target_src :target_src,\n                                                       self.target_srcm:target_srcm,\n                                                       self.warped_dst :warped_dst,\n                                                       self.target_dst :target_dst,\n                                                       self.target_dstm:target_dstm,\n                                                       })\n                s = np.mean(s)\n                d = np.mean(d)\n                return s, d\n            self.src_dst_train = src_dst_train\n\n            def AE_view(warped_src, warped_dst):\n                return nn.tf_sess.run ( [pred_src_src, pred_dst_dst, pred_dst_dstm, pred_src_dst, pred_src_dstm],\n                                            feed_dict={self.warped_src:warped_src,\n                                                    self.warped_dst:warped_dst})\n\n            self.AE_view = AE_view\n        else:\n            # Initializing merge function\n            with tf.device( nn.tf_default_device_name if len(devices) != 0 else f'/CPU:0'):\n                gpu_dst_code     = self.inter(self.encoder(self.warped_dst))\n                gpu_pred_src_dst, gpu_pred_src_dstm = self.decoder_src(gpu_dst_code)\n                _, gpu_pred_dst_dstm = self.decoder_dst(gpu_dst_code)\n\n            def AE_merge( warped_dst):\n\n                return nn.tf_sess.run ( [gpu_pred_src_dst, gpu_pred_dst_dstm, gpu_pred_src_dstm], feed_dict={self.warped_dst:warped_dst})\n\n            self.AE_merge = AE_merge\n\n        # Loading/initializing all models/optimizers weights\n        for model, filename in io.progress_bar_generator(self.model_filename_list, \"Initializing models\"):\n            if self.pretrain_just_disabled:\n                do_init = False\n                if model == self.inter:\n                    do_init = True\n            else:\n                do_init = self.is_first_run()\n\n            if not do_init:\n                do_init = not model.load_weights( self.get_strpath_storage_for_file(filename) )\n\n            if do_init and self.pretrained_model_path is not None:\n                pretrained_filepath = self.pretrained_model_path / filename\n                if pretrained_filepath.exists():\n                    do_init = not model.load_weights(pretrained_filepath)\n\n            if do_init:\n                model.init_weights()\n\n        # initializing sample generators\n        if self.is_training:\n            training_data_src_path = self.training_data_src_path if not self.pretrain else self.get_pretraining_data_path()\n            training_data_dst_path = self.training_data_dst_path if not self.pretrain else self.get_pretraining_data_path()\n\n            cpu_count = min(multiprocessing.cpu_count(), 8)\n            src_generators_count = cpu_count // 2\n            dst_generators_count = cpu_count // 2\n\n            self.set_training_data_generators ([\n                    SampleGeneratorFace(training_data_src_path, debug=self.is_debug(), batch_size=self.get_batch_size(),\n                        sample_process_options=SampleProcessor.Options(random_flip=True if self.pretrain else False),\n                        output_sample_types = [ {'sample_type': SampleProcessor.SampleType.FACE_IMAGE,'warp':True,  'transform':True, 'channel_type' : SampleProcessor.ChannelType.BGR,                                                           'face_type':self.face_type, 'data_format':nn.data_format, 'resolution': resolution},\n                                                {'sample_type': SampleProcessor.SampleType.FACE_IMAGE,'warp':False, 'transform':True, 'channel_type' : SampleProcessor.ChannelType.BGR,                                                           'face_type':self.face_type, 'data_format':nn.data_format, 'resolution': resolution},\n                                                {'sample_type': SampleProcessor.SampleType.FACE_MASK, 'warp':False, 'transform':True, 'channel_type' : SampleProcessor.ChannelType.G,   'face_mask_type' : SampleProcessor.FaceMaskType.FULL_FACE, 'face_type':self.face_type, 'data_format':nn.data_format, 'resolution': resolution}\n                                              ],\n                        generators_count=src_generators_count ),\n\n                    SampleGeneratorFace(training_data_dst_path, debug=self.is_debug(), batch_size=self.get_batch_size(),\n                        sample_process_options=SampleProcessor.Options(random_flip=True if self.pretrain else False),\n                        output_sample_types = [ {'sample_type': SampleProcessor.SampleType.FACE_IMAGE,'warp':True,  'transform':True, 'channel_type' : SampleProcessor.ChannelType.BGR,                                                           'face_type':self.face_type, 'data_format':nn.data_format, 'resolution': resolution},\n                                                {'sample_type': SampleProcessor.SampleType.FACE_IMAGE,'warp':False, 'transform':True, 'channel_type' : SampleProcessor.ChannelType.BGR,                                                           'face_type':self.face_type, 'data_format':nn.data_format, 'resolution': resolution},\n                                                {'sample_type': SampleProcessor.SampleType.FACE_MASK, 'warp':False, 'transform':True, 'channel_type' : SampleProcessor.ChannelType.G,   'face_mask_type' : SampleProcessor.FaceMaskType.FULL_FACE, 'face_type':self.face_type, 'data_format':nn.data_format, 'resolution': resolution}\n                                               ],\n                        generators_count=dst_generators_count )\n                             ])\n\n            self.last_samples = None",
    "smell": []
}
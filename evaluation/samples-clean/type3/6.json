{
  "code": "    def _copy_dir(self, source_path, destination_path, threads=DEFAULT_THREADS,\n                  start_time=None, end_time=None, part_size=DEFAULT_PART_SIZE, **kwargs):\n        start = datetime.datetime.now()\n        copy_jobs = []\n        management_pool = ThreadPool(processes=threads)\n        transfer_config = TransferConfig(max_concurrency=threads, multipart_chunksize=part_size)\n        src_bucket, src_key = self._path_to_bucket_and_key(source_path)\n        dst_bucket, dst_key = self._path_to_bucket_and_key(destination_path)\n        src_prefix = self._add_path_delimiter(src_key)\n        dst_prefix = self._add_path_delimiter(dst_key)\n        key_path_len = len(src_prefix)\n        total_size_bytes = 0\n        total_keys = 0\n        for item in self.list(source_path, start_time=start_time, end_time=end_time, return_key=True):\n            path = item.key[key_path_len:]\n            # prevents copy attempt of empty key in folder\n            if path != '' and path != '/':\n                total_keys += 1\n                total_size_bytes += item.size\n                copy_source = {\n                    'Bucket': src_bucket,\n                    'Key': src_prefix + path\n                }\n                the_kwargs = {'Config': transfer_config, 'ExtraArgs': kwargs}\n                job = management_pool.apply_async(self.s3.meta.client.copy,\n                                                  args=(copy_source, dst_bucket, dst_prefix + path),\n                                                  kwds=the_kwargs)\n                copy_jobs.append(job)\n        # Wait for the pools to finish scheduling all the copies\n        management_pool.close()\n        management_pool.join()\n        # Raise any errors encountered in any of the copy processes\n        for result in copy_jobs:\n            result.get()\n        end = datetime.datetime.now()\n        duration = end - start\n        logger.info('%s : Complete : %s total keys copied in %s' %\n                    (datetime.datetime.now(), total_keys, duration))\n        return total_keys, total_size_bytes",
  "smell": [
    {
      "smell_id": 3,
      "line_no": 11,
      "description": "The variable referenced in the statement has inconsistent types."
    }
  ]
}
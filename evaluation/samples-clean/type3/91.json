{
  "code": "def start_ray_processes(address_info=None,\n                        object_manager_ports=None,\n                        node_manager_ports=None,\n                        node_ip_address=\"127.0.0.1\",\n                        redis_port=None,\n                        redis_shard_ports=None,\n                        num_workers=None,\n                        num_local_schedulers=1,\n                        object_store_memory=None,\n                        num_redis_shards=1,\n                        redis_max_clients=None,\n                        redis_password=None,\n                        worker_path=None,\n                        cleanup=True,\n                        redirect_worker_output=False,\n                        redirect_output=False,\n                        include_log_monitor=False,\n                        include_webui=False,\n                        start_workers_from_local_scheduler=True,\n                        resources=None,\n                        plasma_directory=None,\n                        huge_pages=False,\n                        autoscaling_config=None,\n                        plasma_store_socket_name=None,\n                        raylet_socket_name=None,\n                        temp_dir=None,\n                        _internal_config=None):\n    \"\"\"Helper method to start Ray processes.\n\n    Args:\n        address_info (dict): A dictionary with address information for\n            processes that have already been started. If provided, address_info\n            will be modified to include processes that are newly started.\n        object_manager_ports (list): A list of the ports to use for the object\n            managers. There should be one per object manager being started on\n            this node (typically just one).\n        node_manager_ports (list): A list of the ports to use for the node\n            managers. There should be one per node manager being started on\n            this node (typically just one).\n        node_ip_address (str): The IP address of this node.\n        redis_port (int): The port that the primary Redis shard should listen\n            to. If None, then a random port will be chosen. If the key\n            \"redis_address\" is in address_info, then this argument will be\n            ignored.\n        redis_shard_ports: A list of the ports to use for the non-primary Redis\n            shards.\n        num_workers (int): The number of workers to start.\n        num_local_schedulers (int): The total number of local schedulers\n            required. This is also the total number of object stores required.\n            This method will start new instances of local schedulers and object\n            stores until there are num_local_schedulers existing instances of\n            each, including ones already registered with the given\n            address_info.\n        object_store_memory: The amount of memory (in bytes) to start the\n            object store with.\n        num_redis_shards: The number of Redis shards to start in addition to\n            the primary Redis shard.\n        redis_max_clients: If provided, attempt to configure Redis with this\n            maxclients number.\n        redis_password (str): Prevents external clients without the password\n            from connecting to Redis if provided.\n        worker_path (str): The path of the source code that will be run by the\n            worker.\n        cleanup (bool): If cleanup is true, then the processes started here\n            will be killed by services.cleanup() when the Python process that\n            called this method exits.\n        redirect_worker_output: True if the stdout and stderr of worker\n            processes should be redirected to files.\n        redirect_output (bool): True if stdout and stderr for non-worker\n            processes should be redirected to files and false otherwise.\n        include_log_monitor (bool): If True, then start a log monitor to\n            monitor the log files for all processes on this node and push their\n            contents to Redis.\n        include_webui (bool): If True, then attempt to start the web UI. Note\n            that this is only possible with Python 3.\n        start_workers_from_local_scheduler (bool): If this flag is True, then\n            start the initial workers from the local scheduler. Else, start\n            them from Python.\n        resources: A dictionary mapping resource name to the quantity of that\n            resource.\n        plasma_directory: A directory where the Plasma memory mapped files will\n            be created.\n        huge_pages: Boolean flag indicating whether to start the Object\n            Store with hugetlbfs support. Requires plasma_directory.\n        autoscaling_config: path to autoscaling config file.\n        plasma_store_socket_name (str): If provided, it will specify the socket\n            name used by the plasma store.\n        raylet_socket_name (str): If provided, it will specify the socket path\n            used by the raylet process.\n        temp_dir (str): If provided, it will specify the root temporary\n            directory for the Ray process.\n        _internal_config (str): JSON configuration for overriding\n            RayConfig defaults. For testing purposes ONLY.\n\n    Returns:\n        A dictionary of the address information for the processes that were\n            started.\n    \"\"\"\n\n    set_temp_root(temp_dir)\n\n    logger.info(\"Process STDOUT and STDERR is being redirected to {}.\".format(\n        get_logs_dir_path()))\n\n    config = json.loads(_internal_config) if _internal_config else None\n\n    if resources is None:\n        resources = {}\n    if not isinstance(resources, list):\n        resources = num_local_schedulers * [resources]\n\n    if num_workers is not None:\n        raise Exception(\"The 'num_workers' argument is deprecated. Please use \"\n                        \"'num_cpus' instead.\")\n    else:\n        workers_per_local_scheduler = []\n        for resource_dict in resources:\n            cpus = resource_dict.get(\"CPU\")\n            workers_per_local_scheduler.append(cpus if cpus is not None else\n                                               multiprocessing.cpu_count())\n\n    if address_info is None:\n        address_info = {}\n    address_info[\"node_ip_address\"] = node_ip_address\n\n    if worker_path is None:\n        worker_path = os.path.join(\n            os.path.dirname(os.path.abspath(__file__)),\n            \"workers/default_worker.py\")\n\n    # Start Redis if there isn't already an instance running. TODO(rkn): We are\n    # suppressing the output of Redis because on Linux it prints a bunch of\n    # warning messages when it starts up. Instead of suppressing the output, we\n    # should address the warnings.\n    redis_address = address_info.get(\"redis_address\")\n    redis_shards = address_info.get(\"redis_shards\", [])\n    if redis_address is None:\n        redis_address, redis_shards = start_redis(\n            node_ip_address,\n            port=redis_port,\n            redis_shard_ports=redis_shard_ports,\n            num_redis_shards=num_redis_shards,\n            redis_max_clients=redis_max_clients,\n            redirect_output=True,\n            redirect_worker_output=redirect_worker_output,\n            cleanup=cleanup,\n            password=redis_password)\n        address_info[\"redis_address\"] = redis_address\n        time.sleep(0.1)\n\n        # Start monitoring the processes.\n        monitor_stdout_file, monitor_stderr_file = new_monitor_log_file(\n            redirect_output)\n        start_monitor(\n            redis_address,\n            node_ip_address,\n            stdout_file=monitor_stdout_file,\n            stderr_file=monitor_stderr_file,\n            cleanup=cleanup,\n            autoscaling_config=autoscaling_config,\n            redis_password=redis_password)\n        start_raylet_monitor(\n            redis_address,\n            stdout_file=monitor_stdout_file,\n            stderr_file=monitor_stderr_file,\n            cleanup=cleanup,\n            redis_password=redis_password,\n            config=config)\n    if redis_shards == []:\n        # Get redis shards from primary redis instance.\n        redis_ip_address, redis_port = redis_address.split(\":\")\n        redis_client = redis.StrictRedis(\n            host=redis_ip_address, port=redis_port, password=redis_password)\n        redis_shards = redis_client.lrange(\"RedisShards\", start=0, end=-1)\n        redis_shards = [ray.utils.decode(shard) for shard in redis_shards]\n        address_info[\"redis_shards\"] = redis_shards\n\n    # Start the log monitor, if necessary.\n    if include_log_monitor:\n        log_monitor_stdout_file, log_monitor_stderr_file = (\n            new_log_monitor_log_file())\n        start_log_monitor(\n            redis_address,\n            node_ip_address,\n            stdout_file=log_monitor_stdout_file,\n            stderr_file=log_monitor_stderr_file,\n            cleanup=cleanup,\n            redis_password=redis_password)\n\n    # Initialize with existing services.\n    if \"object_store_addresses\" not in address_info:\n        address_info[\"object_store_addresses\"] = []\n    object_store_addresses = address_info[\"object_store_addresses\"]\n    if \"raylet_socket_names\" not in address_info:\n        address_info[\"raylet_socket_names\"] = []\n    raylet_socket_names = address_info[\"raylet_socket_names\"]\n\n    # Get the ports to use for the object managers if any are provided.\n    if not isinstance(object_manager_ports, list):\n        assert object_manager_ports is None or num_local_schedulers == 1\n        object_manager_ports = num_local_schedulers * [object_manager_ports]\n    assert len(object_manager_ports) == num_local_schedulers\n    if not isinstance(node_manager_ports, list):\n        assert node_manager_ports is None or num_local_schedulers == 1\n        node_manager_ports = num_local_schedulers * [node_manager_ports]\n    assert len(node_manager_ports) == num_local_schedulers\n\n    # Start any object stores that do not yet exist.\n    for i in range(num_local_schedulers - len(object_store_addresses)):\n        # Start Plasma.\n        plasma_store_stdout_file, plasma_store_stderr_file = (\n            new_plasma_store_log_file(i, redirect_output))\n\n        object_store_address = start_plasma_store(\n            node_ip_address,\n            redis_address,\n            store_stdout_file=plasma_store_stdout_file,\n            store_stderr_file=plasma_store_stderr_file,\n            object_store_memory=object_store_memory,\n            cleanup=cleanup,\n            plasma_directory=plasma_directory,\n            huge_pages=huge_pages,\n            plasma_store_socket_name=plasma_store_socket_name,\n            redis_password=redis_password)\n        object_store_addresses.append(object_store_address)\n        time.sleep(0.1)\n\n    # Start any raylets that do not exist yet.\n    for i in range(len(raylet_socket_names), num_local_schedulers):\n        raylet_stdout_file, raylet_stderr_file = new_raylet_log_file(\n            i, redirect_output=redirect_worker_output)\n        address_info[\"raylet_socket_names\"].append(\n            start_raylet(\n                redis_address,\n                node_ip_address,\n                raylet_socket_name or get_raylet_socket_name(),\n                object_store_addresses[i],\n                worker_path,\n                object_manager_port=object_manager_ports[i],\n                node_manager_port=node_manager_ports[i],\n                resources=resources[i],\n                num_workers=workers_per_local_scheduler[i],\n                stdout_file=raylet_stdout_file,\n                stderr_file=raylet_stderr_file,\n                cleanup=cleanup,\n                redis_password=redis_password,\n                config=config))\n\n    # Try to start the web UI.\n    if include_webui:\n        ui_stdout_file, ui_stderr_file = new_webui_log_file()\n        address_info[\"webui_url\"] = start_ui(\n            redis_address,\n            stdout_file=ui_stdout_file,\n            stderr_file=ui_stderr_file,\n            cleanup=cleanup)\n    else:\n        address_info[\"webui_url\"] = \"\"\n    # Return the addresses of the relevant processes.\n    return address_info",
  "smell": [
    {
      "smell_id": 3,
      "line_no": 239,
      "description": "The variable referenced in the statement has inconsistent types."
    }
  ]
}
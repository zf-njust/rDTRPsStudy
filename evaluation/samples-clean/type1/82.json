{
  "code": "def pre_process(self, batch_data_samples, device):\n        extra = {}\n        if self.task != 'caption':\n            # have text\n            all_text_prompts = []\n            num_thing_class = 0\n            for data_samples in batch_data_samples:\n                if isinstance(data_samples.text, str):\n                    text = data_samples.text.split('.')\n                elif isinstance(data_samples.text, Sequence):\n                    text = data_samples.text\n                else:\n                    raise TypeError(\n                        'Type pf data_sample.text must be sequence or str')\n                text = list(filter(lambda x: len(x) > 0, text))\n                all_text_prompts.append(text)\n                num_thing_class = len(text)\n                # for panoptic\n                if 'stuff_text' in data_samples:\n                    if isinstance(data_samples.stuff_text, str):\n                        text = data_samples.stuff_text.split('.')\n                    elif isinstance(data_samples.stuff_text, Sequence):\n                        text = data_samples.stuff_text\n                    else:\n                        raise TypeError('Type pf data_sample.stuff_text '\n                                        'must be sequence or str')\n                    text = list(filter(lambda x: len(x) > 0, text))\n                    all_text_prompts[-1].extend(text)\n\n            # TODO: support batch\n            all_text_prompts = all_text_prompts[0]\n\n            if all_text_prompts != self._all_text_prompts \\\n                    or self._force_not_use_cache:\n                # avoid redundant computation\n                self._all_text_prompts = all_text_prompts\n                if self.task in ['semseg', 'instance', 'panoptic']:\n                    self.predictor.lang_encoder.get_mean_embeds(\n                        all_text_prompts + ['background'])\n                elif self.task == 'ref-seg':\n                    token_info = self.predictor.lang_encoder.get_text_embeds(\n                        all_text_prompts, norm=False)\n                    token_emb = token_info['token_emb']\n                    tokens = token_info['tokens']\n                    query_emb = token_emb[tokens['attention_mask'].bool()]\n                    extra['grounding_tokens'] = query_emb[:, None]\n                    extra['class_emb'] = token_info['class_emb']\n                elif self.task == 'retrieval':\n                    token_info = self.predictor.lang_encoder.get_text_embeds(\n                        all_text_prompts, norm=True)\n                    extra['class_emb'] = token_info['class_emb']\n                self._extra = extra\n                return extra, all_text_prompts, num_thing_class\n            else:\n                return self._extra, all_text_prompts, num_thing_class\n        else:\n            if not hasattr(self, 'start_token'):\n                self.start_token = self.predictor.lang_encoder. \\\n                    get_sot_token(device=device)\n            extra['start_token'] = self.start_token\n            return extra, None, None",
  "smell": [
    {
      "smell_id": 1,
      "line_no": 11,
      "description": "The variable is redefined with an inconsistent type object."
    }
  ]
}
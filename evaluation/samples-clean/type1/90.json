{
  "code": "def convert_groundtruths_to_coco_dataset(groundtruths, label_map=None):\n  \"\"\"Converts ground-truths to the dataset in COCO format.\n\n  Args:\n    groundtruths: a dictionary of numpy arrays including the fields below.\n      Note that each element in the list represent the number for a single\n      example without batch dimension. 'K' below denotes the actual number of\n      instances for each image.\n      Required fields:\n        - source_id: a list of numpy arrays of int or string of shape\n          [batch_size].\n        - height: a list of numpy arrays of int of shape [batch_size].\n        - width: a list of numpy arrays of int of shape [batch_size].\n        - num_detections: a list of numpy arrays of int of shape [batch_size].\n        - boxes: a list of numpy arrays of float of shape [batch_size, K, 4],\n            where coordinates are in the original image space (not the\n            normalized coordinates).\n        - classes: a list of numpy arrays of int of shape [batch_size, K].\n      Optional fields:\n        - is_crowds: a list of numpy arrays of int of shape [batch_size, K]. If\n            th field is absent, it is assumed that this instance is not crowd.\n        - areas: a list of numy arrays of float of shape [batch_size, K]. If the\n            field is absent, the area is calculated using either boxes or\n            masks depending on which one is available.\n        - masks: a list of numpy arrays of string of shape [batch_size, K],\n    label_map: (optional) a dictionary that defines items from the category id\n      to the category name. If `None`, collect the category mapping from the\n      `groundtruths`.\n\n  Returns:\n    coco_groundtruths: the ground-truth dataset in COCO format.\n  \"\"\"\n  source_ids = np.concatenate(groundtruths['source_id'], axis=0)\n  heights = np.concatenate(groundtruths['height'], axis=0)\n  widths = np.concatenate(groundtruths['width'], axis=0)\n  gt_images = [{'id': int(i), 'height': int(h), 'width': int(w)} for i, h, w\n               in zip(source_ids, heights, widths)]\n\n  gt_annotations = []\n  num_batches = len(groundtruths['source_id'])\n  for i in range(num_batches):\n    logging.log_every_n(\n        logging.INFO,\n        'convert_groundtruths_to_coco_dataset: Processing annotation %d', 100,\n        i)\n    max_num_instances = groundtruths['classes'][i].shape[1]\n    batch_size = groundtruths['source_id'][i].shape[0]\n    for j in range(batch_size):\n      num_instances = groundtruths['num_detections'][i][j]\n      if num_instances > max_num_instances:\n        logging.warning(\n            'num_groundtruths is larger than max_num_instances, %d v.s. %d',\n            num_instances, max_num_instances)\n        num_instances = max_num_instances\n      for k in range(int(num_instances)):\n        ann = {}\n        ann['image_id'] = int(groundtruths['source_id'][i][j])\n        if 'is_crowds' in groundtruths:\n          ann['iscrowd'] = int(groundtruths['is_crowds'][i][j, k])\n        else:\n          ann['iscrowd'] = 0\n        ann['category_id'] = int(groundtruths['classes'][i][j, k])\n        boxes = groundtruths['boxes'][i]\n        ann['bbox'] = [\n            float(boxes[j, k, 1]),\n            float(boxes[j, k, 0]),\n            float(boxes[j, k, 3] - boxes[j, k, 1]),\n            float(boxes[j, k, 2] - boxes[j, k, 0])]\n        if 'areas' in groundtruths:\n          ann['area'] = float(groundtruths['areas'][i][j, k])\n        else:\n          ann['area'] = float(\n              (boxes[j, k, 3] - boxes[j, k, 1]) *\n              (boxes[j, k, 2] - boxes[j, k, 0]))\n        if 'masks' in groundtruths:\n          if isinstance(groundtruths['masks'][i][j, k], tf.Tensor):\n            mask = Image.open(\n                six.BytesIO(groundtruths['masks'][i][j, k].numpy()))\n          else:\n            mask = Image.open(\n                six.BytesIO(groundtruths['masks'][i][j, k]))\n          np_mask = np.array(mask, dtype=np.uint8)\n          np_mask[np_mask > 0] = 255\n          encoded_mask = mask_api.encode(np.asfortranarray(np_mask))\n          ann['segmentation'] = encoded_mask\n          # Ensure the content of `counts` is JSON serializable string.\n          if 'counts' in ann['segmentation']:\n            ann['segmentation']['counts'] = six.ensure_str(\n                ann['segmentation']['counts'])\n          if 'areas' not in groundtruths:\n            ann['area'] = mask_api.area(encoded_mask)\n        if 'keypoints' in groundtruths:\n          keypoints = groundtruths['keypoints'][i]\n          coco_keypoints = []\n          num_valid_keypoints = 0\n          for z in range(len(keypoints[j, k, :, 1])):\n            # Convert from [y, x] to [x, y] as mandated by COCO.\n            x = float(keypoints[j, k, z, 1])\n            y = float(keypoints[j, k, z, 0])\n            coco_keypoints.append(x)\n            coco_keypoints.append(y)\n            if tf.math.is_nan(x) or tf.math.is_nan(y) or (\n                x == 0 and y == 0):\n              visibility = 0\n            else:\n              visibility = 2\n              num_valid_keypoints = num_valid_keypoints + 1\n            coco_keypoints.append(visibility)\n          ann['keypoints'] = coco_keypoints\n          ann['num_keypoints'] = num_valid_keypoints\n        gt_annotations.append(ann)\n\n  for i, ann in enumerate(gt_annotations):\n    ann['id'] = i + 1\n\n  if label_map:\n    gt_categories = [{'id': i, 'name': label_map[i]} for i in label_map]\n  else:\n    category_ids = [gt['category_id'] for gt in gt_annotations]\n    gt_categories = [{'id': i} for i in set(category_ids)]\n\n  gt_dataset = {\n      'images': gt_images,\n      'categories': gt_categories,\n      'annotations': copy.deepcopy(gt_annotations),\n  }\n  return gt_dataset",
  "smell": [
    {
      "smell_id": 1,
      "line_no": 64,
      "description": "The variable is redefined with an inconsistent type object."
    }
  ]
}
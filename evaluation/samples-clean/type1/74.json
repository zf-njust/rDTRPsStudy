{
  "code": "def train(sbn, train_xs, valid_xs, test_xs, training_steps, debug=False):\n  hparams = sorted(sbn.hparams.values().items())\n  hparams = (map(str, x) for x in hparams)\n  hparams = ('_'.join(x) for x in hparams)\n  hparams_str = '.'.join(hparams)\n\n  logger = L.Logger()\n\n  # Create the experiment name from the hparams\n  experiment_name = ([str(sbn.hparams.n_hidden) for i in xrange(sbn.hparams.n_layer)] +\n                     [str(sbn.hparams.n_input)])\n  if sbn.hparams.nonlinear:\n    experiment_name = '~'.join(experiment_name)\n  else:\n    experiment_name = '-'.join(experiment_name)\n  experiment_name = 'SBN_%s' % experiment_name\n  rowkey = {'experiment': experiment_name,\n            'model': hparams_str}\n\n  # Create summary writer\n  summ_dir = os.path.join(FLAGS.working_dir, hparams_str)\n  summary_writer = tf.summary.FileWriter(\n      summ_dir, flush_secs=15, max_queue=100)\n\n  sv = tf.train.Supervisor(logdir=os.path.join(\n      FLAGS.working_dir, hparams_str),\n                     save_summaries_secs=0,\n                     save_model_secs=1200,\n                     summary_op=None,\n                     recovery_wait_secs=30,\n                     global_step=sbn.global_step)\n  with sv.managed_session() as sess:\n    # Dump hparams to file\n    with gfile.Open(os.path.join(FLAGS.working_dir,\n                                 hparams_str,\n                                 'hparams.json'),\n                    'w') as out:\n      json.dump(sbn.hparams.values(), out)\n\n    sbn.initialize(sess)\n    batch_size = sbn.hparams.batch_size\n    scores = []\n    n = train_xs.shape[0]\n    index = range(n)\n\n    while not sv.should_stop():\n      lHats = []\n      grad_variances = []\n      temperatures = []\n      random.shuffle(index)\n      i = 0\n      while i < n:\n        batch_index = index[i:min(i+batch_size, n)]\n        batch_xs = train_xs[batch_index, :]\n\n        if sbn.hparams.dynamic_b:\n          # Dynamically binarize the batch data\n          batch_xs = (np.random.rand(*batch_xs.shape) < batch_xs).astype(float)\n\n        lHat, grad_variance, step, temperature = sbn.partial_fit(batch_xs,\n                                                    sbn.hparams.n_samples)\n        if debug:\n          print(i, lHat)\n          if i > 100:\n            return\n        lHats.append(lHat)\n        grad_variances.append(grad_variance)\n        temperatures.append(temperature)\n        i += batch_size\n\n      grad_variances = np.log(np.mean(grad_variances, axis=0)).tolist()\n      summary_strings = []\n      if isinstance(grad_variances, list):\n        grad_variances = dict(zip([k for (k, v) in sbn.losses], map(float, grad_variances)))\n        rowkey['step'] = step\n        logger.log(rowkey, {'step': step,\n                             'train': np.mean(lHats, axis=0)[0],\n                             'grad_variances': grad_variances,\n                             'temperature': np.mean(temperatures), })\n        grad_variances = '\\n'.join(map(str, sorted(grad_variances.iteritems())))\n      else:\n        rowkey['step'] = step\n        logger.log(rowkey, {'step': step,\n                             'train': np.mean(lHats, axis=0)[0],\n                             'grad_variance': grad_variances,\n                             'temperature': np.mean(temperatures), })\n        summary_strings.append(manual_scalar_summary(\"log grad variance\", grad_variances))\n\n      print('Step %d: %s\\n%s' % (step, str(np.mean(lHats, axis=0)), str(grad_variances)))\n\n      # Every few epochs compute test and validation scores\n      epoch = int(step / (train_xs.shape[0] / sbn.hparams.batch_size))\n      if epoch % FLAGS.eval_freq == 0:\n        valid_res = eval(sbn, valid_xs)\n        test_res= eval(sbn, test_xs)\n\n        print('\\nValid %d: %s' % (step, str(valid_res)))\n        print('Test %d: %s\\n' % (step, str(test_res)))\n        logger.log(rowkey, {'step': step,\n                             'valid': valid_res[0],\n                             'test': test_res[0]})\n        logger.flush()  # Flush infrequently\n\n      # Create summaries\n      summary_strings.extend([\n        manual_scalar_summary(\"Train ELBO\", np.mean(lHats, axis=0)[0]),\n        manual_scalar_summary(\"Temperature\", np.mean(temperatures)),\n      ])\n      for summ_str in summary_strings:\n        summary_writer.add_summary(summ_str, global_step=step)\n      summary_writer.flush()\n\n      sys.stdout.flush()\n      scores.append(np.mean(lHats, axis=0))\n\n      if step > training_steps:\n        break\n\n    return scores",
  "smell": [
    {
      "smell_id": 1,
      "line_no": 74,
      "description": "The variable is redefined with an inconsistent type object."
    }
  ]
}
file,method,params,startlineno,endlineno,CountLine,CountLineBlank,CountLineCode,CountLineCodeDecl,CountLineCodeExe,CountLineComment,CountPath,CountStmtDecl,CountStmtExe,Cyclomatic,CyclomaticModified,CyclomaticStrict,Essential,MaxNesting,RatioCommentToCode,n1,n2,N1,N2,N,n,V,D,L,E,T,I,B,Incompatible Assignment Types,Incompatible Argument Types,Incompatible Variable Types,Dynamic Element Deletion,Dynamic Attribute Deletion,Dynamic Attribute Access,Bug
examples\extract_features.py,__init__,"self, unique_id, text_a, text_b",42,45,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,6,5,12,14,26,11,89.9452220845697,8.4,0.119047619047619,755.539865510386,41.9744369727992,10.7077645338774,0.0276513921650145,0,0,0,0,0,0,0
examples\extract_features.py,__init__,"self, unique_id, tokens, input_ids, input_mask, input_type_ids",51,56,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,6,5,12,14,26,11,89.9452220845697,8.4,0.119047619047619,755.539865510386,41.9744369727992,10.7077645338774,0.0276513921650145,0,0,0,0,0,0,0
examples\extract_features.py,convert_examples_to_features,"examples, seq_length, tokenizer",59,147,89,11,52,1,51,26,145,1,43,10,10,10,1,3,0.50,21,44,162,165,327,65,1969.3142748603,39.375,0.0253968253968254,77541.7495726245,4307.87497625692,50.014330790103,0.606134693355754,0,0,4,0,0,0,0
examples\extract_features.py,_truncate_seq_pair,"tokens_a, tokens_b, max_length",150,164,15,1,9,1,8,5,5,1,7,4,4,4,3,2,0.56,14,8,27,20,47,22,209.593286075953,17.5,0.0571428571428571,3667.88250632918,203.771250351621,11.9767592043402,0.0792785482774753,0,0,0,0,0,0,0
examples\extract_features.py,read_examples,input_file,167,188,22,0,21,1,20,1,5,1,18,4,4,4,3,3,0.05,19,25,57,49,106,44,578.699751575553,18.62,0.0537056928034372,10775.3893743368,598.632743018711,31.0794710835421,0.162617542502606,0,0,0,0,0,0,0
examples\extract_features.py,main,,191,293,103,16,83,1,82,4,120,1,66,10,10,10,1,5,0.05,25,149,350,347,697,174,5187.73161660656,29.1107382550336,0.0343515850144092,151018.697228396,8389.92762379977,178.206803659799,0.945291802196756,2,0,0,0,0,0,0
examples\run_classifier.py,__init__,"self, guid, text_a, text_b=None, label=None",48,63,16,1,5,1,4,10,1,1,4,1,1,1,1,0,2.00,7,7,19,19,38,14,144.679487038189,9.5,0.105263157894737,1374.45512686279,76.3586181590442,15.2294196882304,0.041206505791902,0,0,0,0,0,0,1
examples\run_classifier.py,__init__,"self, input_ids, input_mask, segment_ids, label_id",69,73,16,1,5,1,4,10,1,1,4,1,1,1,1,0,2.00,7,7,19,19,38,14,144.679487038189,9.5,0.105263157894737,1374.45512686279,76.3586181590442,15.2294196882304,0.041206505791902,0,0,0,0,0,0,1
examples\run_classifier.py,get_train_examples,"self, data_dir",79,81,4,0,3,1,2,1,1,1,1,1,1,1,1,0,0.33,6,11,14,14,28,17,114.44895955501,3.81818181818182,0.261904761904762,436.986936482764,24.2770520268202,29.9747275025025,0.0191951295709786,0,0,0,0,0,0,1
examples\run_classifier.py,get_dev_examples,"self, data_dir",83,85,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,5,5,6,5,11,10,36.541209043761,2.5,0.4,91.3530226094025,5.07516792274458,14.6164836175044,0.00676125568483764,0,0,0,0,0,0,1
examples\run_classifier.py,get_labels,self,87,89,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,4,4,5,4,9,8,27,2,0.5,54,3,13.5,0.0047622031559046,0,0,0,0,0,0,1
examples\run_classifier.py,_read_tsv,"cls, input_file, quotechar=None",91,101,10,0,9,1,8,1,3,1,8,3,3,3,1,3,0.11,15,23,38,35,73,38,383.098708481382,11.4130434782609,0.0876190476190476,4372.3222163636,242.906789797978,33.5667439812258,0.089129236239763,0,0,0,0,0,0,1
examples\run_classifier.py,get_train_examples,"self, data_dir",107,111,4,0,3,1,2,1,1,1,1,1,1,1,1,0,0.33,6,11,14,14,28,17,114.44895955501,3.81818181818182,0.261904761904762,436.986936482764,24.2770520268202,29.9747275025025,0.0191951295709786,0,0,0,0,0,0,1
examples\run_classifier.py,get_dev_examples,"self, data_dir",113,116,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,5,5,6,5,11,10,36.541209043761,2.5,0.4,91.3530226094025,5.07516792274458,14.6164836175044,0.00676125568483764,0,0,0,0,0,0,1
examples\run_classifier.py,get_labels,self,118,120,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,4,4,5,4,9,8,27,2,0.5,54,3,13.5,0.0047622031559046,0,0,0,0,0,0,1
examples\run_classifier.py,_create_examples,"self, lines, set_type",122,134,13,0,12,1,11,1,3,1,10,3,3,3,3,2,0.08,14,19,38,37,75,33,378.329558951884,13.6315789473684,0.0733590733590734,5157.22925097568,286.512736165316,27.7539058690571,0.0994999899268267,0,0,0,0,0,0,1
examples\run_classifier.py,get_train_examples,"self, data_dir",140,143,4,0,3,1,2,1,1,1,1,1,1,1,1,0,0.33,6,11,14,14,28,17,114.44895955501,3.81818181818182,0.261904761904762,436.986936482764,24.2770520268202,29.9747275025025,0.0191951295709786,0,0,0,0,0,0,1
examples\run_classifier.py,get_dev_examples,"self, data_dir",145,149,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,5,5,6,5,11,10,36.541209043761,2.5,0.4,91.3530226094025,5.07516792274458,14.6164836175044,0.00676125568483764,0,0,0,0,0,0,1
examples\run_classifier.py,get_labels,self,151,153,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,4,4,5,4,9,8,27,2,0.5,54,3,13.5,0.0047622031559046,0,0,0,0,0,0,1
examples\run_classifier.py,_create_examples,"self, lines, set_type",155,167,13,0,12,1,11,1,3,1,10,3,3,3,3,2,0.08,14,19,38,37,75,33,378.329558951884,13.6315789473684,0.0733590733590734,5157.22925097568,286.512736165316,27.7539058690571,0.0994999899268267,0,0,0,0,0,0,1
examples\run_classifier.py,get_train_examples,"self, data_dir",173,176,4,0,3,1,2,1,1,1,1,1,1,1,1,0,0.33,6,11,14,14,28,17,114.44895955501,3.81818181818182,0.261904761904762,436.986936482764,24.2770520268202,29.9747275025025,0.0191951295709786,0,0,0,0,0,0,1
examples\run_classifier.py,get_dev_examples,"self, data_dir",178,181,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,5,5,6,5,11,10,36.541209043761,2.5,0.4,91.3530226094025,5.07516792274458,14.6164836175044,0.00676125568483764,0,0,0,0,0,0,1
examples\run_classifier.py,get_labels,self,183,185,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,4,4,5,4,9,8,27,2,0.5,54,3,13.5,0.0047622031559046,0,0,0,0,0,0,1
examples\run_classifier.py,_create_examples,"self, lines, set_type",187,196,13,0,12,1,11,1,3,1,10,3,3,3,3,2,0.08,14,19,38,37,75,33,378.329558951884,13.6315789473684,0.0733590733590734,5157.22925097568,286.512736165316,27.7539058690571,0.0994999899268267,0,0,0,0,0,0,1
examples\run_classifier.py,convert_examples_to_features,"examples, label_list, max_seq_length, tokenizer",199,278,80,11,43,1,42,26,13,1,35,6,6,6,1,3,0.60,23,50,161,157,318,73,1968.36420972385,36.11,0.027693159789532,71077.6316131281,3948.75731184045,54.5102245838783,0.571962265117248,0,0,15,0,0,0,1
examples\run_classifier.py,_truncate_seq_pair,"tokens_a, tokens_b, max_length",281,295,15,1,9,1,8,5,5,1,7,4,4,4,3,2,0.56,14,8,27,20,47,22,209.593286075953,17.5,0.0571428571428571,3667.88250632918,203.771250351621,11.9767592043402,0.0792785482774753,0,0,0,0,0,0,1
examples\run_classifier.py,accuracy,"out, labels",297,299,3,0,3,1,2,0,1,1,2,1,1,1,1,0,0.00,8,9,13,13,26,17,106.274033872509,5.77777777777778,0.173076923076923,614.027751263384,34.1126528479658,18.3935827856265,0.0240807908155972,0,0,0,0,0,0,0
examples\run_classifier.py,main,,301,634,334,36,287,5,282,13,21196800,5,186,32,32,32,9,6,0.05,37,317,986,992,1978,354,16748.9237780642,57.8927444794953,0.0172733217088056,969641.164590011,53868.953588334,289.309548694766,3.26552321040469,0,0,0,0,0,0,1
examples\run_gpt2.py,top_k_logits,"logits, k",18,23,6,0,6,1,5,0,2,1,5,2,2,2,1,1,0.00,13,14,31,27,58,27,275.783475125481,12.5357142857143,0.0797720797720798,3457.14284889443,192.063491605246,21.9998213775313,0.0762120473423061,0,0,0,0,0,0,0
examples\run_gpt2.py,sample_sequence,"model, length, start_token=None, batch_size=None, context=None, temperature='1', top_k='0', device='cuda', sample=True",25,46,22,0,22,1,21,0,6,1,19,4,4,4,1,3,0.00,20,39,122,98,220,59,1294.18147085961,25.1282051282051,0.0397959183673469,32520.4574728824,1806.6920818268,51.5031401668618,0.339612116314758,0,0,0,0,0,0,0
examples\run_gpt2.py,run_model,,48,102,55,5,50,1,49,0,60,1,42,9,9,9,3,3,0.00,25,82,215,218,433,107,2919.0552051117,33.2317073170732,0.0300917431192661,97005.1882186509,5389.17712325838,87.8394593831777,0.703734302169167,0,0,0,0,0,0,1
examples\run_gpt2_generate_unconditional_samples.py,top_k_logits,"logits, k",18,23,6,0,6,1,5,0,2,1,5,2,2,2,1,1,0.00,13,14,31,27,58,27,275.783475125481,12.5357142857143,0.0797720797720798,3457.14284889443,192.063491605246,21.9998213775313,0.0762120473423061,0,0,0,0,0,0,0
examples\run_gpt2_generate_unconditional_samples.py,sample_sequence,"model, length, start_token=None, batch_size=None, context=None, temperature='1', top_k='0', device='cuda'",25,43,19,0,19,1,18,0,4,1,17,3,3,3,1,2,0.00,19,34,101,82,183,53,1048.20944318507,22.9117647058824,0.0436456996148909,24016.3281247402,1334.24045137445,45.7498344907474,0.277470287585225,0,0,0,0,0,0,0
examples\run_gpt2_generate_unconditional_samples.py,sample_model,,45,85,41,4,37,1,36,0,9,1,30,5,5,5,3,2,0.00,23,66,159,172,331,89,2143.46776564988,29.969696969697,0.0333670374115268,64239.0794008403,3568.83774449113,71.5211691268412,0.534660726644328,0,0,0,0,0,0,0
examples\run_lm_finetuning.py,__init__,"self, corpus_path, tokenizer, seq_len, encoding='utf-8', corpus_lines=None, on_memory=True",46,109,64,8,48,1,47,13,13,1,43,9,9,9,1,5,0.27,22,38,170,163,333,60,1966.99456833764,47.1842105263158,0.0211935303959844,92811.0858165627,5156.17143425348,41.6875591727999,0.683300881543001,0,0,0,0,0,0,1
examples\run_lm_finetuning.py,__len__,self,111,113,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,6,5,8,7,15,11,51.8914742795595,4.2,0.238095238095238,217.94419197415,12.1080106652305,12.3551129237046,0.0120718995186948,0,0,0,0,0,0,1
examples\run_lm_finetuning.py,__getitem__,"self, item",115,142,28,6,18,1,17,4,3,1,13,3,3,3,1,2,0.22,14,37,81,84,165,51,935.950181425297,15.8918918918919,0.0629251700680272,14874.0190994074,826.334394411523,58.8948243413877,0.201603299284183,0,0,0,0,0,0,1
examples\run_lm_finetuning.py,random_sent,"self, index",144,160,17,1,10,1,9,6,2,1,8,2,2,2,1,1,0.60,11,14,29,28,57,25,264.699802817159,11,0.0909090909090909,2911.69783098875,161.760990610486,24.0636184379236,0.0679688017928819,0,0,0,0,0,0,0
examples\run_lm_finetuning.py,get_corpus_line,"self, item",162,197,36,1,26,1,25,9,5,1,23,5,5,5,1,3,0.35,19,20,89,88,177,39,935.516192738618,41.8,0.0239234449760766,39104.5768564742,2172.47649202635,22.380770161211,0.38402880937302,0,0,0,0,0,0,0
examples\run_lm_finetuning.py,get_random_line,self,199,220,22,0,13,1,12,9,7,1,11,5,5,5,3,3,0.69,16,23,50,47,97,39,512.684015229638,16.3478260869565,0.0611702127659574,8381.26911853669,465.626062140927,31.3609902933023,0.137536700848858,0,0,0,0,0,0,0
examples\run_lm_finetuning.py,get_next_line,self,222,234,13,0,11,1,10,2,3,1,10,3,3,3,1,2,0.18,12,16,41,39,80,28,384.588393764608,14.625,0.0683760683760684,5624.6052588074,312.478069933744,26.2966423086912,0.105424150695899,0,0,0,0,0,0,0
examples\run_lm_finetuning.py,__init__,"self, guid, tokens_a, tokens_b=None, is_next=None, lm_labels=None",240,256,64,8,48,1,47,13,13,1,43,9,9,9,1,5,0.27,22,38,170,163,333,60,1966.99456833764,47.1842105263158,0.0211935303959844,92811.0858165627,5156.17143425348,41.6875591727999,0.683300881543001,0,0,0,0,0,0,1
examples\run_lm_finetuning.py,__init__,"self, input_ids, input_mask, segment_ids, is_next, lm_label_ids",262,267,64,8,48,1,47,13,13,1,43,9,9,9,1,5,0.27,22,38,170,163,333,60,1966.99456833764,47.1842105263158,0.0211935303959844,92811.0858165627,5156.17143425348,41.6875591727999,0.683300881543001,0,0,0,0,0,0,1
examples\run_lm_finetuning.py,random_word,"tokens, tokenizer",270,306,37,6,18,1,17,13,8,1,15,6,6,6,1,3,0.72,18,27,58,53,111,45,609.595693692594,17.6666666666667,0.0566037735849057,10769.5239219025,598.306884550139,34.5054166241091,0.162558524557038,0,0,0,0,0,0,0
examples\run_lm_finetuning.py,convert_example_to_features,"example, max_seq_length, tokenizer",309,400,92,9,50,1,49,33,16,1,43,5,5,5,1,1,0.66,20,44,167,176,343,64,2058,40,0.025,82320,4573.33333333333,51.45,0.630786397942344,0,0,4,0,0,0,0
examples\run_lm_finetuning.py,main,,403,619,217,20,186,4,182,13,1052160,4,112,27,27,27,8,6,0.07,36,218,586,579,1165,254,9306.81766008957,47.8073394495413,0.0209172903473422,444934.191070888,24718.5661706049,194.673407205865,1.94271577013725,0,0,0,0,0,0,1
examples\run_lm_finetuning.py,_truncate_seq_pair,"tokens_a, tokens_b, max_length",622,636,15,1,9,1,8,5,5,1,7,4,4,4,3,2,0.56,14,8,27,20,47,22,209.593286075953,17.5,0.0571428571428571,3667.88250632918,203.771250351621,11.9767592043402,0.0792785482774753,0,0,0,0,0,0,0
examples\run_lm_finetuning.py,accuracy,"out, labels",639,641,3,0,3,1,2,0,1,1,2,1,1,1,1,0,0.00,8,9,13,13,26,17,106.274033872509,5.77777777777778,0.173076923076923,614.027751263384,34.1126528479658,18.3935827856265,0.0240807908155972,0,0,0,0,0,0,0
examples\run_openai_gpt.py,accuracy,"out, labels",43,45,3,0,3,1,2,0,1,1,2,1,1,1,1,0,0.00,8,9,13,13,26,17,106.274033872509,5.77777777777778,0.173076923076923,614.027751263384,34.1126528479658,18.3935827856265,0.0240807908155972,0,0,0,0,0,0,0
examples\run_openai_gpt.py,load_rocstories_dataset,dataset_path,47,55,9,0,8,1,7,2,2,1,7,2,2,2,1,2,0.25,13,20,36,34,70,33,353.107588355092,11.05,0.0904977375565611,3901.83885132376,216.768825073542,31.9554378601893,0.0826148840735683,1,0,0,0,0,0,0
examples\run_openai_gpt.py,pre_process_datasets,"encoded_datasets, input_len, cap_length, start_token, delimiter_token, clf_token",57,82,26,1,21,1,20,4,3,1,20,3,3,3,1,2,0.19,12,39,141,129,270,51,1531.5548423323,19.8461538461538,0.0503875968992248,30395.4730247488,1688.63739026382,77.1713680244959,0.324651950332527,0,0,0,0,0,0,1
examples\run_openai_gpt.py,main,,84,256,173,22,140,3,137,13,640,3,123,12,12,12,1,3,0.09,30,250,626,656,1282,280,10421.7408277234,39.36,0.0254065040650407,410199.718979195,22788.8732766219,264.780000704356,1.84024501921968,0,0,0,0,0,0,1
examples\run_openai_gpt.py,tokenize_and_encode,obj,145,151,7,0,6,1,5,1,3,1,4,3,3,3,3,1,0.17,10,11,22,20,42,21,184.477331756708,9.09090909090909,0.11,1677.06665233371,93.1703695740949,20.2925064932379,0.0470520945233371,0,0,0,0,0,0,0
examples\run_squad.py,__init__,"self, qas_id, question_text, doc_tokens, orig_answer_text=None, start_position=None, end_position=None, is_impossible=None",61,75,25,0,25,13,12,0,1,1,12,1,1,1,1,0,0.00,7,14,45,50,95,21,417.270155163982,12.5,0.08,5215.87693954978,289.770941086099,33.3816124131186,0.100252905833025,0,0,0,0,0,0,0
examples\run_squad.py,__str__,self,77,78,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,3,6,4,10,8,30,3.33333333333333,0.3,100,5.55555555555555,9,0.00718144896677294,0,0,0,0,0,0,0
examples\run_squad.py,__repr__,self,80,92,13,0,13,1,12,0,8,1,11,4,4,4,1,1,0.00,9,18,40,37,77,27,366.126337666587,9.25,0.108108108108108,3386.66862341593,188.148256856441,39.5812256936851,0.0751727690360851,0,0,0,0,0,0,1
examples\run_squad.py,__init__,"self, unique_id, example_index, doc_span_index, tokens, token_to_orig_map, token_is_max_context, input_ids, input_mask, segment_ids, start_position=None, end_position=None, is_impossible=None",98,122,25,0,25,13,12,0,1,1,12,1,1,1,1,0,0.00,7,14,45,50,95,21,417.270155163982,12.5,0.08,5215.87693954978,289.770941086099,33.3816124131186,0.100252905833025,0,0,0,0,0,0,0
examples\run_squad.py,read_squad_examples,"input_file, is_training, version_2_with_negative",125,200,76,4,65,2,63,7,58,2,50,12,12,12,8,6,0.11,27,65,175,153,328,92,2139.7283215867,31.7769230769231,0.0314693778746066,67993.9822805743,3777.44346003191,67.3359191010097,0.555297515591447,0,0,1,0,0,0,0
examples\run_squad.py,is_whitespace,c,130,133,4,0,4,1,3,0,2,1,3,2,2,2,1,1,0.00,9,8,19,13,32,17,130.798810920011,7.3125,0.136752136752137,956.46630485258,53.1370169362544,17.8870168779502,0.0323587593290127,0,0,0,0,0,0,0
examples\run_squad.py,convert_examples_to_features,"examples, tokenizer, max_seq_length, doc_stride, max_query_length, is_training",203,363,161,17,134,2,132,11,72181,1,106,22,22,22,4,4,0.08,31,96,408,401,809,127,5653.84591159868,64.7447916666667,0.015445257823184,366057.075661892,20336.5042034384,87.3251077971963,1.70573390701989,0,0,9,0,0,0,0
examples\run_squad.py,_improve_answer_span,"doc_tokens, input_start, input_end, tokenizer, orig_answer_text",366,400,35,3,9,2,7,23,4,1,7,4,4,4,4,3,2.56,14,16,42,37,79,30,387.644357053073,16.1875,0.0617760617760618,6274.99302979662,348.61072387759,23.9471417484524,0.113402051293564,0,0,0,0,0,0,0
examples\run_squad.py,_check_is_max_context,"doc_spans, cur_span_index, position",403,437,35,2,16,1,15,17,9,1,15,5,5,5,4,2,1.06,20,19,50,45,95,39,502.113210791914,23.6842105263158,0.0422222222222222,11892.1549924401,660.675277357781,21.2003355667697,0.17366772658532,0,0,0,0,0,0,0
examples\run_squad.py,write_predictions,"all_examples, all_features, all_results, n_best_size, max_answer_length, do_lower_case, output_prediction_file, output_nbest_file, output_null_log_odds_file, verbose_logging, version_2_with_negative, null_score_diff_threshold",444,633,190,24,152,4,148,23,10510088,1,116,32,32,32,16,5,0.15,29,119,461,436,897,148,6466.87966896917,53.1260504201681,0.0188231572287251,343559.775354816,19086.6541863787,121.727092788252,1.63510991494104,0,0,0,0,0,0,1
examples\run_squad.py,get_final_text,"pred_text, orig_text, do_lower_case, verbose_logging=False",636,729,94,13,50,2,48,31,70,2,46,14,14,14,5,2,0.62,21,47,143,126,269,68,1637.52750429634,28.1489361702128,0.035525321239607,46094.6571954055,2560.81428863364,58.1736906288194,0.428527935177255,0,0,0,0,0,0,0
examples\run_squad.py,_strip_spaces,text,664,673,10,0,10,1,9,0,3,1,9,3,3,3,3,2,0.00,13,15,29,25,54,28,259.597165791111,10.8333333333333,0.0923076923076923,2812.3026294037,156.239034966872,23.9628153037948,0.0664130533145259,0,0,0,0,0,0,0
examples\run_squad.py,_get_best_indexes,"logits, n_best_size",732,741,10,1,8,1,7,1,3,1,7,3,3,3,3,2,0.12,15,17,31,26,57,32,285,11.4705882352941,0.0871794871794872,3269.11764705882,181.617647058824,24.8461538461539,0.0734230540746813,0,0,0,0,0,0,0
examples\run_squad.py,_compute_softmax,scores,744,764,21,3,17,1,16,1,13,1,16,6,6,6,1,2,0.06,18,13,42,35,77,31,381.473115899789,24.2307692307692,0.0412698412698413,9243.38703911028,513.521502172793,15.7433349418961,0.146813560333763,0,0,0,0,0,0,0
examples\run_squad.py,main,,766,1080,315,29,274,4,270,15,329287680,4,184,38,38,38,12,6,0.05,37,332,1063,1051,2114,369,18027.0863908117,58.5647590361446,0.017075115077018,1055751.97060165,58652.8872556471,307.814574626455,3.45610301671221,0,0,0,0,0,0,1
examples\run_swag.py,__init__,"self, swag_id, context_sentence, start_ending, ending_0, ending_1, ending_2, ending_3, label=None",46,64,19,0,19,9,10,0,1,1,5,1,1,1,1,0,0.00,8,11,28,28,56,19,237.883940752841,10.1818181818182,0.0982142857142857,2422.09103311983,134.560612951102,23.3636013239397,0.060118165526561,0,0,0,0,0,0,0
examples\run_swag.py,__str__,self,66,67,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,3,6,4,10,8,30,3.33333333333333,0.3,100,5.55555555555555,9,0.00718144896677294,0,0,0,0,0,0,0
examples\run_swag.py,__repr__,self,69,83,15,2,13,1,12,0,2,1,4,2,2,2,1,1,0.00,12,24,51,46,97,36,501.482725139904,11.5,0.0869565217391304,5767.0513391089,320.391741061606,43.6071934904265,0.10719666897896,0,0,0,0,0,0,0
examples\run_swag.py,__init__,"self, example_id, choices_features, label",87,102,19,0,19,9,10,0,1,1,5,1,1,1,1,0,0.00,8,11,28,28,56,19,237.883940752841,10.1818181818182,0.0982142857142857,2422.09103311983,134.560612951102,23.3636013239397,0.060118165526561,0,0,0,0,0,0,0
examples\run_swag.py,read_swag_examples,"input_file, is_training",105,134,30,3,25,1,24,4,6,1,11,4,4,4,1,3,0.16,20,42,76,69,145,62,863.358465006097,16.4285714285714,0.0608695652173913,14183.7462108144,787.985900600803,52.5522543916755,0.195316700833867,0,0,0,0,0,0,0
examples\run_swag.py,convert_examples_to_features,"examples, tokenizer, max_seq_length, is_training",136,212,77,10,43,2,41,24,11,1,35,6,6,6,1,3,0.56,18,57,162,165,327,75,2036.82371179215,26.0526315789474,0.0383838383838384,53064.617754585,2948.03431969917,78.1811121697998,0.470704957191799,0,0,11,0,0,0,0
examples\run_swag.py,_truncate_seq_pair,"tokens_a, tokens_b, max_length",214,228,15,1,9,1,8,5,5,1,7,4,4,4,3,2,0.56,14,8,27,20,47,22,209.593286075953,17.5,0.0571428571428571,3667.88250632918,203.771250351621,11.9767592043402,0.0792785482774753,0,0,0,0,0,0,0
examples\run_swag.py,accuracy,"out, labels",230,232,3,0,3,1,2,0,1,1,2,1,1,1,1,0,0.00,8,9,13,13,26,17,106.274033872509,5.77777777777778,0.173076923076923,614.027751263384,34.1126528479658,18.3935827856265,0.0240807908155972,0,0,0,0,0,0,0
examples\run_swag.py,select_field,"features, field",234,240,8,0,8,1,7,0,1,1,1,1,1,1,1,0,0.00,9,6,13,10,23,15,89.8584836989959,7.5,0.133333333333333,673.938627742469,37.4410348745816,11.9811311598661,0.0256227444298562,0,0,0,0,0,0,0
examples\run_swag.py,main,,243,543,301,33,254,4,250,16,10214400,4,169,31,31,31,8,6,0.06,37,290,897,904,1801,327,15044.017432722,57.6689655172414,0.0173403491987563,867572.922568426,48198.4956982459,260.868515635577,3.03214108168092,0,0,0,0,0,0,1
examples\run_transfo_xl.py,main,,38,149,112,12,88,4,84,12,128,4,65,9,9,9,1,1,0.14,29,127,338,346,684,156,4983.21511770178,39.503937007874,0.0253139326290612,196856.616106377,10936.4786725765,126.144771765622,1.12800776413008,0,0,0,0,0,0,1
examples\run_transfo_xl.py,evaluate,eval_iter,107,123,17,0,16,1,15,1,2,1,14,2,2,2,1,2,0.06,16,29,54,52,106,45,582.136428210946,14.3448275862069,0.0697115384615385,8350.64669433632,463.924816352018,40.58162600509,0.137201487011805,0,0,0,0,0,0,0
examples\run_transfo_xl.py,format_log,"loss, split",136,139,4,0,4,1,3,0,1,1,2,1,1,1,1,0,0.00,7,8,12,12,24,15,93.7653742946044,5.25,0.19047619047619,492.268215046673,27.3482341692596,17.8600712942104,0.0207816459655284,0,0,0,0,0,0,0
pytorch_pretrained_bert\convert_gpt2_checkpoint_to_pytorch.py,convert_gpt2_checkpoint_to_pytorch,"gpt2_checkpoint_path, gpt2_config_file, pytorch_dump_folder_path",30,48,19,2,14,1,13,3,2,1,12,2,2,2,1,1,0.21,12,29,46,48,94,41,503.6098884341,9.93103448275862,0.100694444444444,5001.36716789727,277.853731549848,50.7107179326003,0.0974850243449805,0,0,0,0,0,0,0
pytorch_pretrained_bert\convert_openai_checkpoint_to_pytorch.py,convert_openai_checkpoint_to_pytorch,"openai_checkpoint_folder_path, openai_config_file, pytorch_dump_folder_path",30,48,19,2,14,1,13,3,2,1,12,2,2,2,1,1,0.21,12,29,46,48,94,41,503.6098884341,9.93103448275862,0.100694444444444,5001.36716789727,277.853731549848,50.7107179326003,0.0974850243449805,0,0,0,0,0,0,0
pytorch_pretrained_bert\convert_tf_checkpoint_to_pytorch.py,convert_tf_checkpoint_to_pytorch,"tf_checkpoint_path, bert_config_file, pytorch_dump_path",30,41,12,2,7,1,6,3,1,1,6,1,1,1,1,0,0.43,6,18,24,28,52,24,238.4180500375,4.66666666666667,0.214285714285714,1112.61756684167,61.8120870467593,51.0895821508929,0.035791180286518,0,0,0,0,0,0,0
pytorch_pretrained_bert\convert_transfo_xl_checkpoint_to_pytorch.py,convert_transfo_xl_checkpoint_to_pytorch,"tf_checkpoint_path, transfo_xl_config_file, pytorch_dump_folder_path, transfo_xl_dataset_file",47,89,43,4,34,4,30,5,6,1,29,4,4,4,1,2,0.15,13,57,116,127,243,70,1489.41577311763,14.4824561403509,0.0690490611750454,21570.3986089228,1198.35547827349,102.842760833077,0.258295907844194,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,url_to_filename,"url, etag=None",39,54,16,2,9,1,8,5,2,1,8,2,2,2,1,1,0.56,11,14,26,27,53,25,246.12437805806,10.6071428571429,0.0942760942760943,2610.67643868728,145.037579927071,23.2036450694468,0.0631995682998421,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,filename_to_url,"filename, cache_dir=None",57,80,24,4,16,1,15,4,16,1,15,5,5,5,3,1,0.25,18,33,63,59,122,51,692.035891720523,16.0909090909091,0.0621468926553672,11135.4866213211,618.638145628952,43.0078802764167,0.166220612744206,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,cached_path,"url_or_filename, cache_dir=None",83,110,28,2,16,1,15,10,32,1,12,7,7,7,4,1,0.62,17,28,63,54,117,45,642.546812270572,16.3928571428571,0.0610021786492375,10533.1781011497,585.176561174985,39.1967554326275,0.160171421653148,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,split_s3_path,url,113,123,11,0,9,1,8,2,4,1,8,3,3,3,1,1,0.22,12,15,29,28,57,27,271.028587623318,11.2,0.0892857142857143,3035.52018138116,168.640010076731,24.1989810377962,0.0698823490370986,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,s3_request,func,126,142,17,2,11,3,8,4,1,2,7,1,1,1,1,0,0.36,17,18,38,26,64,35,328.274113084478,12.2777777777778,0.081447963800905,4030.47661064831,223.91536725824,26.7372580792787,0.0844208425205181,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,wrapper,"url, *args, **kwargs",132,140,8,0,8,1,7,0,3,1,6,3,3,3,3,2,0.00,16,15,32,20,52,31,257.618208140118,10.6666666666667,0.09375,2747.92755349459,152.66264186081,24.151707013136,0.0653956605897843,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,s3_etag,url,145,151,6,0,5,1,4,1,1,1,4,1,1,1,1,0,0.20,7,13,15,18,33,20,142.623627131283,4.84615384615385,0.206349206349206,691.176039174679,38.3986688430377,29.4302722651854,0.0260578068965135,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,s3_get,"url, temp_file",154,159,5,0,4,1,3,1,1,1,3,1,1,1,1,0,0.25,6,13,15,18,33,19,140.181607943638,4.15384615384615,0.240740740740741,582.292832996651,32.3496018331473,33.7474241345796,0.0232437596017462,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,http_get,"url, temp_file",162,171,10,0,10,1,9,1,3,1,9,3,3,3,1,2,0.10,14,24,42,38,80,38,419.834201075487,11.0833333333333,0.0902255639097744,4653.16239525331,258.509021958517,37.8797775406454,0.0929060975799513,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,get_from_cache,"url, cache_dir=None",174,231,58,11,36,1,35,11,72,1,32,8,8,8,3,3,0.31,22,66,133,128,261,88,1685.91165246433,21.3333333333333,0.046875,35966.1152525725,1998.1175140318,79.0271087092657,0.363196035842289,0,0,0,0,0,0,1
pytorch_pretrained_bert\file_utils.py,read_set_from_file,filename,234,243,10,0,6,1,5,4,2,1,5,2,2,2,1,2,0.67,11,13,20,18,38,24,174.228575027404,7.61538461538462,0.131313131313131,1326.81760982408,73.7120894346709,22.8784997510733,0.0402487962904608,0,0,0,0,0,0,0
pytorch_pretrained_bert\file_utils.py,get_file_extension,"path, dot=True, lower=True",246,249,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,11,8,24,19,43,19,182.660883078074,13.0625,0.076555023923445,2386.00778520734,132.555988067075,13.9836082739196,0.0595195971197257,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,load_tf_weights_in_bert,"model, tf_checkpoint_path",52,110,59,1,53,4,49,5,820,4,43,14,14,14,5,3,0.09,25,70,168,162,330,95,2168.05235074921,28.9285714285714,0.0345679012345679,62718.6572895308,3484.36984941838,74.9450195320715,0.526190795394536,0,0,0,0,0,5,1
pytorch_pretrained_bert\modeling.py,gelu,x,113,119,7,0,2,1,1,5,1,1,1,1,1,1,1,0,2.50,8,10,13,12,25,18,104.248125036058,4.8,0.208333333333333,500.391000173077,27.7995000096154,21.718359382512,0.0210096300574662,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,swish,x,122,123,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,6,4,7,6,13,10,43.1850652335357,4.5,0.222222222222222,194.332793550911,10.7962663083839,9.59668116300794,0.0111834587733184,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,__init__,"self, vocab_size_or_config_json_file, hidden_size='768', num_hidden_layers='12', num_attention_heads='12', intermediate_size='3072', hidden_act='gelu', hidden_dropout_prob='0.1', attention_probs_dropout_prob='0.1', max_position_embeddings='512', type_vocab_size='2', initializer_range='0.02'",132,187,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,from_dict,"cls, json_object",190,196,6,0,5,1,4,1,2,1,4,2,2,2,1,1,0.20,11,12,18,17,35,23,158.324668461995,7.79166666666667,0.128342245989305,1233.61304176638,68.5340578759101,20.3197435459245,0.038341112782099,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,from_json_file,"cls, json_file",198,203,5,0,4,1,3,1,1,1,3,1,1,1,1,1,0.25,9,14,19,18,37,23,167.371792374109,5.78571428571429,0.17283950617284,968.365370164491,53.7980761202495,28.9284579412041,0.0326265819835266,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,__repr__,self,205,206,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,4,7,5,12,9,38.0391000173078,3.125,0.32,118.872187554087,6.60401041967148,12.1725120055385,0.00805871100793169,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,to_dict,self,208,211,4,0,3,1,2,1,1,1,2,1,1,1,1,0,0.33,6,7,8,9,17,13,62.9074752083986,3.85714285714286,0.259259259259259,242.643118660966,13.4801732589426,16.3093454243996,0.0129675340826782,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,to_json_string,self,213,215,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,9,10,14,11,25,19,106.19818783609,4.95,0.202020202020202,525.681029788644,29.2045016549247,21.4541793608262,0.0217116892877492,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,__init__,"self, hidden_size, eps='1e-12'",222,228,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, x",230,234,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",239,248,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_ids, token_type_ids=None",250,264,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",268,282,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,transpose_for_scores,"self, x",284,287,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,11,13,25,21,46,24,210.908275033173,8.88461538461539,0.112554112554113,1873.83890510242,104.102161394579,23.7385937266775,0.0506640899845542,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,forward,"self, hidden_states, attention_mask",289,315,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",319,323,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, hidden_states, input_tensor",325,329,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",333,336,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_tensor, attention_mask",338,341,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",345,351,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, hidden_states",353,356,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",360,364,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, hidden_states, input_tensor",366,370,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",374,378,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, hidden_states, attention_mask",380,384,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",388,391,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, hidden_states, attention_mask, output_all_encoded_layers=True",393,401,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",405,408,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, hidden_states",410,416,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",420,427,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, hidden_states",429,433,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config, bert_model_embedding_weights",437,447,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, hidden_states",449,452,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config, bert_model_embedding_weights",456,458,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, sequence_output",460,462,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",466,468,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, pooled_output",470,472,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config, bert_model_embedding_weights",476,479,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, sequence_output, pooled_output",481,484,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config, *inputs, **kwargs",491,500,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,init_bert_weights,"self, module",502,513,12,0,8,1,7,4,6,1,6,4,4,4,1,1,0.50,12,21,47,42,89,33,448.951076622902,12,0.0833333333333333,5387.41291947483,299.300717748602,37.4125897185752,0.102439060687124,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,from_pretrained,"cls, pretrained_model_name_or_path, state_dict=None, cache_dir=None, from_tf=False, *inputs, **kwargs",515,636,121,3,85,3,82,33,18466,2,67,18,18,18,4,2,0.39,31,107,301,258,559,138,3973.665171339,37.3738317757009,0.0267566891722931,148511.093646586,8250.61631369919,106.322123864284,0.934798505646259,0,0,0,0,0,1,1
pytorch_pretrained_bert\modeling.py,load,"module, prefix=''",616,622,7,0,7,1,6,0,3,1,5,3,3,3,1,2,0.00,18,18,43,29,72,36,372.234600103846,14.5,0.0689655172413793,5397.40170150577,299.855650083654,25.6713517312998,0.102565642842753,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling.py,__init__,"self, config",683,688,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True",690,719,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",772,776,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_ids, token_type_ids=None, attention_mask=None, masked_lm_labels=None, next_sentence_label=None",778,790,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",835,839,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_ids, token_type_ids=None, attention_mask=None, masked_lm_labels=None",841,851,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",897,901,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_ids, token_type_ids=None, attention_mask=None, next_sentence_label=None",903,913,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config, num_labels",961,967,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_ids, token_type_ids=None, attention_mask=None, labels=None",969,979,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config, num_choices",1026,1032,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_ids, token_type_ids=None, attention_mask=None, labels=None",1034,1048,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config, num_labels",1096,1102,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_ids, token_type_ids=None, attention_mask=None, labels=None",1104,1121,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,__init__,"self, config",1171,1177,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,6,11,17,19,36,17,147.148662285012,5.18181818181818,0.192982456140351,762.4976136587,42.3609785365944,28.3971102655287,0.0278208933350113,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling.py,forward,"self, input_ids, token_type_ids=None, attention_mask=None, start_positions=None, end_positions=None",1179,1203,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,8,7,16,18,34,15,132.83428025069,10.2857142857143,0.0972222222222222,1366.29545400709,75.9053030003941,12.9144439132615,0.0410432579888638,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,load_tf_weights_in_gpt2,"model, gpt2_checkpoint_path",46,97,52,1,48,4,44,4,140,4,39,11,11,11,4,3,0.08,23,62,148,146,294,85,1884.36093522448,27.0806451612903,0.0369267421083979,51029.7098426114,2834.98388014508,69.5833102941739,0.458593059718782,0,0,0,0,0,5,0
pytorch_pretrained_bert\modeling_gpt2.py,gelu,x,100,101,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,9,13,21,18,39,22,173.917833126855,6.23076923076923,0.160493827160494,1083.64188332886,60.2023268516035,27.912738649989,0.0351670495659916,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, vocab_size_or_config_json_file='50257', n_positions='1024', n_ctx='1024', n_embd='768', n_layer='12', n_head='12', layer_norm_epsilon='1e-05', initializer_range='0.02'",108,150,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,from_dict,"cls, json_object",154,160,6,0,5,1,4,1,2,1,4,2,2,2,1,1,0.20,11,12,18,17,35,23,158.324668461995,7.79166666666667,0.128342245989305,1233.61304176638,68.5340578759101,20.3197435459245,0.038341112782099,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,from_json_file,"cls, json_file",162,167,5,0,4,1,3,1,1,1,3,1,1,1,1,1,0.25,9,14,19,18,37,23,167.371792374109,5.78571428571429,0.17283950617284,968.365370164491,53.7980761202495,28.9284579412041,0.0326265819835266,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,__repr__,self,169,170,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,4,7,5,12,9,38.0391000173078,3.125,0.32,118.872187554087,6.60401041967148,12.1725120055385,0.00805871100793169,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,to_dict,self,172,175,4,0,3,1,2,1,1,1,2,1,1,1,1,0,0.33,6,7,8,9,17,13,62.9074752083986,3.85714285714286,0.259259259259259,242.643118660966,13.4801732589426,16.3093454243996,0.0129675340826782,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,to_json_string,self,177,179,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,9,10,14,11,25,19,106.19818783609,4.95,0.202020202020202,525.681029788644,29.2045016549247,21.4541793608262,0.0217116892877492,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, nf, nx",183,189,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,forward,"self, x",191,195,11,0,5,1,4,6,1,1,4,1,1,1,1,0,1.20,8,14,36,31,67,22,298.781918448699,8.85714285714286,0.112903225806452,2646.35413483133,147.019674157296,33.7334424054983,0.0637740580281057,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, nx, n_ctx, config, scale=False",199,209,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,_attn,"self, q, k, v",211,224,10,1,9,1,8,0,2,1,8,2,2,2,1,1,0.00,12,22,56,50,106,34,539.271061172536,13.6363636363636,0.0733333333333333,7353.6962887164,408.538682706467,39.546544485986,0.126051844441615,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,merge_heads,"self, x",222,225,4,0,4,1,3,1,1,1,3,1,1,1,1,0,0.25,11,12,32,24,56,23,253.319469539193,11,0.0909090909090909,2786.51416493112,154.806342496173,23.0290426853812,0.0660064306654621,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,split_heads,"self, x, k=False",227,233,7,0,7,1,6,3,2,1,5,2,2,2,1,1,0.43,15,13,42,32,74,28,355.744264232263,18.4615384615385,0.0541666666666667,6567.58641659562,364.86591203309,19.2694809792476,0.116900385300834,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,forward,"self, x, layer_past=None",235,249,11,0,5,1,4,6,1,1,4,1,1,1,1,0,1.20,8,14,36,31,67,22,298.781918448699,8.85714285714286,0.112903225806452,2646.35413483133,147.019674157296,33.7334424054983,0.0637740580281057,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, n_state, config",253,258,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,forward,"self, x",260,263,11,0,5,1,4,6,1,1,4,1,1,1,1,0,1.20,8,14,36,31,67,22,298.781918448699,8.85714285714286,0.112903225806452,2646.35413483133,147.019674157296,33.7334424054983,0.0637740580281057,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, n_ctx, config, scale=False",267,273,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,forward,"self, x, layer_past=None",275,280,11,0,5,1,4,6,1,1,4,1,1,1,1,0,1.20,8,14,36,31,67,22,298.781918448699,8.85714285714286,0.112903225806452,2646.35413483133,147.019674157296,33.7334424054983,0.0637740580281057,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, model_embeddings_weights, config",286,289,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,set_embeddings_weights,"self, model_embeddings_weights",291,294,4,0,4,1,3,1,1,1,3,1,1,1,1,0,0.25,8,12,19,19,38,20,164.23326760572,6.33333333333333,0.157894736842105,1040.14402816956,57.7857793427533,25.9315685693242,0.0342195582334444,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,forward,"self, hidden_state",296,300,11,0,5,1,4,6,1,1,4,1,1,1,1,0,1.20,8,14,36,31,67,22,298.781918448699,8.85714285714286,0.112903225806452,2646.35413483133,147.019674157296,33.7334424054983,0.0637740580281057,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, config",306,312,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,forward,"self, hidden_states, mc_token_ids",314,324,11,0,5,1,4,6,1,1,4,1,1,1,1,0,1.20,8,14,36,31,67,22,298.781918448699,8.85714285714286,0.112903225806452,2646.35413483133,147.019674157296,33.7334424054983,0.0637740580281057,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, config, *inputs, **kwargs",332,342,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,set_tied,self,344,345,4,0,2,1,1,2,1,1,1,1,1,1,1,0,1.00,4,8,9,10,19,12,68.114287513702,2.5,0.4,170.285718784255,9.46031771023639,27.2457150054808,0.01024072954112,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,init_weights,"self, module",347,358,12,0,8,1,7,4,6,1,6,4,4,4,1,1,0.50,12,21,47,42,89,33,448.951076622902,12,0.0833333333333333,5387.41291947483,299.300717748602,37.4125897185752,0.102439060687124,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,from_pretrained,"cls, pretrained_model_name_or_path, state_dict=None, cache_dir=None, from_tf=False, *inputs, **kwargs",360,477,117,7,85,4,81,25,4618,2,60,17,17,17,4,2,0.29,29,100,298,252,550,129,3856.17499048279,36.54,0.0273672687465791,140904.634152241,7828.03523068006,105.53297729838,0.902600555344888,0,0,0,0,0,1,1
pytorch_pretrained_bert\modeling_gpt2.py,load,"module, prefix=''",448,455,8,0,8,1,7,0,3,1,5,3,3,3,1,2,0.00,18,18,43,29,72,36,372.234600103846,14.5,0.0689655172413793,5397.40170150577,299.855650083654,25.6713517312998,0.102565642842753,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, config",514,522,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,forward,"self, input_ids, position_ids=None, token_type_ids=None, past=None",524,552,11,0,5,1,4,6,1,1,4,1,1,1,1,0,1.20,8,14,36,31,67,22,298.781918448699,8.85714285714286,0.112903225806452,2646.35413483133,147.019674157296,33.7334424054983,0.0637740580281057,0,0,1,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, config",594,598,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,set_tied,self,600,603,4,0,2,1,1,2,1,1,1,1,1,1,1,0,1.00,4,8,9,10,19,12,68.114287513702,2.5,0.4,170.285718784255,9.46031771023639,27.2457150054808,0.01024072954112,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,forward,"self, input_ids, position_ids=None, token_type_ids=None, lm_labels=None, past=None",605,612,11,0,5,1,4,6,1,1,4,1,1,1,1,0,1.20,8,14,36,31,67,22,298.781918448699,8.85714285714286,0.112903225806452,2646.35413483133,147.019674157296,33.7334424054983,0.0637740580281057,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_gpt2.py,__init__,"self, config",659,664,6,0,6,1,5,1,1,1,5,1,1,1,1,0,0.17,6,13,21,24,45,19,191.156738104961,5.53846153846154,0.180555555555556,1058.71424181209,58.8174578784496,34.5144110467291,0.034625648455343,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,set_tied,self,666,669,4,0,2,1,1,2,1,1,1,1,1,1,1,0,1.00,4,8,9,10,19,12,68.114287513702,2.5,0.4,170.285718784255,9.46031771023639,27.2457150054808,0.01024072954112,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_gpt2.py,forward,"self, input_ids, mc_token_ids, lm_labels=None, mc_labels=None, token_type_ids=None, position_ids=None, past=None",671,684,11,0,5,1,4,6,1,1,4,1,1,1,1,0,1.20,8,14,36,31,67,22,298.781918448699,8.85714285714286,0.112903225806452,2646.35413483133,147.019674157296,33.7334424054983,0.0637740580281057,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,load_tf_weights_in_openai_gpt,"model, openai_checkpoint_folder_path",46,113,68,4,58,3,55,8,138,3,51,11,11,11,5,3,0.14,24,70,239,230,469,94,3074.10217143681,39.4285714285714,0.0253623188405797,121207.457045223,6733.74761362349,77.9663594204988,0.816391181890645,0,0,0,0,0,4,0
pytorch_pretrained_bert\modeling_openai.py,gelu,x,116,117,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,9,13,21,18,39,22,173.917833126855,6.23076923076923,0.160493827160494,1083.64188332886,60.2023268516035,27.912738649989,0.0351670495659916,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,swish,x,120,121,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,6,4,7,6,13,10,43.1850652335357,4.5,0.222222222222222,194.332793550911,10.7962663083839,9.59668116300794,0.0111834587733184,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, vocab_size_or_config_json_file='40478', n_special='0', n_positions='512', n_ctx='512', n_embd='768', n_layer='12', n_head='12', afn='gelu', resid_pdrop='0.1', embd_pdrop='0.1', attn_pdrop='0.1', layer_norm_epsilon='1e-05', initializer_range='0.02'",131,191,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,from_dict,"cls, json_object",199,205,6,0,5,1,4,1,2,1,4,2,2,2,1,1,0.20,11,12,18,17,35,23,158.324668461995,7.79166666666667,0.128342245989305,1233.61304176638,68.5340578759101,20.3197435459245,0.038341112782099,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,from_json_file,"cls, json_file",207,212,5,0,4,1,3,1,1,1,3,1,1,1,1,1,0.25,9,14,19,18,37,23,167.371792374109,5.78571428571429,0.17283950617284,968.365370164491,53.7980761202495,28.9284579412041,0.0326265819835266,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,__repr__,self,214,215,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,4,7,5,12,9,38.0391000173078,3.125,0.32,118.872187554087,6.60401041967148,12.1725120055385,0.00805871100793169,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,to_dict,self,217,220,4,0,3,1,2,1,1,1,2,1,1,1,1,0,0.33,6,7,8,9,17,13,62.9074752083986,3.85714285714286,0.259259259259259,242.643118660966,13.4801732589426,16.3093454243996,0.0129675340826782,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,to_json_string,self,222,224,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,9,10,14,11,25,19,106.19818783609,4.95,0.202020202020202,525.681029788644,29.2045016549247,21.4541793608262,0.0217116892877492,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, nf, rf, nx",228,238,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,forward,"self, x",240,247,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,7,9,15,16,31,16,124,6.22222222222222,0.160714285714286,771.555555555555,42.8641975308642,19.9285714285714,0.02804078798652,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, nx, n_ctx, config, scale=False",251,263,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,_attn,"self, q, k, v",265,280,12,1,9,1,8,2,2,1,8,2,2,2,1,1,0.22,13,21,56,48,104,34,529.096135490035,14.8571428571429,0.0673076923076923,7860.85687013767,436.714270563204,35.6122398887524,0.131782781888265,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,merge_heads,"self, x",278,281,4,0,4,1,3,1,1,1,3,1,1,1,1,0,0.25,11,12,32,24,56,23,253.319469539193,11,0.0909090909090909,2786.51416493112,154.806342496173,23.0290426853812,0.0660064306654621,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,split_heads,"self, x, k=False",283,289,7,0,7,1,6,1,2,1,5,2,2,2,1,1,0.14,15,13,42,32,74,28,355.744264232263,18.4615384615385,0.0541666666666667,6567.58641659562,364.86591203309,19.2694809792476,0.116900385300834,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,forward,"self, x",291,301,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,7,9,15,16,31,16,124,6.22222222222222,0.160714285714286,771.555555555555,42.8641975308642,19.9285714285714,0.02804078798652,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, n_state, config",305,311,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,forward,"self, x",313,316,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,7,9,15,16,31,16,124,6.22222222222222,0.160714285714286,771.555555555555,42.8641975308642,19.9285714285714,0.02804078798652,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, n_ctx, config, scale=False",320,326,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,forward,"self, x",328,333,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,7,9,15,16,31,16,124,6.22222222222222,0.160714285714286,771.555555555555,42.8641975308642,19.9285714285714,0.02804078798652,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, model_embeddings_weights, config",339,342,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,set_embeddings_weights,"self, model_embeddings_weights",344,347,4,0,4,1,3,1,1,1,3,1,1,1,1,0,0.25,8,12,19,19,38,20,164.23326760572,6.33333333333333,0.157894736842105,1040.14402816956,57.7857793427533,25.9315685693242,0.0342195582334444,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,forward,"self, hidden_state",349,353,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,7,9,15,16,31,16,124,6.22222222222222,0.160714285714286,771.555555555555,42.8641975308642,19.9285714285714,0.02804078798652,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, config",359,367,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,forward,"self, hidden_states, mc_token_ids",369,379,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,7,9,15,16,31,16,124,6.22222222222222,0.160714285714286,771.555555555555,42.8641975308642,19.9285714285714,0.02804078798652,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, config, *inputs, **kwargs",387,397,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,init_weights,"self, module",399,410,12,0,8,1,7,4,6,1,6,4,4,4,1,1,0.50,12,21,47,42,89,33,448.951076622902,12,0.0833333333333333,5387.41291947483,299.300717748602,37.4125897185752,0.102439060687124,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,set_num_special_tokens,"self, num_special_tokens",412,413,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,3,5,3,8,8,24,2.5,0.4,60,3.33333333333333,9.6,0.00510872954929035,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,from_pretrained,"cls, pretrained_model_name_or_path, num_special_tokens=None, state_dict=None, cache_dir=None, from_tf=False, *inputs, **kwargs",415,533,118,7,85,4,81,26,4618,2,60,17,17,17,4,2,0.31,29,102,307,257,564,131,3966.85057286712,36.5343137254902,0.0273715282436603,144926.163331268,8051.45351840378,108.578762493612,0.919693835232809,0,0,0,0,0,1,0
pytorch_pretrained_bert\modeling_openai.py,load,"module, prefix=''",503,510,8,0,8,1,7,0,3,1,5,3,3,3,1,2,0.00,18,18,43,29,72,36,372.234600103846,14.5,0.0689655172413793,5397.40170150577,299.855650083654,25.6713517312998,0.102565642842753,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, config",587,596,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,set_num_special_tokens,"self, num_special_tokens",599,612,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,3,5,3,8,8,24,2.5,0.4,60,3.33333333333333,9.6,0.00510872954929035,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,forward,"self, input_ids, position_ids=None, token_type_ids=None",614,640,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,7,9,15,16,31,16,124,6.22222222222222,0.160714285714286,771.555555555555,42.8641975308642,19.9285714285714,0.02804078798652,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, config",699,703,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,set_num_special_tokens,"self, num_special_tokens",705,710,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,3,5,3,8,8,24,2.5,0.4,60,3.33333333333333,9.6,0.00510872954929035,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,forward,"self, input_ids, position_ids=None, token_type_ids=None, lm_labels=None",712,719,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,7,9,15,16,31,16,124,6.22222222222222,0.160714285714286,771.555555555555,42.8641975308642,19.9285714285714,0.02804078798652,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,__init__,"self, config",783,788,63,1,41,16,25,21,4,1,19,4,4,4,3,2,0.51,18,49,97,103,200,67,1213.21783809155,18.9183673469388,0.0528586839266451,22952.1007328749,1275.11670738194,64.1290982378492,0.269211560924346,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_openai.py,set_num_special_tokens,"self, num_special_tokens",790,795,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,3,5,3,8,8,24,2.5,0.4,60,3.33333333333333,9.6,0.00510872954929035,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_openai.py,forward,"self, input_ids, mc_token_ids, lm_labels=None, mc_labels=None, token_type_ids=None, position_ids=None",797,810,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,7,9,15,16,31,16,124,6.22222222222222,0.160714285714286,771.555555555555,42.8641975308642,19.9285714285714,0.02804078798652,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,build_tf_to_pytorch_map,"model, config",55,125,71,4,58,1,57,9,72,1,28,9,9,9,4,3,0.16,17,69,209,196,405,86,2602.63722565435,24.1449275362319,0.0414165666266507,62840.4872165239,3491.13817869577,107.792298061315,0.526871986104363,0,0,1,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,load_tf_weights_in_transfo_xl,"model, config, tf_path",127,180,54,3,44,3,41,7,44,3,39,9,9,9,7,4,0.16,26,54,153,138,291,80,1839.68107561222,33.2222222222222,0.0301003344481605,61118.2935120061,3395.460750667,55.3750156538796,0.517201241217372,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, vocab_size_or_config_json_file='267735', cutoffs=['20000', '40000', '200000'], d_model='1024', d_embed='1024', n_head='16', d_head='64', d_inner='4096', div_val='4', pre_lnorm=False, n_layer='18', tgt_len='128', ext_len='0', mem_len='1600', clamp_len='1000', same_length=True, proj_share_all_but_first=True, attn_type='0', sample_softmax=(- '1'), adaptive=True, tie_weight=True, dropout='0.1', dropatt='0.0', untie_r=True, init='normal', init_range='0.01', proj_init_std='0.01', init_std='0.02'",186,287,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,1,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,from_dict,"cls, json_object",290,296,6,0,5,1,4,1,2,1,4,2,2,2,1,1,0.20,11,12,18,17,35,23,158.324668461995,7.79166666666667,0.128342245989305,1233.61304176638,68.5340578759101,20.3197435459245,0.038341112782099,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,from_json_file,"cls, json_file",298,303,5,0,4,1,3,1,1,1,3,1,1,1,1,1,0.25,9,14,19,18,37,23,167.371792374109,5.78571428571429,0.17283950617284,968.365370164491,53.7980761202495,28.9284579412041,0.0326265819835266,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,__repr__,self,305,306,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,4,7,5,12,9,38.0391000173078,3.125,0.32,118.872187554087,6.60401041967148,12.1725120055385,0.00805871100793169,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,to_dict,self,308,311,4,0,3,1,2,1,1,1,2,1,1,1,1,0,0.33,6,7,8,9,17,13,62.9074752083986,3.85714285714286,0.259259259259259,242.643118660966,13.4801732589426,16.3093454243996,0.0129675340826782,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,to_json_string,self,313,315,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,9,10,14,11,25,19,106.19818783609,4.95,0.202020202020202,525.681029788644,29.2045016549247,21.4541793608262,0.0217116892877492,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, demb",319,325,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, pos_seq, bsz=None",327,334,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, d_model, d_inner, dropout, pre_lnorm=False",338,354,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, inp",356,370,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, n_head, d_model, d_head, dropout, dropatt='0', pre_lnorm=False, r_r_bias=None, r_w_bias=None",373,400,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, h, attn_mask=None, mems=None",402,451,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, n_head, d_model, d_head, dropout, dropatt='0', tgt_len=None, ext_len=None, mem_len=None, pre_lnorm=False, r_r_bias=None, r_w_bias=None",454,481,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,_parallelogram_mask,"self, h, w, left=False",483,492,10,1,9,1,8,0,2,1,7,2,2,2,1,1,0.00,12,15,52,36,88,27,418.430100190385,14.4,0.0694444444444444,6025.39344274155,334.744080152308,29.0576458465545,0.110374568547785,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,_shift,"self, x, qlen, klen, mask, left=False",494,510,17,3,14,1,13,0,4,1,9,3,3,3,1,1,0.00,14,24,102,82,184,38,965.61866247362,23.9166666666667,0.0418118466898955,23094.3796774941,1283.02109319411,40.3742994762489,0.270322967461451,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,_rel_shift,"self, x, zero_triu=False",512,526,15,4,11,1,10,0,2,1,10,2,2,2,1,1,0.00,14,22,85,71,156,36,806.508300225001,22.5909090909091,0.0442655935613682,18219.7556914466,1012.20864952481,35.7005686216298,0.230802466027938,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, w, r, attn_mask=None, mems=None",528,529,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, *args, **kwargs",532,535,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, w, r, attn_mask=None, mems=None",537,610,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, *args, **kwargs",613,614,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, w, r_emb, r_w_bias, r_bias, attn_mask=None, mems=None",616,695,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, n_head, d_model, d_head, d_inner, dropout, **kwargs",698,703,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, dec_inp, dec_attn_mask=None, mems=None",705,711,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, n_head, d_model, d_head, d_inner, dropout, **kwargs",714,721,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, dec_inp, r_emb, r_w_bias, r_bias, dec_attn_mask=None, mems=None",723,730,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, n_head, d_model, d_head, d_inner, dropout, **kwargs",733,740,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, dec_inp, r, dec_attn_mask=None, mems=None",742,749,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, n_token, d_embed, d_proj, cutoffs, div_val='1', sample_softmax=False",753,781,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, inp",783,813,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, config, *inputs, **kwargs",820,829,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,init_weight,"self, weight",831,835,5,0,5,1,4,0,3,1,3,3,3,3,1,1,0.00,9,13,31,29,60,22,267.565897118238,10.0384615384615,0.0996168582375479,2685.94996722539,149.219442623633,26.6540740424298,0.064408624467272,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,init_bias,"self, bias",837,838,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,7,8,8,16,12,57.3594000115385,2.85714285714286,0.35,163.884000032967,9.10466666849817,20.0757900040385,0.00998243403419704,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,init_weights,"self, m",840,879,40,0,38,1,37,2,47,1,32,24,24,24,1,4,0.05,17,49,202,166,368,66,2224.33703592391,28.7959183673469,0.034727143869596,64051.8277079314,3558.43487266285,77.2448722610004,0.533621226196479,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,set_num_special_tokens,"self, num_special_tokens",881,882,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,3,5,3,8,8,24,2.5,0.4,60,3.33333333333333,9.6,0.00510872954929035,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,from_pretrained,"cls, pretrained_model_name_or_path, state_dict=None, cache_dir=None, from_tf=False, *inputs, **kwargs",884,980,96,5,66,3,63,25,522,2,48,12,12,12,4,1,0.38,28,85,248,211,459,113,3130.46214374857,34.7529411764706,0.0287745429925525,108792.766736862,6044.04259649234,90.0776175418513,0.75964746513278,0,0,0,0,0,1,0
pytorch_pretrained_bert\modeling_transfo_xl.py,load,"module, prefix=''",955,961,7,0,7,1,6,0,3,1,5,3,3,3,1,2,0.00,18,18,43,29,72,36,372.234600103846,14.5,0.0689655172413793,5397.40170150577,299.855650083654,25.6713517312998,0.102565642842753,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, config",1023,1096,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,backward_compatible,self,1098,1099,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,6,4,6,5,11,10,36.541209043761,3.75,0.266666666666667,137.029533914104,7.61275188411687,9.7443224116696,0.00885975132504212,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,reset_length,"self, tgt_len, ext_len, mem_len",1102,1105,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,6,5,12,14,26,11,89.9452220845697,8.4,0.119047619047619,755.539865510386,41.9744369727992,10.7077645338774,0.0276513921650145,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,init_mems,"self, data",1107,1118,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,6,4,8,7,15,10,49.8289214233104,5.25,0.19047619047619,261.60183747238,14.5334354151322,9.49122312824961,0.0136345017506334,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,_update_mems,"self, hids, mems, qlen, mlen",1120,1141,22,4,11,1,10,7,3,1,11,3,3,3,1,2,0.64,18,23,57,49,106,41,567.900512489517,19.1739130434783,0.0521541950113379,10888.8750438207,604.937502434486,29.618394075417,0.163757332240116,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,_forward,"self, dec_inp, mems=None",1143,1231,89,13,76,1,75,4,54,1,61,17,17,17,1,4,0.05,23,56,364,318,682,79,4299.17847025678,65.3035714285714,0.0153130981678972,280751.70831659,15597.3171286995,65.8337419563522,1.429202224969,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, input_ids, mems=None",1233,1257,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl.py,__init__,"self, config",1310,1323,8,1,7,2,5,0,1,1,3,1,1,1,1,0,0.00,7,17,31,30,61,24,279.682712543991,6.17647058823529,0.161904761904762,1727.45204806582,95.9695582258791,45.2819629833128,0.0479898522055984,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,tie_weights,self,1325,1341,17,0,14,1,13,3,17,1,11,9,9,9,1,4,0.21,16,26,85,79,164,42,884.340057335717,24.3076923076923,0.0411392405063291,21496.2660090836,1194.23700050464,36.3810783081149,0.257703765118466,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,reset_length,"self, tgt_len, ext_len, mem_len",1343,1344,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,6,5,12,14,26,11,89.9452220845697,8.4,0.119047619047619,755.539865510386,41.9744369727992,10.7077645338774,0.0276513921650145,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,init_mems,"self, data",1346,1347,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,6,4,8,7,15,10,49.8289214233104,5.25,0.19047619047619,261.60183747238,14.5334354151322,9.49122312824961,0.0136345017506334,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl.py,forward,"self, input_ids, target=None, mems=None",1349,1381,25,2,7,1,6,16,2,1,6,2,2,2,1,1,2.29,10,13,35,31,66,23,298.555089099763,11.9230769230769,0.0838709677419355,3559.69529311256,197.760849617364,25.0401042470769,0.0777118584064468,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl_utilities.py,__init__,"self, n_token, d_embed, d_proj, cutoffs, div_val='1', keep_order=False",32,76,45,10,35,2,33,0,10,1,27,6,6,6,1,3,0.00,20,35,144,146,290,55,1676.59431692215,41.7142857142857,0.023972602739726,69937.9343630383,3885.44079794657,40.1923295152571,0.565831706231856,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl_utilities.py,_compute_logit,"self, hidden, weight, bias, proj",78,90,13,1,7,1,6,5,2,1,5,2,2,2,1,1,0.71,11,12,34,29,63,23,284.984403231592,13.2916666666667,0.0752351097178683,3787.91769295324,210.439871830736,21.44083284501,0.0809988962849982,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl_utilities.py,forward,"self, hidden, target=None, keep_order=False",92,195,104,15,75,1,74,15,1116,1,59,17,17,17,7,4,0.20,28,74,366,306,672,102,4483.86982980484,57.8918918918919,0.0172735760971055,259579.707444378,14421.094858021,77.4524667146495,1.35641496011397,0,0,0,0,0,0,1
pytorch_pretrained_bert\modeling_transfo_xl_utilities.py,log_prob,"self, hidden",198,257,60,9,38,1,37,13,16,1,31,7,7,7,1,3,0.34,15,49,192,183,375,64,2250,28.0102040816327,0.0357012750455373,63022.9591836735,3501.27551020408,80.327868852459,0.527891423357558,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl_utilities.py,__init__,"self, range_max, n_sample",261,279,45,10,35,2,33,0,10,1,27,6,6,6,1,3,0.00,20,35,144,146,290,55,1676.59431692215,41.7142857142857,0.023972602739726,69937.9343630383,3885.44079794657,40.1923295152571,0.565831706231856,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl_utilities.py,sample,"self, labels",281,300,20,2,10,1,9,8,1,1,9,1,1,1,1,1,0.80,11,19,40,42,82,30,402.365028839899,12.1578947368421,0.0822510822510822,4891.91166642192,271.772870356774,33.0949590820696,0.0960574712567068,0,0,0,0,0,0,0
pytorch_pretrained_bert\modeling_transfo_xl_utilities.py,sample_logits,"embedding, bias, labels, inputs, sampler",302,333,32,4,19,1,18,9,1,1,16,1,1,1,1,0,0.47,12,36,107,91,198,48,1105.82257514279,15.1666666666667,0.0659340659340659,16771.6423896656,931.757910536979,72.9113785808432,0.218404948619928,0,0,0,0,0,0,0
pytorch_pretrained_bert\optimization.py,warmup_cosine,"x, warmup='0.002'",23,26,4,0,4,1,3,0,2,1,3,2,2,2,1,1,0.00,12,10,18,15,33,22,147.161243415031,9,0.111111111111111,1324.45119073528,73.5806217075154,16.3512492683368,0.0402009254282256,0,0,0,0,0,0,1
pytorch_pretrained_bert\optimization.py,warmup_constant,"x, warmup='0.002'",28,31,4,0,4,1,3,0,2,1,3,2,2,2,1,1,0.00,9,5,11,9,20,14,76.1470984411521,8.1,0.123456790123457,616.791497373332,34.2661942985184,9.40087635075952,0.0241529953321968,0,0,0,0,0,0,1
pytorch_pretrained_bert\optimization.py,warmup_linear,"x, warmup='0.002'",33,36,4,0,4,1,3,0,2,1,3,2,2,2,1,1,0.00,10,5,12,10,22,15,85.9515931033874,10,0.1,859.515931033874,47.7508850574374,8.59515931033874,0.0301333927721598,0,0,0,0,0,0,1
pytorch_pretrained_bert\optimization.py,__init__,"self, params, lr=required, warmup=(- '1'), t_total=(- '1'), schedule='warmup_linear', b1='0.9', b2='0.999', e='1e-06', weight_decay='0.01', max_grad_norm='1.0'",59,77,19,0,19,3,16,0,64,1,14,7,7,7,7,1,0.00,17,34,105,90,195,51,1106.12294168444,22.5,0.0444444444444444,24887.7661878999,1382.65367710555,49.1610196304196,0.284142386652212,0,0,0,0,0,0,1
pytorch_pretrained_bert\optimization.py,get_lr,self,79,92,14,0,14,1,13,0,5,1,12,5,5,5,4,3,0.00,17,20,46,41,87,37,453.222442809719,17.425,0.0573888091822095,7897.40106595935,438.744503664408,26.0098962875018,0.132190894484114,0,0,0,0,0,0,1
pytorch_pretrained_bert\optimization.py,step,"self, closure=None",94,162,69,13,34,1,33,22,132,1,32,10,10,10,5,3,0.65,25,47,131,125,256,72,1579.50080036923,33.2446808510638,0.03008,52510.000012275,2917.22222290417,47.5113840751065,0.467419425767774,0,0,0,0,0,0,0
pytorch_pretrained_bert\optimization_openai.py,warmup_cosine,"x, warmup='0.002'",23,25,3,0,3,1,2,0,1,1,2,1,1,1,1,0,0.00,14,12,25,21,46,26,216.22022703449,12.25,0.0816326530612245,2648.69778117251,147.149876731806,17.6506307783257,0.0638117052407439,0,0,0,0,0,0,1
pytorch_pretrained_bert\optimization_openai.py,warmup_constant,"x, warmup='0.002'",27,29,3,0,3,1,2,0,1,1,2,1,1,1,1,0,0.00,13,7,17,15,32,20,138.301699036396,13.9285714285714,0.0717948717948718,1926.34509372122,107.019171873401,9.92935275133097,0.0516061514637142,0,0,0,0,0,0,1
pytorch_pretrained_bert\optimization_openai.py,warmup_linear,"x, warmup='0.002'",31,33,3,0,3,1,2,0,1,1,2,1,1,1,1,0,0.00,13,7,20,16,36,20,155.589411415945,14.8571428571429,0.0673076923076923,2311.61411246547,128.423006248082,10.4723642299194,0.0582758974070957,0,0,0,0,0,0,1
pytorch_pretrained_bert\optimization_openai.py,__init__,"self, params, lr=required, schedule='warmup_linear', warmup=(- '1'), t_total=(- '1'), b1='0.9', b2='0.999', e='1e-08', weight_decay='0', vector_l2=False, max_grad_norm=(- '1'), **kwargs",45,63,19,0,19,3,16,0,64,1,14,7,7,7,7,1,0.00,19,36,113,94,207,55,1196.7414606996,24.8055555555556,0.0403135498320269,29685.8367890208,1649.2131549456,48.2448965119661,0.319579030968819,0,0,0,0,0,0,0
pytorch_pretrained_bert\optimization_openai.py,get_lr,self,65,78,14,0,14,1,13,0,5,1,12,5,5,5,4,3,0.00,17,20,46,41,87,37,453.222442809719,17.425,0.0573888091822095,7897.40106595935,438.744503664408,26.0098962875018,0.132190894484114,0,0,0,0,0,0,0
pytorch_pretrained_bert\optimization_openai.py,step,"self, closure=None",80,140,61,14,36,1,35,11,132,1,34,10,10,10,5,3,0.31,27,52,155,149,304,79,1916.34934744584,38.6826923076923,0.0258513547104151,74129.5521612943,4118.30845340524,49.5402267298949,0.588219832159696,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,load_vocab,vocab_file,50,62,13,0,12,1,11,1,3,1,11,3,3,3,3,3,0.08,16,17,31,27,58,33,292.57485892279,12.7058823529412,0.0787037037037037,3717.42173690134,206.523429827852,23.0267250078122,0.0799907866897228,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,whitespace_tokenize,text,65,71,7,0,6,1,5,1,2,1,5,2,2,2,1,1,0.17,9,6,15,11,26,15,101.579155485821,8.25,0.121212121212121,838.028032758027,46.5571129310015,12.3126249073723,0.0296290533666621,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,__init__,"self, vocab_file, do_lower_case=True, max_len=None, never_split=('[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]')",77,89,13,0,13,2,11,0,2,1,7,2,2,2,1,1,0.00,16,32,62,54,116,48,647.855650083654,13.5,0.0740740740740741,8746.05127612933,485.891737562741,47.989307413604,0.141499017629074,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,tokenize,"self, text",91,96,50,7,31,1,30,13,45,1,29,9,9,9,7,4,0.42,23,26,74,66,140,49,786.059378176129,29.1923076923077,0.0342555994729908,22946.8872321416,1274.82706845231,26.9269352207897,0.269170792315936,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization.py,convert_tokens_to_ids,"self, tokens",98,109,12,0,11,1,10,1,4,1,6,3,3,3,1,1,0.09,13,15,26,26,52,28,249.982455946995,11.2666666666667,0.0887573964497041,2816.46900366948,156.47050020386,22.1877919479582,0.0664786302684199,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,convert_ids_to_tokens,"self, ids",111,116,6,0,5,1,4,1,2,1,4,2,2,2,1,1,0.20,10,8,14,13,27,18,112.587975038942,8.125,0.123076923076923,914.777297191407,50.8209609550782,13.8569815432545,0.0314115232392422,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,from_pretrained,"cls, pretrained_model_name_or_path, cache_dir=None, *inputs, **kwargs",118,154,36,0,28,1,27,8,20,1,18,6,6,6,1,1,0.29,17,36,83,75,158,53,905.011431820986,17.7083333333333,0.0564705882352941,16026.2441051633,890.346894731294,51.1065279145968,0.211884854371384,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization.py,__init__,"self, do_lower_case=True, never_split=('[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]')",160,169,13,0,13,2,11,0,2,1,7,2,2,2,1,1,0.00,16,32,62,54,116,48,647.855650083654,13.5,0.0740740740740741,8746.05127612933,485.891737562741,47.989307413604,0.141499017629074,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,tokenize,"self, text",171,190,50,7,31,1,30,13,45,1,29,9,9,9,7,4,0.42,23,26,74,66,140,49,786.059378176129,29.1923076923077,0.0342555994729908,22946.8872321416,1274.82706845231,26.9269352207897,0.269170792315936,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization.py,_run_strip_accents,"self, text",192,201,10,0,9,1,8,1,3,1,8,3,3,3,3,2,0.11,13,15,25,24,49,28,235.560391180823,10.4,0.0961538461538461,2449.82806828055,136.10155934892,22.6500376135406,0.0605762636807036,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,_run_split_on_punc,"self, text",203,223,21,1,19,1,18,1,5,1,17,5,5,5,1,3,0.05,18,19,51,42,93,37,484.479163003492,19.8947368421053,0.0502645502645503,9638.5854534379,535.476969635439,24.3521272409163,0.150968942637074,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,_tokenize_chinese_chars,"self, text",225,236,12,0,11,1,10,1,3,1,9,3,3,3,1,2,0.09,12,13,28,28,56,25,260.055946627385,12.9230769230769,0.0773809523809524,3360.72300256928,186.706833476071,20.1233768223571,0.0747883395227789,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,_is_chinese_char,"self, cp",238,258,21,1,11,1,10,16,2,1,3,2,2,2,1,1,1.45,12,20,50,36,86,32,430,10.8,0.0925925925925926,4644,258,39.8148148148148,0.0927840985437422,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,_clean_text,"self, text",260,271,12,0,11,1,10,1,5,1,9,4,4,4,3,2,0.09,15,16,31,27,58,31,287.343386002439,12.65625,0.0790123456790123,3636.68972909337,202.038318282965,22.7036749434026,0.0788284363524509,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,__init__,"self, vocab, unk_token='[UNK]', max_input_chars_per_word='100'",277,280,13,0,13,2,11,0,2,1,7,2,2,2,1,1,0.00,16,32,62,54,116,48,647.855650083654,13.5,0.0740740740740741,8746.05127612933,485.891737562741,47.989307413604,0.141499017629074,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,tokenize,"self, text",282,331,50,7,31,1,30,13,45,1,29,9,9,9,7,4,0.42,23,26,74,66,140,49,786.059378176129,29.1923076923077,0.0342555994729908,22946.8872321416,1274.82706845231,26.9269352207897,0.269170792315936,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization.py,_is_whitespace,char,334,343,10,0,7,1,6,3,3,1,6,3,3,3,3,1,0.43,11,11,24,17,41,22,182.836696364129,8.5,0.117647058823529,1554.1119190951,86.3395510608388,21.5101995722505,0.044723275772664,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,_is_control,char,346,355,10,0,7,1,6,3,3,1,6,3,3,3,3,1,0.43,11,11,23,16,39,22,173.917833126855,8,0.125,1391.34266501484,77.2968147230465,21.7397291408568,0.041543346743398,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization.py,_is_punctuation,char,358,371,14,0,9,1,8,5,3,1,7,3,3,3,3,1,0.56,13,18,40,29,69,31,341.839545416694,10.4722222222222,0.0954907161803713,3579.81968394705,198.878871330392,32.6425030106127,0.0780044740771232,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_gpt2.py,lru_cache,,30,31,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,2,6,3,9,7,25.2661942985184,3.75,0.266666666666667,94.7482286194441,5.26379047885801,6.73765181293825,0.00692775964222594,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_gpt2.py,bytes_to_unicode,,49,69,20,0,11,1,10,9,3,1,10,3,3,3,1,2,0.82,15,23,53,53,106,38,556.28031642502,17.2826086956522,0.0578616352201258,9613.97503386719,534.109724103733,32.1872887491207,0.150711851528859,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_gpt2.py,get_pairs,word,71,81,11,1,7,1,6,3,2,1,6,2,2,2,1,1,0.43,10,10,18,18,36,20,155.589411415945,9,0.111111111111111,1400.30470274351,77.7947057079725,17.2877123795495,0.0417215508596257,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_gpt2.py,from_pretrained,"cls, pretrained_model_name_or_path, cache_dir=None, *inputs, **kwargs",88,129,41,0,33,1,32,8,10,1,21,5,5,5,1,1,0.24,18,41,102,99,201,59,1182.41125292173,21.7317073170732,0.0460157126823794,25695.8152769088,1427.5452931616,54.4094964868585,0.290259881064512,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_gpt2.py,__init__,"self, vocab_file, merges_file, errors='replace', max_len=None",131,144,14,1,12,1,11,2,1,1,11,1,1,1,1,0,0.17,16,40,80,74,154,56,894.332657996871,14.8,0.0675675675675676,13236.1233383537,735.340185464094,60.4278822970859,0.186517369649667,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_gpt2.py,__len__,self,146,147,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,4,6,5,11,9,34.8691750158654,3.125,0.32,108.96617192458,6.05367621803219,11.1581360050769,0.00760454454094143,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_gpt2.py,bpe,"self, token",149,188,40,3,37,1,36,0,23,1,34,9,9,9,8,3,0.00,24,30,107,99,206,54,1185.50682544567,39.6,0.0252525252525253,46946.0702876487,2608.11501598048,29.9370410466079,0.43378870706007,1,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_gpt2.py,encode,"self, text",190,201,12,0,12,1,11,0,4,1,7,3,3,3,1,1,0.00,13,26,45,45,90,39,475.686199697602,11.25,0.0888888888888889,5351.46974659803,297.303874811001,42.283217750898,0.101982924468635,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_gpt2.py,decode,"self, tokens",203,206,4,0,4,1,3,0,1,1,3,1,1,1,1,0,0.00,10,13,25,24,49,23,221.654535846794,9.23076923076923,0.108333333333333,2046.04186935502,113.668992741945,24.012574716736,0.0537223608604645,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,get_pairs,word,45,55,11,0,7,1,6,4,2,1,6,2,2,2,1,1,0.57,10,10,18,18,36,20,155.589411415945,9,0.111111111111111,1400.30470274351,77.7947057079725,17.2877123795495,0.0417215508596257,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,text_standardize,text,57,70,14,0,10,1,9,4,1,1,9,1,1,1,1,0,0.40,7,21,41,48,89,28,427.854588063127,8,0.125,3422.83670450501,190.157594694723,53.4818235078908,0.0757070282310241,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,from_pretrained,"cls, pretrained_model_name_or_path, cache_dir=None, *inputs, **kwargs",80,121,41,0,33,1,32,8,10,1,21,5,5,5,1,1,0.24,18,41,102,99,201,59,1182.41125292173,21.7317073170732,0.0460157126823794,25695.8152769088,1427.5452931616,54.4094964868585,0.290259881064512,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_openai.py,__init__,"self, vocab_file, merges_file, special_tokens=None, max_len=None",123,142,20,1,19,3,16,0,2,3,15,2,2,2,1,1,0.00,20,50,103,87,190,70,1164.56377321954,17.4,0.0574712643678161,20263.4096540201,1125.74498077889,66.9289524838818,0.247753859263701,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,__len__,self,144,145,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,6,5,9,8,17,11,58.8103375168341,4.8,0.208333333333333,282.289620080804,15.6827566711558,12.2521536493404,0.0143441676155824,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,set_special_tokens,"self, special_tokens",147,161,15,0,10,1,9,5,3,1,9,3,3,3,1,1,0.50,15,21,49,42,91,36,470.46317513125,15,0.0666666666666667,7056.94762696876,392.052645942709,31.3642116754167,0.122637514905109,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,bpe,"self, token",163,204,42,3,39,1,38,0,44,1,36,10,10,10,8,3,0.00,24,33,121,108,229,57,1335.73181324373,39.2727272727273,0.025462962962963,52457.8312110263,2914.32395616813,34.0116896890764,0.46710978632625,2,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,tokenize,"self, text",206,219,14,0,11,1,10,3,4,1,9,4,4,4,1,2,0.27,14,15,51,44,95,29,461.508194537119,20.5333333333333,0.0487012987012987,9476.30159449552,526.461199694195,22.4760484352493,0.149269585925282,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,convert_tokens_to_ids,"self, tokens",221,240,20,0,19,1,18,1,8,1,12,6,6,6,4,2,0.05,17,24,64,57,121,41,648.263792558788,20.1875,0.0495356037151703,13086.8253122805,727.045850682252,32.1121383310855,0.185112160162403,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,convert_ids_to_tokens,"self, ids, skip_special_tokens=False",242,251,10,0,9,1,8,1,4,1,7,4,4,4,1,3,0.11,14,10,30,23,53,24,243.003012538221,16.1,0.062111801242236,3912.34850186536,217.352694548076,15.0933548160386,0.0827631670216572,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_openai.py,decode,"self, ids, skip_special_tokens=False, clean_up_tokenization_spaces=False",253,263,11,0,10,1,9,1,2,1,6,2,2,2,1,1,0.10,9,42,73,71,144,51,816.829249243895,7.60714285714286,0.131455399061033,6213.73678889106,345.207599382837,107.37661492408,0.112662827658463,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,from_pretrained,"cls, pretrained_model_name_or_path, cache_dir=None, *inputs, **kwargs",57,91,41,1,35,1,34,5,66,1,24,8,8,8,1,1,0.14,20,44,127,109,236,64,1416,24.7727272727273,0.0403669724770642,35078.1818181818,1948.78787878788,57.1596330275229,0.357193429736227,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_transfo_xl.py,__init__,"self, special=[], min_freq='0', max_size=None, lower_case=False, delimiter=None, vocab_file=None, never_split=('<unk>', '<eos>', '<formula>')",93,102,12,3,9,2,7,0,1,1,7,1,1,1,1,0,0.00,12,11,34,33,67,23,303.07865105582,18,0.0555555555555556,5455.41571900476,303.07865105582,16.8377028364344,0.103299284269354,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,count_file,"self, path, verbose=False, add_eos=False",104,117,14,2,12,1,11,0,6,1,12,4,4,4,1,3,0.00,19,27,54,49,103,46,568.926881473872,17.2407407407407,0.0580021482277121,9808.72086392917,544.928936884954,32.9989813099776,0.152740308110336,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,count_sents,"self, sents, verbose=False",119,127,9,0,6,1,5,3,6,1,6,4,4,4,1,2,0.50,14,17,31,29,60,31,297.251778623213,11.9411764705882,0.083743842364532,3549.53594473601,197.196441374223,24.8930060915991,0.0775639285428787,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,_build_from_file,"self, vocab_file",129,142,14,1,13,1,12,0,6,1,10,4,4,4,3,2,0.00,15,22,48,42,90,37,468.850802906606,14.3181818181818,0.0698412698412698,6713.09104161731,372.949502312073,32.7451354410963,0.118620687461477,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,build_vocab,self,144,163,20,3,17,1,16,0,7,1,14,5,5,5,4,3,0.00,13,23,59,57,116,36,599.711300167308,16.1086956521739,0.0620782726045884,9660.56681356468,536.698156309149,37.2290415758383,0.151198384508935,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,encode_file,"self, path, ordered=False, verbose=False, add_eos=True, add_double_eos=False",165,181,17,2,15,2,13,0,12,1,13,5,5,5,1,3,0.00,20,30,66,56,122,50,688.550455152516,18.6666666666667,0.0535714285714286,12852.9418295136,714.052323861869,36.8866315260277,0.182900028553498,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,encode_sents,"self, sents, ordered=False, verbose=False",183,194,12,2,10,1,9,0,12,1,10,5,5,5,1,2,0.00,16,20,43,37,80,36,413.594000115385,14.8,0.0675675675675676,6121.1912017077,340.06617787265,27.9455405483368,0.111541387411853,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,add_special,"self, sym",196,200,5,0,5,1,4,0,2,1,4,2,2,2,1,1,0.00,11,13,27,27,54,24,247.587975038942,11.4230769230769,0.0875420875420875,2828.21648409869,157.123138005483,21.6743681852273,0.0666633567271326,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,add_symbol,"self, sym",202,205,4,0,4,1,3,0,2,1,3,2,2,2,1,1,0.00,11,8,18,17,35,19,148.677462970525,11.6875,0.0855614973262032,1737.66784846802,96.5371026926676,12.7210663504193,0.0481788677006194,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,get_sym,"self, idx",207,209,3,0,3,1,2,0,1,1,2,1,1,1,1,0,0.00,10,8,14,13,27,18,112.587975038942,8.125,0.123076923076923,914.777297191407,50.8209609550782,13.8569815432545,0.0314115232392422,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,get_idx,"self, sym",211,225,15,0,12,1,11,3,5,1,7,5,5,5,5,2,0.25,12,12,41,32,73,24,334.702262552644,16,0.0625,5355.23620084231,297.513122269017,20.9188914095403,0.102030770386776,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,convert_ids_to_tokens,"self, indices",227,229,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,9,6,10,9,19,15,74.2309213165619,6.75,0.148148148148148,501.058718886793,27.8365954937107,10.9971735283795,0.0210283159851671,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,convert_tokens_to_ids,"self, symbols",231,233,3,0,2,1,1,1,1,1,1,1,1,1,1,0,0.50,9,6,10,9,19,15,74.2309213165619,6.75,0.148148148148148,501.058718886793,27.8365954937107,10.9971735283795,0.0210283159851671,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,convert_to_tensor,"self, symbols",235,236,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,6,6,9,8,17,12,60.9443625122597,4,0.25,243.777450049039,13.543191669391,15.2360906280649,0.0130079172426106,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,decode,"self, indices, exclude=None",238,243,6,0,5,1,4,1,2,1,3,2,2,2,1,1,0.20,15,9,32,22,54,24,247.587975038942,18.3333333333333,0.0545454545454545,4539.11287571395,252.172937539664,13.5047986384878,0.0913817351954731,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,__len__,self,245,246,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,5,4,6,5,11,9,34.8691750158654,3.125,0.32,108.96617192458,6.05367621803219,11.1581360050769,0.00760454454094143,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,_run_split_on_punc,"self, text",248,268,21,1,19,1,18,1,5,1,17,5,5,5,1,3,0.05,18,19,51,42,93,37,484.479163003492,19.8947368421053,0.0502645502645503,9638.5854534379,535.476969635439,24.3521272409163,0.150968942637074,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_transfo_xl.py,_run_strip_accents,"self, text",270,279,10,0,9,1,8,1,3,1,8,3,3,3,3,2,0.11,13,15,25,24,49,28,235.560391180823,10.4,0.0961538461538461,2449.82806828055,136.10155934892,22.6500376135406,0.0605762636807036,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_transfo_xl.py,_clean_text,"self, text",281,292,12,0,11,1,10,1,5,1,9,4,4,4,3,2,0.09,15,16,31,27,58,31,287.343386002439,12.65625,0.0790123456790123,3636.68972909337,202.038318282965,22.7036749434026,0.0788284363524509,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_transfo_xl.py,whitespace_tokenize,"self, text",294,303,10,0,9,1,8,1,3,1,7,3,3,3,1,1,0.11,12,9,24,19,43,21,188.869649179487,12.6666666666667,0.0789473684210526,2392.34888960683,132.908271644824,14.9107617773279,0.0596250041530231,0,0,1,0,0,0,1
pytorch_pretrained_bert\tokenization_transfo_xl.py,tokenize,"self, line, add_eos=False, add_double_eos=False",305,323,19,3,16,1,15,1,9,1,13,5,5,5,3,2,0.06,17,19,56,44,100,36,516.992500144231,19.6842105263158,0.0508021390374332,10176.5892133654,565.366067409189,26.2643248736374,0.15653576310325,0,0,1,0,0,0,1
pytorch_pretrained_bert\tokenization_transfo_xl.py,__init__,"self, data, bsz, bptt, device='cpu', ext_len=None",327,347,12,3,9,2,7,0,1,1,7,1,1,1,1,0,0.00,12,11,34,33,67,23,303.07865105582,18,0.0555555555555556,5455.41571900476,303.07865105582,16.8377028364344,0.103299284269354,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,get_batch,"self, i, bptt=None",349,362,14,4,10,1,9,0,2,1,10,2,2,2,1,1,0.00,13,21,60,60,120,34,610.495540950041,18.5714285714286,0.0538461538461538,11337.7743319293,629.876351773852,32.8728368203868,0.168227613606461,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,get_fixlen_iter,"self, start='0'",364,366,3,0,3,1,2,0,2,1,2,2,2,2,1,1,0.00,10,11,19,17,36,21,158.123427220035,7.72727272727273,0.129411764705882,1221.86284670027,67.8812692611263,20.4630317578869,0.0380972579270882,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,get_varlen_iter,"self, start='0', std='5', min_len='5', max_deviation='3'",368,378,11,0,11,1,10,0,3,1,10,3,3,3,3,2,0.00,19,26,57,56,113,45,620.579399885253,20.4615384615385,0.0488721804511278,12698.0092591906,705.44495884392,30.3290684154447,0.181427244624138,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,__iter__,self,380,381,6,1,4,1,3,1,2,1,3,2,2,2,1,1,0.25,8,6,12,10,22,14,83.7618082852673,6.66666666666667,0.15,558.412055235115,31.0228919575064,12.5642712427901,0.0226038249620779,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,__init__,"self, data, bsz, bptt, device='cpu', ext_len=None, shuffle=False",385,396,12,3,9,2,7,0,1,1,7,1,1,1,1,0,0.00,12,11,34,33,67,23,303.07865105582,18,0.0555555555555556,5455.41571900476,303.07865105582,16.8377028364344,0.103299284269354,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,get_sent_stream,self,398,405,7,1,6,1,5,0,2,1,5,2,2,2,1,1,0.00,9,12,20,19,39,21,171.300379488372,7.125,0.140350877192982,1220.51520385465,67.8064002141471,24.0421585246837,0.0380692400855186,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,stream_iterator,"self, sent_stream",407,454,48,9,34,1,33,5,16,1,31,8,8,8,5,5,0.15,29,32,145,131,276,61,1636.88350516736,59.359375,0.0168465385627797,97164.3818145436,5398.02121191909,27.5758210925798,0.704504016152105,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,__iter__,self,456,461,6,1,4,1,3,1,2,1,3,2,2,2,1,1,0.25,8,6,12,10,22,14,83.7618082852673,6.66666666666667,0.15,558.412055235115,31.0228919575064,12.5642712427901,0.0226038249620779,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,__init__,"self, paths, vocab, bsz, bptt, device='cpu', ext_len=None, shuffle=False",465,476,12,3,9,2,7,0,1,1,7,1,1,1,1,0,0.00,12,11,34,33,67,23,303.07865105582,18,0.0555555555555556,5455.41571900476,303.07865105582,16.8377028364344,0.103299284269354,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,get_sent_stream,"self, path",478,484,7,1,6,1,5,0,2,1,5,2,2,2,1,1,0.00,9,12,20,19,39,21,171.300379488372,7.125,0.140350877192982,1220.51520385465,67.8064002141471,24.0421585246837,0.0380692400855186,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,__iter__,self,486,494,6,1,4,1,3,1,2,1,3,2,2,2,1,1,0.25,8,6,12,10,22,14,83.7618082852673,6.66666666666667,0.15,558.412055235115,31.0228919575064,12.5642712427901,0.0226038249620779,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,from_pretrained,"cls, pretrained_model_name_or_path, cache_dir=None, *inputs, **kwargs",498,539,41,1,35,1,34,5,66,1,24,8,8,8,1,1,0.14,20,44,127,109,236,64,1416,24.7727272727273,0.0403669724770642,35078.1818181818,1948.78787878788,57.1596330275229,0.357193429736227,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_transfo_xl.py,__init__,"self, *args, **kwargs",541,546,12,3,9,2,7,0,1,1,7,1,1,1,1,0,0.00,12,11,34,33,67,23,303.07865105582,18,0.0555555555555556,5455.41571900476,303.07865105582,16.8377028364344,0.103299284269354,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,build_corpus,"self, path, dataset",548,585,38,3,34,1,33,1,16,1,19,7,7,7,1,1,0.03,13,31,194,174,368,44,2009.07083565853,36.4838709677419,0.0274093722369584,73298.6811332191,4072.14895184551,55.0673703849817,0.583816258805428,0,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,get_iterator,"self, split, *args, **kwargs",587,601,15,1,14,1,13,0,7,1,10,7,7,7,1,2,0.00,16,25,80,64,144,41,771.487488665004,20.48,0.048828125,15800.0637678593,877.781320436627,37.6702875324709,0.209886564269996,2,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,get_lm_corpus,"datadir, dataset",604,633,30,2,28,1,27,0,7,1,22,7,7,7,1,2,0.00,20,37,94,85,179,57,1044.08731253549,22.972972972973,0.0435294117647059,23985.7896123018,1332.5438673501,45.4485065456624,0.277235021905823,4,0,0,0,0,0,0
pytorch_pretrained_bert\tokenization_transfo_xl.py,_is_whitespace,char,635,644,10,0,7,1,6,3,3,1,6,3,3,3,3,1,0.43,11,11,24,17,41,22,182.836696364129,8.5,0.117647058823529,1554.1119190951,86.3395510608388,21.5101995722505,0.044723275772664,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_transfo_xl.py,_is_control,char,647,656,10,0,7,1,6,3,3,1,6,3,3,3,3,1,0.43,11,11,23,16,39,22,173.917833126855,8,0.125,1391.34266501484,77.2968147230465,21.7397291408568,0.041543346743398,0,0,0,0,0,0,1
pytorch_pretrained_bert\tokenization_transfo_xl.py,_is_punctuation,char,659,672,14,0,9,1,8,5,3,1,7,3,3,3,3,1,0.56,13,18,40,29,69,31,341.839545416694,10.4722222222222,0.0954907161803713,3579.81968394705,198.878871330392,32.6425030106127,0.0780044740771232,0,0,0,0,0,0,1
pytorch_pretrained_bert\__main__.py,main,,2,81,80,3,76,6,70,1,19,6,43,13,13,13,8,3,0.01,21,38,172,160,332,59,1953.03749238813,44.2105263157895,0.0226190476190476,86344.815452949,4796.9341918305,44.1758480421125,0.651182802321631,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,__init__,"self, parent, batch_size='13', seq_length='7', is_training=True, use_position_ids=True, use_token_type_ids=True, use_labels=True, vocab_size='99', n_positions='33', n_embd='32', n_layer='5', n_head='4', n_choices='3', type_sequence_label_size='2', initializer_range='0.02', num_labels='3', scope=None",32,66,35,0,35,18,17,0,1,1,17,1,1,1,1,0,0.00,8,29,75,81,156,37,812.674725038116,11.1724137931034,0.0895061728395062,9079.5383073224,504.418794851245,72.7394044015598,0.145073444318264,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,prepare_config_and_inputs,self,68,97,30,5,25,1,24,0,8,1,17,4,4,4,1,1,0.00,10,28,110,102,212,38,1112.56063285004,18.2142857142857,0.0549019607843137,20264.4972411972,1125.80540228873,61.0817602349042,0.247762724224886,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,create_gpt2_model,"self, config, input_ids, token_type_ids, position_ids, mc_labels, lm_labels, mc_token_ids",99,108,10,0,10,2,8,0,1,1,5,1,1,1,1,0,0.00,8,17,26,26,52,25,241.480521868286,6.11764705882353,0.163461538461538,1477.29260437069,82.0718113539271,39.4727776130852,0.0432370871051253,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,check_gpt2_model_output,"self, result",110,113,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,6,12,20,18,38,18,158.457150054808,4.5,0.222222222222222,713.057175246635,39.614287513702,35.2127000121795,0.026604901061711,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,create_gpt2_lm_head,"self, config, input_ids, token_type_ids, position_ids, mc_labels, lm_labels, mc_token_ids",116,127,12,0,12,2,10,0,1,1,6,1,1,1,1,0,0.00,8,19,33,34,67,27,318.577462644952,7.15789473684211,0.139705882352941,2280.34394314282,126.685774619045,44.5071455165742,0.05774915707645,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,check_gpt2_lm_head_output,"self, result",129,133,5,0,5,1,4,0,1,1,2,1,1,1,1,0,0.00,7,13,21,20,41,20,177.199051890382,5.38461538461539,0.185714285714286,954.14874094821,53.0082633860117,32.9083953510709,0.0323064669758197,0,0,0,0,0,0,1
tests\modeling_gpt2_test.py,check_gpt2_lm_head_loss_output,"self, result",135,138,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,6,8,13,10,23,14,87.5691632073249,3.75,0.266666666666667,328.384362027468,18.2435756681927,23.3517768552866,0.015865985640733,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,create_gpt2_double_heads,"self, config, input_ids, token_type_ids, position_ids, mc_labels, lm_labels, mc_token_ids",140,154,15,0,15,2,13,0,1,1,6,1,1,1,1,0,0.00,8,21,45,46,91,29,442.076270556609,8.76190476190476,0.114130434782609,3873.43018011505,215.190565561947,50.4543569657,0.0822133919531278,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,check_gpt2_double_heads_output,"self, result",156,163,8,0,8,1,7,0,1,1,3,1,1,1,1,0,0.00,7,14,33,31,64,21,281.108315057841,7.75,0.129032258064516,2178.58944169827,121.032746761015,36.2720406526246,0.0560181817516366,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,check_gpt2_double_heads_loss_output,"self, result",165,168,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,8,9,19,12,31,17,126.711348078761,5.33333333333333,0.1875,675.793856420056,37.5441031344476,23.7583777647676,0.025669746006644,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,test_default,self,170,171,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,4,5,7,7,14,9,44.3789500201924,2.8,0.357142857142857,124.261060056539,6.90339222536326,15.8496250072116,0.00830045911529385,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,test_config_to_json_string,self,173,177,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,7,15,21,23,44,22,196.214991220041,5.36666666666667,0.186335403726708,1053.02045288089,58.5011362711604,36.5617996062188,0.0345013919035719,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,run_tester,"self, tester",179,190,12,2,10,1,9,0,1,1,9,1,1,1,1,0,0.00,7,14,29,33,62,21,272.323680212283,8.25,0.121212121212121,2246.67036175134,124.815020097296,33.0089309348222,0.0571792317571686,0,0,0,0,0,0,0
tests\modeling_gpt2_test.py,ids_tensor,"cls, shape, vocab_size, rng=None, name=None",192,206,14,3,10,1,9,1,8,1,9,4,4,4,1,1,0.10,15,25,46,38,84,40,447.041959970538,11.4,0.087719298245614,5096.27834366414,283.126574648008,39.2142070149595,0.0987144746350487,0,0,0,0,0,0,0
tests\modeling_openai_test.py,__init__,"self, parent, batch_size='13', seq_length='7', is_training=True, use_position_ids=True, use_token_type_ids=True, use_labels=True, vocab_size='99', n_special='1', n_positions='33', n_embd='32', n_layer='5', n_head='4', n_choices='3', afn='gelu', resid_pdrop='0.1', attn_pdrop='0.1', embd_pdrop='0.1', type_sequence_label_size='2', initializer_range='0.02', num_labels='3', scope=None",32,76,45,0,45,23,22,0,1,1,22,1,1,1,1,0,0.00,8,37,95,106,201,45,1103.86247236226,11.4594594594595,0.0872641509433962,12649.6672508541,702.759291714115,96.3276214089712,0.180966483065494,0,0,0,0,0,0,0
tests\modeling_openai_test.py,prepare_config_and_inputs,self,78,112,35,5,30,1,29,0,8,1,17,4,4,4,1,1,0.00,11,33,127,119,246,44,1343.02017818478,19.8333333333333,0.0504201680672269,26636.5668673314,1479.8092704073,67.7153031017534,0.297301826814029,0,0,0,0,0,0,0
tests\modeling_openai_test.py,create_openai_model,"self, config, input_ids, token_type_ids, position_ids, mc_labels, lm_labels, mc_token_ids",114,122,9,0,9,2,7,0,1,1,5,1,1,1,1,0,0.00,8,15,23,23,46,23,208.083849978623,6.13333333333333,0.16304347826087,1276.24761320222,70.902645177901,33.9267146704276,0.0392194989064629,0,0,0,0,0,0,0
tests\modeling_openai_test.py,check_openai_model_output,"self, result",124,127,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,6,12,20,18,38,18,158.457150054808,4.5,0.222222222222222,713.057175246635,39.614287513702,35.2127000121795,0.026604901061711,0,0,0,0,0,0,0
tests\modeling_openai_test.py,create_openai_lm_head,"self, config, input_ids, token_type_ids, position_ids, mc_labels, lm_labels, mc_token_ids",130,140,11,0,11,2,9,0,1,1,6,1,1,1,1,0,0.00,8,17,30,31,61,25,283.275227576258,7.29411764705882,0.137096774193548,2066.24283643859,114.791268691033,38.8361199096483,0.054075389032451,0,0,0,0,0,0,0
tests\modeling_openai_test.py,check_openai_lm_head_output,"self, result",142,146,5,0,5,1,4,0,1,1,2,1,1,1,1,0,0.00,8,14,23,22,45,22,200.674422838678,6.28571428571429,0.159090909090909,1261.38208641455,70.0767825785861,31.9254763606988,0.0389143563293658,0,0,0,0,0,0,0
tests\modeling_openai_test.py,check_openai_lm_head_loss_output,"self, result",148,151,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,6,8,13,10,23,14,87.5691632073249,3.75,0.266666666666667,328.384362027468,18.2435756681927,23.3517768552866,0.015865985640733,0,0,0,0,0,0,0
tests\modeling_openai_test.py,create_openai_double_heads,"self, config, input_ids, token_type_ids, position_ids, mc_labels, lm_labels, mc_token_ids",153,166,14,0,14,2,12,0,1,1,6,1,1,1,1,0,0.00,8,19,42,43,85,27,404.165437683895,9.05263157894737,0.11046511627907,3658.76080429631,203.264489127573,44.6461820697326,0.0791470545409096,0,0,0,0,0,0,0
tests\modeling_openai_test.py,check_openai_double_heads_output,"self, result",168,175,8,0,8,1,7,0,1,1,3,1,1,1,1,0,0.00,8,15,35,33,68,23,307.602213011877,8.8,0.113636363636364,2706.89947450452,150.38330413914,34.9547969331678,0.0647431010247705,0,0,0,0,0,0,0
tests\modeling_openai_test.py,check_openai_double_heads_loss_output,"self, result",177,180,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,8,9,19,12,31,17,126.711348078761,5.33333333333333,0.1875,675.793856420056,37.5441031344476,23.7583777647676,0.025669746006644,0,0,0,0,0,0,0
tests\modeling_openai_test.py,test_default,self,182,183,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,4,5,7,7,14,9,44.3789500201924,2.8,0.357142857142857,124.261060056539,6.90339222536326,15.8496250072116,0.00830045911529385,0,0,0,0,0,0,0
tests\modeling_openai_test.py,test_config_to_json_string,self,185,189,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,7,15,21,23,44,22,196.214991220041,5.36666666666667,0.186335403726708,1053.02045288089,58.5011362711604,36.5617996062188,0.0345013919035719,0,0,0,0,0,0,0
tests\modeling_openai_test.py,run_tester,"self, tester",191,202,12,2,10,1,9,0,1,1,9,1,1,1,1,0,0.00,7,14,29,33,62,21,272.323680212283,8.25,0.121212121212121,2246.67036175134,124.815020097296,33.0089309348222,0.0571792317571686,0,0,0,0,0,0,0
tests\modeling_openai_test.py,ids_tensor,"cls, shape, vocab_size, rng=None, name=None",204,218,14,3,10,1,9,1,8,1,9,4,4,4,1,1,0.10,15,25,46,38,84,40,447.041959970538,11.4,0.087719298245614,5096.27834366414,283.126574648008,39.2142070149595,0.0987144746350487,0,0,0,0,0,0,0
tests\modeling_test.py,__init__,"self, parent, batch_size='13', seq_length='7', is_training=True, use_input_mask=True, use_token_type_ids=True, use_labels=True, vocab_size='99', hidden_size='32', num_hidden_layers='5', num_attention_heads='4', intermediate_size='37', hidden_act='gelu', hidden_dropout_prob='0.1', attention_probs_dropout_prob='0.1', max_position_embeddings='512', type_vocab_size='16', type_sequence_label_size='2', initializer_range='0.02', num_labels='3', scope=None",34,76,43,0,43,22,21,0,1,1,21,1,1,1,1,0,0.00,8,37,91,101,192,45,1054.4357944953,10.9189189189189,0.0915841584158416,11513.2989453,639.627719183334,96.5696148423911,0.16995943010867,0,0,0,0,0,0,0
tests\modeling_test.py,prepare_config_and_inputs,self,78,108,31,5,26,1,25,0,8,1,14,4,4,4,1,1,0.00,10,31,103,96,199,41,1066.152848919,15.4838709677419,0.0645833333333333,16508.1731445522,917.120730252902,68.8557048260187,0.216111605035737,0,0,0,0,0,0,0
tests\modeling_test.py,check_loss_output,"self, result",110,113,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,6,8,13,10,23,14,87.5691632073249,3.75,0.266666666666667,328.384362027468,18.2435756681927,23.3517768552866,0.015865985640733,0,0,0,0,0,0,0
tests\modeling_test.py,create_bert_model,"self, config, input_ids, token_type_ids, input_mask, sequence_labels, token_labels",115,124,10,0,10,1,9,0,1,1,5,1,1,1,1,0,0.00,10,18,30,29,59,28,283.633940401399,8.05555555555556,0.124137931034483,2284.8289643446,126.934942463589,35.2097305325874,0.0578248536589128,0,0,0,0,0,0,1
tests\modeling_test.py,check_bert_model_output,"self, result",126,133,8,0,8,1,7,0,1,1,3,1,1,1,1,0,0.00,9,15,50,45,95,24,435.57143756851,13.5,0.0740740740740741,5880.21440717488,326.678578176382,32.2645509310007,0.108594422431394,0,0,0,0,0,0,1
tests\modeling_test.py,create_bert_for_masked_lm,"self, config, input_ids, token_type_ids, input_mask, sequence_labels, token_labels",136,145,10,0,10,1,9,0,1,1,6,1,1,1,1,0,0.00,8,16,30,31,61,24,279.682712543991,7.75,0.129032258064516,2167.54102221593,120.418945678663,36.0880919411601,0.0558286289266195,0,0,0,0,0,0,1
tests\modeling_test.py,check_bert_for_masked_lm_output,"self, result",147,150,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,6,11,18,16,34,17,138.973736602512,4.36363636363636,0.229166666666667,606.430850629141,33.6906028127301,31.8481479714089,0.0238817567139228,0,0,0,0,0,0,0
tests\modeling_test.py,create_bert_for_next_sequence_prediction,"self, config, input_ids, token_type_ids, input_mask, sequence_labels, token_labels",152,161,10,0,10,1,9,0,1,1,6,1,1,1,1,0,0.00,8,16,30,31,61,24,279.682712543991,7.75,0.129032258064516,2167.54102221593,120.418945678663,36.0880919411601,0.0558286289266195,0,0,0,0,0,0,1
tests\modeling_test.py,check_bert_for_next_sequence_prediction_output,"self, result",163,166,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,6,10,15,13,28,16,112,3.9,0.256410256410256,436.8,24.2666666666667,28.7179487179487,0.0191896549208354,0,0,0,0,0,0,0
tests\modeling_test.py,create_bert_for_pretraining,"self, config, input_ids, token_type_ids, input_mask, sequence_labels, token_labels",169,179,11,0,11,1,10,0,1,1,6,1,1,1,1,0,0.00,8,18,34,35,69,26,324.330340551735,7.77777777777778,0.128571428571429,2522.56931540239,140.142739744577,41.6996152137946,0.0617695092655575,0,0,0,0,0,0,1
tests\modeling_test.py,check_bert_for_pretraining_output,"self, result",181,187,7,0,7,1,6,0,1,1,2,1,1,1,1,0,0.00,6,13,29,26,55,19,233.636013239397,6,0.166666666666667,1401.81607943638,77.8786710797991,38.9393355398995,0.0417515660612057,0,0,0,0,0,0,0
tests\modeling_test.py,create_bert_for_question_answering,"self, config, input_ids, token_type_ids, input_mask, sequence_labels, token_labels",190,200,11,0,11,1,10,0,1,1,6,1,1,1,1,0,0.00,8,18,34,35,69,26,324.330340551735,7.77777777777778,0.128571428571429,2522.56931540239,140.142739744577,41.6996152137946,0.0617695092655575,0,0,0,0,0,0,1
tests\modeling_test.py,check_bert_for_question_answering_output,"self, result",202,208,7,0,7,1,6,0,1,1,2,1,1,1,1,0,0.00,6,11,28,25,53,17,216.635530586268,6.81818181818182,0.146666666666667,1477.06043581546,82.0589131008591,31.7732111526526,0.0432325569463889,0,0,0,0,0,0,0
tests\modeling_test.py,create_bert_for_sequence_classification,"self, config, input_ids, token_type_ids, input_mask, sequence_labels, token_labels",211,220,10,0,10,1,9,0,1,1,6,1,1,1,1,0,0.00,8,17,33,34,67,25,311.138364714907,8,0.125,2489.10691771925,138.28371765107,38.8922955893633,0.0612220376094328,0,0,0,0,0,0,1
tests\modeling_test.py,check_bert_for_sequence_classification_output,"self, result",222,225,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,6,10,16,14,30,16,120,4.2,0.238095238095238,504,28,28.5714285714286,0.0211105283516163,0,0,0,0,0,0,0
tests\modeling_test.py,create_bert_for_token_classification,"self, config, input_ids, token_type_ids, input_mask, sequence_labels, token_labels",228,237,10,0,10,1,9,0,1,1,6,1,1,1,1,0,0.00,8,17,33,34,67,25,311.138364714907,8,0.125,2489.10691771925,138.28371765107,38.8922955893633,0.0612220376094328,0,0,0,0,0,0,1
tests\modeling_test.py,check_bert_for_token_classification_output,"self, result",239,242,4,0,4,1,3,0,1,1,1,1,1,1,1,0,0.00,6,11,18,16,34,17,138.973736602512,4.36363636363636,0.229166666666667,606.430850629141,33.6906028127301,31.8481479714089,0.0238817567139228,0,0,0,0,0,0,0
tests\modeling_test.py,test_default,self,245,246,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,4,5,7,7,14,9,44.3789500201924,2.8,0.357142857142857,124.261060056539,6.90339222536326,15.8496250072116,0.00830045911529385,0,0,0,0,0,0,0
tests\modeling_test.py,test_config_to_json_string,self,248,252,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,7,15,21,23,44,22,196.214991220041,5.36666666666667,0.186335403726708,1053.02045288089,58.5011362711604,36.5617996062188,0.0345013919035719,0,0,0,0,0,0,0
tests\modeling_test.py,run_tester,"self, tester",254,281,28,6,22,1,21,0,1,1,21,1,1,1,1,0,0.00,7,21,61,73,134,28,644.185559555719,12.1666666666667,0.0821917808219178,7837.59097459458,435.42172081081,52.9467583196481,0.131522627139432,0,0,0,0,0,0,0
tests\modeling_test.py,ids_tensor,"cls, shape, vocab_size, rng=None, name=None",283,297,14,3,10,1,9,1,8,1,9,4,4,4,1,1,0.10,15,25,46,38,84,40,447.041959970538,11.4,0.087719298245614,5096.27834366414,283.126574648008,39.2142070149595,0.0987144746350487,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,__init__,"self, parent, batch_size='13', seq_length='7', mem_len='30', clamp_len='15', is_training=True, use_labels=True, vocab_size='99', cutoffs=['10', '50', '80'], d_model='32', d_embed='32', n_head='4', d_head='8', d_inner='128', div_val='2', n_layer='5', scope=None, seed='1'",31,67,37,0,37,19,18,0,1,1,18,1,1,1,1,0,0.00,9,35,80,90,170,44,928.103375168341,11.5714285714286,0.0864197530864197,10739.4819126622,596.63788403679,80.2064645207208,0.162256074913418,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,prepare_config_and_inputs,self,69,90,22,3,19,1,18,0,2,1,7,2,2,2,1,1,0.00,10,24,74,71,145,34,737.682111981299,14.7916666666667,0.0676056338028169,10911.5479063901,606.197105910559,49.8714667254963,0.163984570908335,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,set_seed,self,92,94,3,0,3,1,2,0,1,1,2,1,1,1,1,0,0.00,4,6,9,10,19,10,63.1166338028599,3.33333333333333,0.3,210.388779342866,11.6882655190481,18.934990140858,0.0117912666637753,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,create_transfo_xl_model,"self, config, input_ids_1, input_ids_2, lm_labels",96,108,13,1,12,1,11,0,1,1,6,1,1,1,1,0,0.00,8,18,29,30,59,26,277.325943370324,6.66666666666667,0.15,1848.83962246883,102.713312359379,41.5988915055487,0.0502124684549259,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,check_transfo_xl_model_output,"self, result",110,122,13,0,13,1,12,0,1,1,4,1,1,1,1,0,0.00,9,17,72,65,137,26,643.96024138533,17.2058823529412,0.0581196581196581,11079.9041532476,615.550230735977,37.4267490719679,0.1656670278966,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,create_transfo_xl_lm_head,"self, config, input_ids_1, input_ids_2, lm_labels",125,145,21,3,18,1,17,0,1,1,8,1,1,1,1,0,0.00,8,28,50,53,103,36,532.502275148558,7.57142857142857,0.132075471698113,4031.80294041051,223.989052245028,70.3304891705643,0.0844393620401043,0,0,0,0,0,0,1
tests\modeling_transfo_xl_test.py,check_transfo_xl_lm_head_output,"self, result",147,178,32,1,31,1,30,0,1,1,10,1,1,1,1,0,0.00,10,25,184,165,349,35,1790.11977291379,33,0.0303030303030303,59073.9525061552,3281.88625034195,54.2460537246604,0.505602754871561,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,test_default,self,180,181,2,0,2,1,1,0,1,1,1,1,1,1,1,0,0.00,4,5,7,7,14,9,44.3789500201924,2.8,0.357142857142857,124.261060056539,6.90339222536326,15.8496250072116,0.00830045911529385,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,test_config_to_json_string,self,183,187,5,0,5,1,4,0,1,1,4,1,1,1,1,0,0.00,7,15,21,23,44,22,196.214991220041,5.36666666666667,0.186335403726708,1053.02045288089,58.5011362711604,36.5617996062188,0.0345013919035719,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,run_tester,"self, tester",189,198,10,2,8,1,7,0,1,1,7,1,1,1,1,0,0.00,7,11,23,24,47,18,195.986475067789,7.63636363636364,0.130952380952381,1496.62399142675,83.1457773014861,25.6648955445914,0.0436134605138678,0,0,0,0,0,0,0
tests\modeling_transfo_xl_test.py,ids_tensor,"cls, shape, vocab_size, rng=None, name=None",200,214,14,3,10,1,9,1,8,1,9,4,4,4,1,1,0.10,15,25,46,38,84,40,447.041959970538,11.4,0.087719298245614,5096.27834366414,283.126574648008,39.2142070149595,0.0987144746350487,0,0,0,0,0,0,0
tests\optimization_test.py,assertListAlmostEqual,"self, list1, list2, tol",27,30,4,0,4,1,3,0,2,1,3,2,2,2,1,1,0.00,8,12,22,22,44,20,190.164836175044,7.33333333333333,0.136363636363636,1394.54213195032,77.474562886129,25.9315685693242,0.0416070097926095,0,0,0,0,0,0,0
tests\optimization_test.py,test_adam,self,32,46,15,0,14,1,13,2,2,1,11,2,2,2,1,1,0.14,11,36,64,55,119,47,660.996073349639,8.40277777777778,0.11900826446281,5554.20311634071,308.566839796706,78.6639955060727,0.104542588822281,0,0,0,0,0,0,0
tests\tokenization_openai_test.py,test_full_tokenizer,self,26,53,28,3,24,1,23,2,1,1,19,1,1,1,1,1,0.08,10,65,89,98,187,75,1164.78909512273,7.53846153846154,0.13265306122449,8780.71779400212,487.81765522234,154.512839148934,0.141872675277531,0,0,0,0,0,0,1
tests\tokenization_test.py,test_full_tokenizer,self,30,47,18,4,14,1,13,3,1,1,9,1,1,1,1,1,0.21,12,42,59,61,120,54,690.586500259616,8.71428571428571,0.114754098360656,6017.96807369094,334.331559649497,79.247631177333,0.110283870146317,0,0,0,0,0,0,0
tests\tokenization_test.py,test_full_tokenizer_raises_error_for_long_sequences,self,49,65,17,2,15,1,14,2,1,1,11,1,1,1,1,1,0.13,12,45,59,64,123,57,717.445471742263,8.53333333333333,0.1171875,6122.20135886731,340.122297714851,84.0756412197965,0.111553658578098,0,0,0,0,0,0,1
tests\tokenization_test.py,test_chinese,self,67,72,6,1,5,1,4,0,1,1,2,1,1,1,1,0,0.00,7,11,14,13,27,18,112.587975038942,4.13636363636364,0.241758241758242,465.704805842898,25.8724892134943,27.2190708885355,0.0200271534322293,0,0,0,0,0,0,0
tests\tokenization_test.py,test_basic_tokenizer_lower,self,74,80,7,1,6,1,5,0,1,1,3,1,1,1,1,0,0.00,8,15,24,22,46,23,208.083849978623,5.86666666666667,0.170454545454545,1220.75858654125,67.819921474514,35.4688380645379,0.0380743008369084,0,0,0,0,0,0,0
tests\tokenization_test.py,test_basic_tokenizer_no_lower,self,82,87,6,1,5,1,4,0,1,1,2,1,1,1,1,0,0.00,8,14,18,16,34,22,151.620675033668,4.57142857142857,0.21875,693.123085868197,38.5068381037887,33.1670226636149,0.026106720606065,0,0,0,0,0,0,0
tests\tokenization_test.py,test_wordpiece_tokenizer,self,89,107,19,4,15,1,14,4,2,1,8,2,2,2,1,1,0.27,10,24,51,48,99,34,503.658821283784,10,0.1,5036.58821283784,279.810456268769,50.3658821283784,0.097942166948177,0,0,0,0,0,0,0
tests\tokenization_test.py,test_is_whitespace,self,109,117,9,1,8,1,7,0,1,1,7,1,1,1,1,0,0.00,4,12,24,30,54,16,216,5,0.2,1080,60,43.2,0.0350882128585544,0,0,0,0,0,0,0
tests\tokenization_test.py,test_is_control,self,119,125,7,1,6,1,5,0,1,1,5,1,1,1,1,0,0.00,4,10,18,22,40,14,152.294196882304,4.4,0.227272727272727,670.094466282138,37.2274703490077,34.6123174732509,0.0255252164158028,0,0,0,0,0,0,0
tests\tokenization_test.py,test_is_punctuation,self,127,134,8,1,7,1,6,0,1,1,6,1,1,1,1,0,0.00,4,11,21,26,47,15,183.6238579936,4.72727272727273,0.211538461538462,868.040055969747,48.2244475538749,38.8435084217232,0.0303322939542148,0,0,0,0,0,0,0
tests\tokenization_transfo_xl_test.py,test_full_tokenizer,self,28,44,17,3,14,1,13,0,1,1,10,1,1,1,1,1,0.00,13,40,59,59,118,53,675.894613638458,9.5875,0.104302477183833,6480.13960825871,360.007756014373,70.4974825177009,0.115860390224377,0,0,0,0,0,0,1
tests\tokenization_transfo_xl_test.py,test_full_tokenizer_lower,self,46,52,7,1,6,1,5,0,1,1,3,1,1,1,1,0,0.00,8,15,24,22,46,23,208.083849978623,5.86666666666667,0.170454545454545,1220.75858654125,67.819921474514,35.4688380645379,0.0380743008369084,0,0,0,0,0,0,1
tests\tokenization_transfo_xl_test.py,test_full_tokenizer_no_lower,self,54,59,6,1,5,1,4,0,1,1,2,1,1,1,1,0,0.00,8,14,18,16,34,22,151.620675033668,4.57142857142857,0.21875,693.123085868197,38.5068381037887,33.1670226636149,0.026106720606065,0,0,0,0,0,0,1
tests\tokenization_transfo_xl_test.py,test_is_whitespace,self,61,69,9,1,8,1,7,0,1,1,7,1,1,1,1,0,0.00,4,12,24,30,54,16,216,5,0.2,1080,60,43.2,0.0350882128585544,0,0,0,0,0,0,0
tests\tokenization_transfo_xl_test.py,test_is_control,self,71,77,7,1,6,1,5,0,1,1,5,1,1,1,1,0,0.00,4,10,18,22,40,14,152.294196882304,4.4,0.227272727272727,670.094466282138,37.2274703490077,34.6123174732509,0.0255252164158028,0,0,0,0,0,0,0
tests\tokenization_transfo_xl_test.py,test_is_punctuation,self,79,86,8,1,7,1,6,0,1,1,6,1,1,1,1,0,0.00,4,11,21,26,47,15,183.6238579936,4.72727272727273,0.211538461538462,868.040055969747,48.2244475538749,38.8435084217232,0.0303322939542148,0,0,0,0,0,0,0

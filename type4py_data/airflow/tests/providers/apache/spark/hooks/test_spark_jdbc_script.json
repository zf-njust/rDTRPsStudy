{"error": null, "response": {"classes": [{"cls_lc": [[41, 0], [220, 9]], "cls_var_ln": {"default_arguments": [[81, 4], [81, 21]], "jdbc_arguments": [[42, 4], [42, 18]]}, "cls_var_occur": {"default_arguments": [], "jdbc_arguments": []}, "funcs": [{"docstring": {"func": null, "long_descr": null, "ret": null}, "fn_lc": [[103, 4], [109, 77]], "fn_var_ln": {"parsed_arguments": [[105, 8], [105, 24]]}, "fn_var_occur": {"parsed_arguments": [["parsed_arguments", "_parse_arguments", "args", "self", "jdbc_arguments"], ["getattr", "parsed_arguments", "argument_name", "argument_value"]]}, "name": "test_parse_arguments", "params": {"self": ""}, "params_descr": {"self": ""}, "params_occur": {"self": [["parsed_arguments", "_parse_arguments", "args", "self", "jdbc_arguments"], ["self", "default_arguments", "items"]]}, "params_p": {"args": [], "kwargs": [], "self": []}, "q_name": "TestSparkJDBCScrip.test_parse_arguments", "ret_exprs": [], "ret_type": "", "variables": {"parsed_arguments": ""}, "variables_p": {"parsed_arguments": []}}, {"docstring": {"func": null, "long_descr": null, "ret": null}, "fn_lc": [[112, 4], [134, 9]], "fn_var_ln": {"arguments": [[114, 8], [114, 17]], "spark_session": [[115, 8], [115, 21]]}, "fn_var_occur": {"arguments": [["arguments", "_parse_arguments", "SPARK_WRITE_TO_JDBC", "self", "jdbc_arguments"], ["spark_session", "mock_spark_session", "builder", "appName", "arguments", "name", "enableHiveSupport", "getOrCreate"], ["_run_spark", "arguments", "arguments"], ["mock_spark_write_to_jdbc", "assert_called_once_with", "spark_session", "arguments", "url", "arguments", "user", "arguments", "password", "arguments", "metastore_table", "arguments", "jdbc_table", "arguments", "jdbc_driver", "arguments", "truncate", "arguments", "save_mode", "arguments", "batch_size", "arguments", "num_partitions", "arguments", "create_table_column_types"]], "spark_session": [["spark_session", "mock_spark_session", "builder", "appName", "arguments", "name", "enableHiveSupport", "getOrCreate"], ["mock_spark_write_to_jdbc", "assert_called_once_with", "spark_session", "arguments", "url", "arguments", "user", "arguments", "password", "arguments", "metastore_table", "arguments", "jdbc_table", "arguments", "jdbc_driver", "arguments", "truncate", "arguments", "save_mode", "arguments", "batch_size", "arguments", "num_partitions", "arguments", "create_table_column_types"]]}, "name": "test_run_spark_write_to_jdbc", "params": {"mock_spark_session": "", "mock_spark_write_to_jdbc": "", "self": ""}, "params_descr": {"mock_spark_session": "", "mock_spark_write_to_jdbc": "", "self": ""}, "params_occur": {"mock_spark_session": [["spark_session", "mock_spark_session", "builder", "appName", "arguments", "name", "enableHiveSupport", "getOrCreate"]], "mock_spark_write_to_jdbc": [["mock_spark_write_to_jdbc", "assert_called_once_with", "spark_session", "arguments", "url", "arguments", "user", "arguments", "password", "arguments", "metastore_table", "arguments", "jdbc_table", "arguments", "jdbc_driver", "arguments", "truncate", "arguments", "save_mode", "arguments", "batch_size", "arguments", "num_partitions", "arguments", "create_table_column_types"]], "self": [["arguments", "_parse_arguments", "SPARK_WRITE_TO_JDBC", "self", "jdbc_arguments"]]}, "params_p": {"args": [], "kwargs": [], "mock_spark_session": [], "mock_spark_write_to_jdbc": [], "self": []}, "q_name": "TestSparkJDBCScrip.test_run_spark_write_to_jdbc", "ret_exprs": [], "ret_type": "", "variables": {"arguments": "", "spark_session": ""}, "variables_p": {"arguments": [["str", 0.3319329798154421], ["Dict[str, Union[int, str]]", 0.10929630237736974], ["Dict[str, List[str]]", 0.10485825398493845]], "spark_session": [["Dict[str, Dict[Any, Any]]", 0.20846890381153238], ["Dict[Any, Union[Any, Any]]", 0.1239375972502954], ["Pattern[str]", 0.10923316480390734], ["Dict[str, Dict[Any, str]]", 0.1053967706612524], ["Dict[str, List[Any]]", 0.10200666736684147], ["Dict[str, Union[Any, Any]]", 0.09934792746920763], ["Dict[Any, str]", 0.08534517414412143], ["List[Tuple[str, Any]]", 0.08412434857297246], ["rotkehlchen.tests.utils.mock.MockResponse", 0.0821394459198694]]}}, {"docstring": {"func": null, "long_descr": null, "ret": null}, "fn_lc": [[137, 4], [161, 9]], "fn_var_ln": {"arguments": [[139, 8], [139, 17]], "spark_session": [[140, 8], [140, 21]]}, "fn_var_occur": {"arguments": [["arguments", "_parse_arguments", "SPARK_READ_FROM_JDBC", "self", "jdbc_arguments"], ["spark_session", "mock_spark_session", "builder", "appName", "arguments", "name", "enableHiveSupport", "getOrCreate"], ["_run_spark", "arguments", "arguments"], ["mock_spark_read_from_jdbc", "assert_called_once_with", "spark_session", "arguments", "url", "arguments", "user", "arguments", "password", "arguments", "metastore_table", "arguments", "jdbc_table", "arguments", "jdbc_driver", "arguments", "save_mode", "arguments", "save_format", "arguments", "fetch_size", "arguments", "num_partitions", "arguments", "partition_column", "arguments", "lower_bound", "arguments", "upper_bound"]], "spark_session": [["spark_session", "mock_spark_session", "builder", "appName", "arguments", "name", "enableHiveSupport", "getOrCreate"], ["mock_spark_read_from_jdbc", "assert_called_once_with", "spark_session", "arguments", "url", "arguments", "user", "arguments", "password", "arguments", "metastore_table", "arguments", "jdbc_table", "arguments", "jdbc_driver", "arguments", "save_mode", "arguments", "save_format", "arguments", "fetch_size", "arguments", "num_partitions", "arguments", "partition_column", "arguments", "lower_bound", "arguments", "upper_bound"]]}, "name": "test_run_spark_read_from_jdbc", "params": {"mock_spark_read_from_jdbc": "", "mock_spark_session": "", "self": ""}, "params_descr": {"mock_spark_read_from_jdbc": "", "mock_spark_session": "", "self": ""}, "params_occur": {"mock_spark_read_from_jdbc": [["mock_spark_read_from_jdbc", "assert_called_once_with", "spark_session", "arguments", "url", "arguments", "user", "arguments", "password", "arguments", "metastore_table", "arguments", "jdbc_table", "arguments", "jdbc_driver", "arguments", "save_mode", "arguments", "save_format", "arguments", "fetch_size", "arguments", "num_partitions", "arguments", "partition_column", "arguments", "lower_bound", "arguments", "upper_bound"]], "mock_spark_session": [["spark_session", "mock_spark_session", "builder", "appName", "arguments", "name", "enableHiveSupport", "getOrCreate"]], "self": [["arguments", "_parse_arguments", "SPARK_READ_FROM_JDBC", "self", "jdbc_arguments"]]}, "params_p": {"args": [], "kwargs": [], "mock_spark_read_from_jdbc": [], "mock_spark_session": [], "self": []}, "q_name": "TestSparkJDBCScrip.test_run_spark_read_from_jdbc", "ret_exprs": [], "ret_type": "", "variables": {"arguments": "", "spark_session": ""}, "variables_p": {"arguments": [["str", 0.3319329798154421], ["Dict[str, Union[int, str]]", 0.10929630237736974], ["Dict[str, List[str]]", 0.10485825398493845]], "spark_session": [["Dict[str, Dict[Any, Any]]", 0.20846890381153238], ["Dict[Any, Union[Any, Any]]", 0.1239375972502954], ["Pattern[str]", 0.10923316480390734], ["Dict[str, Dict[Any, str]]", 0.1053967706612524], ["Dict[str, List[Any]]", 0.10200666736684147], ["Dict[str, Union[Any, Any]]", 0.09934792746920763], ["Dict[Any, str]", 0.08534517414412143], ["List[Tuple[str, Any]]", 0.08412434857297246], ["rotkehlchen.tests.utils.mock.MockResponse", 0.0821394459198694]]}}, {"docstring": {"func": null, "long_descr": null, "ret": null}, "fn_lc": [[165, 4], [189, 74]], "fn_var_ln": {"arguments": [[167, 8], [167, 17]], "spark_session": [[168, 8], [168, 21]]}, "fn_var_occur": {"arguments": [["arguments", "_parse_arguments", "self", "jdbc_arguments"], ["spark_session", "_create_spark_session", "arguments"], ["spark_session", "sql", "arguments", "metastore_table"], ["spark_write_to_jdbc", "spark_session", "spark_session", "url", "arguments", "url", "user", "arguments", "user", "password", "arguments", "password", "metastore_table", "arguments", "metastore_table", "jdbc_table", "arguments", "jdbc_table", "driver", "arguments", "jdbc_driver", "truncate", "arguments", "truncate", "save_mode", "arguments", "save_mode", "batch_size", "arguments", "batch_size", "num_partitions", "arguments", "num_partitions", "create_table_column_types", "arguments", "create_table_column_types"], ["mock_writer_save", "assert_called_once_with", "mode", "arguments", "save_mode"]], "spark_session": [["spark_session", "_create_spark_session", "arguments"], ["spark_session", "sql", "arguments", "metastore_table"], ["spark_write_to_jdbc", "spark_session", "spark_session", "url", "arguments", "url", "user", "arguments", "user", "password", "arguments", "password", "metastore_table", "arguments", "metastore_table", "jdbc_table", "arguments", "jdbc_table", "driver", "arguments", "jdbc_driver", "truncate", "arguments", "truncate", "save_mode", "arguments", "save_mode", "batch_size", "arguments", "batch_size", "num_partitions", "arguments", "num_partitions", "create_table_column_types", "arguments", "create_table_column_types"]]}, "name": "test_spark_write_to_jdbc", "params": {"mock_writer_save": "", "self": ""}, "params_descr": {"mock_writer_save": "", "self": ""}, "params_occur": {"mock_writer_save": [["mock_writer_save", "assert_called_once_with", "mode", "arguments", "save_mode"]], "self": [["arguments", "_parse_arguments", "self", "jdbc_arguments"]]}, "params_p": {"args": [], "kwargs": [], "mock_writer_save": [], "self": []}, "q_name": "TestSparkJDBCScrip.test_spark_write_to_jdbc", "ret_exprs": [], "ret_type": "", "variables": {"arguments": "", "spark_session": ""}, "variables_p": {"arguments": [["str", 0.34931238770430917], ["Dict[str, Union[Any, str]]", 0.1180252135624236], ["list", 0.07715922720356105]], "spark_session": [["bytes", 0.1084734223754422], ["str", 0.10719647189262006], ["Dict[str, Dict[str, Any]]", 0.09074110634594337]]}}, {"docstring": {"func": null, "long_descr": null, "ret": null}, "fn_lc": [[193, 4], [220, 9]], "fn_var_ln": {"arguments": [[195, 8], [195, 17]], "spark_session": [[196, 8], [196, 21]]}, "fn_var_occur": {"arguments": [["arguments", "_parse_arguments", "self", "jdbc_arguments"], ["spark_session", "_create_spark_session", "arguments"], ["spark_session", "sql", "arguments", "metastore_table"], ["spark_read_from_jdbc", "spark_session", "arguments", "url", "arguments", "user", "arguments", "password", "arguments", "metastore_table", "arguments", "jdbc_table", "arguments", "jdbc_driver", "arguments", "save_mode", "arguments", "save_format", "arguments", "fetch_size", "arguments", "num_partitions", "arguments", "partition_column", "arguments", "lower_bound", "arguments", "upper_bound"], ["mock_reader_load", "write", "saveAsTable", "assert_called_once_with", "arguments", "metastore_table", "format", "arguments", "save_format", "mode", "arguments", "save_mode"]], "spark_session": [["spark_session", "_create_spark_session", "arguments"], ["spark_session", "sql", "arguments", "metastore_table"], ["spark_read_from_jdbc", "spark_session", "arguments", "url", "arguments", "user", "arguments", "password", "arguments", "metastore_table", "arguments", "jdbc_table", "arguments", "jdbc_driver", "arguments", "save_mode", "arguments", "save_format", "arguments", "fetch_size", "arguments", "num_partitions", "arguments", "partition_column", "arguments", "lower_bound", "arguments", "upper_bound"]]}, "name": "test_spark_read_from_jdbc", "params": {"mock_reader_load": "", "self": ""}, "params_descr": {"mock_reader_load": "", "self": ""}, "params_occur": {"mock_reader_load": [["mock_reader_load", "write", "saveAsTable", "assert_called_once_with", "arguments", "metastore_table", "format", "arguments", "save_format", "mode", "arguments", "save_mode"]], "self": [["arguments", "_parse_arguments", "self", "jdbc_arguments"]]}, "params_p": {"args": [], "kwargs": [], "mock_reader_load": [], "self": []}, "q_name": "TestSparkJDBCScrip.test_spark_read_from_jdbc", "ret_exprs": [], "ret_type": "", "variables": {"arguments": "", "spark_session": ""}, "variables_p": {"arguments": [["str", 0.34931238770430917], ["Dict[str, Union[Any, str]]", 0.1180252135624236], ["list", 0.07715922720356105]], "spark_session": [["bytes", 0.11087748870473475], ["str", 0.10566507026038198], ["Dict[str, Dict[str, Any]]", 0.08733874620718958], ["RuntimeError", 0.08731255520316043], ["dict", 0.08666044914171644]]}}], "name": "TestSparkJDBCScrip", "q_name": "TestSparkJDBCScrip", "variables": {"default_arguments": "", "jdbc_arguments": ""}, "variables_p": {"default_arguments": [["str", 0.4], ["int", 0.30000000000000004], ["List[Tuple[str, int]]", 0.1]], "jdbc_arguments": [["str", 0.4], ["List[str]", 0.1], ["int", 0.1], ["Dict[str, List[Any]]", 0.1], ["Tuple[str, str, str, str, str, str, str, str]", 0.1]]}}], "funcs": [{"docstring": {"func": null, "long_descr": null, "ret": null}, "fn_lc": [[36, 0], [38, 17]], "fn_var_ln": {}, "fn_var_occur": {}, "name": "mock_spark_session", "params": {}, "params_descr": {}, "params_occur": {}, "params_p": {"args": [], "kwargs": []}, "q_name": "mock_spark_session", "ret_exprs": [], "ret_type": "", "variables": {}, "variables_p": {}}], "imports": ["__future__", "annotations", "unittest", "mock", "pytest", "pyspark", "sql", "readwriter", "DataFrameReader", "DataFrameWriter", "airflow", "providers", "apache", "spark", "hooks", "spark_jdbc_script", "SPARK_READ_FROM_JDBC", "SPARK_WRITE_TO_JDBC", "_create_spark_session", "_parse_arguments", "_run_spark", "spark_read_from_jdbc", "spark_write_to_jdbc"], "mod_var_ln": {}, "mod_var_occur": {}, "no_types_annot": {"D": 0, "I": 0, "U": 23}, "session_id": "jmST3kXmentufsdX07UmyElSrkNIZodamZ2nW7aNnDM", "set": null, "tc": [false, null], "type_annot_cove": 0.0, "typed_seq": "", "untyped_seq": "", "variables": {}, "variables_p": {}}}
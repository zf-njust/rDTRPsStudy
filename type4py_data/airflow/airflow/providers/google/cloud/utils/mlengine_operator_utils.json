{"error": null, "response": {"classes": [], "funcs": [{"docstring": {"func": null, "long_descr": null, "ret": null}, "fn_lc": [[245, 4], [253, 35]], "fn_var_ln": {"_": [[247, 32], [247, 33]], "bucket": [[247, 16], [247, 22]], "gcs_hook": [[251, 8], [251, 16]], "obj": [[247, 24], [247, 27]], "prediction_path": [[246, 8], [246, 23]], "scheme": [[247, 8], [247, 14]], "summary": [[252, 8], [252, 15]]}, "fn_var_occur": {"_": [["scheme", "bucket", "obj", "_", "_", "urlsplit", "prediction_path"]], "bucket": [["scheme", "bucket", "obj", "_", "_", "urlsplit", "prediction_path"], ["scheme", "bucket", "obj"], ["summary", "json", "loads", "gcs_hook", "download", "bucket", "summary", "decode"]], "gcs_hook": [["gcs_hook", "GCSHook"], ["summary", "json", "loads", "gcs_hook", "download", "bucket", "summary", "decode"]], "obj": [["scheme", "bucket", "obj", "_", "_", "urlsplit", "prediction_path"], ["scheme", "bucket", "obj"], ["summary", "os", "path", "join", "obj", "strip"]], "prediction_path": [["evaluate_prediction", "MLEngineStartBatchPredictionJobOperator", "task_id", "task_prefix", "project_id", "project_id", "job_id", "batch_prediction_job_id", "region", "region", "data_format", "data_format", "input_paths", "input_paths", "output_path", "prediction_path", "uri", "model_uri", "model_name", "model_name", "version_name", "version_name", "dag", "dag"], ["evaluate_summary", "BeamRunPythonPipelineOperator", "task_id", "task_prefix", "runner", "BeamRunnerType", "DataflowRunner", "py_file", "os", "path", "join", "os", "path", "dirname", "__file__", "default_pipeline_options", "dataflow_options", "pipeline_options", "prediction_path", "metric_fn_encoded", "join", "metric_keys", "py_interpreter", "py_interpreter", "py_requirements", "dag", "dag"], ["prediction_path", "templates_dict"], ["scheme", "bucket", "obj", "_", "_", "urlsplit", "prediction_path"], ["ValueError", "prediction_path"]], "scheme": [["scheme", "bucket", "obj", "_", "_", "urlsplit", "prediction_path"], ["scheme", "bucket", "obj"]], "summary": [["summary", "os", "path", "join", "obj", "strip"], ["summary", "json", "loads", "gcs_hook", "download", "bucket", "summary", "decode"], ["validate_fn", "summary"]]}, "name": "apply_validate_fn", "params": {"args": "", "kwargs": "", "templates_dict": ""}, "params_descr": {"args": "", "kwargs": "", "templates_dict": ""}, "params_occur": {"args": [], "kwargs": [], "templates_dict": [["prediction_path", "templates_dict"]]}, "params_p": {"args": [], "kwargs": [], "templates_dict": [["str", 0.6459347573210406], ["Sequence[str]", 0.16866340762922788], ["dict", 0.09332426145770181]]}, "q_name": "create_evaluate_ops.<locals>.apply_validate_fn", "ret_exprs": ["return validate_fn(summary)"], "ret_type": "", "ret_type_p": [["int", 0.30000000000000004], ["Callable", 0.2], ["str", 0.1]], "variables": {"_": "", "bucket": "", "gcs_hook": "", "obj": "", "prediction_path": "", "scheme": "", "summary": ""}, "variables_p": {"_": [["list", 0.20342399617906437], ["Pattern[str]", 0.09898750729178146], ["str", 0.09540201902976185], ["int", 0.09513596083573536], ["dict", 0.09490101834897999]], "bucket": [["str", 0.38979889544941204], ["IO[bytes]", 0.15379564512547414], ["int", 0.09100550898029011], ["List[str]", 0.07941012611625216]], "gcs_hook": [["dict", 0.30384181975549346], ["str", 0.19608416320232602], ["Dict[str, Union[Any, Any]]", 0.09826044363393223], ["Dict[str, int]", 0.09113503926397859]], "obj": [["str", 0.9999999999999998]], "prediction_path": [["str", 0.6264477871555469]], "scheme": [["str", 0.4880455787962899], ["List[str]", 0.0958803398058627], ["Dict[str, Any]", 0.08449719820329925]], "summary": [["str", 0.8228890662764138]]}}, {"docstring": {"func": "Creates Operators needed for model evaluation and returns.", "long_descr": "It gets prediction over inputs via Cloud ML Engine BatchPrediction API by\ncalling MLEngineBatchPredictionOperator, then summarize and validate\nthe result via Cloud Dataflow using DataFlowPythonOperator.\n\nFor details and pricing about Batch prediction, please refer to the website\nhttps://cloud.google.com/ml-engine/docs/how-tos/batch-predict\nand for Cloud Dataflow, https://cloud.google.com/dataflow/docs/\n\nIt returns three chained operators for prediction, summary, and validation,\nnamed as ``<prefix>-prediction``, ``<prefix>-summary``, and ``<prefix>-validation``,\nrespectively.\n(``<prefix>`` should contain only alphanumeric characters or hyphen.)\n\nThe upstream and downstream can be set accordingly like:\n\n.. code-block:: python\n\n    pred, _, val = create_evaluate_ops(...)\n    pred.set_upstream(upstream_op)\n    ...\n    downstream_op.set_upstream(val)\n\nCallers will provide two python callables, metric_fn and validate_fn, in\norder to customize the evaluation behavior as they wish.\n\n- metric_fn receives a dictionary per instance derived from json in the\n  batch prediction result. The keys might vary depending on the model.\n  It should return a tuple of metrics.\n- validation_fn receives a dictionary of the averaged metrics that metric_fn\n  generated over all instances.\n  The key/value of the dictionary matches to what's given by\n  metric_fn_and_keys arg.\n  The dictionary contains an additional metric, 'count' to represent the\n  total number of instances received for evaluation.\n  The function would raise an exception to mark the task as failed, in a\n  case the validation result is not okay to proceed (i.e. to set the trained\n  version as default).\n\nTypical examples are like this:\n\n.. code-block:: python\n\n    def get_metric_fn_and_keys():\n        import math  # imports should be outside of the metric_fn below.\n\n        def error_and_squared_error(inst):\n            label = float(inst[\"input_label\"])\n            classes = float(inst[\"classes\"])  # 0 or 1\n            err = abs(classes - label)\n            squared_err = math.pow(classes - label, 2)\n            return (err, squared_err)  # returns a tuple.\n\n        return error_and_squared_error, [\"err\", \"mse\"]  # key order must match.\n\n\n    def validate_err_and_count(summary):\n        if summary[\"err\"] > 0.2:\n            raise ValueError(\"Too high err>0.2; summary=%s\" % summary)\n        if summary[\"mse\"] > 0.05:\n            raise ValueError(\"Too high mse>0.05; summary=%s\" % summary)\n        if summary[\"count\"] < 1000:\n            raise ValueError(\"Too few instances<1000; summary=%s\" % summary)\n        return summary\n\nFor the details on the other BatchPrediction-related arguments (project_id,\njob_id, region, data_format, input_paths, prediction_path, model_uri),\nplease refer to MLEngineBatchPredictionOperator too.", "ret": "a tuple of three operators, (prediction, summary, validation)\nPythonOperator)"}, "fn_lc": [[40, 0], [263, 69]], "fn_var_ln": {"batch_prediction_job_id": [[188, 4], [188, 27]], "dataflow_options": [[212, 8], [212, 24]], "default_args": [[207, 8], [207, 20]], "evaluate_prediction": [[214, 4], [214, 23]], "evaluate_summary": [[229, 4], [229, 20]], "evaluate_validation": [[255, 4], [255, 23]], "metric_fn": [[200, 4], [200, 13]], "metric_fn_encoded": [[228, 4], [228, 21]], "metric_keys": [[200, 15], [200, 26]], "model_name": [[210, 8], [210, 18]], "project_id": [[208, 8], [208, 18]], "region": [[209, 8], [209, 14]], "version_name": [[211, 8], [211, 20]]}, "fn_var_occur": {"batch_prediction_job_id": [], "dataflow_options": [], "default_args": [], "evaluate_prediction": [["evaluate_prediction", "evaluate_summary", "evaluate_validation"]], "evaluate_summary": [["evaluate_validation", "set_upstream", "evaluate_summary"], ["evaluate_prediction", "evaluate_summary", "evaluate_validation"]], "evaluate_validation": [["evaluate_validation", "PythonOperator", "task_id", "task_prefix", "python_callable", "apply_validate_fn", "templates_dict", "prediction_path", "dag", "dag"], ["evaluate_validation", "set_upstream", "evaluate_summary"], ["evaluate_prediction", "evaluate_summary", "evaluate_validation"]], "metric_fn": [], "metric_fn_encoded": [], "metric_keys": [], "model_name": [], "project_id": [], "region": [], "version_name": []}, "name": "create_evaluate_ops", "params": {"batch_prediction_job_id": "str | None", "dag": "DAG | None", "data_format": "builtins.str", "dataflow_options": "dict | None", "input_paths": "builtins.list[builtins.str]", "metric_fn_and_keys": "builtins.tuple[T, typing.Iterable[builtins.str]]", "model_name": "str | None", "model_uri": "str | None", "prediction_path": "builtins.str", "project_id": "str | None", "py_interpreter": "", "region": "str | None", "task_prefix": "builtins.str", "validate_fn": "T", "version_name": "str | None"}, "params_descr": {"batch_prediction_job_id": "the id to use for the Cloud ML Batch\nprediction job. Passed directly to the MLEngineBatchPredictionOperator as\nthe job_id argument.", "dag": "The `DAG` to use for all Operators.", "data_format": "either of 'TEXT', 'TF_RECORD', 'TF_RECORD_GZIP'", "dataflow_options": "options to run Dataflow jobs. If None, then the\n`dag`'s `default_args['dataflow_default_options']` will be used.", "input_paths": "a list of input paths to be sent to BatchPrediction.", "metric_fn_and_keys": "a tuple of metric_fn and metric_keys:\n- metric_fn is a function that accepts a dictionary (for an instance),\n  and returns a tuple of metric(s) that it calculates.\n\n- metric_keys is a list of strings to denote the key of each metric.", "model_name": "Used to indicate a model to use for prediction. Can be\nused in combination with version_name, but cannot be used together with\nmodel_uri. See MLEngineBatchPredictionOperator for more detail. If None,\nthen the `dag`'s `default_args['model_name']` will be used.", "model_uri": "GCS path of the model exported by Tensorflow using\n``tensorflow.estimator.export_savedmodel()``. It cannot be used with\nmodel_name or version_name below. See MLEngineBatchPredictionOperator for\nmore detail.", "prediction_path": "GCS path to put the prediction results in.", "project_id": "the Google Cloud project id in which to execute\nCloud ML Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n`default_args['project_id']` will be used.", "py_interpreter": "Python version of the beam pipeline.\nIf None, this defaults to the python3.\nTo track python versions supported by beam and related\nissues check: https://issues.apache.org/jira/browse/BEAM-1251", "region": "the Google Cloud region in which to execute Cloud ML\nBatch Prediction and Dataflow jobs. If None, then the `dag`'s\n`default_args['region']` will be used.", "task_prefix": "a prefix for the tasks. Only alphanumeric characters and\nhyphen are allowed (no underscores), since this will be used as dataflow\njob name, which doesn't allow other characters.", "validate_fn": "a function to validate whether the averaged metric(s) is\ngood enough to push the model.", "version_name": "Used to indicate a model version to use for prediction,\nin combination with model_name. Cannot be used together with model_uri.\nSee MLEngineBatchPredictionOperator for more detail. If None, then the\n`dag`'s `default_args['version_name']` will be used."}, "params_occur": {"batch_prediction_job_id": [], "dag": [["evaluate_validation", "PythonOperator", "task_id", "task_prefix", "python_callable", "apply_validate_fn", "templates_dict", "prediction_path", "dag", "dag"]], "data_format": [], "dataflow_options": [], "input_paths": [], "metric_fn_and_keys": [], "model_name": [], "model_uri": [], "prediction_path": [["evaluate_validation", "PythonOperator", "task_id", "task_prefix", "python_callable", "apply_validate_fn", "templates_dict", "prediction_path", "dag", "dag"]], "project_id": [], "py_interpreter": [], "region": [], "task_prefix": [["evaluate_validation", "PythonOperator", "task_id", "task_prefix", "python_callable", "apply_validate_fn", "templates_dict", "prediction_path", "dag", "dag"]], "validate_fn": [], "version_name": []}, "params_p": {"args": [], "batch_prediction_job_id": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "dag": [["str", 0.30464889619874386], ["Dict[str, Any]", 0.11291817681530784]], "data_format": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "dataflow_options": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "input_paths": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "kwargs": [], "metric_fn_and_keys": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "model_name": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "model_uri": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "prediction_path": [["str", 0.30464889619874386], ["Dict[str, Any]", 0.11291817681530784]], "project_id": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "py_interpreter": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "region": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "task_prefix": [["str", 0.30464889619874386], ["Dict[str, Any]", 0.11291817681530784]], "validate_fn": [["bool", 0.685389207698596], ["str", 0.12343847574366601]], "version_name": [["bool", 0.685389207698596], ["str", 0.12343847574366601]]}, "q_name": "create_evaluate_ops", "ret_exprs": ["return evaluate_prediction, evaluate_summary, evaluate_validation"], "ret_type": "builtins.tuple[airflow.providers.google.cloud.operators.mlengine.MLEngineStartBatchPredictionJobOperator, airflow.providers.apache.beam.operators.beam.BeamRunPythonPipelineOperator, airflow.operators.python.PythonOperator]", "ret_type_p": [["bool", 0.5], ["float", 0.1]], "variables": {"batch_prediction_job_id": "", "dataflow_options": "", "default_args": "", "evaluate_prediction": "", "evaluate_summary": "", "evaluate_validation": "", "metric_fn": "", "metric_fn_encoded": "", "metric_keys": "", "model_name": "", "project_id": "", "region": "", "version_name": ""}, "variables_p": {"batch_prediction_job_id": [["int", 0.6], ["str", 0.2], ["Optional[str]", 0.2]], "dataflow_options": [["List[str]", 0.3], ["List[Tuple[str, str]]", 0.09999999999999999], ["List[Union[Any, Any, Any]]", 0.09999999999999999], ["list", 0.09999999999999999], ["List[int]", 0.09999999999999999], ["List[Dict[str, Any]]", 0.09999999999999999], ["Dict[int, str]", 0.09999999999999999]], "default_args": [["Dict[str, Union[float, str]]", 0.33333333320259995], ["Dict[str, Any]", 0.33333333320259995], ["dict", 3.022791746344274e-10], ["bool", 8.99213064939781e-11]], "evaluate_prediction": [["int", 0.2], ["dict", 0.1], ["List[int]", 0.1], ["List[List[int]]", 0.1], ["str", 0.1]], "evaluate_summary": [["Tuple[int, int, int]", 0.24999999999158673], ["int", 1.7465626226746873e-11], ["List[str]", 5.395820832013966e-12]], "evaluate_validation": [["str", 0.11501566247838689], ["list", 0.1016605948529254], ["int", 0.07666297330888304]], "metric_fn": [["str", 0.4], ["List[str]", 0.1], ["int", 0.1], ["Dict[str, List[Any]]", 0.1], ["Tuple[str, str, str, str, str, str, str, str]", 0.1]], "metric_fn_encoded": [["str", 0.4], ["List[str]", 0.1], ["int", 0.1], ["Dict[str, List[Any]]", 0.1], ["Tuple[str, str, str, str, str, str, str, str]", 0.1]], "metric_keys": [["str", 0.8999999999999999], ["bytes", 0.1]], "model_name": [["str", 0.999999999770391], ["List[str]", 2.296089489798233e-10]], "project_id": [["Optional[str]", 0.4], ["str", 0.4], ["dict", 0.1]], "region": [["str", 0.4], ["List[str]", 0.1], ["int", 0.1], ["Dict[str, List[Any]]", 0.1], ["Tuple[str, str, str, str, str, str, str, str]", 0.1]], "version_name": [["str", 0.9999999988787669], ["Type[str]", 1.121233037973532e-09]]}}], "imports": ["__future__", "annotations", "base64", "json", "os", "re", "typing", "Callable", "Iterable", "TypeVar", "urllib", "parse", "urlsplit", "dill", "airflow", "DAG", "airflow", "exceptions", "AirflowException", "airflow", "operators", "python", "PythonOperator", "airflow", "providers", "apache", "beam", "hooks", "beam", "BeamRunnerType", "airflow", "providers", "apache", "beam", "operators", "beam", "BeamRunPythonPipelineOperator", "airflow", "providers", "google", "cloud", "hooks", "gcs", "GCSHook", "airflow", "providers", "google", "cloud", "operators", "mlengine", "MLEngineStartBatchPredictionJobOperator"], "mod_var_ln": {"T": [[37, 0], [37, 1]]}, "mod_var_occur": {"T": []}, "no_types_annot": {"D": 9, "I": 0, "U": 26}, "session_id": "GSgoteG3OqX4ElB0wM4i7RpxqZNrCdEZqI2x_EPZrBk", "set": null, "tc": [false, null], "type_annot_cove": 0.26, "typed_seq": "", "untyped_seq": "", "variables": {"T": ""}, "variables_p": {"T": [["str", 0.9999999999999999]]}}}
{"error": null, "response": {"classes": [{"cls_lc": [[23, 0], [44, 76]], "cls_var_ln": {}, "cls_var_occur": {}, "funcs": [{"docstring": {"func": null, "long_descr": null, "ret": null}, "fn_lc": [[25, 2], [44, 76]], "fn_var_ln": {"global_step": [[35, 6], [35, 17]], "grads": [[34, 6], [34, 11]], "init_op": [[38, 6], [38, 13]], "loss": [[32, 6], [32, 10]], "optimizer": [[36, 6], [36, 15]], "train_op": [[37, 6], [37, 14]], "tvars": [[33, 6], [33, 11]], "w": [[27, 6], [27, 7]], "w_np": [[43, 6], [43, 10]], "x": [[31, 6], [31, 7]]}, "fn_var_occur": {"global_step": [["global_step", "tf", "train", "get_or_create_global_step"], ["train_op", "optimizer", "apply_gradients", "zip", "grads", "tvars", "global_step"]], "grads": [["grads", "tf", "gradients", "loss", "tvars"], ["train_op", "optimizer", "apply_gradients", "zip", "grads", "tvars", "global_step"]], "init_op": [["init_op", "tf", "group", "tf", "global_variables_initializer", "tf", "local_variables_initializer"], ["sess", "run", "init_op"]], "loss": [["loss", "tf", "reduce_mean", "tf", "square", "x", "w"], ["grads", "tf", "gradients", "loss", "tvars"]], "optimizer": [["optimizer", "optimization", "AdamWeightDecayOptimizer", "learning_rate"], ["train_op", "optimizer", "apply_gradients", "zip", "grads", "tvars", "global_step"]], "train_op": [["train_op", "optimizer", "apply_gradients", "zip", "grads", "tvars", "global_step"], ["sess", "run", "train_op"]], "tvars": [["tvars", "tf", "trainable_variables"], ["grads", "tf", "gradients", "loss", "tvars"], ["train_op", "optimizer", "apply_gradients", "zip", "grads", "tvars", "global_step"]], "w": [["w", "tf", "get_variable", "shape", "initializer", "tf", "constant_initializer"], ["loss", "tf", "reduce_mean", "tf", "square", "x", "w"], ["w_np", "sess", "run", "w"]], "w_np": [["w_np", "sess", "run", "w"], ["self", "assertAllClose", "w_np", "flat", "rtol", "atol"]], "x": [["x", "tf", "constant"], ["loss", "tf", "reduce_mean", "tf", "square", "x", "w"]]}, "name": "test_adam", "params": {"self": ""}, "params_descr": {"self": ""}, "params_occur": {"self": [["self", "test_session", "sess"], ["self", "assertAllClose", "w_np", "flat", "rtol", "atol"]]}, "params_p": {"args": [], "kwargs": [], "self": []}, "q_name": "OptimizationTest.test_adam", "ret_exprs": [], "ret_type": "", "variables": {"global_step": "", "grads": "", "init_op": "", "loss": "", "optimizer": "", "train_op": "", "tvars": "", "w": "", "w_np": "", "x": ""}, "variables_p": {"global_step": [["Tuple[int]", 0.08523106201921946]], "grads": [["int", 0.15472847901280448], ["Pattern[str]", 0.09915945656984247], ["str", 0.07736423950640224]], "init_op": [], "loss": [["float", 1.2563131480466388e-10]], "optimizer": [], "train_op": [["int", 0.32324905901017187], ["Tuple[List[str], Tuple[Literal, Literal], List[str]]", 0.17464649847387015], ["Union[None, bool, str]", 0.12179715104563436], ["Tuple[Literal, Literal, Literal]", 0.0897489483550836], ["str", 0.08937133849764937]], "tvars": [], "w": [["list", 0.1079724701591486]], "w_np": [], "x": [["int", 0.2268411208169295], ["list", 0.19379881495960796]]}}], "name": "OptimizationTest", "q_name": "OptimizationTest", "variables": {}, "variables_p": {}}], "funcs": [], "imports": ["__future__", "absolute_import", "__future__", "division", "__future__", "print_function", "optimization", "tensorflow", "tf"], "mod_var_ln": {}, "mod_var_occur": {}, "no_types_annot": {"D": 0, "I": 0, "U": 11}, "session_id": "UVJBeiz2xYN2WzDQABNZIly46TITUKDsqWSiap-7gn8", "set": null, "tc": [false, null], "type_annot_cove": 0.0, "typed_seq": "", "untyped_seq": "", "variables": {}, "variables_p": {}}}
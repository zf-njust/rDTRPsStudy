<<TransformerSemanticTextualSimilarity>> <<23:1019-1055>> <<type>> <<CLASS>> <<ANCHOR>>
<<__init__>> <<25:1084-1092>> <<function>> <<CONSTRUCTOR>> <<ANCHOR>>
<<build_dataloader>> <<37:1460-1476>> <<function>> <<METHOD>> <<ANCHOR>>
<<build_optimizer>> <<64:3061-3076>> <<function>> <<METHOD>> <<ANCHOR>>
<<build_criterion>> <<74:3855-3870>> <<function>> <<METHOD>> <<ANCHOR>>
<<build_metric>> <<77:3913-3925>> <<function>> <<METHOD>> <<ANCHOR>>
<<execute_training_loop>> <<80:3992-4013>> <<function>> <<METHOD>> <<ANCHOR>>
<<fit_dataloader>> <<101:5348-5362>> <<function>> <<METHOD>> <<ANCHOR>>
<<evaluate_dataloader>> <<130:6747-6766>> <<function>> <<METHOD>> <<ANCHOR>>
<<build_model>> <<162:8112-8123>> <<function>> <<METHOD>> <<ANCHOR>>
<<predict>> <<170:8507-8514>> <<function>> <<METHOD>> <<ANCHOR>>
<<fit>> <<203:9757-9760>> <<function>> <<METHOD>> <<ANCHOR>>
<<on_config_ready>> <<226:10524-10539>> <<function>> <<METHOD>> <<ANCHOR>>
<<feed_batch>> <<234:11027-11037>> <<function>> <<METHOD>> <<ANCHOR>>
<<decode>> <<238:11293-11299>> <<function>> <<METHOD>> <<ANCHOR>>
<<report_metrics>> <<241:11454-11468>> <<function>> <<METHOD>> <<ANCHOR>>
<<self>> <<64:3077-3080>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<trn>> <<64:3083-3086>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<epochs>> <<64:3088-3091>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<gradient_accumulation>> <<64:3096-3099>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<lr>> <<64:3121-3124>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<transformer_lr>> <<64:3130-3133>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<adam_epsilon>> <<64:3151-3154>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<weight_decay>> <<65:3195-3198>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<warmup_steps>> <<65:3213-3216>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<mup_steps>> <<65:3216-3225>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_training_steps>> <<66:3251-3269>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<optimizer>> <<67:3324-3333>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<scheduler>> <<67:3335-3344>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<241:11469-11472>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<loss>> <<241:11475-11478>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<metric>> <<241:11481-11484>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<238:11300-11303>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<output>> <<238:11306-11309>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<170:8515-8518>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<data>> <<170:8521-8524>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<batch_size>> <<170:8562-8565>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<ch_size>> <<170:8565-8572>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<flat>> <<184:8972-8976>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<data>> <<186:9035-9039>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<x>> <<187:9131-9132>> <<?>> <<SCOPE>> <<ANCHOR>>
<<self>> <<37:1477-1480>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<data>> <<37:1483-1486>> <<list>> <<PARAMETER>> <<ANCHOR>>
<<batch_size>> <<37:1489-1492>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<sent_a_col>> <<37:1501-1504>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<sent_b_col>> <<38:1544-1547>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<similarity_col>> <<39:1587-1590>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<delimiter>> <<40:1634-1637>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<gradient_accumulation>> <<41:1678-1681>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<sampler_builder>> <<42:1729-1732>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<shuffle>> <<43:1777-1780>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<device>> <<43:1792-1795>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<logger>> <<43:1805-1808>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<split>> <<44:1862-1865>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<it>> <<44:1865-1867>> <<dict>> <<PARAMETER>> <<ANCHOR>>
<<dataset>> <<46:1934-1941>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<x>> <<54:2483-2484>> <<?>> <<SCOPE>> <<ANCHOR>>
<<scores>> <<54:2453-2459>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<sampler_builder>> <<58:2641-2656>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<x>> <<59:2745-2746>> <<?>> <<SCOPE>> <<ANCHOR>>
<<lens>> <<59:2713-2717>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<dataloader>> <<187:9058-9068>> <<None>> <<VARIABLE>> <<ANCHOR>>
<<orders>> <<190:9309-9315>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<predictions>> <<191:9330-9341>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<batch>> <<192:9360-9365>> <<?>> <<SCOPE>> <<ANCHOR>>
<<self>> <<234:11038-11041>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<batch>> <<234:11044-11047>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<output_dict>> <<193:9394-9405>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<prediction>> <<194:9444-9454>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<predictions>> <<197:9583-9594>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<74:3871-3874>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<f>> <<74:3874-3875>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<226:10540-10543>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<transformer>> <<226:10546-10549>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<max_seq_len>> <<226:10559-10562>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<_seq_len>> <<226:10562-10570>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<_tokenizer>> <<228:10640-10650>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<self>> <<25:1093-1096>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<f>> <<25:1096-1097>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<203:9761-9764>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<trn_data>> <<203:9767-9770>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<dev_data>> <<203:9777-9780>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<save_dir>> <<203:9787-9790>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<transformer>> <<204:9810-9813>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<sent_a_col>> <<205:9836-9839>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<sent_b_col>> <<206:9861-9864>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<similarity_col>> <<207:9886-9889>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<delimiter>> <<208:9915-9918>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<batch_size>> <<209:9946-9949>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<max_seq_len>> <<210:9974-9977>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<epochs>> <<211:10004-10007>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<lr>> <<212:10027-10030>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<transformer_lr>> <<213:10049-10052>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<adam_epsilon>> <<214:10083-10086>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<weight_decay>> <<215:10115-10118>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<warmup_steps>> <<216:10146-10149>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<gradient_accumulation>> <<217:10177-10180>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<grad_norm>> <<218:10215-10218>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<sampler_builder>> <<219:10243-10246>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<devices>> <<220:10278-10281>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<logger>> <<221:10305-10308>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<seed>> <<222:10331-10334>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<finetune>> <<223:10355-10358>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<eval_trn>> <<223:10391-10394>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<_device_placeholder>> <<223:10406-10409>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<vice_placeholder>> <<223:10409-10425>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<80:4014-4017>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<trn>> <<80:4020-4023>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<dev>> <<80:4037-4040>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<epochs>> <<80:4054-4057>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<criterion>> <<80:4062-4065>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<optimizer>> <<80:4073-4076>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<metric>> <<80:4084-4087>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<save_dir>> <<80:4092-4095>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<logger>> <<81:4133-4136>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<devices>> <<81:4157-4160>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<ratio_width>> <<81:4166-4169>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<gradient_accumulation>> <<81:4184-4187>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<dient_accumulation>> <<81:4187-4205>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<best_epoch>> <<82:4229-4239>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<best_metric>> <<82:4241-4252>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<timer>> <<83:4270-4275>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<history>> <<84:4310-4317>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<epoch>> <<85:4343-4348>> <<int>> <<SCOPE>> <<ANCHOR>>
<<self>> <<101:5363-5366>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<trn>> <<101:5369-5372>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<criterion>> <<101:5386-5389>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<optimizer>> <<101:5397-5400>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<metric>> <<101:5408-5411>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<logger>> <<101:5437-5440>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<history>> <<102:5485-5488>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<gradient_accumulation>> <<102:5499-5502>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<dient_accumulation>> <<102:5502-5520>> <<dict>> <<PARAMETER>> <<ANCHOR>>
<<optimizer>> <<104:5572-5581>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<scheduler>> <<104:5583-5592>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<timer>> <<105:5614-5619>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<total_loss>> <<106:5729-5739>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<batch>> <<108:5781-5786>> <<?>> <<SCOPE>> <<ANCHOR>>
<<output>> <<109:5808-5814>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<prediction>> <<110:5853-5863>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<loss>> <<112:5952-5956>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<loss>> <<114:6060-6064>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<total_loss>> <<116:6132-6142>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<162:8124-8127>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<transformer>> <<162:8130-8133>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<training>> <<162:8143-8146>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<ining>> <<162:8146-8151>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<config>> <<163:8197-8203>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<model>> <<165:8296-8301>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<model>> <<167:8411-8416>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<77:3926-3929>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<f>> <<77:3929-3930>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<130:6767-6770>> <<TransformerSemanticTextualSimilarity>> <<PARAMETER>> <<ANCHOR>>
<<data>> <<130:6773-6776>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<logger>> <<130:6791-6794>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<metric>> <<130:6815-6818>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<output>> <<130:6828-6831>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<put>> <<130:6831-6834>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<timer>> <<132:6889-6894>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<total_loss>> <<133:6932-6942>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<predictions>> <<136:7004-7015>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<orders>> <<137:7034-7040>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<samples>> <<138:7059-7066>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<batch>> <<139:7085-7090>> <<?>> <<SCOPE>> <<ANCHOR>>
<<output_dict>> <<140:7113-7124>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<prediction>> <<141:7163-7173>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<loss>> <<147:7468-7472>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<total_loss>> <<148:7508-7518>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<trn>> <<66:3276-3279>> <<?>> <<VARIABLE>> <<LINK>>
<<epochs>> <<66:3283-3289>> <<?>> <<VARIABLE>> <<LINK>>
<<gradient_accumulation>> <<66:3293-3314>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<67:3390-3394>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<self>> <<68:3477-3481>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<lr>> <<69:3575-3577>> <<float>> <<VARIABLE>> <<LINK>>
<<transformer_lr>> <<69:3579-3593>> <<float>> <<VARIABLE>> <<LINK>>
<<num_training_steps>> <<70:3670-3688>> <<int>> <<VARIABLE>> <<LINK>>
<<warmup_steps>> <<70:3690-3702>> <<float>> <<VARIABLE>> <<LINK>>
<<weight_decay>> <<71:3779-3791>> <<float>> <<VARIABLE>> <<LINK>>
<<adam_epsilon>> <<71:3793-3805>> <<float>> <<VARIABLE>> <<LINK>>
<<optimizer>> <<72:3823-3832>> <<?>> <<VARIABLE>> <<LINK>>
<<scheduler>> <<72:3834-3843>> <<?>> <<VARIABLE>> <<LINK>>
<<output>> <<239:11357-11363>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<239:11397-11401>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<self>> <<239:11420-11424>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<data>> <<182:8934-8938>> <<?>> <<VARIABLE>> <<LINK>>
<<data>> <<184:8990-8994>> <<?>> <<VARIABLE>> <<LINK>>
<<flat>> <<185:9016-9020>> <<int>> <<VARIABLE>> <<LINK>>
<<data>> <<186:9043-9047>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<187:9071-9075>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<build_dataloader>> <<187:9076-9092>> <<function>> <<VARIABLE>> <<LINK>>
<<data>> <<187:9136-9140>> <<{list||?}>> <<VARIABLE>> <<LINK>>
<<x>> <<187:9131-9132>> <<?>> <<VARIABLE>> <<LINK>>
<<x>> <<187:9105-9106>> <<?>> <<VARIABLE>> <<LINK>>
<<x>> <<187:9121-9122>> <<?>> <<VARIABLE>> <<LINK>>
<<batch_size>> <<188:9198-9208>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<188:9212-9216>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<self>> <<189:9287-9291>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<data>> <<46:1977-1981>> <<list>> <<VARIABLE>> <<LINK>>
<<sent_a_col>> <<47:2035-2045>> <<?>> <<VARIABLE>> <<LINK>>
<<sent_b_col>> <<48:2099-2109>> <<?>> <<VARIABLE>> <<LINK>>
<<similarity_col>> <<49:2163-2177>> <<?>> <<VARIABLE>> <<LINK>>
<<delimiter>> <<50:2241-2250>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<51:2314-2318>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<data>> <<52:2400-2404>> <<list>> <<VARIABLE>> <<LINK>>
<<split>> <<53:2424-2429>> <<?>> <<VARIABLE>> <<LINK>>
<<dataset>> <<54:2488-2495>> <<?>> <<VARIABLE>> <<LINK>>
<<x>> <<54:2483-2484>> <<?>> <<VARIABLE>> <<LINK>>
<<x>> <<54:2463-2464>> <<?>> <<VARIABLE>> <<LINK>>
<<scores>> <<55:2538-2544>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<55:2510-2514>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<scores>> <<56:2587-2593>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<56:2559-2563>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<sampler_builder>> <<57:2611-2626>> <<?>> <<VARIABLE>> <<LINK>>
<<batch_size>> <<58:2692-2702>> <<?>> <<VARIABLE>> <<LINK>>
<<dataset>> <<59:2750-2757>> <<?>> <<VARIABLE>> <<LINK>>
<<x>> <<59:2745-2746>> <<?>> <<VARIABLE>> <<LINK>>
<<x>> <<59:2725-2726>> <<?>> <<VARIABLE>> <<LINK>>
<<dataset>> <<60:2797-2804>> <<?>> <<VARIABLE>> <<LINK>>
<<sampler_builder>> <<60:2820-2835>> <<?>> <<VARIABLE>> <<LINK>>
<<lens>> <<60:2842-2846>> <<list>> <<VARIABLE>> <<LINK>>
<<shuffle>> <<60:2848-2855>> <<?>> <<VARIABLE>> <<LINK>>
<<gradient_accumulation>> <<60:2857-2878>> <<?>> <<VARIABLE>> <<LINK>>
<<device>> <<61:2926-2932>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<62:3009-3013>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<dataloader>> <<192:9369-9379>> <<None>> <<VARIABLE>> <<LINK>>
<<self>> <<193:9408-9412>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<feed_batch>> <<193:9413-9423>> <<function>> <<VARIABLE>> <<LINK>>
<<batch>> <<193:9424-9429>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<235:11096-11100>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<batch>> <<235:11117-11122>> <<?>> <<VARIABLE>> <<LINK>>
<<batch>> <<235:11152-11157>> <<?>> <<VARIABLE>> <<LINK>>
<<batch>> <<236:11219-11224>> <<?>> <<VARIABLE>> <<LINK>>
<<batch>> <<236:11251-11256>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<194:9457-9461>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<decode>> <<194:9462-9468>> <<function>> <<VARIABLE>> <<LINK>>
<<output_dict>> <<194:9469-9480>> <<?>> <<VARIABLE>> <<LINK>>
<<predictions>> <<195:9495-9506>> <<list>> <<VARIABLE>> <<LINK>>
<<prediction>> <<195:9514-9524>> <<?>> <<VARIABLE>> <<LINK>>
<<orders>> <<196:9548-9554>> <<list>> <<VARIABLE>> <<LINK>>
<<batch>> <<196:9562-9567>> <<?>> <<VARIABLE>> <<LINK>>
<<predictions>> <<197:9605-9616>> <<list>> <<VARIABLE>> <<LINK>>
<<orders>> <<197:9618-9624>> <<list>> <<VARIABLE>> <<LINK>>
<<flat>> <<198:9638-9642>> <<int>> <<VARIABLE>> <<LINK>>
<<predictions>> <<199:9664-9675>> <<?>> <<VARIABLE>> <<LINK>>
<<predictions>> <<200:9695-9706>> <<?>> <<VARIABLE>> <<LINK>>
<<transformer>> <<228:10709-10720>> <<?>> <<VARIABLE>> <<LINK>>
<<max_seq_len>> <<232:11003-11014>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<228:10635-10639>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<epochs>> <<83:4293-4299>> <<?>> <<VARIABLE>> <<LINK>>
<<epochs>> <<85:4361-4367>> <<?>> <<VARIABLE>> <<LINK>>
<<logger>> <<86:4387-4393>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<87:4459-4463>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<fit_dataloader>> <<87:4464-4478>> <<function>> <<VARIABLE>> <<LINK>>
<<trn>> <<87:4479-4482>> <<?>> <<VARIABLE>> <<LINK>>
<<criterion>> <<87:4484-4493>> <<?>> <<VARIABLE>> <<LINK>>
<<optimizer>> <<87:4495-4504>> <<?>> <<VARIABLE>> <<LINK>>
<<metric>> <<87:4506-4512>> <<?>> <<VARIABLE>> <<LINK>>
<<logger>> <<87:4514-4520>> <<?>> <<VARIABLE>> <<LINK>>
<<ratio_width>> <<87:4534-4545>> <<?>> <<VARIABLE>> <<LINK>>
<<gradient_accumulation>> <<88:4602-4623>> <<int>> <<VARIABLE>> <<LINK>>
<<history>> <<88:4633-4640>> <<?>> <<VARIABLE>> <<LINK>>
<<save_dir>> <<88:4651-4659>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<103:5544-5548>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<optimizer>> <<104:5595-5604>> <<?>> <<VARIABLE>> <<LINK>>
<<history>> <<105:5637-5644>> <<?>> <<VARIABLE>> <<LINK>>
<<trn>> <<105:5668-5671>> <<?>> <<VARIABLE>> <<LINK>>
<<gradient_accumulation>> <<105:5696-5717>> <<int>> <<VARIABLE>> <<LINK>>
<<metric>> <<107:5753-5759>> <<?>> <<VARIABLE>> <<LINK>>
<<trn>> <<108:5790-5793>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<109:5817-5821>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<feed_batch>> <<109:5822-5832>> <<function>> <<VARIABLE>> <<LINK>>
<<batch>> <<109:5833-5838>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<110:5866-5870>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<decode>> <<110:5871-5877>> <<function>> <<VARIABLE>> <<LINK>>
<<output>> <<110:5878-5884>> <<?>> <<VARIABLE>> <<LINK>>
<<metric>> <<111:5899-5905>> <<?>> <<VARIABLE>> <<LINK>>
<<prediction>> <<111:5906-5916>> <<?>> <<VARIABLE>> <<LINK>>
<<batch>> <<111:5918-5923>> <<?>> <<VARIABLE>> <<LINK>>
<<output>> <<112:5959-5965>> <<?>> <<VARIABLE>> <<LINK>>
<<gradient_accumulation>> <<113:5990-6011>> <<int>> <<VARIABLE>> <<LINK>>
<<gradient_accumulation>> <<113:6016-6037>> <<int>> <<VARIABLE>> <<LINK>>
<<loss>> <<114:6060-6064>> <<?>> <<VARIABLE>> <<LINK>>
<<gradient_accumulation>> <<114:6068-6089>> <<int>> <<VARIABLE>> <<LINK>>
<<loss>> <<115:6103-6107>> <<{int||?}>> <<VARIABLE>> <<LINK>>
<<total_loss>> <<116:6132-6142>> <<int>> <<VARIABLE>> <<LINK>>
<<loss>> <<116:6146-6150>> <<{int||?}>> <<VARIABLE>> <<LINK>>
<<history>> <<117:6174-6181>> <<?>> <<VARIABLE>> <<LINK>>
<<gradient_accumulation>> <<117:6187-6208>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<118:6231-6235>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<self>> <<119:6306-6310>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<self>> <<119:6331-6335>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<optimizer>> <<120:6371-6380>> <<?>> <<VARIABLE>> <<LINK>>
<<scheduler>> <<121:6408-6417>> <<?>> <<VARIABLE>> <<LINK>>
<<scheduler>> <<122:6440-6449>> <<?>> <<VARIABLE>> <<LINK>>
<<optimizer>> <<123:6474-6483>> <<?>> <<VARIABLE>> <<LINK>>
<<timer>> <<124:6513-6518>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<124:6523-6527>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<report_metrics>> <<124:6528-6542>> <<function>> <<VARIABLE>> <<LINK>>
<<total_loss>> <<124:6543-6553>> <<int>> <<VARIABLE>> <<LINK>>
<<timer>> <<124:6557-6562>> <<?>> <<VARIABLE>> <<LINK>>
<<metric>> <<124:6577-6583>> <<?>> <<VARIABLE>> <<LINK>>
<<transformer>> <<163:8234-8245>> <<?>> <<VARIABLE>> <<LINK>>
<<training>> <<164:8273-8281>> <<?>> <<VARIABLE>> <<LINK>>
<<transformer>> <<165:8355-8366>> <<?>> <<VARIABLE>> <<LINK>>
<<config>> <<165:8375-8381>> <<?>> <<VARIABLE>> <<LINK>>
<<config>> <<167:8466-8472>> <<?>> <<VARIABLE>> <<LINK>>
<<model>> <<168:8490-8495>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<131:6862-6866>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<data>> <<132:6916-6920>> <<?>> <<VARIABLE>> <<LINK>>
<<metric>> <<134:6956-6962>> <<?>> <<VARIABLE>> <<LINK>>
<<output>> <<135:6983-6989>> <<?>> <<VARIABLE>> <<LINK>>
<<data>> <<139:7094-7098>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<140:7127-7131>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<feed_batch>> <<140:7132-7142>> <<function>> <<VARIABLE>> <<LINK>>
<<batch>> <<140:7143-7148>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<141:7176-7180>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<decode>> <<141:7181-7187>> <<function>> <<VARIABLE>> <<LINK>>
<<output_dict>> <<141:7188-7199>> <<?>> <<VARIABLE>> <<LINK>>
<<metric>> <<142:7214-7220>> <<?>> <<VARIABLE>> <<LINK>>
<<prediction>> <<142:7221-7231>> <<?>> <<VARIABLE>> <<LINK>>
<<batch>> <<142:7233-7238>> <<?>> <<VARIABLE>> <<LINK>>
<<output>> <<143:7270-7276>> <<?>> <<VARIABLE>> <<LINK>>
<<predictions>> <<144:7295-7306>> <<list>> <<VARIABLE>> <<LINK>>
<<prediction>> <<144:7314-7324>> <<?>> <<VARIABLE>> <<LINK>>
<<orders>> <<145:7352-7358>> <<list>> <<VARIABLE>> <<LINK>>
<<batch>> <<145:7366-7371>> <<?>> <<VARIABLE>> <<LINK>>
<<samples>> <<146:7395-7402>> <<list>> <<VARIABLE>> <<LINK>>
<<batch>> <<146:7419-7424>> <<?>> <<VARIABLE>> <<LINK>>
<<batch>> <<146:7436-7441>> <<?>> <<VARIABLE>> <<LINK>>
<<output_dict>> <<147:7475-7486>> <<?>> <<VARIABLE>> <<LINK>>
<<total_loss>> <<148:7508-7518>> <<int>> <<VARIABLE>> <<LINK>>
<<loss>> <<148:7522-7526>> <<?>> <<VARIABLE>> <<LINK>>
<<timer>> <<149:7547-7552>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<149:7557-7561>> <<TransformerSemanticTextualSimilarity>> <<VARIABLE>> <<LINK>>
<<report_metrics>> <<149:7562-7576>> <<function>> <<VARIABLE>> <<LINK>>
<<total_loss>> <<149:7577-7587>> <<int>> <<VARIABLE>> <<LINK>>
<<timer>> <<149:7591-7596>> <<?>> <<VARIABLE>> <<LINK>>
<<metric>> <<149:7611-7617>> <<?>> <<VARIABLE>> <<LINK>>

<<unittest>> <<17:792-800>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<ConvolutionalKerasBoxPredictorTest>> <<34:1525-1559>> <<type>> <<CLASS>> <<ANCHOR>>
<<_build_conv_hyperparams>> <<36:1590-1613>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_get_boxes_for_five_aspect_ratios_per_location>> <<52:2048-2098>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_get_boxes_for_one_aspect_ratio_per_location>> <<83:3440-3488>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_get_multi_class_predictions_for_five_aspect_ratios_per_location>> <<113:4817-4885>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_get_predictions_with_feature_maps_of_dynamic_shape>> <<148:6406-6461>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_use_depthwise_convolution>> <<197:8718-8748>> <<function>> <<METHOD>> <<ANCHOR>>
<<WeightSharedConvolutionalKerasBoxPredictorTest>> <<261:11500-11546>> <<type>> <<CLASS>> <<ANCHOR>>
<<_build_conv_hyperparams>> <<263:11577-11600>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_get_boxes_for_five_aspect_ratios_per_location>> <<289:12313-12363>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_bias_predictions_to_background_with_sigmoid_score_conversion>> <<316:13532-13597>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_get_multi_class_predictions_for_five_aspect_ratios_per_location>> <<341:14618-14686>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_get_multi_class_predictions_from_two_feature_maps>> <<372:16034-16088>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_get_multi_class_predictions_from_feature_maps_of_different_depth>> <<405:17575-17644>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_predictions_multiple_feature_maps_share_weights_separate_batchnorm>> <<440:19267-19338>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_predictions_multiple_feature_maps_share_weights_without_batchnorm>> <<544:24825-24895>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_predictions_multiple_feature_maps_share_weights_with_depthwise>> <<609:27815-27882>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_no_batchnorm_params_when_batchnorm_is_not_configured>> <<687:31619-31676>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_predictions_share_weights_share_tower_separate_batchnorm>> <<752:34620-34681>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_predictions_share_weights_share_tower_without_batchnorm>> <<829:38433-38493>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_other_heads_predictions>> <<888:41042-41070>> <<function>> <<METHOD>> <<ANCHOR>>
<<self>> <<342:14695-14698>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<343:14707-14737>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<263:11601-11604>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<add_batch_norm>> <<263:11607-11610>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<conv_hyperparams>> <<264:11634-11650>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<conv_hyperparams_text_proto>> <<265:11688-11715>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<batch_norm_proto>> <<279:11981-11997>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<conv_hyperparams_text_proto>> <<284:12079-12106>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<344:14747-14765>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<357:15260-15268>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<image_features>> <<365:15658-15672>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<366:15728-15741>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<366:15743-15776>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<52:2099-2102>> <<ConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<36:1614-1617>> <<ConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<conv_hyperparams>> <<37:1626-1642>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<conv_hyperparams_text_proto>> <<38:1680-1707>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<53:2111-2129>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<69:2704-2712>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<image_features>> <<77:3089-3103>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<78:3159-3172>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<78:3174-3196>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<830:38502-38505>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<832:38552-38582>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<833:38592-38610>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<variables>> <<847:39201-39210>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<849:39227-39235>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<var>> <<864:39951-39954>> <<?>> <<SCOPE>> <<ANCHOR>>
<<actual_variable_set>> <<864:39897-39916>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<expected_variable_set>> <<865:39975-39996>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<753:34690-34693>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<755:34740-34770>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<756:34780-34798>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<variables>> <<769:35332-35341>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<771:35358-35366>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<var>> <<786:36082-36085>> <<?>> <<SCOPE>> <<ANCHOR>>
<<actual_variable_set>> <<786:36028-36047>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<expected_variable_set>> <<787:36106-36127>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<545:24904-24907>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<547:24954-24984>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<548:24994-25012>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<variables>> <<561:25541-25550>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<563:25567-25575>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<var>> <<577:26279-26282>> <<?>> <<SCOPE>> <<ANCHOR>>
<<actual_variable_set>> <<577:26225-26244>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<expected_variable_set>> <<578:26303-26324>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<687:31677-31680>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<689:31727-31757>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<690:31767-31785>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<variables>> <<703:32334-32343>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<705:32360-32368>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<var>> <<720:33084-33087>> <<?>> <<SCOPE>> <<ANCHOR>>
<<actual_variable_set>> <<720:33030-33049>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<expected_variable_set>> <<721:33108-33129>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<83:3489-3492>> <<ConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<conv_box_predictor>> <<84:3501-3519>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<100:4094-4102>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<image_features>> <<107:4468-4482>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<108:4538-4551>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<108:4553-4575>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<406:17653-17656>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<407:17665-17695>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<408:17705-17723>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<421:18224-18232>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<image_features1>> <<431:18715-18730>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features2>> <<432:18785-18800>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features3>> <<433:18855-18870>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<434:18926-18939>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<434:18941-18974>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<316:13598-13601>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<conv_box_predictor>> <<317:13610-13628>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<331:14139-14147>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<image_features>> <<337:14407-14421>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions>> <<338:14476-14493>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<114:4894-4897>> <<ConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<115:4906-4936>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<116:4946-4960>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<117:5015-5033>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<133:5637-5645>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<box_encodings>> <<141:6045-6058>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<142:6066-6099>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<197:8749-8752>> <<ConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<conv_box_predictor>> <<199:8799-8817>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<variables>> <<216:9421-9430>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<217:9445-9453>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<resolution>> <<227:9890-9900>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<expected_num_anchors>> <<228:9911-9931>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<229:9963-9976>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<229:9978-10000>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<var>> <<232:10146-10149>> <<?>> <<SCOPE>> <<ANCHOR>>
<<actual_variable_set>> <<232:10092-10111>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<expected_variable_set>> <<236:10359-10380>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<149:6470-6473>> <<ConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<conv_box_predictor>> <<151:6520-6538>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<variables>> <<167:7109-7118>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<168:7133-7141>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<resolution>> <<177:7576-7586>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<expected_num_anchors>> <<178:7597-7617>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<179:7649-7662>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<179:7664-7686>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<var>> <<182:7832-7835>> <<?>> <<SCOPE>> <<ANCHOR>>
<<actual_variable_set>> <<182:7778-7797>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<expected_variable_set>> <<186:8045-8066>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<610:27891-27894>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<612:27941-27971>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<613:27981-27999>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<variables>> <<627:28581-28590>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<629:28607-28615>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<var>> <<643:29319-29322>> <<?>> <<SCOPE>> <<ANCHOR>>
<<actual_variable_set>> <<643:29265-29284>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<expected_variable_set>> <<644:29343-29364>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<441:19347-19350>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<443:19397-19427>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<444:19437-19455>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<variables>> <<456:19947-19956>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<458:19973-19981>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<var>> <<472:20685-20688>> <<?>> <<SCOPE>> <<ANCHOR>>
<<actual_variable_set>> <<472:20631-20650>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<expected_variable_set>> <<473:20709-20730>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<373:16097-16100>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<num_classes_without_background>> <<374:16109-16139>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<375:16149-16167>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<388:16665-16673>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<image_features1>> <<397:17110-17125>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features2>> <<398:17180-17195>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<399:17251-17264>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<399:17266-17299>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<888:41071-41074>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<box_code_size>> <<889:41083-41096>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<num_classes_without_background>> <<890:41106-41136>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<other_head_name>> <<891:41146-41161>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<mask_height>> <<892:41176-41187>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<mask_width>> <<893:41197-41207>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<num_predictions_per_location>> <<894:41217-41245>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<box_prediction_head>> <<895:41255-41274>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_prediction_head>> <<899:41495-41516>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<other_heads>> <<903:41764-41775>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<conv_box_predictor>> <<913:42169-42187>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<924:42662-42670>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<batch_size>> <<933:43095-43105>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<feature_ht>> <<934:43115-43125>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<feature_wt>> <<935:43135-43145>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<936:43155-43169>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<938:43289-43302>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions>> <<938:43304-43321>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<other_head_predictions>> <<938:43323-43345>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<num_anchors>> <<940:43405-43416>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<289:12364-12367>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<PARAMETER>> <<ANCHOR>>
<<conv_box_predictor>> <<290:12376-12394>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<graph_fn>> <<303:12860-12868>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<image_features>> <<310:13234-13248>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<311:13304-13317>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<311:13319-13341>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features1>> <<629:28616-28619>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_features2>> <<629:28633-28636>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<630:28658-28673>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<632:28798-28811>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<634:28897-28930>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<69:2713-2716>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<70:2737-2752>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<71:2799-2812>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<73:2898-2920>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<357:15269-15272>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<358:15293-15308>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<359:15355-15368>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<361:15454-15487>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<331:14148-14151>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<332:14172-14187>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions>> <<333:14234-14251>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<924:42671-42674>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<925:42695-42710>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<key>> <<926:42761-42764>> <<?>> <<SCOPE>> <<ANCHOR>>
<<value>> <<926:42766-42771>> <<?>> <<SCOPE>> <<ANCHOR>>
<<image_features1>> <<771:35367-35370>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_features2>> <<771:35384-35387>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<772:35409-35424>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<775:35561-35574>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<777:35660-35693>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features1>> <<849:39236-39239>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_features2>> <<849:39253-39256>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<850:39278-39293>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<853:39430-39443>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<855:39529-39562>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<217:9454-9457>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<218:9478-9493>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<220:9600-9613>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<222:9699-9721>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<168:7142-7145>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<169:7166-7181>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<171:7288-7301>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<173:7387-7409>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<303:12869-12872>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<304:12893-12908>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<305:12955-12968>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<307:13054-13076>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features1>> <<388:16674-16677>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_features2>> <<388:16691-16694>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<389:16716-16731>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<390:16796-16809>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<392:16895-16928>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features1>> <<421:18233-18236>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_features2>> <<421:18250-18253>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_features3>> <<421:18267-18270>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<422:18292-18307>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<424:18401-18414>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<426:18500-18533>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<100:4103-4106>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<101:4127-4142>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<102:4189-4202>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<objectness_predictions>> <<104:4288-4310>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features1>> <<458:19982-19985>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_features2>> <<458:19999-20002>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<459:20024-20039>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<461:20164-20177>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<463:20263-20296>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features>> <<133:5646-5649>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<134:5670-5685>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<135:5732-5745>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<137:5831-5864>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features1>> <<705:32369-32372>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_features2>> <<705:32386-32389>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<706:32411-32426>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<709:32563-32576>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<711:32662-32695>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<image_features1>> <<563:25576-25579>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_features2>> <<563:25593-25596>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_predictions>> <<564:25618-25633>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_encodings>> <<566:25758-25771>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<568:25857-25890>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<num_classes_without_background>> <<348:14923-14953>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<349:14985-14989>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<349:14990-15013>> <<function>> <<VARIABLE>> <<LINK>>
<<add_batch_norm>> <<278:11958-11972>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_hyperparams_text_proto>> <<284:12079-12106>> <<str>> <<VARIABLE>> <<LINK>>
<<batch_norm_proto>> <<284:12110-12126>> <<str>> <<VARIABLE>> <<LINK>>
<<conv_hyperparams_text_proto>> <<285:12150-12177>> <<str>> <<VARIABLE>> <<LINK>>
<<conv_hyperparams>> <<285:12179-12195>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_hyperparams>> <<286:12251-12267>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<366:15780-15784>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<367:15803-15811>> <<function>> <<VARIABLE>> <<LINK>>
<<image_features>> <<367:15814-15828>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<368:15836-15840>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<368:15856-15869>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<369:15895-15899>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<369:15915-15948>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<370:15990-16020>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<57:2296-2300>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<57:2301-2324>> <<function>> <<VARIABLE>> <<LINK>>
<<conv_hyperparams_text_proto>> <<49:1920-1947>> <<str>> <<VARIABLE>> <<LINK>>
<<conv_hyperparams>> <<49:1949-1965>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_hyperparams>> <<50:2021-2037>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<78:3200-3204>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<78:3213-3221>> <<function>> <<VARIABLE>> <<LINK>>
<<image_features>> <<79:3284-3298>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<80:3306-3310>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<80:3326-3339>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<81:3368-3372>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<81:3388-3410>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<837:38768-38798>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<838:38830-38834>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<838:38835-38858>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<860:39744-39748>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<860:39757-39765>> <<function>> <<VARIABLE>> <<LINK>>
<<variables>> <<864:39958-39967>> <<list>> <<VARIABLE>> <<LINK>>
<<var>> <<864:39951-39954>> <<?>> <<VARIABLE>> <<LINK>>
<<var>> <<864:39924-39927>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<886:40972-40976>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<expected_variable_set>> <<886:40989-41010>> <<?>> <<VARIABLE>> <<LINK>>
<<actual_variable_set>> <<886:41012-41031>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<760:34956-34986>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<761:35018-35022>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<761:35023-35046>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<782:35875-35879>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<782:35888-35896>> <<function>> <<VARIABLE>> <<LINK>>
<<variables>> <<786:36089-36098>> <<list>> <<VARIABLE>> <<LINK>>
<<var>> <<786:36082-36085>> <<?>> <<VARIABLE>> <<LINK>>
<<var>> <<786:36055-36058>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<827:38363-38367>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<expected_variable_set>> <<827:38380-38401>> <<?>> <<VARIABLE>> <<LINK>>
<<actual_variable_set>> <<827:38403-38422>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<552:25170-25200>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<553:25232-25236>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<553:25237-25260>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<573:26072-26076>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<573:26085-26093>> <<function>> <<VARIABLE>> <<LINK>>
<<variables>> <<577:26286-26295>> <<list>> <<VARIABLE>> <<LINK>>
<<var>> <<577:26279-26282>> <<?>> <<VARIABLE>> <<LINK>>
<<var>> <<577:26252-26255>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<607:27745-27749>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<expected_variable_set>> <<607:27762-27783>> <<?>> <<VARIABLE>> <<LINK>>
<<actual_variable_set>> <<607:27785-27804>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<694:31943-31973>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<695:32005-32009>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<695:32010-32033>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<716:32877-32881>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<716:32890-32898>> <<function>> <<VARIABLE>> <<LINK>>
<<variables>> <<720:33091-33100>> <<list>> <<VARIABLE>> <<LINK>>
<<var>> <<720:33084-33087>> <<?>> <<VARIABLE>> <<LINK>>
<<var>> <<720:33057-33060>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<750:34550-34554>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<expected_variable_set>> <<750:34567-34588>> <<?>> <<VARIABLE>> <<LINK>>
<<actual_variable_set>> <<750:34590-34609>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<88:3686-3690>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<88:3691-3714>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<108:4579-4583>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<108:4592-4600>> <<function>> <<VARIABLE>> <<LINK>>
<<image_features>> <<109:4663-4677>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<110:4685-4689>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<110:4705-4718>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<111:4746-4750>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<111:4766-4788>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<412:17881-17911>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<413:17943-17947>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<413:17948-17971>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<434:18978-18982>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<435:19001-19009>> <<function>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<435:19012-19027>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<435:19029-19044>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features3>> <<435:19046-19061>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<436:19069-19073>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<436:19089-19102>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<437:19128-19132>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<437:19148-19181>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<438:19223-19253>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<322:13818-13822>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<322:13823-13846>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<338:14496-14500>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<338:14509-14517>> <<function>> <<VARIABLE>> <<LINK>>
<<image_features>> <<338:14520-14534>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<339:14542-14546>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<class_predictions>> <<339:14573-14590>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<120:5167-5197>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<121:5229-5233>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<121:5234-5257>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<142:6103-6107>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<142:6116-6124>> <<function>> <<VARIABLE>> <<LINK>>
<<image_features>> <<143:6183-6197>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<144:6205-6209>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<144:6225-6238>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<145:6267-6271>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<145:6287-6320>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<146:6362-6392>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<203:8984-8988>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<203:8989-9012>> <<function>> <<VARIABLE>> <<LINK>>
<<resolution>> <<228:9934-9944>> <<int>> <<VARIABLE>> <<LINK>>
<<resolution>> <<228:9945-9955>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<229:10003-10007>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<230:10026-10034>> <<function>> <<VARIABLE>> <<LINK>>
<<resolution>> <<230:10055-10065>> <<int>> <<VARIABLE>> <<LINK>>
<<resolution>> <<230:10067-10077>> <<int>> <<VARIABLE>> <<LINK>>
<<variables>> <<232:10153-10162>> <<list>> <<VARIABLE>> <<LINK>>
<<var>> <<232:10146-10149>> <<?>> <<VARIABLE>> <<LINK>>
<<var>> <<232:10119-10122>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<233:10170-10174>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<233:10190-10203>> <<?>> <<VARIABLE>> <<LINK>>
<<expected_num_anchors>> <<233:10215-10235>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<234:10249-10253>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<234:10269-10291>> <<?>> <<VARIABLE>> <<LINK>>
<<expected_num_anchors>> <<235:10328-10348>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<255:11221-11225>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<expected_variable_set>> <<255:11238-11259>> <<?>> <<VARIABLE>> <<LINK>>
<<actual_variable_set>> <<255:11261-11280>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<256:11287-11291>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<256:11304-11322>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<155:6705-6709>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<155:6710-6733>> <<function>> <<VARIABLE>> <<LINK>>
<<resolution>> <<178:7620-7630>> <<int>> <<VARIABLE>> <<LINK>>
<<resolution>> <<178:7631-7641>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<179:7689-7693>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<180:7712-7720>> <<function>> <<VARIABLE>> <<LINK>>
<<resolution>> <<180:7741-7751>> <<int>> <<VARIABLE>> <<LINK>>
<<resolution>> <<180:7753-7763>> <<int>> <<VARIABLE>> <<LINK>>
<<variables>> <<182:7839-7848>> <<list>> <<VARIABLE>> <<LINK>>
<<var>> <<182:7832-7835>> <<?>> <<VARIABLE>> <<LINK>>
<<var>> <<182:7805-7808>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<183:7856-7860>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<183:7876-7889>> <<?>> <<VARIABLE>> <<LINK>>
<<expected_num_anchors>> <<183:7901-7921>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<184:7935-7939>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<184:7955-7977>> <<?>> <<VARIABLE>> <<LINK>>
<<expected_num_anchors>> <<185:8014-8034>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<193:8509-8513>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<expected_variable_set>> <<193:8526-8547>> <<?>> <<VARIABLE>> <<LINK>>
<<actual_variable_set>> <<193:8549-8568>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<194:8575-8579>> <<ConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<194:8592-8610>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<617:28157-28187>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<618:28219-28223>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<618:28224-28247>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<639:29112-29116>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<639:29125-29133>> <<function>> <<VARIABLE>> <<LINK>>
<<variables>> <<643:29326-29335>> <<list>> <<VARIABLE>> <<LINK>>
<<var>> <<643:29319-29322>> <<?>> <<VARIABLE>> <<LINK>>
<<var>> <<643:29292-29295>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<685:31549-31553>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<expected_variable_set>> <<685:31566-31587>> <<?>> <<VARIABLE>> <<LINK>>
<<actual_variable_set>> <<685:31589-31608>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<448:19613-19643>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<449:19675-19679>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<449:19680-19703>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<468:20478-20482>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<468:20491-20499>> <<function>> <<VARIABLE>> <<LINK>>
<<variables>> <<472:20692-20701>> <<list>> <<VARIABLE>> <<LINK>>
<<var>> <<472:20685-20688>> <<?>> <<VARIABLE>> <<LINK>>
<<var>> <<472:20658-20661>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<542:24755-24759>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<expected_variable_set>> <<542:24772-24793>> <<?>> <<VARIABLE>> <<LINK>>
<<actual_variable_set>> <<542:24795-24814>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<379:16325-16355>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<380:16387-16391>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<380:16392-16415>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<399:17303-17307>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<400:17326-17334>> <<function>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<400:17337-17352>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<400:17354-17369>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<401:17377-17381>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<401:17397-17410>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<402:17436-17440>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<402:17456-17489>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<403:17531-17561>> <<int>> <<VARIABLE>> <<LINK>>
<<box_code_size>> <<896:41349-41362>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<897:41390-41394>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<897:41395-41418>> <<function>> <<VARIABLE>> <<LINK>>
<<num_predictions_per_location>> <<898:41460-41488>> <<int>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<900:41597-41627>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<901:41659-41663>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<901:41664-41687>> <<function>> <<VARIABLE>> <<LINK>>
<<num_predictions_per_location>> <<902:41729-41757>> <<int>> <<VARIABLE>> <<LINK>>
<<other_head_name>> <<904:41789-41804>> <<str>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<906:41899-41929>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<907:41965-41969>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<907:41970-41993>> <<function>> <<VARIABLE>> <<LINK>>
<<num_predictions_per_location>> <<908:42043-42071>> <<int>> <<VARIABLE>> <<LINK>>
<<mask_height>> <<909:42102-42113>> <<int>> <<VARIABLE>> <<LINK>>
<<mask_width>> <<910:42143-42153>> <<int>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<915:42292-42322>> <<int>> <<VARIABLE>> <<LINK>>
<<box_prediction_head>> <<916:42353-42372>> <<?>> <<VARIABLE>> <<LINK>>
<<class_prediction_head>> <<917:42405-42426>> <<?>> <<VARIABLE>> <<LINK>>
<<other_heads>> <<918:42449-42460>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<919:42488-42492>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<919:42493-42516>> <<function>> <<VARIABLE>> <<LINK>>
<<batch_size>> <<936:43187-43197>> <<int>> <<VARIABLE>> <<LINK>>
<<feature_ht>> <<936:43199-43209>> <<int>> <<VARIABLE>> <<LINK>>
<<feature_wt>> <<936:43211-43221>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<938:43349-43353>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<939:43372-43380>> <<function>> <<VARIABLE>> <<LINK>>
<<image_features>> <<939:43383-43397>> <<?>> <<VARIABLE>> <<LINK>>
<<feature_ht>> <<940:43419-43429>> <<int>> <<VARIABLE>> <<LINK>>
<<feature_wt>> <<940:43432-43442>> <<int>> <<VARIABLE>> <<LINK>>
<<num_predictions_per_location>> <<940:43445-43473>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<941:43479-43483>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<941:43499-43512>> <<?>> <<VARIABLE>> <<LINK>>
<<batch_size>> <<942:43546-43556>> <<int>> <<VARIABLE>> <<LINK>>
<<num_anchors>> <<942:43558-43569>> <<int>> <<VARIABLE>> <<LINK>>
<<box_code_size>> <<942:43571-43584>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<943:43592-43596>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<class_predictions>> <<944:43622-43639>> <<?>> <<VARIABLE>> <<LINK>>
<<batch_size>> <<945:43657-43667>> <<int>> <<VARIABLE>> <<LINK>>
<<num_anchors>> <<945:43669-43680>> <<int>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<945:43682-43712>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<946:43724-43728>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<other_head_predictions>> <<946:43744-43766>> <<?>> <<VARIABLE>> <<LINK>>
<<batch_size>> <<947:43785-43795>> <<int>> <<VARIABLE>> <<LINK>>
<<num_anchors>> <<947:43797-43808>> <<int>> <<VARIABLE>> <<LINK>>
<<num_classes_without_background>> <<947:43810-43840>> <<int>> <<VARIABLE>> <<LINK>>
<<mask_height>> <<947:43842-43853>> <<int>> <<VARIABLE>> <<LINK>>
<<mask_width>> <<948:43864-43874>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<295:12585-12589>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<_build_conv_hyperparams>> <<295:12590-12613>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<311:13345-13349>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<graph_fn>> <<312:13368-13376>> <<function>> <<VARIABLE>> <<LINK>>
<<image_features>> <<312:13379-13393>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<313:13401-13405>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<313:13421-13434>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<314:13460-13464>> <<WeightSharedConvolutionalKerasBoxPredictorTest>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<314:13480-13502>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<630:28676-28694>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<630:28696-28711>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<630:28713-28728>> <<?>> <<VARIABLE>> <<LINK>>
<<variables>> <<631:28738-28747>> <<list>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<631:28760-28778>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<633:28836-28851>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<635:28955-28970>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<637:29055-29068>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<637:29070-29103>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<70:2755-2773>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features>> <<70:2775-2789>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<72:2837-2852>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<74:2945-2960>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<76:3045-3058>> <<?>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<76:3060-3082>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<358:15311-15329>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features>> <<358:15331-15345>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<360:15393-15408>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<361:15500-15515>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<363:15601-15614>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<363:15616-15649>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<332:14190-14208>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features>> <<332:14210-14224>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<333:14264-14279>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions>> <<335:14379-14396>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<925:42713-42731>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features>> <<925:42733-42747>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<926:42775-42790>> <<?>> <<VARIABLE>> <<LINK>>
<<value>> <<927:42842-42847>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<927:42809-42824>> <<?>> <<VARIABLE>> <<LINK>>
<<key>> <<927:42825-42828>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<928:42875-42890>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<929:42912-42927>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<930:42973-42988>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<931:43054-43069>> <<?>> <<VARIABLE>> <<LINK>>
<<other_head_name>> <<931:43070-43085>> <<str>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<772:35427-35445>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<773:35459-35474>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<773:35476-35491>> <<?>> <<VARIABLE>> <<LINK>>
<<variables>> <<774:35501-35510>> <<list>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<774:35523-35541>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<776:35599-35614>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<778:35718-35733>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<780:35818-35831>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<780:35833-35866>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<850:39296-39314>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<851:39328-39343>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<851:39345-39360>> <<?>> <<VARIABLE>> <<LINK>>
<<variables>> <<852:39370-39379>> <<list>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<852:39392-39410>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<854:39468-39483>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<856:39587-39602>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<858:39687-39700>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<858:39702-39735>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<218:9496-9514>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features>> <<218:9516-9530>> <<?>> <<VARIABLE>> <<LINK>>
<<variables>> <<219:9540-9549>> <<list>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<219:9562-9580>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<221:9638-9653>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<223:9746-9761>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<225:9845-9858>> <<?>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<225:9860-9882>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<169:7184-7202>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features>> <<169:7204-7218>> <<?>> <<VARIABLE>> <<LINK>>
<<variables>> <<170:7228-7237>> <<list>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<170:7250-7268>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<172:7326-7341>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<174:7434-7449>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<176:7533-7546>> <<?>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<176:7548-7570>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<304:12911-12929>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features>> <<304:12931-12945>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<306:12993-13008>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<307:13089-13104>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<309:13190-13203>> <<?>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<309:13205-13227>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<389:16734-16752>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<389:16754-16769>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<389:16771-16786>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<391:16834-16849>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<393:16953-16968>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<395:17053-17066>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<395:17068-17101>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<422:18310-18328>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<423:18342-18357>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<423:18359-18374>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features3>> <<423:18376-18391>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<425:18439-18454>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<427:18558-18573>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<429:18658-18671>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<429:18673-18706>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<101:4145-4163>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features>> <<101:4165-4179>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<103:4227-4242>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<104:4323-4338>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<106:4424-4437>> <<?>> <<VARIABLE>> <<LINK>>
<<objectness_predictions>> <<106:4439-4461>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<459:20042-20060>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<459:20062-20077>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<459:20079-20094>> <<?>> <<VARIABLE>> <<LINK>>
<<variables>> <<460:20104-20113>> <<list>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<460:20126-20144>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<462:20202-20217>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<464:20321-20336>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<466:20421-20434>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<466:20436-20469>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<134:5688-5706>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features>> <<134:5708-5722>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<136:5770-5785>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<138:5889-5904>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<140:5989-6002>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<140:6004-6037>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<706:32429-32447>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<707:32461-32476>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<707:32478-32493>> <<?>> <<VARIABLE>> <<LINK>>
<<variables>> <<708:32503-32512>> <<list>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<708:32525-32543>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<710:32601-32616>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<712:32720-32735>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<714:32820-32833>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<714:32835-32868>> <<?>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<564:25636-25654>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features1>> <<564:25656-25671>> <<?>> <<VARIABLE>> <<LINK>>
<<image_features2>> <<564:25673-25688>> <<?>> <<VARIABLE>> <<LINK>>
<<variables>> <<565:25698-25707>> <<list>> <<VARIABLE>> <<LINK>>
<<conv_box_predictor>> <<565:25720-25738>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<567:25796-25811>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<569:25915-25930>> <<?>> <<VARIABLE>> <<LINK>>
<<box_encodings>> <<571:26015-26028>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<571:26030-26063>> <<?>> <<VARIABLE>> <<LINK>>

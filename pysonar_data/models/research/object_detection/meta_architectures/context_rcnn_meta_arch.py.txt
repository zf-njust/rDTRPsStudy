<<__future__>> <<22:983-993>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<__future__>> <<23:1023-1033>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<__future__>> <<24:1056-1066>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<_UNINITIALIZED_FEATURE_EXTRACTOR>> <<39:1608-1640>> <<str>> <<SCOPE>> <<ANCHOR>>
<<ContextRCNNMetaArch>> <<42:1674-1693>> <<type>> <<CLASS>> <<ANCHOR>>
<<__init__>> <<45:1799-1807>> <<function>> <<CONSTRUCTOR>> <<ANCHOR>>
<<get_side_inputs>> <<333:17652-17667>> <<function>> <<METHOD>> <<ANCHOR>>
<<_predict_second_stage>> <<362:18697-18718>> <<function>> <<METHOD>> <<ANCHOR>>
<<_box_prediction>> <<438:23211-23226>> <<function>> <<METHOD>> <<ANCHOR>>
<<_compute_second_stage_input_feature_maps>> <<541:28665-28705>> <<function>> <<METHOD>> <<ANCHOR>>
<<_extract_box_classifier_features>> <<591:30937-30969>> <<function>> <<METHOD>> <<ANCHOR>>
<<self>> <<592:30978-30981>> <<ContextRCNNMetaArch>> <<PARAMETER>> <<ANCHOR>>
<<flattened_box_features>> <<592:30984-30987>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_proposals>> <<592:31008-31011>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<context_features>> <<592:31023-31026>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<valid_context_size>> <<593:31048-31051>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<attention_position>> <<594:31075-31078>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<_feature_extractor_for_box_classifier_features>> <<598:31285-31331>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<box_classifier_features>> <<603:31549-31572>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_classifier_features>> <<607:31699-31722>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<attention_features>> <<614:32011-32029>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_classifier_features>> <<621:32312-32335>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<438:23227-23230>> <<ContextRCNNMetaArch>> <<PARAMETER>> <<ANCHOR>>
<<rpn_features_to_crop>> <<438:23233-23236>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<proposal_boxes_normalized>> <<438:23255-23258>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_shape>> <<439:23305-23308>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<true_image_shapes>> <<439:23318-23321>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_proposals>> <<439:23337-23340>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<_proposals>> <<439:23340-23350>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<541:28706-28709>> <<ContextRCNNMetaArch>> <<PARAMETER>> <<ANCHOR>>
<<features_to_crop>> <<541:28712-28715>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<proposal_boxes_normalized>> <<542:28778-28781>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_shape>> <<543:28853-28856>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_proposals>> <<544:28914-28917>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<context_features>> <<545:28977-28980>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<valid_context_size>> <<546:29043-29046>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<box_features>> <<569:30078-30090>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<flattened_box_features>> <<573:30247-30269>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<flattened_box_features>> <<575:30328-30350>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<attention_features>> <<579:30498-30516>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<flattened_box_features>> <<586:30798-30820>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<flattened_proposal_feature_maps>> <<495:26646-26677>> <<None>> <<VARIABLE>> <<ANCHOR>>
<<box_classifier_features>> <<500:26864-26887>> <<None>> <<VARIABLE>> <<ANCHOR>>
<<box_predictions>> <<504:27064-27079>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<box_predictions>> <<508:27200-27215>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<refined_box_encodings>> <<514:27434-27455>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<class_predictions_with_background>> <<517:27581-27614>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<absolute_proposal_boxes>> <<521:27774-27797>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<prediction_dict>> <<524:27920-27935>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<362:18719-18722>> <<ContextRCNNMetaArch>> <<PARAMETER>> <<ANCHOR>>
<<rpn_box_encodings>> <<362:18725-18728>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<rpn_objectness_predictions_with_background>> <<363:18773-18776>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<rpn_features_to_crop>> <<364:18846-18849>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<anchors>> <<364:18868-18871>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_shape>> <<364:18877-18880>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<true_image_shapes>> <<365:18919-18922>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<e_image_shapes>> <<365:18922-18936>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<proposal_boxes_normalized>> <<426:22594-22619>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<num_proposals>> <<426:22621-22634>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<prediction_dict>> <<430:22794-22809>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<features>> <<333:17668-17671>> <<ContextRCNNMetaArch>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<45:1808-1811>> <<ContextRCNNMetaArch>> <<PARAMETER>> <<ANCHOR>>
<<is_training>> <<46:1830-1833>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_classes>> <<47:1859-1862>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<image_resizer_fn>> <<48:1888-1891>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<feature_extractor>> <<49:1922-1925>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<number_of_stages>> <<50:1957-1960>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_anchor_generator>> <<51:1991-1994>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_target_assigner>> <<52:2037-2040>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_atrous_rate>> <<53:2082-2085>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_box_predictor_arg_scope_fn>> <<54:2123-2126>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_box_predictor_kernel_size>> <<55:2179-2182>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_box_predictor_depth>> <<56:2234-2237>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_minibatch_size>> <<57:2283-2286>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_sampler>> <<58:2327-2330>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_non_max_suppression_fn>> <<59:2364-2367>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_max_proposals>> <<60:2416-2419>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_localization_loss_weight>> <<61:2459-2462>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<first_stage_objectness_loss_weight>> <<62:2513-2516>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<crop_and_resize_fn>> <<63:2565-2568>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<initial_crop_size>> <<64:2601-2604>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<maxpool_kernel_size>> <<65:2636-2639>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<maxpool_stride>> <<66:2673-2676>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_target_assigner>> <<67:2705-2708>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_mask_rcnn_box_predictor>> <<68:2751-2754>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_batch_size>> <<69:2805-2808>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_sampler>> <<70:2846-2849>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_non_max_suppression_fn>> <<71:2884-2887>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_score_conversion_fn>> <<72:2937-2940>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_localization_loss_weight>> <<73:2987-2990>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_classification_loss_weight>> <<74:3042-3045>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_classification_loss>> <<75:3099-3102>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<second_stage_mask_prediction_loss_weight>> <<76:3149-3152>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<hard_example_miner>> <<77:3211-3214>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<parallel_iterations>> <<78:3252-3255>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<add_summaries>> <<79:3292-3295>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<clip_anchors_to_image>> <<80:3328-3331>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<use_static_shapes>> <<81:3373-3376>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<resize_masks>> <<82:3414-3417>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<freeze_batchnorm>> <<83:3449-3452>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<return_raw_detections_during_predict>> <<84:3489-3492>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<output_final_box_features>> <<85:3549-3552>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<output_final_box_rpn_features>> <<86:3598-3601>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<attention_bottleneck_dimension>> <<87:3651-3654>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<attention_temperature>> <<88:3704-3707>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<use_self_attention>> <<89:3748-3751>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<use_long_term_attention>> <<90:3790-3793>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self_attention_in_sequence>> <<91:3836-3839>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_attention_heads>> <<92:3886-3889>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<num_attention_layers>> <<93:3925-3928>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<attention_position>> <<94:3965-3968>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<_attention_position>> <<300:16288-16307>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_context_feature_extract_fn>> <<303:16372-16399>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_context_feature_extract_fn>> <<326:17350-17377>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<absolute_import>> <<22:1001-1016>> <<_Feature>> <<VARIABLE>> <<LINK>>
<<division>> <<23:1041-1049>> <<_Feature>> <<VARIABLE>> <<LINK>>
<<print_function>> <<24:1074-1088>> <<_Feature>> <<VARIABLE>> <<LINK>>
<<self>> <<596:31172-31176>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<_UNINITIALIZED_FEATURE_EXTRACTOR>> <<597:31238-31270>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<599:31347-31351>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<600:31435-31439>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<598:31280-31284>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<602:31489-31493>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<_feature_extractor_for_box_classifier_features>> <<602:31494-31540>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<604:31588-31592>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<_feature_extractor_for_box_classifier_features>> <<604:31593-31639>> <<?>> <<VARIABLE>> <<LINK>>
<<flattened_box_features>> <<605:31656-31678>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<608:31738-31742>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<flattened_box_features>> <<609:31810-31832>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<610:31855-31859>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<612:31909-31913>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<614:32032-32036>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<box_classifier_features>> <<615:32090-32113>> <<?>> <<VARIABLE>> <<LINK>>
<<num_proposals>> <<616:32140-32153>> <<?>> <<VARIABLE>> <<LINK>>
<<context_features>> <<617:32183-32199>> <<?>> <<VARIABLE>> <<LINK>>
<<valid_context_size>> <<618:32231-32249>> <<?>> <<VARIABLE>> <<LINK>>
<<box_classifier_features>> <<621:32312-32335>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<621:32339-32343>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<attention_features>> <<622:32386-32404>> <<?>> <<VARIABLE>> <<LINK>>
<<box_classifier_features>> <<624:32420-32443>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<496:26691-26695>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<_compute_second_stage_input_feature_maps>> <<496:26696-26736>> <<function>> <<VARIABLE>> <<LINK>>
<<rpn_features_to_crop>> <<497:26751-26771>> <<?>> <<VARIABLE>> <<LINK>>
<<proposal_boxes_normalized>> <<497:26773-26798>> <<?>> <<VARIABLE>> <<LINK>>
<<image_shape>> <<498:26813-26824>> <<?>> <<VARIABLE>> <<LINK>>
<<num_proposals>> <<498:26826-26839>> <<?>> <<VARIABLE>> <<LINK>>
<<image_shape>> <<568:30061-30072>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<569:30093-30097>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<features_to_crop>> <<570:30128-30144>> <<?>> <<VARIABLE>> <<LINK>>
<<proposal_boxes_normalized>> <<570:30146-30171>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<571:30189-30193>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<571:30214-30218>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<573:30272-30276>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<box_features>> <<573:30307-30319>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<575:30353-30357>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<flattened_box_features>> <<575:30373-30395>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<577:30407-30411>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<579:30519-30523>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<flattened_box_features>> <<580:30577-30599>> <<?>> <<VARIABLE>> <<LINK>>
<<num_proposals>> <<581:30626-30639>> <<?>> <<VARIABLE>> <<LINK>>
<<context_features>> <<582:30669-30685>> <<?>> <<VARIABLE>> <<LINK>>
<<valid_context_size>> <<583:30717-30735>> <<?>> <<VARIABLE>> <<LINK>>
<<flattened_box_features>> <<586:30798-30820>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<586:30824-30828>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<attention_features>> <<587:30871-30889>> <<?>> <<VARIABLE>> <<LINK>>
<<flattened_box_features>> <<589:30905-30927>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<500:26890-26894>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<_extract_box_classifier_features>> <<500:26895-26927>> <<function>> <<VARIABLE>> <<LINK>>
<<flattened_proposal_feature_maps>> <<501:26938-26969>> <<None>> <<VARIABLE>> <<LINK>>
<<num_proposals>> <<501:26971-26984>> <<?>> <<VARIABLE>> <<LINK>>
<<_feature_extractor_for_box_classifier_features>> <<596:31177-31223>> <<?>> <<VARIABLE>> <<LINK>>
<<_feature_extractor_for_box_classifier_features>> <<598:31285-31331>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<503:27011-27015>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<504:27082-27086>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<box_classifier_features>> <<505:27125-27148>> <<None>> <<VARIABLE>> <<LINK>>
<<self>> <<508:27218-27222>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<box_classifier_features>> <<509:27269-27292>> <<None>> <<VARIABLE>> <<LINK>>
<<self>> <<511:27357-27361>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<515:27479-27494>> <<?>> <<VARIABLE>> <<LINK>>
<<box_predictions>> <<518:27638-27653>> <<?>> <<VARIABLE>> <<LINK>>
<<proposal_boxes_normalized>> <<522:27846-27871>> <<?>> <<VARIABLE>> <<LINK>>
<<image_shape>> <<522:27873-27884>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<522:27886-27890>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<refined_box_encodings>> <<525:27982-28003>> <<?>> <<VARIABLE>> <<LINK>>
<<class_predictions_with_background>> <<528:28129-28162>> <<?>> <<VARIABLE>> <<LINK>>
<<absolute_proposal_boxes>> <<529:28210-28233>> <<?>> <<VARIABLE>> <<LINK>>
<<box_classifier_features>> <<530:28271-28294>> <<None>> <<VARIABLE>> <<LINK>>
<<proposal_boxes_normalized>> <<531:28334-28359>> <<?>> <<VARIABLE>> <<LINK>>
<<proposal_boxes_normalized>> <<532:28387-28412>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<535:28430-28434>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<prediction_dict>> <<536:28481-28496>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<536:28504-28508>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<refined_box_encodings>> <<537:28558-28579>> <<?>> <<VARIABLE>> <<LINK>>
<<absolute_proposal_boxes>> <<537:28581-28604>> <<?>> <<VARIABLE>> <<LINK>>
<<true_image_shapes>> <<537:28606-28623>> <<?>> <<VARIABLE>> <<LINK>>
<<prediction_dict>> <<539:28640-28655>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<426:22637-22641>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<rpn_box_encodings>> <<427:22674-22691>> <<?>> <<VARIABLE>> <<LINK>>
<<rpn_objectness_predictions_with_background>> <<427:22693-22735>> <<?>> <<VARIABLE>> <<LINK>>
<<anchors>> <<427:22737-22744>> <<?>> <<VARIABLE>> <<LINK>>
<<image_shape>> <<428:22755-22766>> <<?>> <<VARIABLE>> <<LINK>>
<<true_image_shapes>> <<428:22768-22785>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<430:22812-22816>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<_box_prediction>> <<430:22817-22832>> <<function>> <<VARIABLE>> <<LINK>>
<<rpn_features_to_crop>> <<430:22833-22853>> <<?>> <<VARIABLE>> <<LINK>>
<<proposal_boxes_normalized>> <<431:22899-22924>> <<?>> <<VARIABLE>> <<LINK>>
<<image_shape>> <<432:22970-22981>> <<?>> <<VARIABLE>> <<LINK>>
<<true_image_shapes>> <<432:22983-23000>> <<?>> <<VARIABLE>> <<LINK>>
<<num_proposals>> <<433:23046-23059>> <<?>> <<VARIABLE>> <<LINK>>
<<num_proposals>> <<435:23160-23173>> <<?>> <<VARIABLE>> <<LINK>>
<<prediction_dict>> <<435:23125-23140>> <<dict>> <<VARIABLE>> <<LINK>>
<<prediction_dict>> <<436:23186-23201>> <<dict>> <<VARIABLE>> <<LINK>>
<<features>> <<349:18223-18231>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<features>> <<350:18293-18301>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<features>> <<357:18513-18521>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<features>> <<359:18629-18637>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<ContextRCNNMetaArch>> <<255:14474-14493>> <<type>> <<VARIABLE>> <<LINK>>
<<self>> <<255:14495-14499>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<is_training>> <<256:14520-14531>> <<?>> <<VARIABLE>> <<LINK>>
<<num_classes>> <<257:14542-14553>> <<?>> <<VARIABLE>> <<LINK>>
<<image_resizer_fn>> <<258:14564-14580>> <<?>> <<VARIABLE>> <<LINK>>
<<feature_extractor>> <<259:14591-14608>> <<?>> <<VARIABLE>> <<LINK>>
<<number_of_stages>> <<260:14619-14635>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_anchor_generator>> <<261:14646-14674>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_target_assigner>> <<262:14685-14712>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_atrous_rate>> <<263:14723-14746>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_box_predictor_arg_scope_fn>> <<264:14757-14795>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_box_predictor_kernel_size>> <<265:14806-14843>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_box_predictor_depth>> <<266:14854-14885>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_minibatch_size>> <<267:14896-14922>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_sampler>> <<268:14933-14952>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_non_max_suppression_fn>> <<269:14963-14997>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_max_proposals>> <<270:15008-15033>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_localization_loss_weight>> <<271:15044-15080>> <<?>> <<VARIABLE>> <<LINK>>
<<first_stage_objectness_loss_weight>> <<272:15091-15125>> <<?>> <<VARIABLE>> <<LINK>>
<<crop_and_resize_fn>> <<273:15136-15154>> <<?>> <<VARIABLE>> <<LINK>>
<<initial_crop_size>> <<274:15165-15182>> <<?>> <<VARIABLE>> <<LINK>>
<<maxpool_kernel_size>> <<275:15193-15212>> <<?>> <<VARIABLE>> <<LINK>>
<<maxpool_stride>> <<276:15223-15237>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_target_assigner>> <<277:15248-15276>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_mask_rcnn_box_predictor>> <<278:15287-15323>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_batch_size>> <<279:15334-15357>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_sampler>> <<280:15368-15388>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_non_max_suppression_fn>> <<281:15399-15434>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_score_conversion_fn>> <<282:15445-15477>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_localization_loss_weight>> <<283:15488-15525>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_classification_loss_weight>> <<284:15536-15575>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_classification_loss>> <<285:15586-15618>> <<?>> <<VARIABLE>> <<LINK>>
<<second_stage_mask_prediction_loss_weight>> <<287:15685-15725>> <<?>> <<VARIABLE>> <<LINK>>
<<hard_example_miner>> <<288:15756-15774>> <<?>> <<VARIABLE>> <<LINK>>
<<parallel_iterations>> <<289:15805-15824>> <<?>> <<VARIABLE>> <<LINK>>
<<add_summaries>> <<290:15849-15862>> <<float>> <<VARIABLE>> <<LINK>>
<<clip_anchors_to_image>> <<291:15895-15916>> <<int>> <<VARIABLE>> <<LINK>>
<<use_static_shapes>> <<292:15945-15962>> <<?>> <<VARIABLE>> <<LINK>>
<<resize_masks>> <<293:15986-15998>> <<?>> <<VARIABLE>> <<LINK>>
<<freeze_batchnorm>> <<294:16026-16042>> <<?>> <<VARIABLE>> <<LINK>>
<<return_raw_detections_during_predict>> <<296:16105-16141>> <<?>> <<VARIABLE>> <<LINK>>
<<output_final_box_features>> <<297:16179-16204>> <<?>> <<VARIABLE>> <<LINK>>
<<output_final_box_rpn_features>> <<298:16245-16274>> <<?>> <<VARIABLE>> <<LINK>>
<<attention_position>> <<300:16310-16328>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<300:16283-16287>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<attention_bottleneck_dimension>> <<305:16513-16543>> <<?>> <<VARIABLE>> <<LINK>>
<<attention_temperature>> <<306:16578-16599>> <<?>> <<VARIABLE>> <<LINK>>
<<is_training>> <<307:16624-16635>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<308:16666-16670>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<use_self_attention>> <<309:16720-16738>> <<?>> <<VARIABLE>> <<LINK>>
<<use_long_term_attention>> <<310:16775-16798>> <<?>> <<VARIABLE>> <<LINK>>
<<self_attention_in_sequence>> <<311:16838-16864>> <<?>> <<VARIABLE>> <<LINK>>
<<num_attention_heads>> <<312:16897-16916>> <<int>> <<VARIABLE>> <<LINK>>
<<num_attention_layers>> <<313:16950-16970>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<303:16367-16371>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<use_self_attention>> <<315:16993-17011>> <<?>> <<VARIABLE>> <<LINK>>
<<self_attention_in_sequence>> <<317:17058-17084>> <<?>> <<VARIABLE>> <<LINK>>
<<use_long_term_attention>> <<319:17135-17158>> <<?>> <<VARIABLE>> <<LINK>>
<<num_attention_heads>> <<321:17205-17224>> <<int>> <<VARIABLE>> <<LINK>>
<<num_attention_layers>> <<323:17275-17295>> <<int>> <<VARIABLE>> <<LINK>>
<<attention_bottleneck_dimension>> <<327:17449-17479>> <<?>> <<VARIABLE>> <<LINK>>
<<attention_temperature>> <<328:17514-17535>> <<?>> <<VARIABLE>> <<LINK>>
<<is_training>> <<329:17560-17571>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<330:17602-17606>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<self>> <<326:17345-17349>> <<ContextRCNNMetaArch>> <<VARIABLE>> <<LINK>>
<<_context_feature_extract_fn>> <<326:17350-17377>> <<?>> <<VARIABLE>> <<LINK>>

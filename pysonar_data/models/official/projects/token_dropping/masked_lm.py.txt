<<official>> <<21:732-740>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<core>> <<21:741-745>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<official>> <<22:772-780>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<nlp>> <<22:781-784>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<tasks>> <<22:785-790>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<TokenDropMaskedLMConfig>> <<26:843-866>> <<type>> <<CLASS>> <<ANCHOR>>
<<TokenDropMaskedLMTask>> <<32:998-1019>> <<type>> <<CLASS>> <<ANCHOR>>
<<build_losses>> <<35:1103-1115>> <<function>> <<METHOD>> <<ANCHOR>>
<<train_step>> <<69:2696-2706>> <<function>> <<METHOD>> <<ANCHOR>>
<<validation_step>> <<106:4103-4118>> <<function>> <<METHOD>> <<ANCHOR>>
<<self>> <<69:2707-2710>> <<TokenDropMaskedLMTask>> <<PARAMETER>> <<ANCHOR>>
<<inputs>> <<69:2713-2716>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<model>> <<69:2721-2724>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<optimizer>> <<70:2762-2765>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<metrics>> <<70:2804-2807>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<tape>> <<82:3154-3158>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<outputs>> <<83:3167-3174>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<35:1116-1119>> <<TokenDropMaskedLMTask>> <<PARAMETER>> <<ANCHOR>>
<<labels>> <<36:1142-1145>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<model_outputs>> <<37:1170-1173>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<metrics>> <<38:1205-1208>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<aux_losses>> <<39:1234-1237>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<metric>> <<42:1438-1444>> <<?>> <<SCOPE>> <<ANCHOR>>
<<metrics>> <<42:1396-1403>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<lm_prediction_losses>> <<43:1465-1485>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<lm_label_weights>> <<47:1670-1686>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<lm_numerator_loss>> <<48:1724-1741>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<lm_denominator_loss>> <<50:1847-1866>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<mlm_loss>> <<51:1908-1916>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<sentence_labels>> <<54:2091-2106>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<sentence_outputs>> <<55:2149-2165>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<sentence_loss>> <<57:2249-2262>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<total_loss>> <<61:2490-2500>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<total_loss>> <<63:2550-2560>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<total_loss>> <<66:2605-2615>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<loss>> <<85:3249-3253>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<lm_prediction_losses>> <<85:3255-3275>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<scaled_loss>> <<96:3707-3718>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<tvars>> <<97:3783-3788>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<grads>> <<99:3861-3866>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<grads>> <<101:3921-3926>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<106:4119-4122>> <<TokenDropMaskedLMTask>> <<PARAMETER>> <<ANCHOR>>
<<inputs>> <<106:4125-4128>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<model>> <<106:4133-4136>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<metrics>> <<106:4156-4159>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<outputs>> <<117:4397-4404>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<loss>> <<118:4447-4451>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<_>> <<118:4453-4454>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<masked_lm>> <<22:798-807>> <<module>> <<VARIABLE>> <<LINK>>
<<masked_lm>> <<26:867-876>> <<module>> <<VARIABLE>> <<LINK>>
<<MaskedLMConfig>> <<26:877-891>> <<type>> <<VARIABLE>> <<LINK>>
<<masked_lm>> <<32:1020-1029>> <<module>> <<VARIABLE>> <<LINK>>
<<MaskedLMTask>> <<32:1030-1042>> <<type>> <<VARIABLE>> <<LINK>>
<<model>> <<83:3177-3182>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<83:3183-3189>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<85:3278-3282>> <<TokenDropMaskedLMTask>> <<VARIABLE>> <<LINK>>
<<build_losses>> <<85:3283-3295>> <<function>> <<VARIABLE>> <<LINK>>
<<inputs>> <<86:3315-3321>> <<?>> <<VARIABLE>> <<LINK>>
<<outputs>> <<87:3348-3355>> <<?>> <<VARIABLE>> <<LINK>>
<<metrics>> <<88:3376-3383>> <<?>> <<VARIABLE>> <<LINK>>
<<model>> <<89:3407-3412>> <<?>> <<VARIABLE>> <<LINK>>
<<metrics>> <<42:1448-1455>> <<?>> <<VARIABLE>> <<LINK>>
<<metric>> <<42:1438-1444>> <<?>> <<VARIABLE>> <<LINK>>
<<metric>> <<42:1413-1419>> <<?>> <<VARIABLE>> <<LINK>>
<<metric>> <<42:1426-1432>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<44:1548-1554>> <<?>> <<VARIABLE>> <<LINK>>
<<model_outputs>> <<45:1592-1605>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<47:1689-1695>> <<?>> <<VARIABLE>> <<LINK>>
<<lm_prediction_losses>> <<48:1758-1778>> <<?>> <<VARIABLE>> <<LINK>>
<<lm_label_weights>> <<49:1822-1838>> <<?>> <<VARIABLE>> <<LINK>>
<<lm_label_weights>> <<50:1883-1899>> <<?>> <<VARIABLE>> <<LINK>>
<<lm_numerator_loss>> <<51:1941-1958>> <<?>> <<VARIABLE>> <<LINK>>
<<lm_denominator_loss>> <<51:1960-1979>> <<?>> <<VARIABLE>> <<LINK>>
<<metrics>> <<52:1988-1995>> <<dict>> <<VARIABLE>> <<LINK>>
<<mlm_loss>> <<52:2028-2036>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<53:2074-2080>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<54:2109-2115>> <<?>> <<VARIABLE>> <<LINK>>
<<model_outputs>> <<56:2190-2203>> <<?>> <<VARIABLE>> <<LINK>>
<<sentence_labels>> <<59:2360-2375>> <<?>> <<VARIABLE>> <<LINK>>
<<sentence_outputs>> <<59:2377-2393>> <<?>> <<VARIABLE>> <<LINK>>
<<metrics>> <<60:2423-2430>> <<dict>> <<VARIABLE>> <<LINK>>
<<sentence_loss>> <<60:2466-2479>> <<?>> <<VARIABLE>> <<LINK>>
<<mlm_loss>> <<61:2503-2511>> <<?>> <<VARIABLE>> <<LINK>>
<<sentence_loss>> <<61:2514-2527>> <<?>> <<VARIABLE>> <<LINK>>
<<mlm_loss>> <<63:2563-2571>> <<?>> <<VARIABLE>> <<LINK>>
<<aux_losses>> <<65:2584-2594>> <<?>> <<VARIABLE>> <<LINK>>
<<total_loss>> <<66:2605-2615>> <<?>> <<VARIABLE>> <<LINK>>
<<aux_losses>> <<66:2628-2638>> <<?>> <<VARIABLE>> <<LINK>>
<<total_loss>> <<67:2654-2664>> <<?>> <<VARIABLE>> <<LINK>>
<<lm_prediction_losses>> <<67:2666-2686>> <<?>> <<VARIABLE>> <<LINK>>
<<model>> <<90:3428-3433>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<91:3486-3492>> <<?>> <<VARIABLE>> <<LINK>>
<<lm_prediction_losses>> <<92:3533-3553>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<93:3565-3569>> <<TokenDropMaskedLMTask>> <<VARIABLE>> <<LINK>>
<<loss>> <<96:3721-3725>> <<?>> <<VARIABLE>> <<LINK>>
<<model>> <<97:3791-3796>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<98:3825-3829>> <<TokenDropMaskedLMTask>> <<VARIABLE>> <<LINK>>
<<tape>> <<99:3869-3873>> <<?>> <<VARIABLE>> <<LINK>>
<<scaled_loss>> <<99:3883-3894>> <<?>> <<VARIABLE>> <<LINK>>
<<tvars>> <<99:3896-3901>> <<?>> <<VARIABLE>> <<LINK>>
<<tape>> <<101:3929-3933>> <<?>> <<VARIABLE>> <<LINK>>
<<loss>> <<101:3943-3947>> <<?>> <<VARIABLE>> <<LINK>>
<<tvars>> <<101:3949-3954>> <<?>> <<VARIABLE>> <<LINK>>
<<optimizer>> <<102:3961-3970>> <<?>> <<VARIABLE>> <<LINK>>
<<grads>> <<102:3996-4001>> <<?>> <<VARIABLE>> <<LINK>>
<<tvars>> <<102:4003-4008>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<103:4017-4021>> <<TokenDropMaskedLMTask>> <<VARIABLE>> <<LINK>>
<<process_metrics>> <<103:4022-4037>> <<function>> <<VARIABLE>> <<LINK>>
<<metrics>> <<103:4038-4045>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<103:4047-4053>> <<?>> <<VARIABLE>> <<LINK>>
<<outputs>> <<103:4055-4062>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<104:4077-4081>> <<TokenDropMaskedLMTask>> <<VARIABLE>> <<LINK>>
<<loss>> <<104:4088-4092>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<117:4407-4411>> <<TokenDropMaskedLMTask>> <<VARIABLE>> <<LINK>>
<<inputs>> <<117:4427-4433>> <<?>> <<VARIABLE>> <<LINK>>
<<model>> <<117:4435-4440>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<118:4457-4461>> <<TokenDropMaskedLMTask>> <<VARIABLE>> <<LINK>>
<<build_losses>> <<118:4462-4474>> <<function>> <<VARIABLE>> <<LINK>>
<<inputs>> <<119:4492-4498>> <<?>> <<VARIABLE>> <<LINK>>
<<outputs>> <<120:4523-4530>> <<?>> <<VARIABLE>> <<LINK>>
<<metrics>> <<121:4549-4556>> <<?>> <<VARIABLE>> <<LINK>>
<<model>> <<122:4578-4583>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<123:4597-4601>> <<TokenDropMaskedLMTask>> <<VARIABLE>> <<LINK>>
<<process_metrics>> <<123:4602-4617>> <<function>> <<VARIABLE>> <<LINK>>
<<metrics>> <<123:4618-4625>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<123:4627-4633>> <<?>> <<VARIABLE>> <<LINK>>
<<outputs>> <<123:4635-4642>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<124:4657-4661>> <<TokenDropMaskedLMTask>> <<VARIABLE>> <<LINK>>
<<loss>> <<124:4668-4672>> <<?>> <<VARIABLE>> <<LINK>>

<<official>> <<22:784-792>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<modeling>> <<22:793-801>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<official>> <<23:824-832>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<nlp>> <<23:833-836>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<modeling>> <<23:837-845>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<layers>> <<23:846-852>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<official>> <<24:876-884>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<nlp>> <<24:885-888>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<modeling>> <<24:889-897>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<layers>> <<24:898-904>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<official>> <<25:942-950>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<nlp>> <<25:951-954>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<modeling>> <<25:955-963>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<layers>> <<25:964-970>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<official>> <<26:1010-1018>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<nlp>> <<26:1019-1022>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<modeling>> <<26:1023-1031>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<layers>> <<26:1032-1038>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<util>> <<26:1039-1043>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<Transformer>> <<30:1144-1155>> <<type>> <<CLASS>> <<ANCHOR>>
<<__init__>> <<65:3026-3034>> <<function>> <<CONSTRUCTOR>> <<ANCHOR>>
<<get_config>> <<108:4745-4755>> <<function>> <<METHOD>> <<ANCHOR>>
<<CompiledTransformer>> <<149:6458-6477>> <<type>> <<CLASS>> <<ANCHOR>>
<<call>> <<152:6553-6557>> <<function>> <<METHOD>> <<ANCHOR>>
<<TransformerDecoderBlock>> <<157:6678-6701>> <<type>> <<CLASS>> <<ANCHOR>>
<<__init__>> <<191:8500-8508>> <<function>> <<CONSTRUCTOR>> <<ANCHOR>>
<<build>> <<241:10808-10813>> <<function>> <<METHOD>> <<ANCHOR>>
<<get_config>> <<336:15028-15038>> <<function>> <<METHOD>> <<ANCHOR>>
<<common_layers_with_encoder>> <<376:16821-16847>> <<function>> <<METHOD>> <<ANCHOR>>
<<call>> <<383:17096-17100>> <<function>> <<METHOD>> <<ANCHOR>>
<<self>> <<191:8509-8512>> <<TransformerDecoderBlock>> <<PARAMETER>> <<ANCHOR>>
<<num_attention_heads>> <<192:8531-8534>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<intermediate_size>> <<193:8568-8571>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<intermediate_activation>> <<194:8603-8606>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<dropout_rate>> <<195:8644-8647>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<attention_dropout_rate>> <<196:8678-8681>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<multi_channel_cross_attention>> <<197:8722-8725>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<kernel_initializer>> <<198:8775-8778>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<bias_initializer>> <<199:8828-8831>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<kernel_regularizer>> <<200:8870-8873>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<bias_regularizer>> <<201:8911-8914>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<activity_regularizer>> <<202:8950-8953>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<kernel_constraint>> <<203:8993-8996>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<bias_constraint>> <<204:9033-9036>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<use_bias>> <<205:9071-9074>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<norm_first>> <<206:9102-9105>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<norm_epsilon>> <<207:9136-9139>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<intermediate_dropout>> <<208:9172-9175>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<attention_initializer>> <<209:9214-9217>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<ention_initializer>> <<209:9217-9235>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_attention_heads>> <<212:9311-9330>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<intermediate_size>> <<213:9363-9380>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<intermediate_activation>> <<214:9411-9434>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<dropout_rate>> <<216:9507-9519>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<attention_dropout_rate>> <<217:9545-9567>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<multi_channel_cross_attention>> <<218:9603-9632>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_kernel_initializer>> <<219:9675-9694>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_bias_initializer>> <<220:9753-9770>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_kernel_regularizer>> <<221:9827-9846>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_bias_regularizer>> <<222:9905-9922>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_activity_regularizer>> <<223:9979-10000>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_kernel_constraint>> <<224:10061-10079>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_bias_constraint>> <<225:10136-10152>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_use_bias>> <<226:10207-10216>> <<str>> <<ATTRIBUTE>> <<ANCHOR>>
<<_norm_first>> <<227:10238-10249>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_norm_epsilon>> <<228:10273-10286>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_intermediate_dropout>> <<229:10312-10333>> <<float>> <<ATTRIBUTE>> <<ANCHOR>>
<<_attention_initializer>> <<231:10400-10422>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_attention_initializer>> <<234:10509-10531>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_cross_attention_cls>> <<237:10655-10675>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_cross_attention_cls>> <<239:10747-10767>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<self>> <<336:15039-15042>> <<TransformerDecoderBlock>> <<PARAMETER>> <<ANCHOR>>
<<config>> <<337:15051-15057>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<base_config>> <<373:16710-16721>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<108:4756-4759>> <<Transformer>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<65:3035-3038>> <<Transformer>> <<PARAMETER>> <<ANCHOR>>
<<num_attention_heads>> <<66:3057-3060>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<intermediate_size>> <<67:3094-3097>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<intermediate_activation>> <<68:3129-3132>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<dropout_rate>> <<69:3170-3173>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<attention_dropout_rate>> <<70:3204-3207>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<output_range>> <<71:3248-3251>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<kernel_initializer>> <<72:3283-3286>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<bias_initializer>> <<73:3336-3339>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<kernel_regularizer>> <<74:3378-3381>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<bias_regularizer>> <<75:3419-3422>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<activity_regularizer>> <<76:3458-3461>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<kernel_constraint>> <<77:3501-3504>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<bias_constraint>> <<78:3541-3544>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<use_bias>> <<79:3579-3582>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<norm_first>> <<80:3610-3613>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<norm_epsilon>> <<81:3644-3647>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<intermediate_dropout>> <<82:3680-3683>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<attention_initializer>> <<83:3722-3725>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<ention_initializer>> <<83:3725-3743>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<152:6558-6561>> <<CompiledTransformer>> <<PARAMETER>> <<ANCHOR>>
<<inputs>> <<152:6564-6567>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<383:17101-17104>> <<TransformerDecoderBlock>> <<PARAMETER>> <<ANCHOR>>
<<inputs>> <<383:17107-17110>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<cache>> <<383:17115-17118>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<decode_loop_step>> <<383:17127-17130>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<input_tensor>> <<393:17555-17567>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<memory>> <<393:17569-17575>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<attention_mask>> <<393:17577-17591>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self_attention_mask>> <<393:17593-17612>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<source_tensor>> <<394:17631-17644>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<input_tensor>> <<396:17693-17705>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self_attention_output>> <<397:17758-17779>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<cache>> <<397:17781-17786>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self_attention_output>> <<403:17984-18005>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self_attention_output>> <<405:18092-18113>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self_attention_output>> <<407:18172-18193>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<source_self_attention_output>> <<410:18310-18338>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self_attention_output>> <<411:18370-18391>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<cross_attn_inputs>> <<413:18467-18484>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<attention_output>> <<420:18787-18803>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<attention_output>> <<421:18854-18870>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<attention_output>> <<423:18954-18970>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<attention_output>> <<425:19039-19055>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<source_attention_output>> <<428:19178-19201>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<attention_output>> <<429:19228-19244>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<intermediate_output>> <<431:19295-19314>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<intermediate_output>> <<432:19364-19383>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<intermediate_output>> <<434:19457-19476>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<layer_output>> <<435:19538-19550>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<layer_output>> <<436:19597-19609>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<layer_output>> <<438:19679-19691>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<layer_output>> <<440:19751-19763>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<376:16848-16851>> <<TransformerDecoderBlock>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<241:10814-10817>> <<TransformerDecoderBlock>> <<PARAMETER>> <<ANCHOR>>
<<input_shape>> <<241:10820-10823>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<target_tensor_shape>> <<242:10839-10858>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<hidden_size>> <<246:11086-11097>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<attention_head_size>> <<251:11358-11377>> <<int>> <<ATTRIBUTE>> <<ANCHOR>>
<<common_kwargs>> <<252:11430-11443>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<self_attention>> <<259:11747-11761>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<self_attention_output_dense>> <<269:12204-12231>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<self_attention_dropout>> <<277:12574-12596>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<self_attention_layer_norm>> <<279:12667-12692>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<encdec_attention>> <<286:12927-12943>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<encdec_attention_dropout>> <<298:13425-13449>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<encdec_attention_layer_norm>> <<300:13520-13547>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<intermediate_dense>> <<308:13791-13809>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<intermediate_activation_layer>> <<316:14169-14198>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<_intermediate_dropout_layer>> <<318:14278-14305>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<output_dense>> <<320:14385-14397>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<output_dropout>> <<328:14740-14754>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<output_layer_norm>> <<329:14815-14832>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<tf_function_if_eager>> <<26:1051-1071>> <<function>> <<VARIABLE>> <<LINK>>
<<Transformer>> <<149:6478-6489>> <<type>> <<VARIABLE>> <<LINK>>
<<num_attention_heads>> <<212:9333-9352>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<212:9306-9310>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<intermediate_size>> <<213:9383-9400>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<213:9358-9362>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<intermediate_activation>> <<215:9472-9495>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<214:9406-9410>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<dropout_rate>> <<216:9522-9534>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<216:9502-9506>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<attention_dropout_rate>> <<217:9570-9592>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<217:9540-9544>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<multi_channel_cross_attention>> <<218:9635-9664>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<218:9598-9602>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<kernel_initializer>> <<219:9723-9741>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<219:9670-9674>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<bias_initializer>> <<220:9799-9815>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<220:9748-9752>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<kernel_regularizer>> <<221:9875-9893>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<221:9822-9826>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<bias_regularizer>> <<222:9951-9967>> <<float>> <<VARIABLE>> <<LINK>>
<<self>> <<222:9900-9904>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<activity_regularizer>> <<223:10029-10049>> <<float>> <<VARIABLE>> <<LINK>>
<<self>> <<223:9974-9978>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<kernel_constraint>> <<224:10107-10124>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<224:10056-10060>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<bias_constraint>> <<225:10180-10195>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<225:10131-10135>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<use_bias>> <<226:10219-10227>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<226:10202-10206>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<norm_first>> <<227:10252-10262>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<227:10233-10237>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<norm_epsilon>> <<228:10289-10301>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<228:10268-10272>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<intermediate_dropout>> <<229:10336-10356>> <<float>> <<VARIABLE>> <<LINK>>
<<self>> <<229:10307-10311>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<attention_initializer>> <<230:10365-10386>> <<float>> <<VARIABLE>> <<LINK>>
<<attention_initializer>> <<232:10463-10484>> <<float>> <<VARIABLE>> <<LINK>>
<<self>> <<231:10395-10399>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<235:10573-10577>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_kernel_initializer>> <<235:10578-10597>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<234:10504-10508>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_attention_initializer>> <<234:10509-10531>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<236:10607-10611>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<multi_channel_cross_attention>> <<236:10612-10641>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<237:10650-10654>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<239:10742-10746>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_cross_attention_cls>> <<239:10747-10767>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<338:15094-15098>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<num_attention_heads>> <<338:15099-15118>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<339:15150-15154>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<intermediate_size>> <<339:15155-15172>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<340:15210-15214>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<intermediate_activation>> <<340:15215-15238>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<341:15265-15269>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<dropout_rate>> <<341:15270-15282>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<342:15319-15323>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<attention_dropout_rate>> <<342:15324-15346>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<343:15390-15394>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<multi_channel_cross_attention>> <<343:15395-15424>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<345:15502-15506>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_kernel_initializer>> <<345:15507-15526>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<348:15637-15641>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_bias_initializer>> <<348:15642-15659>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<351:15772-15776>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_kernel_regularizer>> <<351:15777-15796>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<354:15907-15911>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_bias_regularizer>> <<354:15912-15929>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<357:16044-16048>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_activity_regularizer>> <<357:16049-16070>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<360:16181-16185>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_kernel_constraint>> <<360:16186-16204>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<363:16313-16317>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_bias_constraint>> <<363:16318-16334>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<365:16392-16396>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_use_bias>> <<365:16397-16406>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<366:16431-16435>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_norm_first>> <<366:16436-16447>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<367:16474-16478>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_norm_epsilon>> <<367:16479-16492>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<368:16527-16531>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_intermediate_dropout>> <<368:16532-16553>> <<float>> <<VARIABLE>> <<LINK>>
<<self>> <<370:16634-16638>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<_attention_initializer>> <<370:16639-16661>> <<?>> <<VARIABLE>> <<LINK>>
<<base_config>> <<374:16767-16778>> <<?>> <<VARIABLE>> <<LINK>>
<<config>> <<374:16795-16801>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<110:4809-4813>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<111:4856-4860>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<112:4909-4913>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<113:4958-4962>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<114:5020-5024>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<115:5075-5079>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<117:5171-5175>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<120:5306-5310>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<123:5441-5445>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<126:5576-5580>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<129:5713-5717>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<132:5850-5854>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<135:5982-5986>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<137:6061-6065>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<138:6100-6104>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<139:6143-6147>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<140:6196-6200>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<self>> <<142:6296-6300>> <<Transformer>> <<VARIABLE>> <<LINK>>
<<num_attention_heads>> <<86:3829-3848>> <<?>> <<VARIABLE>> <<LINK>>
<<intermediate_size>> <<87:3869-3886>> <<?>> <<VARIABLE>> <<LINK>>
<<intermediate_activation>> <<88:3914-3937>> <<?>> <<VARIABLE>> <<LINK>>
<<dropout_rate>> <<89:3963-3975>> <<?>> <<VARIABLE>> <<LINK>>
<<attention_dropout_rate>> <<90:4004-4026>> <<?>> <<VARIABLE>> <<LINK>>
<<output_range>> <<91:4050-4062>> <<?>> <<VARIABLE>> <<LINK>>
<<kernel_initializer>> <<92:4092-4110>> <<?>> <<VARIABLE>> <<LINK>>
<<bias_initializer>> <<93:4138-4154>> <<?>> <<VARIABLE>> <<LINK>>
<<kernel_regularizer>> <<94:4184-4202>> <<?>> <<VARIABLE>> <<LINK>>
<<bias_regularizer>> <<95:4230-4246>> <<?>> <<VARIABLE>> <<LINK>>
<<activity_regularizer>> <<96:4278-4298>> <<float>> <<VARIABLE>> <<LINK>>
<<kernel_constraint>> <<97:4327-4344>> <<float>> <<VARIABLE>> <<LINK>>
<<bias_constraint>> <<98:4371-4386>> <<str>> <<VARIABLE>> <<LINK>>
<<use_bias>> <<99:4406-4414>> <<str>> <<VARIABLE>> <<LINK>>
<<norm_first>> <<100:4436-4446>> <<?>> <<VARIABLE>> <<LINK>>
<<norm_epsilon>> <<101:4470-4482>> <<?>> <<VARIABLE>> <<LINK>>
<<intermediate_dropout>> <<102:4507-4527>> <<float>> <<VARIABLE>> <<LINK>>
<<attention_initializer>> <<103:4560-4581>> <<float>> <<VARIABLE>> <<LINK>>
<<inputs>> <<153:6598-6604>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<384:17159-17163>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<inputs>> <<385:17209-17215>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<389:17413-17419>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<393:17615-17621>> <<?>> <<VARIABLE>> <<LINK>>
<<input_tensor>> <<394:17647-17659>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<395:17668-17672>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<396:17708-17712>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<input_tensor>> <<396:17739-17751>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<397:17789-17793>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<input_tensor>> <<398:17825-17837>> <<?>> <<VARIABLE>> <<LINK>>
<<input_tensor>> <<399:17854-17866>> <<?>> <<VARIABLE>> <<LINK>>
<<self_attention_mask>> <<400:17892-17911>> <<?>> <<VARIABLE>> <<LINK>>
<<cache>> <<401:17928-17933>> <<?>> <<VARIABLE>> <<LINK>>
<<decode_loop_step>> <<402:17961-17977>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<403:18008-18012>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self_attention_output>> <<403:18036-18057>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<404:18067-18071>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<source_tensor>> <<405:18116-18129>> <<?>> <<VARIABLE>> <<LINK>>
<<self_attention_output>> <<405:18132-18153>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<407:18196-18200>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<input_tensor>> <<408:18239-18251>> <<?>> <<VARIABLE>> <<LINK>>
<<self_attention_output>> <<408:18254-18275>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<409:18285-18289>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self_attention_output>> <<410:18341-18362>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<411:18394-18398>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self_attention_output>> <<412:18439-18460>> <<?>> <<VARIABLE>> <<LINK>>
<<self_attention_output>> <<414:18508-18529>> <<?>> <<VARIABLE>> <<LINK>>
<<memory>> <<415:18546-18552>> <<?>> <<VARIABLE>> <<LINK>>
<<attention_mask>> <<416:18578-18592>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<417:18602-18606>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<inputs>> <<419:18771-18777>> <<?>> <<VARIABLE>> <<LINK>>
<<cross_attn_inputs>> <<419:18722-18739>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<420:18806-18810>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<cross_attn_inputs>> <<420:18830-18847>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<421:18873-18877>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<attention_output>> <<421:18903-18919>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<422:18929-18933>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<source_self_attention_output>> <<423:18973-19001>> <<?>> <<VARIABLE>> <<LINK>>
<<attention_output>> <<423:19004-19020>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<425:19058-19062>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self_attention_output>> <<426:19103-19124>> <<?>> <<VARIABLE>> <<LINK>>
<<attention_output>> <<426:19127-19143>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<427:19153-19157>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<attention_output>> <<428:19204-19220>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<429:19247-19251>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<attention_output>> <<429:19270-19286>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<431:19317-19321>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<attention_output>> <<431:19341-19357>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<432:19386-19390>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<intermediate_output>> <<433:19431-19450>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<434:19479-19483>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<intermediate_output>> <<434:19512-19531>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<435:19553-19557>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<intermediate_output>> <<435:19571-19590>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<436:19612-19616>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<layer_output>> <<436:19632-19644>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<437:19654-19658>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<source_attention_output>> <<438:19694-19717>> <<?>> <<VARIABLE>> <<LINK>>
<<layer_output>> <<438:19720-19732>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<440:19766-19770>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<layer_output>> <<440:19789-19801>> <<?>> <<VARIABLE>> <<LINK>>
<<attention_output>> <<440:19804-19820>> <<?>> <<VARIABLE>> <<LINK>>
<<layer_output>> <<441:19834-19846>> <<?>> <<VARIABLE>> <<LINK>>
<<cache>> <<441:19848-19853>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<379:16951-16955>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<379:16972-16976>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<380:17013-17017>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<380:17038-17042>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<380:17057-17061>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<input_shape>> <<242:10876-10887>> <<?>> <<VARIABLE>> <<LINK>>
<<target_tensor_shape>> <<243:10904-10923>> <<?>> <<VARIABLE>> <<LINK>>
<<target_tensor_shape>> <<246:11100-11119>> <<?>> <<VARIABLE>> <<LINK>>
<<hidden_size>> <<247:11131-11142>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<247:11145-11149>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<hidden_size>> <<251:11384-11395>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<251:11400-11404>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<251:11353-11357>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<253:11480-11484>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<254:11532-11536>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<255:11586-11590>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<256:11641-11645>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<257:11691-11695>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<260:11810-11814>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<261:11853-11857>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<attention_head_size>> <<261:11858-11877>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<262:11896-11900>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<263:11943-11947>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<265:12028-12032>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<266:12111-12115>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<common_kwargs>> <<268:12179-12192>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<259:11742-11746>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<hidden_size>> <<271:12316-12327>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<273:12409-12413>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<274:12489-12493>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<common_kwargs>> <<276:12549-12562>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<269:12199-12203>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<278:12638-12642>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<277:12569-12573>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<283:12832-12836>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<279:12662-12666>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<286:12946-12950>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<287:12992-12996>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<288:13035-13039>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<attention_head_size>> <<288:13040-13059>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<289:13078-13082>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<hidden_size>> <<290:13129-13140>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<291:13160-13164>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<293:13245-13249>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<294:13328-13332>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<common_kwargs>> <<296:13398-13411>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<286:12922-12926>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<299:13491-13495>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<298:13420-13424>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<304:13696-13700>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<300:13515-13519>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<310:13894-13898>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<312:13998-14002>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<313:14078-14082>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<common_kwargs>> <<315:14144-14157>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<308:13786-13790>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<317:14238-14242>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<316:14164-14168>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<319:14347-14351>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<318:14273-14277>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<hidden_size>> <<322:14482-14493>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<324:14575-14579>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<325:14655-14659>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<common_kwargs>> <<327:14715-14728>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<320:14380-14384>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<328:14786-14790>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<328:14735-14739>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<332:14941-14945>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<self>> <<329:14810-14814>> <<TransformerDecoderBlock>> <<VARIABLE>> <<LINK>>
<<input_shape>> <<334:15006-15017>> <<?>> <<VARIABLE>> <<LINK>>

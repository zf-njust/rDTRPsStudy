<<official>> <<25:836-844>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<nlp>> <<25:845-848>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<modeling>> <<25:849-857>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<layers>> <<25:858-864>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<BertTokenizerTest>> <<31:1085-1102>> <<type>> <<CLASS>> <<ANCHOR>>
<<_make_vocab_file>> <<33:1131-1147>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_uncased>> <<41:1417-1429>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_cased>> <<60:2510-2520>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_special_tokens_complete>> <<74:3336-3364>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_special_tokens_partial>> <<86:3896-3923>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_special_tokens_in_estimator>> <<97:4396-4428>> <<function>> <<METHOD>> <<ANCHOR>>
<<SentencepieceTokenizerTest>> <<134:6096-6122>> <<type>> <<CLASS>> <<ANCHOR>>
<<setUp>> <<136:6151-6156>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_uncased>> <<159:7138-7150>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_cased>> <<178:8020-8030>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_special_tokens>> <<200:8832-8851>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_special_tokens_in_estimator>> <<210:9325-9357>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_strip_diacritics>> <<243:10890-10911>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_fail_on_tokenize_with_offsets_and_strip_diacritics>> <<255:11344-11399>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_serialize_deserialize>> <<277:12128-12154>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_saving>> <<294:12901-12912>> <<function>> <<METHOD>> <<ANCHOR>>
<<BertPackInputsTest>> <<304:13324-13342>> <<type>> <<CLASS>> <<ANCHOR>>
<<test_round_robin_correct_outputs>> <<306:13371-13403>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_waterfall_correct_outputs>> <<364:15934-15964>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_special_tokens_dict>> <<430:18876-18900>> <<function>> <<METHOD>> <<ANCHOR>>
<<FastWordPieceBertTokenizerTest>> <<447:19685-19715>> <<type>> <<CLASS>> <<ANCHOR>>
<<_make_vocab_file>> <<449:19744-19760>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_uncased>> <<457:20030-20042>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_cased>> <<476:21128-21138>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_special_tokens_complete>> <<490:21967-21995>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_special_tokens_partial>> <<502:22540-22567>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_special_tokens_in_estimator>> <<514:23122-23154>> <<function>> <<METHOD>> <<ANCHOR>>
<<self>> <<449:19761-19764>> <<FastWordPieceBertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab>> <<449:19767-19770>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<filename>> <<449:19774-19777>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<path>> <<450:19802-19806>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<f>> <<454:19961-19962>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<97:4429-4432>> <<BertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<33:1148-1151>> <<BertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab>> <<33:1154-1157>> <<list>> <<PARAMETER>> <<ANCHOR>>
<<filename>> <<33:1161-1164>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<path>> <<34:1189-1193>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<f>> <<37:1348-1349>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<vocab_file>> <<99:4512-4522>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<input_fn>> <<102:4632-4640>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<model_fn>> <<122:5582-5590>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<estimator>> <<127:5785-5794>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<outputs>> <<128:5844-5851>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<256:11400-11403>> <<SentencepieceTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<sentencepiece_tokenizer>> <<265:11700-11723>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<273:11982-11988>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<365:15965-15968>> <<BertPackInputsTest>> <<PARAMETER>> <<ANCHOR>>
<<bpi>> <<365:15977-15980>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_inputs>> <<372:16184-16195>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_inputs>> <<389:16955-16966>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_inputs>> <<409:17891-17902>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<200:8852-8855>> <<SentencepieceTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<sentencepiece_tokenizer>> <<201:8864-8887>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<178:8031-8034>> <<SentencepieceTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<sentencepiece_tokenizer>> <<179:8043-8066>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<185:8241-8247>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids>> <<186:8293-8302>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids_2>> <<191:8498-8509>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<start_offsets>> <<191:8511-8524>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<limit_offsets>> <<191:8526-8539>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<295:12913-12916>> <<SentencepieceTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<sentencepiece_tokenizer>> <<295:12925-12948>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<297:13064-13070>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<outputs>> <<298:13121-13128>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<model>> <<299:13168-13173>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<export_path>> <<300:13213-13224>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<136:6157-6160>> <<SentencepieceTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<tmp_dir>> <<139:6225-6232>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<vocab>> <<141:6295-6300>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<model_prefix>> <<142:6362-6374>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<input_text_file_path>> <<143:6417-6437>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<f>> <<144:6539-6540>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<full_vocab_size>> <<147:6661-6676>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<flags>> <<148:6699-6704>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<k>> <<156:7058-7059>> <<?>> <<SCOPE>> <<ANCHOR>>
<<v>> <<156:7061-7062>> <<?>> <<SCOPE>> <<ANCHOR>>
<<_spm_path>> <<157:7093-7102>> <<str>> <<ATTRIBUTE>> <<ANCHOR>>
<<self>> <<86:3924-3927>> <<BertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_file>> <<87:3936-3946>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenize>> <<89:4015-4028>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<159:7151-7154>> <<SentencepieceTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<sentencepiece_tokenizer>> <<160:7163-7186>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<163:7304-7310>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids>> <<164:7356-7365>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids_2>> <<169:7562-7573>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<start_offsets>> <<169:7575-7588>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<limit_offsets>> <<169:7590-7603>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<491:21996-21999>> <<FastWordPieceBertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_file>> <<491:22008-22018>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenize>> <<493:22119-22132>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<60:2521-2524>> <<BertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_file>> <<61:2533-2543>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenize>> <<63:2648-2661>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<65:2774-2780>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids>> <<66:2824-2833>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<start_offsets>> <<66:2835-2848>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<limit_offsets>> <<66:2850-2863>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<278:12155-12158>> <<SentencepieceTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<sentencepiece_tokenizer>> <<279:12201-12224>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<config>> <<285:12444-12450>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<new_tokenizer>> <<286:12495-12508>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<288:12629-12635>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids>> <<289:12681-12690>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids_2>> <<290:12730-12741>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<431:18901-18904>> <<BertPackInputsTest>> <<PARAMETER>> <<ANCHOR>>
<<special_tokens_dict>> <<431:18913-18932>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<bpi>> <<435:19128-19131>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_inputs>> <<437:19249-19260>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<458:20043-20046>> <<FastWordPieceBertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_file>> <<458:20055-20065>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenize>> <<460:20169-20182>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<462:20279-20285>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids>> <<463:20331-20340>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids_2>> <<467:20567-20578>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<start_offsets>> <<467:20580-20593>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<limit_offsets>> <<467:20595-20608>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<74:3365-3368>> <<BertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_file>> <<75:3377-3387>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenize>> <<77:3488-3501>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<477:21139-21142>> <<FastWordPieceBertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_file>> <<477:21151-21161>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenize>> <<479:21266-21279>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<481:21405-21411>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids>> <<482:21455-21464>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<start_offsets>> <<482:21466-21479>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<limit_offsets>> <<482:21481-21494>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<41:1430-1433>> <<BertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_file>> <<42:1442-1452>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenize>> <<44:1556-1569>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<46:1653-1659>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids>> <<47:1705-1714>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids_2>> <<51:1941-1952>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<start_offsets>> <<51:1954-1967>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<limit_offsets>> <<51:1969-1982>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<503:22568-22571>> <<FastWordPieceBertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_file>> <<504:22640-22650>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenize>> <<506:22728-22741>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<515:23155-23158>> <<FastWordPieceBertTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_file>> <<516:23238-23248>> <<str>> <<VARIABLE>> <<ANCHOR>>
<<input_fn>> <<519:23358-23366>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<model_fn>> <<539:24321-24329>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<estimator>> <<544:24524-24533>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<outputs>> <<545:24583-24590>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<243:10912-10915>> <<SentencepieceTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<sentencepiece_tokenizer>> <<244:10924-10947>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<249:11113-11119>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<token_ids>> <<250:11174-11183>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<210:9358-9361>> <<SentencepieceTokenizerTest>> <<PARAMETER>> <<ANCHOR>>
<<input_fn>> <<213:9447-9455>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<model_fn>> <<233:10456-10464>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<estimator>> <<238:10659-10668>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<outputs>> <<239:10718-10725>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<307:13404-13407>> <<BertPackInputsTest>> <<PARAMETER>> <<ANCHOR>>
<<bpi>> <<307:13416-13419>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_inputs>> <<314:13625-13636>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_inputs>> <<331:14396-14407>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_inputs>> <<351:15287-15298>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<sentences>> <<217:9583-9592>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<sentencepiece_tokenizer>> <<218:9651-9674>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<special_tokens_dict>> <<220:9794-9813>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<k>> <<221:9877-9878>> <<?>> <<SCOPE>> <<ANCHOR>>
<<v>> <<221:9880-9881>> <<?>> <<SCOPE>> <<ANCHOR>>
<<tokens>> <<223:9996-10002>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<packed_inputs>> <<224:10047-10060>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<preprocessing>> <<226:10161-10174>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<ds>> <<228:10251-10253>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<ds>> <<230:10356-10358>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<sentences>> <<106:4768-4777>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenizer>> <<107:4836-4850>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<special_tokens_dict>> <<109:4938-4957>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<k>> <<110:5012-5013>> <<?>> <<SCOPE>> <<ANCHOR>>
<<v>> <<110:5015-5016>> <<?>> <<SCOPE>> <<ANCHOR>>
<<tokens>> <<112:5131-5137>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<packed_inputs>> <<113:5173-5186>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<preprocessing>> <<115:5287-5300>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<ds>> <<117:5377-5379>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<ds>> <<119:5482-5484>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<sentences>> <<523:23494-23503>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_tokenizer>> <<524:23562-23576>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<special_tokens_dict>> <<526:23677-23696>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<k>> <<527:23751-23752>> <<?>> <<SCOPE>> <<ANCHOR>>
<<v>> <<527:23754-23755>> <<?>> <<SCOPE>> <<ANCHOR>>
<<tokens>> <<529:23870-23876>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<packed_inputs>> <<530:23912-23925>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<preprocessing>> <<532:24026-24039>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<ds>> <<534:24116-24118>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<ds>> <<536:24221-24223>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<features>> <<539:24330-24333>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<labels>> <<539:24340-24343>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<mode>> <<540:24348-24351>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<features>> <<233:10465-10468>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<labels>> <<233:10475-10478>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<mode>> <<233:10483-10486>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<features>> <<122:5591-5594>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<labels>> <<122:5601-5604>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<mode>> <<122:5609-5612>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<features>> <<230:10375-10378>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<labels>> <<230:10385-10388>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<features>> <<119:5501-5504>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<labels>> <<119:5511-5514>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<features>> <<536:24240-24243>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<labels>> <<536:24250-24253>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<451:19853-19857>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<filename>> <<452:19909-19917>> <<str>> <<VARIABLE>> <<LINK>>
<<path>> <<453:19947-19951>> <<str>> <<VARIABLE>> <<LINK>>
<<f>> <<454:19971-19972>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab>> <<454:19989-19994>> <<?>> <<VARIABLE>> <<LINK>>
<<path>> <<457:20016-20020>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<99:4525-4529>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<99:4530-4546>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<35:1240-1244>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<filename>> <<36:1296-1304>> <<str>> <<VARIABLE>> <<LINK>>
<<path>> <<37:1334-1338>> <<str>> <<VARIABLE>> <<LINK>>
<<f>> <<38:1358-1359>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab>> <<38:1376-1381>> <<list>> <<VARIABLE>> <<LINK>>
<<path>> <<39:1403-1407>> <<str>> <<VARIABLE>> <<LINK>>
<<model_fn>> <<127:5829-5837>> <<function>> <<VARIABLE>> <<LINK>>
<<estimator>> <<128:5859-5868>> <<?>> <<VARIABLE>> <<LINK>>
<<input_fn>> <<128:5877-5885>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<129:5893-5897>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<outputs>> <<129:5913-5920>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<257:11450-11454>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<self>> <<259:11551-11555>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<self>> <<266:11787-11791>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<270:11889-11912>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<274:12049-12053>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<275:12087-12110>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<276:12111-12117>> <<?>> <<VARIABLE>> <<LINK>>
<<bpi>> <<373:16198-16201>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<375:16324-16328>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<376:16354-16365>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<379:16533-16537>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<380:16563-16574>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<383:16705-16709>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<384:16735-16746>> <<?>> <<VARIABLE>> <<LINK>>
<<bpi>> <<390:16969-16972>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<395:17245-17249>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<396:17275-17286>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<399:17467-17471>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<400:17497-17508>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<403:17639-17643>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<404:17669-17680>> <<?>> <<VARIABLE>> <<LINK>>
<<bpi>> <<410:17905-17908>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<417:18300-18304>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<418:18330-18341>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<421:18524-18528>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<422:18554-18565>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<425:18696-18700>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<426:18726-18737>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<202:8951-8955>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<self>> <<203:9003-9007>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<203:9024-9047>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<180:8130-8134>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<186:8305-8328>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<186:8329-8335>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<187:8342-8346>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<188:8372-8381>> <<?>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<190:8440-8463>> <<?>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<191:8542-8565>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<191:8566-8572>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<192:8579-8583>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<192:8599-8608>> <<?>> <<VARIABLE>> <<LINK>>
<<token_ids_2>> <<192:8610-8621>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<193:8628-8632>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<start_offsets>> <<194:8658-8671>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<196:8728-8732>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<limit_offsets>> <<197:8758-8771>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<296:13012-13016>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<298:13131-13154>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<299:13155-13161>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<299:13191-13197>> <<?>> <<VARIABLE>> <<LINK>>
<<outputs>> <<299:13199-13206>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<300:13248-13252>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<model>> <<301:13274-13279>> <<?>> <<VARIABLE>> <<LINK>>
<<export_path>> <<301:13285-13296>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<139:6235-6239>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<tmp_dir>> <<140:6281-6288>> <<?>> <<VARIABLE>> <<LINK>>
<<tmp_dir>> <<142:6390-6397>> <<?>> <<VARIABLE>> <<LINK>>
<<tmp_dir>> <<143:6453-6460>> <<?>> <<VARIABLE>> <<LINK>>
<<input_text_file_path>> <<144:6509-6529>> <<str>> <<VARIABLE>> <<LINK>>
<<f>> <<145:6549-6550>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab>> <<145:6566-6571>> <<list>> <<VARIABLE>> <<LINK>>
<<vocab>> <<147:6683-6688>> <<list>> <<VARIABLE>> <<LINK>>
<<model_prefix>> <<149:6735-6747>> <<str>> <<VARIABLE>> <<LINK>>
<<input_text_file_path>> <<151:6792-6812>> <<str>> <<VARIABLE>> <<LINK>>
<<full_vocab_size>> <<153:6901-6916>> <<int>> <<VARIABLE>> <<LINK>>
<<full_vocab_size>> <<154:6934-6949>> <<int>> <<VARIABLE>> <<LINK>>
<<full_vocab_size>> <<154:6960-6975>> <<int>> <<VARIABLE>> <<LINK>>
<<flags>> <<156:7066-7071>> <<dict>> <<VARIABLE>> <<LINK>>
<<k>> <<156:7058-7059>> <<?>> <<VARIABLE>> <<LINK>>
<<v>> <<156:7061-7062>> <<?>> <<VARIABLE>> <<LINK>>
<<k>> <<156:7048-7049>> <<?>> <<VARIABLE>> <<LINK>>
<<v>> <<156:7051-7052>> <<?>> <<VARIABLE>> <<LINK>>
<<model_prefix>> <<157:7105-7117>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<157:7088-7092>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<self>> <<87:3949-3953>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<87:3954-3970>> <<function>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<90:4078-4088>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<91:4112-4116>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<91:4133-4146>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<161:7250-7254>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_spm_path>> <<161:7255-7264>> <<str>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<164:7368-7391>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<164:7392-7398>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<165:7405-7409>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<166:7435-7444>> <<?>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<168:7504-7527>> <<?>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<169:7606-7629>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<169:7630-7636>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<170:7643-7647>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<170:7663-7672>> <<?>> <<VARIABLE>> <<LINK>>
<<token_ids_2>> <<170:7674-7685>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<171:7692-7696>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<start_offsets>> <<172:7722-7735>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<173:7783-7787>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<limit_offsets>> <<174:7813-7826>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<175:7874-7878>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<175:7891-7914>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<491:22021-22025>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<491:22026-22042>> <<function>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<494:22195-22205>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<495:22229-22233>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<495:22250-22263>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<61:2546-2550>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<61:2551-2567>> <<function>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<64:2711-2721>> <<str>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<66:2866-2879>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<66:2880-2886>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<67:2893-2897>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<67:2913-2922>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<69:3034-3038>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<start_offsets>> <<69:3054-3067>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<71:3183-3187>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<limit_offsets>> <<71:3203-3216>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<278:12167-12171>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<self>> <<280:12288-12292>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_spm_path>> <<280:12293-12302>> <<str>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<285:12453-12476>> <<?>> <<VARIABLE>> <<LINK>>
<<config>> <<287:12558-12564>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<287:12571-12575>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<config>> <<287:12588-12594>> <<?>> <<VARIABLE>> <<LINK>>
<<new_tokenizer>> <<287:12596-12609>> <<?>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<289:12693-12716>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<290:12717-12723>> <<?>> <<VARIABLE>> <<LINK>>
<<new_tokenizer>> <<290:12744-12757>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<291:12758-12764>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<291:12771-12775>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<291:12791-12800>> <<?>> <<VARIABLE>> <<LINK>>
<<token_ids_2>> <<291:12802-12813>> <<?>> <<VARIABLE>> <<LINK>>
<<special_tokens_dict>> <<436:19223-19242>> <<dict>> <<VARIABLE>> <<LINK>>
<<bpi>> <<438:19263-19266>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<440:19389-19393>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<441:19419-19430>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<458:20068-20072>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<458:20073-20089>> <<function>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<461:20245-20255>> <<str>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<463:20343-20356>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<464:20357-20363>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<464:20370-20374>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<464:20390-20399>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<466:20519-20532>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<467:20611-20624>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<468:20625-20631>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<468:20638-20642>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<468:20658-20667>> <<?>> <<VARIABLE>> <<LINK>>
<<token_ids_2>> <<468:20669-20680>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<469:20687-20691>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<start_offsets>> <<469:20707-20720>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<471:20844-20848>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<limit_offsets>> <<471:20864-20877>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<473:21001-21005>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<473:21018-21031>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<75:3390-3394>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<75:3395-3411>> <<function>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<78:3551-3561>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<79:3585-3589>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<79:3606-3619>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<477:21164-21168>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<477:21169-21185>> <<function>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<480:21342-21352>> <<str>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<482:21497-21510>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<483:21511-21517>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<483:21524-21528>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<483:21544-21553>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<485:21665-21669>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<start_offsets>> <<485:21685-21698>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<487:21814-21818>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<limit_offsets>> <<487:21834-21847>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<42:1455-1459>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<42:1460-1476>> <<function>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<45:1619-1629>> <<str>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<47:1717-1730>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<47:1731-1737>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<48:1744-1748>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<48:1764-1773>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<50:1893-1906>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<51:1985-1998>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<51:1999-2005>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<52:2012-2016>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<52:2032-2041>> <<?>> <<VARIABLE>> <<LINK>>
<<token_ids_2>> <<52:2043-2054>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<53:2061-2065>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<start_offsets>> <<53:2081-2094>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<55:2218-2222>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<limit_offsets>> <<55:2238-2251>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<57:2375-2379>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<57:2392-2405>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<504:22653-22657>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<504:22658-22674>> <<function>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<507:22804-22814>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<508:22838-22842>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<bert_tokenize>> <<508:22859-22872>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<516:23251-23255>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_make_vocab_file>> <<516:23256-23272>> <<function>> <<VARIABLE>> <<LINK>>
<<model_fn>> <<544:24568-24576>> <<function>> <<VARIABLE>> <<LINK>>
<<estimator>> <<545:24598-24607>> <<?>> <<VARIABLE>> <<LINK>>
<<input_fn>> <<545:24616-24624>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<546:24632-24636>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<outputs>> <<546:24652-24659>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<245:11011-11015>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_spm_path>> <<245:11016-11025>> <<str>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<250:11186-11209>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<250:11210-11216>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<251:11223-11227>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<token_ids>> <<252:11253-11262>> <<?>> <<VARIABLE>> <<LINK>>
<<model_fn>> <<238:10703-10711>> <<function>> <<VARIABLE>> <<LINK>>
<<estimator>> <<239:10733-10742>> <<?>> <<VARIABLE>> <<LINK>>
<<input_fn>> <<239:10751-10759>> <<function>> <<VARIABLE>> <<LINK>>
<<self>> <<240:10767-10771>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<outputs>> <<240:10787-10794>> <<list>> <<VARIABLE>> <<LINK>>
<<bpi>> <<315:13639-13642>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<317:13765-13769>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<318:13795-13806>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<321:13974-13978>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<322:14004-14015>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<325:14146-14150>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<326:14176-14187>> <<?>> <<VARIABLE>> <<LINK>>
<<bpi>> <<332:14410-14413>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<337:14686-14690>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<338:14716-14727>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<341:14908-14912>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<342:14938-14949>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<345:15080-15084>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<346:15110-15121>> <<?>> <<VARIABLE>> <<LINK>>
<<bpi>> <<352:15301-15304>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<359:15706-15710>> <<BertPackInputsTest>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<360:15736-15747>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<215:9497-9501>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<self>> <<219:9740-9744>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<_spm_path>> <<219:9745-9754>> <<str>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<220:9816-9839>> <<?>> <<VARIABLE>> <<LINK>>
<<special_tokens_dict>> <<221:9885-9904>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<222:9923-9927>> <<SentencepieceTokenizerTest>> <<VARIABLE>> <<LINK>>
<<v>> <<222:9945-9946>> <<?>> <<VARIABLE>> <<LINK>>
<<k>> <<222:9985-9986>> <<?>> <<VARIABLE>> <<LINK>>
<<sentencepiece_tokenizer>> <<223:10005-10028>> <<?>> <<VARIABLE>> <<LINK>>
<<sentences>> <<223:10029-10038>> <<?>> <<VARIABLE>> <<LINK>>
<<special_tokens_dict>> <<225:10125-10144>> <<?>> <<VARIABLE>> <<LINK>>
<<tokens>> <<225:10146-10152>> <<?>> <<VARIABLE>> <<LINK>>
<<sentences>> <<226:10192-10201>> <<?>> <<VARIABLE>> <<LINK>>
<<packed_inputs>> <<226:10203-10216>> <<?>> <<VARIABLE>> <<LINK>>
<<ds>> <<230:10361-10363>> <<?>> <<VARIABLE>> <<LINK>>
<<ds>> <<231:10442-10444>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<104:4682-4686>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<108:4902-4912>> <<str>> <<VARIABLE>> <<LINK>>
<<bert_tokenizer>> <<109:4960-4974>> <<?>> <<VARIABLE>> <<LINK>>
<<special_tokens_dict>> <<110:5020-5039>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<111:5058-5062>> <<BertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<v>> <<111:5080-5081>> <<?>> <<VARIABLE>> <<LINK>>
<<k>> <<111:5120-5121>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_tokenizer>> <<112:5140-5154>> <<?>> <<VARIABLE>> <<LINK>>
<<sentences>> <<112:5155-5164>> <<?>> <<VARIABLE>> <<LINK>>
<<special_tokens_dict>> <<114:5251-5270>> <<?>> <<VARIABLE>> <<LINK>>
<<tokens>> <<114:5272-5278>> <<?>> <<VARIABLE>> <<LINK>>
<<sentences>> <<115:5318-5327>> <<?>> <<VARIABLE>> <<LINK>>
<<packed_inputs>> <<115:5329-5342>> <<?>> <<VARIABLE>> <<LINK>>
<<ds>> <<119:5487-5489>> <<?>> <<VARIABLE>> <<LINK>>
<<ds>> <<120:5568-5570>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<521:23408-23412>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<525:23641-23651>> <<str>> <<VARIABLE>> <<LINK>>
<<bert_tokenizer>> <<526:23699-23713>> <<?>> <<VARIABLE>> <<LINK>>
<<special_tokens_dict>> <<527:23759-23778>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<528:23797-23801>> <<FastWordPieceBertTokenizerTest>> <<VARIABLE>> <<LINK>>
<<v>> <<528:23819-23820>> <<?>> <<VARIABLE>> <<LINK>>
<<k>> <<529:23859-23860>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_tokenizer>> <<529:23879-23893>> <<?>> <<VARIABLE>> <<LINK>>
<<sentences>> <<529:23894-23903>> <<?>> <<VARIABLE>> <<LINK>>
<<special_tokens_dict>> <<531:23990-24009>> <<?>> <<VARIABLE>> <<LINK>>
<<tokens>> <<532:24011-24017>> <<?>> <<VARIABLE>> <<LINK>>
<<sentences>> <<532:24057-24066>> <<?>> <<VARIABLE>> <<LINK>>
<<packed_inputs>> <<532:24068-24081>> <<?>> <<VARIABLE>> <<LINK>>
<<ds>> <<536:24226-24228>> <<?>> <<VARIABLE>> <<LINK>>
<<ds>> <<539:24307-24309>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<540:24366-24372>> <<?>> <<VARIABLE>> <<LINK>>
<<mode>> <<542:24430-24434>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<542:24489-24497>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<234:10501-10507>> <<?>> <<VARIABLE>> <<LINK>>
<<mode>> <<235:10565-10569>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<236:10624-10632>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<123:5627-5633>> <<?>> <<VARIABLE>> <<LINK>>
<<mode>> <<124:5691-5695>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<125:5750-5758>> <<?>> <<VARIABLE>> <<LINK>>
<<preprocessing>> <<230:10394-10407>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<230:10408-10416>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<230:10419-10425>> <<?>> <<VARIABLE>> <<LINK>>
<<preprocessing>> <<119:5520-5533>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<119:5534-5542>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<119:5545-5551>> <<?>> <<VARIABLE>> <<LINK>>
<<preprocessing>> <<536:24259-24272>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<536:24273-24281>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<536:24284-24290>> <<?>> <<VARIABLE>> <<LINK>>

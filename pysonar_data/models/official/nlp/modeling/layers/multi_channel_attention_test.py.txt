<<official>> <<20:734-742>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<nlp>> <<20:743-746>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<modeling>> <<20:747-755>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<layers>> <<20:756-762>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<MultiChannelAttentionTest>> <<23:805-830>> <<type>> <<CLASS>> <<ANCHOR>>
<<test_doc_attention>> <<25:859-877>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_multi_channel_attention>> <<35:1247-1275>> <<function>> <<METHOD>> <<ANCHOR>>
<<self>> <<25:878-881>> <<MultiChannelAttentionTest>> <<PARAMETER>> <<ANCHOR>>
<<num_heads>> <<26:890-899>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<doc_attention>> <<27:909-922>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<num_docs>> <<29:1004-1012>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<inputs>> <<30:1022-1028>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<doc_mask>> <<31:1086-1094>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<outputs>> <<32:1144-1151>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<35:1276-1279>> <<MultiChannelAttentionTest>> <<PARAMETER>> <<ANCHOR>>
<<num_heads>> <<36:1288-1297>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<num_docs>> <<37:1307-1315>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<attention_layer>> <<38:1325-1340>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<from_data>> <<41:1428-1437>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<to_data>> <<42:1485-1492>> <<int>> <<VARIABLE>> <<ANCHOR>>
<<mask_data>> <<43:1550-1559>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<doc_probs>> <<44:1614-1623>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<outputs>> <<46:1710-1717>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<num_heads>> <<28:975-984>> <<int>> <<VARIABLE>> <<LINK>>
<<num_docs>> <<30:1044-1052>> <<int>> <<VARIABLE>> <<LINK>>
<<num_docs>> <<31:1110-1118>> <<int>> <<VARIABLE>> <<LINK>>
<<doc_attention>> <<32:1154-1167>> <<?>> <<VARIABLE>> <<LINK>>
<<inputs>> <<32:1168-1174>> <<?>> <<VARIABLE>> <<LINK>>
<<doc_mask>> <<32:1176-1184>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<33:1191-1195>> <<MultiChannelAttentionTest>> <<VARIABLE>> <<LINK>>
<<outputs>> <<33:1208-1215>> <<?>> <<VARIABLE>> <<LINK>>
<<num_docs>> <<33:1227-1235>> <<int>> <<VARIABLE>> <<LINK>>
<<num_heads>> <<39:1399-1408>> <<int>> <<VARIABLE>> <<LINK>>
<<num_docs>> <<42:1528-1536>> <<int>> <<VARIABLE>> <<LINK>>
<<num_docs>> <<43:1592-1600>> <<int>> <<VARIABLE>> <<LINK>>
<<num_heads>> <<45:1666-1675>> <<int>> <<VARIABLE>> <<LINK>>
<<num_docs>> <<45:1680-1688>> <<int>> <<VARIABLE>> <<LINK>>
<<attention_layer>> <<46:1720-1735>> <<?>> <<VARIABLE>> <<LINK>>
<<from_data>> <<47:1752-1761>> <<int>> <<VARIABLE>> <<LINK>>
<<to_data>> <<48:1778-1785>> <<int>> <<VARIABLE>> <<LINK>>
<<doc_probs>> <<49:1822-1831>> <<?>> <<VARIABLE>> <<LINK>>
<<mask_data>> <<50:1857-1866>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<51:1873-1877>> <<MultiChannelAttentionTest>> <<VARIABLE>> <<LINK>>
<<outputs>> <<51:1890-1897>> <<?>> <<VARIABLE>> <<LINK>>

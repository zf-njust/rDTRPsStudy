<<official>> <<21:697-705>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<nlp>> <<21:706-709>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<tools>> <<21:710-715>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<TokenizationTest>> <<24:747-763>> <<type>> <<CLASS>> <<ANCHOR>>
<<test_full_tokenizer>> <<31:945-964>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_chinese>> <<54:1776-1788>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_basic_tokenizer_lower>> <<61:1977-2003>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_basic_tokenizer_no_lower>> <<69:2296-2325>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_basic_tokenizer_no_split_on_punc>> <<76:2548-2585>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_wordpiece_tokenizer>> <<84:2826-2850>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_convert_tokens_to_ids>> <<112:3722-3748>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_is_whitespace>> <<126:4137-4155>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_is_control>> <<136:4576-4591>> <<function>> <<METHOD>> <<ANCHOR>>
<<test_is_punctuation>> <<145:4949-4968>> <<function>> <<METHOD>> <<ANCHOR>>
<<self>> <<84:2851-2854>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_tokens>> <<85:2863-2875>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<vocab>> <<90:3005-3010>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<i>> <<91:3026-3027>> <<?>> <<SCOPE>> <<ANCHOR>>
<<token>> <<91:3029-3034>> <<?>> <<SCOPE>> <<ANCHOR>>
<<tokenizer>> <<93:3093-3102>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<61:2004-2007>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<tokenizer>> <<62:2016-2025>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<126:4156-4159>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<112:3749-3752>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_tokens>> <<113:3761-3773>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<vocab>> <<118:3891-3896>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<i>> <<119:3912-3913>> <<?>> <<SCOPE>> <<ANCHOR>>
<<token>> <<119:3915-3920>> <<?>> <<SCOPE>> <<ANCHOR>>
<<self>> <<76:2586-2589>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<tokenizer>> <<77:2598-2607>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<54:1789-1792>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<tokenizer>> <<55:1801-1810>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<31:965-968>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_tokens>> <<32:977-989>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<vocab_writer>> <<36:1160-1172>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<x>> <<38:1243-1244>> <<str>> <<SCOPE>> <<ANCHOR>>
<<x>> <<40:1327-1328>> <<str>> <<SCOPE>> <<ANCHOR>>
<<vocab_file>> <<43:1410-1420>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<tokenizer>> <<45:1448-1457>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<tokens>> <<48:1533-1539>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<69:2326-2329>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<tokenizer>> <<70:2338-2347>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<136:4592-4595>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<145:4969-4972>> <<TokenizationTest>> <<PARAMETER>> <<ANCHOR>>
<<vocab_tokens>> <<91:3049-3061>> <<list>> <<VARIABLE>> <<LINK>>
<<i>> <<92:3086-3087>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab>> <<92:3071-3076>> <<dict>> <<VARIABLE>> <<LINK>>
<<token>> <<92:3077-3082>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab>> <<93:3143-3148>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<95:3157-3161>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<95:3177-3186>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<97:3212-3216>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<98:3242-3251>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<101:3341-3345>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<102:3371-3380>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<105:3477-3481>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<106:3507-3516>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<109:3614-3618>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<110:3644-3653>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<64:2083-2087>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<65:2113-2122>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<67:2221-2225>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<67:2241-2250>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<127:4168-4172>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<128:4224-4228>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<129:4281-4285>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<130:4338-4342>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<131:4395-4399>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<133:4458-4462>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<134:4515-4519>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<vocab_tokens>> <<119:3935-3947>> <<list>> <<VARIABLE>> <<LINK>>
<<i>> <<120:3972-3973>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab>> <<120:3957-3962>> <<dict>> <<VARIABLE>> <<LINK>>
<<token>> <<120:3963-3968>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<122:3981-3985>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<vocab>> <<124:4060-4065>> <<dict>> <<VARIABLE>> <<LINK>>
<<self>> <<80:2696-2700>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<81:2726-2735>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<57:1850-1854>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<58:1880-1889>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab_writer>> <<38:1202-1214>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab_tokens>> <<38:1248-1260>> <<list>> <<VARIABLE>> <<LINK>>
<<x>> <<38:1243-1244>> <<str>> <<VARIABLE>> <<LINK>>
<<x>> <<38:1230-1231>> <<str>> <<VARIABLE>> <<LINK>>
<<vocab_writer>> <<40:1286-1298>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab_tokens>> <<40:1332-1344>> <<list>> <<VARIABLE>> <<LINK>>
<<x>> <<40:1327-1328>> <<str>> <<VARIABLE>> <<LINK>>
<<x>> <<40:1314-1315>> <<str>> <<VARIABLE>> <<LINK>>
<<vocab_writer>> <<43:1423-1435>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<45:1487-1497>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<46:1514-1524>> <<?>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<48:1542-1551>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<49:1592-1596>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokens>> <<49:1612-1618>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<51:1675-1679>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<52:1705-1714>> <<?>> <<VARIABLE>> <<LINK>>
<<tokens>> <<52:1737-1743>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<72:2406-2410>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<tokenizer>> <<73:2436-2445>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<137:4604-4608>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<139:4664-4668>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<140:4718-4722>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<141:4772-4776>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<142:4827-4831>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<143:4882-4886>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<146:4981-4985>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<147:5038-5042>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<148:5095-5099>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<149:5152-5156>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<151:5211-5215>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>
<<self>> <<152:5269-5273>> <<TokenizationTest>> <<VARIABLE>> <<LINK>>

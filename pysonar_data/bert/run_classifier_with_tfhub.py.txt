<<__future__>> <<17:679-689>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<__future__>> <<18:719-729>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<__future__>> <<19:752-762>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<run_classifier>> <<23:827-841>> <<module>> <<VARIABLE>> <<ANCHOR>>
<<flags>> <<28:921-926>> <<?>> <<SCOPE>> <<ANCHOR>>
<<FLAGS>> <<30:941-946>> <<?>> <<SCOPE>> <<ANCHOR>>
<<create_model>> <<37:1074-1086>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<model_fn_builder>> <<87:2800-2816>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<create_tokenizer_from_hub_module>> <<146:4987-5019>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<main>> <<158:5577-5581>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<_>> <<158:5582-5585>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<processors>> <<161:5636-5646>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<task_name>> <<172:5966-5975>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<processor>> <<177:6102-6111>> <<{MrpcProcessor||ColaProcessor||MnliProcessor}>> <<VARIABLE>> <<ANCHOR>>
<<label_list>> <<179:6143-6153>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<bert_hub_module_handle>> <<146:5020-5023>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<bert_module>> <<149:5148-5159>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<tokenization_info>> <<150:5202-5219>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<sess>> <<151:5305-5309>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<vocab_file>> <<152:5318-5328>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<do_lower_case>> <<152:5330-5343>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<tokenizer>> <<181:6184-6193>> <<None>> <<VARIABLE>> <<ANCHOR>>
<<num_labels>> <<87:2817-2820>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<learning_rate>> <<87:2829-2832>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_train_steps>> <<87:2844-2847>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_warmup_steps>> <<88:2883-2886>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<use_tpu>> <<88:2901-2904>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<bert_hub_module_handle>> <<88:2910-2913>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<model_fn>> <<91:2998-3006>> <<function>> <<FUNCTION>> <<ANCHOR>>
<<is_training>> <<37:1087-1090>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<input_ids>> <<37:1100-1103>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<input_mask>> <<37:1111-1114>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<segment_ids>> <<37:1123-1126>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<labels>> <<37:1136-1139>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<num_labels>> <<38:1162-1165>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<bert_hub_module_handle>> <<38:1174-1177>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<tags>> <<40:1243-1247>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_module>> <<43:1301-1312>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<bert_inputs>> <<44:1380-1391>> <<dict>> <<VARIABLE>> <<ANCHOR>>
<<bert_outputs>> <<48:1493-1505>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<output_layer>> <<58:1792-1804>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<hidden_size>> <<60:1842-1853>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<output_weights>> <<62:1890-1904>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<output_bias>> <<66:2046-2057>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<output_layer>> <<72:2241-2253>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<logits>> <<74:2306-2312>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<logits>> <<75:2378-2384>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<probabilities>> <<76:2428-2441>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<log_probs>> <<77:2480-2489>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<one_hot_labels>> <<79:2534-2548>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<per_example_loss>> <<81:2613-2629>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<loss>> <<82:2689-2693>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<features>> <<91:3007-3010>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<labels>> <<91:3017-3020>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<mode>> <<91:3025-3028>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<params>> <<91:3031-3034>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<name>> <<95:3171-3175>> <<?>> <<SCOPE>> <<ANCHOR>>
<<input_ids>> <<98:3292-3301>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<input_mask>> <<99:3331-3341>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<segment_ids>> <<100:3372-3383>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<label_ids>> <<101:3415-3424>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<is_training>> <<103:3456-3467>> <<bool>> <<VARIABLE>> <<ANCHOR>>
<<total_loss>> <<105:3516-3526>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<per_example_loss>> <<105:3528-3544>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<logits>> <<105:3546-3552>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<probabilities>> <<105:3554-3567>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<absolute_import>> <<17:697-712>> <<_Feature>> <<VARIABLE>> <<LINK>>
<<division>> <<18:737-745>> <<_Feature>> <<VARIABLE>> <<LINK>>
<<print_function>> <<19:770-784>> <<_Feature>> <<VARIABLE>> <<LINK>>
<<flags>> <<30:949-954>> <<?>> <<VARIABLE>> <<LINK>>
<<flags>> <<32:964-969>> <<?>> <<VARIABLE>> <<LINK>>
<<flags>> <<310:11537-11542>> <<?>> <<VARIABLE>> <<LINK>>
<<flags>> <<311:11580-11585>> <<?>> <<VARIABLE>> <<LINK>>
<<flags>> <<312:11624-11629>> <<?>> <<VARIABLE>> <<LINK>>
<<flags>> <<313:11681-11686>> <<?>> <<VARIABLE>> <<LINK>>
<<run_classifier>> <<162:5666-5680>> <<module>> <<VARIABLE>> <<LINK>>
<<ColaProcessor>> <<162:5681-5694>> <<type>> <<VARIABLE>> <<LINK>>
<<run_classifier>> <<163:5711-5725>> <<module>> <<VARIABLE>> <<LINK>>
<<MnliProcessor>> <<163:5726-5739>> <<type>> <<VARIABLE>> <<LINK>>
<<run_classifier>> <<164:5756-5770>> <<module>> <<VARIABLE>> <<LINK>>
<<MrpcProcessor>> <<164:5771-5784>> <<type>> <<VARIABLE>> <<LINK>>
<<FLAGS>> <<167:5803-5808>> <<?>> <<VARIABLE>> <<LINK>>
<<FLAGS>> <<167:5826-5831>> <<?>> <<VARIABLE>> <<LINK>>
<<FLAGS>> <<170:5943-5948>> <<?>> <<VARIABLE>> <<LINK>>
<<FLAGS>> <<172:5978-5983>> <<?>> <<VARIABLE>> <<LINK>>
<<task_name>> <<174:6010-6019>> <<?>> <<VARIABLE>> <<LINK>>
<<processors>> <<174:6027-6037>> <<dict>> <<VARIABLE>> <<LINK>>
<<processors>> <<177:6114-6124>> <<dict>> <<VARIABLE>> <<LINK>>
<<task_name>> <<177:6125-6134>> <<?>> <<VARIABLE>> <<LINK>>
<<processor>> <<179:6156-6165>> <<{MrpcProcessor||ColaProcessor||MnliProcessor}>> <<VARIABLE>> <<LINK>>
<<get_labels>> <<179:6166-6176>> <<{function||function||function}>> <<VARIABLE>> <<LINK>>
<<create_tokenizer_from_hub_module>> <<181:6196-6228>> <<function>> <<VARIABLE>> <<LINK>>
<<FLAGS>> <<181:6229-6234>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_hub_module_handle>> <<149:5173-5195>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_module>> <<150:5222-5233>> <<?>> <<VARIABLE>> <<LINK>>
<<sess>> <<152:5346-5350>> <<?>> <<VARIABLE>> <<LINK>>
<<tokenization_info>> <<152:5356-5373>> <<?>> <<VARIABLE>> <<LINK>>
<<tokenization_info>> <<153:5434-5451>> <<?>> <<VARIABLE>> <<LINK>>
<<vocab_file>> <<155:5527-5537>> <<?>> <<VARIABLE>> <<LINK>>
<<do_lower_case>> <<155:5553-5566>> <<?>> <<VARIABLE>> <<LINK>>
<<model_fn>> <<143:4969-4977>> <<function>> <<VARIABLE>> <<LINK>>
<<is_training>> <<41:1262-1273>> <<?>> <<VARIABLE>> <<LINK>>
<<tags>> <<42:1280-1284>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_hub_module_handle>> <<43:1326-1348>> <<?>> <<VARIABLE>> <<LINK>>
<<tags>> <<43:1355-1359>> <<?>> <<VARIABLE>> <<LINK>>
<<input_ids>> <<45:1417-1426>> <<?>> <<VARIABLE>> <<LINK>>
<<input_mask>> <<46:1446-1456>> <<?>> <<VARIABLE>> <<LINK>>
<<segment_ids>> <<47:1477-1488>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_module>> <<48:1508-1519>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_inputs>> <<49:1535-1546>> <<dict>> <<VARIABLE>> <<LINK>>
<<bert_outputs>> <<58:1807-1819>> <<?>> <<VARIABLE>> <<LINK>>
<<output_layer>> <<60:1856-1868>> <<?>> <<VARIABLE>> <<LINK>>
<<num_labels>> <<63:1950-1960>> <<?>> <<VARIABLE>> <<LINK>>
<<hidden_size>> <<63:1962-1973>> <<?>> <<VARIABLE>> <<LINK>>
<<num_labels>> <<67:2100-2110>> <<?>> <<VARIABLE>> <<LINK>>
<<is_training>> <<70:2194-2205>> <<?>> <<VARIABLE>> <<LINK>>
<<output_layer>> <<72:2270-2282>> <<?>> <<VARIABLE>> <<LINK>>
<<output_layer>> <<74:2325-2337>> <<?>> <<VARIABLE>> <<LINK>>
<<output_weights>> <<74:2339-2353>> <<?>> <<VARIABLE>> <<LINK>>
<<logits>> <<75:2402-2408>> <<?>> <<VARIABLE>> <<LINK>>
<<output_bias>> <<75:2410-2421>> <<?>> <<VARIABLE>> <<LINK>>
<<logits>> <<76:2458-2464>> <<?>> <<VARIABLE>> <<LINK>>
<<logits>> <<77:2510-2516>> <<?>> <<VARIABLE>> <<LINK>>
<<labels>> <<79:2562-2568>> <<?>> <<VARIABLE>> <<LINK>>
<<num_labels>> <<79:2576-2586>> <<?>> <<VARIABLE>> <<LINK>>
<<one_hot_labels>> <<81:2647-2661>> <<?>> <<VARIABLE>> <<LINK>>
<<log_probs>> <<81:2664-2673>> <<?>> <<VARIABLE>> <<LINK>>
<<per_example_loss>> <<82:2711-2727>> <<?>> <<VARIABLE>> <<LINK>>
<<loss>> <<84:2744-2748>> <<?>> <<VARIABLE>> <<LINK>>
<<per_example_loss>> <<84:2750-2766>> <<?>> <<VARIABLE>> <<LINK>>
<<logits>> <<84:2768-2774>> <<?>> <<VARIABLE>> <<LINK>>
<<probabilities>> <<84:2776-2789>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<95:3186-3194>> <<?>> <<VARIABLE>> <<LINK>>
<<name>> <<96:3256-3260>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<96:3262-3270>> <<?>> <<VARIABLE>> <<LINK>>
<<name>> <<96:3271-3275>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<98:3304-3312>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<99:3344-3352>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<100:3386-3394>> <<?>> <<VARIABLE>> <<LINK>>
<<features>> <<101:3427-3435>> <<?>> <<VARIABLE>> <<LINK>>
<<mode>> <<103:3471-3475>> <<?>> <<VARIABLE>> <<LINK>>
<<create_model>> <<105:3571-3583>> <<function>> <<VARIABLE>> <<LINK>>
<<is_training>> <<106:3594-3605>> <<bool>> <<VARIABLE>> <<LINK>>
<<input_ids>> <<106:3607-3616>> <<?>> <<VARIABLE>> <<LINK>>
<<input_mask>> <<106:3618-3628>> <<?>> <<VARIABLE>> <<LINK>>
<<segment_ids>> <<106:3630-3641>> <<?>> <<VARIABLE>> <<LINK>>
<<label_ids>> <<106:3643-3652>> <<?>> <<VARIABLE>> <<LINK>>
<<num_labels>> <<106:3654-3664>> <<?>> <<VARIABLE>> <<LINK>>
<<bert_hub_module_handle>> <<107:3675-3697>> <<?>> <<VARIABLE>> <<LINK>>

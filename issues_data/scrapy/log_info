==================
9a28eb0b;Eugene;2022-03-17 05:39:54 +0100;Suggest installing the brotli package instead of brotlipy (#4267)

==

docs/topics/downloader-middleware.rst
tests/requirements.txt
==================
2d6042b1;Andrey Rahmatullin;2022-03-11 20:05:43 +0500;Merge pull request #5432 from Farsene1/master
Recommend Common Crawl instead of Google Cache
==
==================
e264cc30;NaincyKumariKnoldus;2022-03-10 19:24:33 +0530;removed  the pywin32 docs section (#5370)

==

docs/faq.rst
==================
d469214f;Ali Rastegar;2022-03-08 01:29:22 -0800;Update tutorial.rst (#5442)
Fixed typo
==

docs/intro/tutorial.rst
==================
ccdbb795;Florentin;2022-03-01 22:01:55 +0100;Recommend Common Crawl instead of Google Cache

==

docs/topics/practices.rst
==================
50c8becb;Adrián Chaves;2022-03-01 17:29:08 +0100;Freeze and upgrade CI packages (#5429)

==

tests/requirements.txt
tox.ini
==================
23537a0f;Adrián Chaves;2022-03-01 13:48:40 +0100;Bump version: 2.6.0 → 2.6.1

==

.bumpversion.cfg
scrapy/VERSION
==================
fab3e907;Adrián Chaves;2022-03-01 13:41:20 +0100;Cover 2.6.1 in the release notes

==

docs/news.rst
==================
d60636d0;Adrián Chaves;2022-03-01 13:06:58 +0100;Fix redirect handling regression

==

scrapy/downloadermiddlewares/redirect.py
==================
84853c4f;Adrián Chaves;2022-03-01 13:01:20 +0100;bandit: allow-list B324 for the time being

==

.bandit.yml
==================
6b63e7c1;Adrián Chaves;2022-03-01 12:43:11 +0100;Bump version: 2.5.0 → 2.6.0

==

.bumpversion.cfg
scrapy/VERSION
==================
e865c443;Adrián Chaves;2022-03-01 12:38:19 +0100;Merge pull request from GHSA-mfjm-vh54-3f96
* Ignore cookies with a public suffix as domain unless it matches the request domain

* Fix the merge of 1.8.2 release notes

* Re-apply removal of tldextract restriction
==

docs/news.rst
scrapy/downloadermiddlewares/cookies.py
setup.py
tests/test_downloadermiddleware_cookies.py
==================
8ce01b3b;Adrián Chaves;2022-03-01 12:26:05 +0100;Merge pull request from GHSA-cjvr-mfj7-j4j8
* Do not carry over cookies to a different domain on redirect

* Cover the cookie-domain redirect fix in the release notes

* Cover 1.8.2 in the release notes

* Fix redirect Cookie handling when the cookie middleware is disabled

* Update the 1.8.2 release date
==

docs/news.rst
scrapy/downloadermiddlewares/redirect.py
tests/test_downloadermiddleware_cookies.py
==================
aa0306a1;Adrián Chaves;2022-03-01 12:16:37 +0100;Cover 2.6.0 in the release notes (#5399)

==

docs/conf.py
docs/index.rst
docs/news.rst
docs/topics/asyncio.rst
docs/topics/commands.rst
docs/topics/feed-exports.rst
docs/topics/media-pipeline.rst
docs/topics/request-response.rst
docs/topics/spiders.rst
scrapy/utils/defer.py
==================
08557e09;Andrey Rahmatullin;2022-02-23 23:52:18 +0500;Pin old markupsafe when we pin old mitmproxy (#5427)

==

tox.ini
==================
3b42ccfe;Gowtham Chowdary;2022-02-17 02:03:56 +0530;Add a link to Discord (#5422)

==

docs/index.rst
==================
8840403b;Andrey Rahmatullin;2022-02-15 18:15:39 +0500;Merge pull request #5412 from Laerte/master

==
==================
0b0eea36;Andrey Rahmatullin;2022-02-15 10:57:35 +0500;Merge pull request #5419 from PendalF89/patch-2
Update downloader-middleware.rst
==
==================
187b5c88;Abhishek K M;2022-02-14 23:46:53 +0530;Update the documentation link for robots.txt (#5415)

==

docs/topics/downloader-middleware.rst
==================
bbb693d0;Boris Zabolotskikh;2022-02-14 12:07:45 +0300;Update downloader-middleware.rst
Added a link to the method
==

docs/topics/downloader-middleware.rst
==================
befb6df1;Laerte Pereira;2022-02-11 06:19:27 -0300;Remove Python 2 code from WrappedRequest

==

scrapy/http/cookies.py
tests/test_http_cookies.py
==================
5d7c0a5f;Andrey Rahmatullin;2022-02-10 14:50:12 +0500;Use toscrape.com instead of example.com in test_command_check. (#5407)

==

tests/test_command_check.py
==================
e2e2ffd0;Alex;2022-02-09 11:52:07 -0800;Move from optparse to argparse (#5374)

==

scrapy/cmdline.py
scrapy/commands/__init__.py
scrapy/commands/check.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/parse.py
scrapy/commands/settings.py
scrapy/commands/shell.py
scrapy/commands/version.py
scrapy/commands/view.py
tests/test_command_parse.py
tests/test_commands.py
==================
1356836e;Andrey Rahmatullin;2022-02-09 00:06:25 +0500;Merge pull request #5405 from wRAR/tests-twisted-22.1-fix
Fix running tests with Twisted 22.1.0
==
==================
77547a1a;Andrey Rakhmatullin;2022-02-08 21:06:02 +0500;Revert "Temporarily pin Twisted to an older version in CI (#5401)"
This reverts commit b282a7af012a4804eb91bdd850df3b86065b3fd6.

==

tox.ini
==================
1e1cfc26;Andrey Rakhmatullin;2022-02-08 21:01:16 +0500;Copy resource classes from twisted.web.test.test_webclient.

==

pytest.ini
tests/mockserver.py
tests/test_downloader_handlers.py
tests/test_webclient.py
==================
fd55f622;Raihan Nismara;2022-02-08 21:36:25 +0700;Update Logo in README.rst (#5258)

==

README.rst
==================
4bda0976;Laerte;2022-02-08 10:57:19 -0300;Fix csviter call, add parse_rows test (#5394)

==

scrapy/spiders/feed.py
tests/test_spider.py
==================
84036249;Andrey Rahmatullin;2022-02-08 11:05:52 +0500;Merge pull request #5396 from peter-gy/master
docs: use https scheme for each quotes.toscrape.com url occurrence
==
==================
b282a7af;Andrey Rahmatullin;2022-02-08 01:25:08 +0500;Temporarily pin Twisted to an older version in CI (#5401)

==

tox.ini
==================
f7bf7414;Andrey Rahmatullin;2022-02-07 12:34:35 +0500;Merge pull request #5398 from elacuesta/remove-deprecated-item-classes
Remove deprecated DictItem/BaseItem classes
==
==================
fca49cca;Eugenio Lacuesta;2022-02-06 18:31:55 -0300;Remove deprecated DictItem class

==

docs/conf.py
scrapy/item.py
tests/test_item.py
==================
c8c1edd4;Eugenio Lacuesta;2022-02-06 18:27:41 -0300;Flake8 adjustments

==

tests/test_item.py
==================
bbfa1856;Eugenio Lacuesta;2022-02-06 18:12:28 -0300;Remove deprecated BaseItem class

==

scrapy/exporters.py
scrapy/item.py
scrapy/utils/misc.py
tests/test_item.py
==================
38d2a154;Péter Ferenc Gyarmati;2022-02-06 18:52:15 +0100;docs: use https scheme for each quotes.toscrape.com url occurrence

==

docs/intro/examples.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/developer-tools.rst
docs/topics/logging.rst
docs/topics/settings.rst
docs/topics/signals.rst
==================
35337174;Andrey Rahmatullin;2022-02-06 19:36:55 +0500;Merge pull request #5393 from elacuesta/remove-textresponse-body-as-unicode
Remove deprecated TextResponse.body_as_unicode
==
==================
55ae2109;Eugenio Lacuesta;2022-02-05 13:02:02 -0300;Remove deprecated TextResponse.body_as_unicode

==

scrapy/http/response/text.py
tests/test_http_response.py
==================
9be878fc;Adrián Chaves;2022-02-04 12:27:39 +0100;CI: stop using tox-pip-version (#5389)

==

.github/workflows/checks.yml
.github/workflows/tests-ubuntu.yml
==================
fe43411b;Laerte;2022-02-04 05:57:57 -0300;Fix TypeError on using pathlib.Path as key on FEEDS settings (#5384)

==

scrapy/settings/__init__.py
tests/test_cmdline/__init__.py
tests/test_cmdline/settings.py
==================
30d5779e;Sixuan (Cherie) Wu;2022-01-28 09:30:30 -0800;Fix FEED_URI_PARAMS: custom params throws KeyError (#4966)
* fix FEED_URI_PARAMS: custom params throws KeyError closes #4962

* another try FEED_URI_PARAMS

* add warning message and change default function

* Add tests for FEED_URI_PARAMS

* FEED_URI_PARAMS: warn if the params dict has been modified in-place

* [Doc] FEED_URI_PARAMS: modifying params in-place is deprecated

* Remove whileline

* Rename parameters for lambda function

* Type hints for FeedExporter._get_uri_params

Co-authored-by: Adrián Chaves <adrian@chaves.io>
Co-authored-by: Eugenio Lacuesta <eugenio.lacuesta@gmail.com>
==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
4bdaa54a;Georgiy Zatserklianyi;2022-01-28 15:39:32 +0200;response_httprepr memory issue fixed (#4972)
* response_httprepr replaced by response.body

* unused import deleted

* get_header_size function added

* response size calculation updated

* flake8 codestyle fix

* added counting status code, line breaks to response size

* get_status size: list to tuple, comments added

* test added: comparing new response size counting method with old `len(response_httprepr)`

* downloader stats : unreachable code deleted

* `get_status_size` optimized

* comment added

* tests.test_downloadermiddleware_stats: statement formatting updated

* scrapy.utils.response: `response_httprepr` -> deprecated

* tests.test_downloadermiddleware_stats: flake8 fix
==

scrapy/downloadermiddlewares/stats.py
scrapy/utils/response.py
tests/test_downloadermiddleware_stats.py
==================
9dd77b42;Mikhail Korobov;2022-01-23 21:40:21 +0500;Merge pull request #1582 from starrify/add_doc_textresponse_urljoin
added: Doc for `scrapy.http.TextResponse.urljoin`
==
==================
92764d68;Andrey Rahmatullin;2022-01-21 13:59:03 +0500;Merge pull request #3155 from aprasanna/doc-fix
A few typo fixes and some grammatical enhancements
==
==================
5059b8c4;Andrey Rahmatullin;2022-01-21 13:58:43 +0500;Merge branch 'master' into doc-fix

==
==================
169bc886;Andrey Rahmatullin;2022-01-21 13:26:11 +0500;Merge pull request #4335 from leobalestri/patch-1
Update install.rst
==
==================
1608b1a7;Andrey Rahmatullin;2022-01-21 13:24:51 +0500;Merge branch 'master' into patch-1

==
==================
9b8285d9;Andrey Rahmatullin;2022-01-10 11:33:12 +0500;Merge pull request #5334 from wRAR/mw-manager-typing-fix
Fix typing of middleware methods.
==
==================
b04cfa48;Andrey Rahmatullin;2022-01-06 11:31:59 +0500;Merge pull request #5352 from wRAR/crawler-process-reactor-later

==
==================
3577c005;Andrey Rakhmatullin;2022-01-03 13:59:26 +0500;Merge remote-tracking branch 'origin/master' into crawler-process-reactor-later

==
==================
c5ab5805;Andrey Rahmatullin;2022-01-01 00:38:10 +0500;Set WindowsSelectorEventLoopPolicy on Windows (#5315)

==

.github/workflows/tests-windows.yml
docs/topics/asyncio.rst
scrapy/utils/reactor.py
tests/CrawlerProcess/asyncio_enabled_reactor.py
tests/test_commands.py
tests/test_crawler.py
tests/test_downloader_handlers.py
tests/test_utils_asyncio.py
==================
6eaceec7;Andrey Rakhmatullin;2021-12-31 20:14:24 +0500;Implement docs suggestions.

==

docs/news.rst
docs/topics/practices.rst
docs/topics/settings.rst
==================
60800ee5;Andrey Rakhmatullin;2021-12-31 20:12:30 +0500;Merge remote-tracking branch 'origin/master' into crawler-process-reactor-later

==
==================
a2763c60;Andrey Rakhmatullin;2021-12-31 18:35:00 +0500;Remove unused MiddlewareManager._process_chain_both().

==

scrapy/middleware.py
==================
a7846d23;Andrey Rakhmatullin;2021-12-31 18:34:29 +0500;Merge remote-tracking branch 'origin/master' into mw-manager-typing-fix

==
==================
57dc5812;Andrey Rahmatullin;2021-12-31 17:15:08 +0500;Remove the experimental note about asyncio (#5332)

==

docs/topics/asyncio.rst
==================
e4bdd1cb;Paweł Miech;2021-12-31 11:57:12 +0100;downloader.webclient: make reactor import local (#5357)

==

scrapy/core/downloader/webclient.py
==================
b8193868;Andrey Oskin;2021-12-31 21:49:18 +1100;Docs: correct process repetition start step (#5356)
The process repeats from step 3, the scheduler feeds request to the engine. Steps 1 and 2 are not parts of the loop as their incarnations steps 7 and 8 are parts of the loop.
==

docs/topics/architecture.rst
==================
0e78b686;Andrey Rakhmatullin;2021-12-31 15:46:25 +0500;Merge remote-tracking branch 'origin/master' into crawler-process-reactor-later

==
==================
64261d9e;Andrey Rakhmatullin;2021-12-31 15:45:59 +0500;Slight refactoring.

==

scrapy/crawler.py
==================
7380888c;Andrey Rahmatullin;2021-12-30 18:55:16 +0500;Fix a warning message. (#5359)

==

scrapy/utils/conf.py
==================
a986792d;Andrey Rakhmatullin;2021-12-24 19:43:14 +0500;Add more docs for TWISTED_REACTOR.

==

docs/topics/settings.rst
==================
940cc077;Andrey Rakhmatullin;2021-12-24 17:12:50 +0500;Add docs about TWISTED_REACTOR and other per-process settings.

==

docs/topics/practices.rst
==================
d4565318;Andrey Rakhmatullin;2021-12-23 17:40:31 +0500;Fix a reactor test on Windows.

==

tests/CrawlerProcess/twisted_reactor_custom_settings_conflict.py
tests/test_crawler.py
==================
df04e934;Andrey Rakhmatullin;2021-12-23 17:25:56 +0500;Merge remote-tracking branch 'origin/master' into crawler-process-reactor-later

==
==================
9c4bfb48;Andrey Rakhmatullin;2021-12-23 17:17:36 +0500;Remove an unused import.

==

tests/test_crawler.py
==================
00251343;Andrey Rakhmatullin;2021-12-23 16:45:17 +0500;Completely skip WindowsRunSpiderCommandTest outside Windows.

==

tests/test_commands.py
==================
ebcafdf4;Andrey Rakhmatullin;2021-12-23 16:35:26 +0500;Add tests for TWISTED_REACTOR in custom_settings.

==

tests/CrawlerProcess/twisted_reactor_custom_settings.py
tests/CrawlerProcess/twisted_reactor_custom_settings_conflict.py
tests/CrawlerProcess/twisted_reactor_custom_settings_same.py
tests/test_crawler.py
==================
041699b5;Andrey Rakhmatullin;2021-12-23 16:14:47 +0500;Remove tests that want to modify the test process reactor.

==

tests/test_crawler.py
==================
60c88385;Andrey Rakhmatullin;2021-12-23 16:07:18 +0500;Move installing the reactor from CrawlerProcess to Crawler.

==

scrapy/crawler.py
scrapy/utils/log.py
tests/test_crawler.py
==================
46ef9cf7;Andrey Rakhmatullin;2021-12-22 21:24:59 +0500;Don't install non-working shutdown handlers in `scrapy shell`.

==

scrapy/commands/shell.py
scrapy/crawler.py
==================
d6a384b3;yogender26;2021-12-23 04:09:05 +0530;corrrection of coma (#5347)

==

scrapy/commands/__init__.py
==================
9ec60e8e;Andrey Rahmatullin;2021-12-21 17:49:31 +0500;Merge pull request #5320 from zessx/5319-oib-base-tag

==
==================
0862b179;Andrey Rahmatullin;2021-12-16 18:54:27 +0500;Merge pull request #5333 from wRAR/pylint-2.12
Fix and pin pylint.
==
==================
6483dfdb;Andrey Rakhmatullin;2021-12-01 19:53:39 +0500;Move install_shutdown_handlers() from __init__() to start().

==

scrapy/crawler.py
==================
eb62906c;Andrey Rakhmatullin;2021-12-01 17:40:41 +0500;Extract utils.log.log_reactor_info().

==

scrapy/utils/log.py
==================
4cc03962;Andrey Rakhmatullin;2021-11-26 19:52:03 +0500;Fix typing of middleware methods.

==

scrapy/core/downloader/middleware.py
scrapy/core/spidermw.py
scrapy/middleware.py
==================
6ec66c96;Andrey Rakhmatullin;2021-11-26 12:25:45 +0500;Fix and pin pylint.

==

pylintrc
tox.ini
==================
c316ca45;Alex;2021-11-16 01:20:56 -0800;Use augmented assignment statements (#5322)

==

scrapy/core/downloader/handlers/http11.py
scrapy/core/http2/stream.py
tests/test_request_left.py
==================
75ed7654;Samuel Marchal;2021-11-15 14:31:24 +0100;Test coverage for open_in_browser base tag injection (#5319)

==

tests/test_utils_response.py
==================
f2c800c5;Samuel Marchal;2021-11-15 11:14:54 +0100;Improve open_in_browser base tag injection (#5319)

==

scrapy/utils/response.py
==================
28eba610;Andrey Rahmatullin;2021-11-15 12:24:54 +0500;Re-enable Windows tests for Python 3.9 and 3.10. (#5316)

==

.github/workflows/tests-windows.yml
==================
9828cb3f;Andrey Rahmatullin;2021-11-08 20:13:00 +0500;Merge pull request #5310 from azzamsa/more-test
test: `test_format_engine_status`
==
==================
55cce25a;azzamsa;2021-10-25 21:14:11 +0700;test: `test_format_engine_status`

==

tests/test_crawl.py
==================
ed50a81f;Andrey Rahmatullin;2021-11-04 19:00:14 +0500;Merge pull request #5299 from azzamsa/fix-tests
fix: `CodeBlockParser` has been renamed to `PythonCodeBlockParser`
==
==================
67994d1d;azzamsa;2021-10-27 21:55:05 +0700;fix: `CodeBlockParser` has been renamed to `PythonCodeBlockParser`

==

docs/conftest.py
==================
3225de72;Andrey Rahmatullin;2021-10-25 11:34:59 +0500;Merge pull request #5292 from azzamsa/tox-patch
refactor: use `pytest` command as the recommended entry point
==
==================
51adf71b;azzamsa;2021-10-24 10:52:56 +0700;refactor: use `pytest` command as the recommended entry point
`pytest` is recommended command since pytest 3.0.
There is a possibility for `py.test` to be deprecated or even removed.

https://github.com/pytest-dev/pytest/issues/1629

==

tox.ini
==================
144d1eb8;Andrey Rahmatullin;2021-10-22 21:46:01 +0500;Add Deferred-to-Future helpers (#5288)

==

conftest.py
docs/topics/asyncio.rst
docs/topics/coroutines.rst
docs/topics/item-pipeline.rst
pytest.ini
scrapy/utils/defer.py
tests/test_pipelines.py
==================
cfff79ce;Eugenio Lacuesta;2021-10-18 17:09:17 -0300;Make Python 3.10 support official (#5265)

==

.github/workflows/checks.yml
.github/workflows/publish.yml
.github/workflows/tests-macos.yml
.github/workflows/tests-ubuntu.yml
.readthedocs.yml
setup.py
tox.ini
==================
afa5881a;Andrey Rahmatullin;2021-10-18 11:51:42 +0500;Merge pull request #5279 from erikkemperman/option-logfile-truncate
Add LOG_FILE_APPEND to settings
==
==================
975f1500;Andrey Rahmatullin;2021-10-18 11:49:55 +0500;Merge pull request #5281 from raphaelts3/add-pronounced-docs
Add how Scrapy is pronounced to the docs
==
==================
027ecd86;raphaelts3;2021-10-16 10:52:54 -0300;Update docs/intro/overview.rst
Co-authored-by: azzamsa <17734314+azzamsa@users.noreply.github.com>
==

docs/intro/overview.rst
==================
aec7146e;Raphael Tomé Santana;2021-10-15 20:38:53 -0300;Add how Scrapy is pronounced to the docs

==

docs/intro/overview.rst
==================
d774d6a9;Adrián Chaves;2021-10-15 17:25:22 +0200;Remove unused variable

==

tests/test_crawler.py
==================
98ee3ddf;Adrián Chaves;2021-10-15 17:18:46 +0200;Freeze flake8

==

tox.ini
==================
ca320feb;Erik Kemperman;2021-10-15 15:43:55 +0200;Add LOG_FILE_APPEND to settings

==

docs/topics/logging.rst
docs/topics/settings.rst
scrapy/settings/default_settings.py
scrapy/utils/log.py
tests/test_crawler.py
==================
5b13bfd1;Andrey Rahmatullin;2021-10-14 16:19:54 +0500;Merge pull request #5269 from Ankur19/allow-non-text-response-types-in-ItemLoader
Fix bug #5145 - Removing Selector for Response's that are not Http or Xml
==
==================
808fb632;Andrey Rahmatullin;2021-10-14 12:51:30 +0500;Merge pull request #5276 from imba-tjd/patch-1
docs: fix typo
==
==================
3243aa2c;谭九鼎;2021-10-14 10:18:26 +0800;docs: fix typo

==

docs/topics/loaders.rst
==================
d08199f6;Jake Herbst;2021-10-12 13:20:09 -0400;Removing unnecessary line from docs to prevent test failure (#5274)

==

docs/intro/tutorial.rst
==================
1ae53a9d;Andrey Rahmatullin;2021-10-12 16:49:31 +0500;Merge pull request #5256 from rydwhelchel/documentation-changes
docs: restructed phrasing for clarity
==
==================
d90b2a2b;Andrey Rahmatullin;2021-10-12 16:48:42 +0500;Merge pull request #5250 from iDeepverma/URLLENGTH_LIMIT-doc
Documentation update for URLLENGTH_LIMIT
==
==================
8a743ae4;Andrey Rahmatullin;2021-10-12 16:46:51 +0500;Merge pull request #5266 from MarvinPetzoldt/patch-1
Fixed documentation example
==
==================
ce96a961;Andrey Rahmatullin;2021-10-12 16:46:05 +0500;Merge pull request #5271 from kianmeng/fix-typos
Fix typos
==
==================
eb0e99dc;Andrey Rahmatullin;2021-10-12 16:41:16 +0500;Merge pull request #5254 from PeterMorrison1/FilePipeline-expire-doc
Document file expiration method in media-pipeline (#5120)
==
==================
3a263280;Kian-Meng, Ang;2021-10-11 22:32:42 +0800;Fix typos

==

docs/news.rst
docs/topics/settings.rst
docs/topics/shell.rst
docs/topics/spiders.rst
docs/versioning.rst
extras/qpsclient.py
scrapy/downloadermiddlewares/retry.py
scrapy/exporters.py
scrapy/linkextractors/lxmlhtml.py
scrapy/pipelines/files.py
scrapy/spiders/feed.py
scrapy/utils/console.py
scrapy/utils/datatypes.py
scrapy/utils/defer.py
scrapy/utils/request.py
sep/sep-001.rst
sep/sep-005.rst
sep/sep-014.rst
sep/sep-021.rst
tests/test_http_response.py
tests/test_request_attribute_binding.py
tests/test_utils_defer.py
tests/test_utils_template.py
==================
6fbd6f94;ankur19;2021-10-09 19:09:51 -0400;Fix issue#5145
Fix condition for failing tests

set Selector to None on AttributeError

Add test and remove unused imports

Fix imports

==

scrapy/loader/__init__.py
tests/test_loader.py
==================
65d60b96;Eugenio Lacuesta;2021-10-10 05:06:36 -0300;[docs] add missing parameter to headers_received signal (#5270)

==

docs/topics/signals.rst
==================
d3f1bf79;Georgiy Zatserklianyi;2021-10-07 17:27:20 +0300;Use f-strings where appropriate (#5246)

==

scrapy/__init__.py
scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/tls.py
scrapy/downloadermiddlewares/httpcache.py
scrapy/extensions/feedexport.py
scrapy/extensions/httpcache.py
scrapy/utils/misc.py
tests/spiders.py
tests/test_closespider.py
tests/test_commands.py
tests/test_downloader_handlers_http2.py
tests/test_http_request.py
==================
029cab72;Eugenio Lacuesta;2021-10-06 14:34:09 -0300;[CI] fix pypy test (#5264)

==

tests/test_request_cb_kwargs.py
==================
b1cb007b;MarvinPetzoldt;2021-10-06 19:08:19 +0200;Fixed documentation example

==

docs/topics/exporters.rst
==================
6c858cec;Laerte;2021-10-06 12:32:04 -0300;Cookies: Cast primitive types to str (#5253)
* cast primitive types to str

* add tests
==

scrapy/downloadermiddlewares/cookies.py
tests/test_downloadermiddleware_cookies.py
==================
214525c2;Adrián Chaves;2021-10-06 13:14:35 +0200;Merge pull request #5263 from Gallaecio/port-security-fix
Port security fix from 1.8.1 and 2.5.1 to the main branch
==
==================
735750c2;Adrián Chaves;2021-10-05 21:10:49 +0200;Cover 1.8.1 in the release notes

==

docs/news.rst
==================
f0105a88;Adrián Chaves;2021-10-05 13:29:06 +0200;Cover 2.5.1 in the release notes

==

docs/news.rst
==================
7ec5f299;Andrey Rakhmatullin;2019-08-22 20:32:56 +0500;Small documentation fixes.

==

docs/topics/downloader-middleware.rst
==================
b081f18a;Andrey Rakhmatullin;2019-08-16 14:53:42 +0500;Add http_auth_domain to HttpAuthMiddleware.

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/httpauth.py
tests/test_downloadermiddleware_httpauth.py
==================
764cf017;Ryan Whelchel;2021-10-05 10:22:57 -0400;Update docs/intro/tutorial.rst
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/intro/tutorial.rst
==================
b9647b85;Ryan Whelchel;2021-10-03 17:32:38 -0400;docs: restructed phrasing for clarity

==

docs/intro/tutorial.rst
==================
cbf93495;Andrey Rahmatullin;2021-10-03 19:59:47 +0500;Merge pull request #5255 from raihan71/raihan71-patch-1
Using Logo Scrapy in Readme.md
==
==================
ef263042;Raihan Nismara;2021-10-03 13:26:20 +0700;Using Logo Scrapy in Readme.md
Logo scrapy used in readme.md made looks nicer
==

README.rst
==================
f1088002;Adrián Chaves;2021-10-02 13:25:15 +0200;Update spider-middleware.rst

==

docs/topics/spider-middleware.rst
==================
de70b3c5;Deepanshu verma;2021-10-02 12:12:58 +0530;Update spider-middleware.rst
added empty line
==

docs/topics/spider-middleware.rst
==================
47533985;Peter Morrison;2021-10-01 12:30:14 -0600;Document file expiration method in media-pipeline

==

docs/topics/media-pipeline.rst
==================
de2043f9;Deepanshu;2021-10-01 20:20:00 +0530;updated docs/topics/spider-middleware.rst

==

docs/topics/spider-middleware.rst
==================
d91d82b5;Adrián Chaves;2021-10-01 16:31:29 +0200;Make Scrapy SFW again

==

docs/topics/request-response.rst
==================
fbb1236f;Deepanshu verma;2021-10-01 18:46:11 +0530;Update docs/topics/settings.rst
added suggestion

Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/settings.rst
==================
552457e6;Deepanshu verma;2021-10-01 16:40:48 +0530;Merge branch 'scrapy:master' into URLLENGTH_LIMIT-doc

==
==================
890f884d;Eugenio Lacuesta;2021-10-01 04:50:42 -0300;Allow 'callback' key in keyword arguments for request callbacks (#5251)

==

scrapy/core/scraper.py
tests/test_request_cb_kwargs.py
==================
74f146bb;Deepanshu;2021-10-01 01:47:05 +0530;Document update URLLENGTH_LIMIT

==

docs/topics/settings.rst
docs/topics/spider-middleware.rst
==================
7d557f89;Andrey Rahmatullin;2021-09-27 15:42:31 +0500;Merge pull request #5239 from maanijou/master
Improve documentation for spider middlewares
==
==================
62491753;Andrey Rahmatullin;2021-09-27 15:41:58 +0500;Merge pull request #5244 from kamran890/spider-state-doc
Document spider.state attribute (#5174)
==
==================
3c57825b;Adrián Chaves;2021-09-26 13:41:26 +0200;Update docs/topics/spider-middleware.rst

==

docs/topics/spider-middleware.rst
==================
dfdb7797;Reza (Milad) Maanijou;2021-09-26 12:45:44 +0330;Apply review comments

==

docs/topics/spider-middleware.rst
==================
1829dd77;Reza (Milad) Maanijou;2021-09-25 20:22:09 +0330;Update spider-middleware.rst

==

docs/topics/spider-middleware.rst
==================
e5998fb8;kamran890;2021-09-22 03:00:18 +0500;Document spider.state attribute (#5174)

==

docs/topics/jobs.rst
docs/topics/spiders.rst
==================
ac917596;maanijou;2021-09-12 17:59:20 +0200;Improve documentation for spider middlewares

==

docs/topics/spider-middleware.rst
==================
8284de5e;Andrey Rahmatullin;2021-08-24 15:15:29 +0500;Fix/silence the Pylint messages added in 2.10 (#5235)

==

pylintrc
scrapy/utils/conf.py
scrapy/utils/deprecate.py
tests/keys/__init__.py
tests/test_downloader_handlers_http2.py
tests/test_engine.py
tests/test_exporters.py
tests/test_http2_client_protocol.py
tests/test_loader_deprecated.py
tests/test_request_cb_kwargs.py
tests/test_scheduler.py
tests/test_utils_conf.py
tests/test_utils_misc/__init__.py
==================
43ea21e8;D R Siddhartha;2021-08-24 15:18:01 +0530;Feed post-processing plugin support (#5190)

==

.github/workflows/tests-ubuntu.yml
docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
scrapy/extensions/postprocessing.py
tests/test_feedexport.py
==================
3f635eb6;Matsievskiy S.V;2021-08-24 12:05:50 +0300;Extract domain from genspider URL (#4439)

==

scrapy/commands/genspider.py
tests/test_commands.py
==================
ada539a6;Andrey Rahmatullin;2021-08-24 12:18:49 +0500;Merge pull request #4676 from Gallaecio/startproject-existing-folder
Fix startproject failing for existing folders
==
==================
cd17c829;Andrey Rakhmatullin;2021-08-23 19:55:35 +0500;Revert "Move documentation about avoiding bans into a topic of its own (#4039)"
This reverts commit 2d2581c68f35799dc4372a257eaa8dbb5208481d.

==

docs/index.rst
docs/topics/avoiding-bans.rst
docs/topics/practices.rst
==================
731f2d30;Andrey Rahmatullin;2021-08-20 16:16:25 +0500;Merge pull request #4178 from elacuesta/remove_spider_make_requests_from_url

==
==================
bdf8355c;Andrey Rahmatullin;2021-08-18 21:08:32 +0500;Merge pull request #5231 from umairnsr87/umairnsr87/issues/5226
updated documentation for python version for reppy
==
==================
572d347b;databender;2021-08-18 16:17:52 +0530;warning view updated

==

docs/topics/downloader-middleware.rst
==================
2d2581c6;Adrián Chaves;2021-08-18 12:46:42 +0200;Move documentation about avoiding bans into a topic of its own (#4039)

==

docs/index.rst
docs/topics/avoiding-bans.rst
docs/topics/practices.rst
==================
d623ed15;databender;2021-08-18 14:51:03 +0530;indentation updated

==

docs/topics/downloader-middleware.rst
==================
bcf38a67;databender;2021-08-18 14:48:47 +0530;added upstream issue for not supported python version

==

docs/topics/downloader-middleware.rst
==================
a7bd6fa2;Andrey Rahmatullin;2021-08-17 19:42:53 +0500;Merge pull request #3669 from Gallaecio/spider-name-collision

==
==================
79bad0cf;databender;2021-08-16 18:10:23 +0530;updated suggested changes after review

==
==================
ebddb77a;databender;2021-08-16 18:08:26 +0530;updated suggested changes after review

==

docs/topics/downloader-middleware.rst
==================
013ac90f;umair ansari;2021-08-16 18:00:06 +0530;Update docs/topics/downloader-middleware.rst
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/downloader-middleware.rst
==================
cc1cb2de;databender;2021-08-16 17:21:47 +0530;updated suggested changes

==

docs/topics/downloader-middleware.rst
==================
1a8b9884;databender;2021-08-16 17:00:05 +0530;updated documentation for python version for reppy

==

docs/topics/downloader-middleware.rst
==================
8bbaea98;databender;2021-08-16 16:57:43 +0530;updated documentation for python version for reppy

==

docs/topics/downloader-middleware.rst
==================
2814e0e1;Andrey Rahmatullin;2021-08-16 16:22:01 +0500;Disable builtin middlewares in spider middleware tests. (#5229)

==

tests/test_spidermiddleware.py
==================
47a281d2;Andrey Rahmatullin;2021-08-16 12:52:02 +0500;Merge pull request #5224 from aaron-tan/jobdir-doc

==
==================
0915be73;Andrey Rahmatullin;2021-08-11 21:04:10 +0500;Merge pull request #5228 from wRAR/test-reqs
Rename tests/requirements-py3.txt to tests/requirements.txt.
==
==================
b63369c1;Andrey Rakhmatullin;2021-08-11 20:02:45 +0500;Rename tests/requirements-py3.txt to tests/requirements.txt.

==

tests/requirements.txt
tox.ini
==================
0590c375;Andrey Rahmatullin;2021-08-11 14:19:51 +0500;Merge pull request #5221 from wRAR/3.10-tests
Fixing tests for upcoming 3.10.
==
==================
74cee38a;Andrey Rakhmatullin;2021-08-11 14:19:08 +0500;Don't run the asyncio tests on 3.9.

==

.github/workflows/tests-ubuntu.yml
==================
902fce06;Andrey Rahmatullin;2021-08-11 10:58:28 +0500;Merge pull request #5225 from divtiply/patch-3
Allow comma-separated values in the rel attribute
==
==================
983b89ad;Andrey Rakhmatullin;2021-08-11 10:39:23 +0500;Fix SpiderLoaderTest on Python 3.10.

==

tests/test_spiderloader/__init__.py
==================
ce9d6c65;Michel Ace;2021-08-10 22:21:51 +0200;Add more rel_has_nofollow tests

==

tests/test_utils_misc/__init__.py
==================
295f0e2b;Michel Ace;2021-08-10 21:38:29 +0200;Make flake8 happy

==

tests/test_utils_misc/__init__.py
==================
07d20a8c;Michel Ace;2021-08-10 21:21:43 +0200;Fix test_rel_has_nofollow test

==

tests/test_utils_misc/__init__.py
==================
18b6f30a;Michel Ace;2021-08-10 21:13:50 +0200;Add test for rel_has_nofollow

==

tests/test_utils_misc/__init__.py
==================
1ba0f684;Michel Ace;2021-08-10 17:09:37 +0200;Allow comma-separated values in the rel tag
Comma-separated `rel` values are often seen in the wild, because Google allows it (see https://developers.google.com/search/docs/advanced/guidelines/qualify-outbound-links).
==

scrapy/utils/misc.py
==================
954f3035;Aaron Tan;2021-08-09 22:23:23 +1000;Update docs/topics/settings.rst
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/settings.rst
==================
48eff4ee;Aaron Tan;2021-08-08 20:52:14 +1000;Remove JOBDIR from default settings

==

scrapy/settings/default_settings.py
==================
8e7d2ef1;Aaron Tan;2021-08-07 11:44:12 +1000;Document JOBDIR option issue #5173
Add JOBDIR setting to the settings page.
Add default JOBDIR setting to global defaults in scrapy.settings.default_settings module.

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
94baa4b2;Mannan2812;2021-08-06 00:53:11 +0530;Fix FileFeedStoragePreFeedOptionsTest fails in CI/CD pipeline (#5198)

==

tests/test_feedexport.py
==================
93bf1ae7;Andrey Rakhmatullin;2021-08-03 20:16:29 +0500;Fix tests for the 3.10 TypeError message change.

==

tests/test_http_response.py
tests/test_request_cb_kwargs.py
==================
ef6fb933;Andrey Rakhmatullin;2021-07-20 12:02:15 +0500;Fix a Python 3.10 logging issue.

==

scrapy/utils/signal.py
==================
2bf2f9d6;Andrey Rakhmatullin;2021-08-03 19:44:11 +0500;Add Python 3.10b4 tests on Ubuntu.

==

.github/workflows/tests-ubuntu.yml
==================
4d1ecc31;Andrey Rahmatullin;2021-08-02 17:36:35 +0500;Merge pull request #5217 from aaron-tan/docs-extension

==
==================
880a4d94;Aaron Tan;2021-08-01 11:02:27 +1000;Update docs/topics/extensions.rst
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/extensions.rst
==================
b406affd;Andrey Rahmatullin;2021-07-30 15:15:55 +0500;Merge pull request #5210 from laggardkernel/feature/aws-session-token

==
==================
cc89f6be;Eugenio Lacuesta;2021-07-29 17:12:44 -0300;Response.attributes (#5218)

==

docs/topics/request-response.rst
scrapy/http/response/__init__.py
scrapy/http/response/text.py
tests/test_http_response.py
==================
22bd0123;Andrey Rahmatullin;2021-07-29 15:25:08 +0500;Merge pull request #4613 from elacuesta/docs-headless-browser
Update headless browser docs
==
==================
4b62ac6c;Eugenio Lacuesta;2021-07-28 15:00:24 -0300;Update headless browser docs to mention playwright

==

docs/topics/dynamic-content.rst
==================
9aef9b78;Eugenio Lacuesta;2021-07-28 14:31:49 -0300;Merge remote-tracking branch 'upstream/master' into docs-headless-browser

==
==================
0e3d50dd;Eugenio Lacuesta;2021-07-28 14:30:16 -0300;Update docs/topics/dynamic-content.rst
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/dynamic-content.rst
==================
494e0ad8;Eugenio Lacuesta;2021-07-28 14:29:50 -0300;Update docs/topics/dynamic-content.rst
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/dynamic-content.rst
==================
d55b6fca;Aaron Tan;2021-07-28 12:10:34 +1000;Fix for duplicate object description error

==

docs/topics/extensions.rst
==================
714aa397;Aaron Tan;2021-07-30 20:36:58 +1000;Merge branch 'scrapy:master' into docs-extension

==
==================
8e7b96d8;laggardkernel;2021-07-27 19:29:25 +0800;Tweak doc for setting AWS_SESSION_TOKEN
Co-authored-by: Adrián Chaves <adrian@chaves.io>

==

docs/topics/feed-exports.rst
docs/topics/settings.rst
==================
7e4321f2;laggardkernel;2021-07-19 12:00:42 +0800;Add support for temporary security credential in AWS auth

==

docs/topics/feed-exports.rst
docs/topics/settings.rst
scrapy/core/downloader/handlers/s3.py
scrapy/extensions/feedexport.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
tests/test_feedexport.py
tox.ini
==================
abe0b37d;laggardkernel;2021-07-27 17:11:32 +0800;Cleanup leftover boto2 code in S3DownloaderHandler (#5209)
S3DownloaderHandler.conn is a leftover attribute from 5e99758.
==

scrapy/core/downloader/handlers/s3.py
==================
b22a0043;Rob Banagale;2021-07-26 11:51:32 -0700;Document media pipeline file naming (#5152)

==

docs/topics/media-pipeline.rst
==================
209c1fce;Aaron Tan;2021-07-24 14:50:48 +1000;Reference MailSender in StatsMailer
Added a reference to MailSender in the StatsMailer extension description and included a link to the document detailing how to instantiate MailSender and using Scrapy settings objects.
==

docs/topics/extensions.rst
==================
ff272d63;Mikhail Korobov;2021-07-22 17:52:48 +0500;Merge pull request #5215 from pcorpet/types
Typing: switch to a newer version of MyPy to check types
==
==================
70dddfe2;Pascal Corpet;2021-07-21 17:10:10 +0200;Typing: switch to a newer version of MyPy to check types

==

tests/CrawlerProcess/asyncio_deferred_signal.py
tox.ini
==================
ee2df97b;Andrey Rahmatullin;2021-07-16 17:28:32 +0500;Pin the libxml2 version in CI as a newer one breaks lxml (#5208)

==

.github/workflows/tests-ubuntu.yml
==================
89b654b8;Andrey Rahmatullin;2021-07-16 15:18:14 +0500;Make the pylint test pass (#5207)
Co-authored-by: Vostretsov Nikita <whalebot.helmsman@gmail.com>
==

.github/workflows/checks.yml
.github/workflows/tests-ubuntu.yml
pylintrc
==================
bcce0660;Eugenio Lacuesta;2021-07-14 12:56:07 -0300;Update ItemFilter (#5203)

==

scrapy/extensions/feedexport.py
==================
d7deba7e;Marlena Chatzigrigoriou;2021-07-14 11:34:28 +0300;Document all import paths and use the shortest in examples (#5099)

==

docs/faq.rst
docs/intro/tutorial.rst
docs/topics/api.rst
docs/topics/contracts.rst
docs/topics/coroutines.rst
docs/topics/debug.rst
docs/topics/developer-tools.rst
docs/topics/downloader-middleware.rst
docs/topics/dynamic-content.rst
docs/topics/exporters.rst
docs/topics/feed-exports.rst
docs/topics/item-pipeline.rst
docs/topics/items.rst
docs/topics/jobs.rst
docs/topics/leaks.rst
docs/topics/logging.rst
docs/topics/media-pipeline.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/shell.rst
docs/topics/signals.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
==================
fcc6becc;Türkalp Burak KAYRANCIOĞLU;2021-07-14 11:00:43 +0300;S3FeedStorage: allow custom endpoint (#4998)
Co-authored-by: Andrey Rahmatullin <wrar@wrar.name>
==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
4ddc9d6b;D R Siddhartha;2021-07-13 20:52:29 +0530;Feeds: Item Filters (#5178)

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
c062ed01;Eugenio Lacuesta;2021-07-12 13:34:22 -0300;[CI] fail-fast: false (#5200)

==

.github/workflows/checks.yml
.github/workflows/tests-macos.yml
.github/workflows/tests-ubuntu.yml
.github/workflows/tests-windows.yml
==================
1c46d5aa;Andrey Rahmatullin;2021-07-12 18:46:40 +0500;Merge pull request #5191 from ivanprado/master
CloseSpider can be raised on spider_idle signal handler to set the closing reason
==
==================
cb08e364;Eugenio Lacuesta;2021-07-08 09:22:21 -0300;Remove trailing whitespaces

==

scrapy/core/engine.py
==================
eca641aa;Iván de Prado;2021-07-08 12:40:20 +0100;Update tests/test_engine.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

tests/test_engine.py
==================
6b8f6946;Iván de Prado;2021-07-08 12:40:02 +0100;Update scrapy/core/engine.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/core/engine.py
==================
7597d860;Iván de Prado;2021-07-08 12:39:17 +0100;Update scrapy/core/engine.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/core/engine.py
==================
15dfc8a7;Andrey Rahmatullin;2021-06-29 17:54:22 +0500;Merge pull request #5194 from scrapy/doc-spiders-warning-indentation-1
spiders.rst: indent warnings into class descriptions
==
==================
e94d3ac1;Iván de Prado Alonso;2021-06-29 13:40:43 +0100;Expanded doc for idle signal

==

docs/topics/signals.rst
scrapy/core/engine.py
==================
f3597077;Iván de Prado Alonso;2021-06-29 13:21:38 +0100;Test case for raising CloseSpider on spider idle signal handler

==

tests/test_engine.py
==================
73ff9ffd;Adrián Chaves;2021-06-26 08:58:29 +0200;spiders.rst: indent warnings into class descriptions

==

docs/topics/spiders.rst
==================
ce445f20;Iván de Prado Alonso;2021-06-24 09:56:05 +0100;Fix typing

==

scrapy/core/engine.py
==================
812b4bb5;Iván de Prado Alonso;2021-06-23 17:09:28 +0100;CloseSpider can be raised on spider_idle signal handler

==

docs/topics/signals.rst
scrapy/core/engine.py
scrapy/utils/signal.py
==================
016c7e92;Andrey Rahmatullin;2021-06-15 13:36:53 +0500;Merge pull request #3579 from maramsumanth/duplicate_key
[MRG+1] Issue #2919: Fix FormRequest.formdata with GET method duplicates same key in query string
==
==================
af975a5b;Andrey Rahmatullin;2021-06-15 13:36:17 +0500;Merge pull request #4649 from ajaymittur28/http-proxy-schema
Support schema-less HTTP proxy (#4504)
==
==================
eb324fad;ajaymittur28;2021-06-14 21:39:43 +0530;Merge branch 'http-proxy-schema' of https://github.com/ajaymittur28/scrapy into http-proxy-schema

==
==================
7d653288;ajaymittur28;2021-06-14 21:39:18 +0530;Update unittest

==

tests/test_downloader_handlers.py
==================
857e0e22;ajaymittur28;2021-06-14 21:18:49 +0530;Merge branch 'master' into http-proxy-schema

==
==================
5044549c;Ajay Mittur;2021-06-14 14:58:19 +0000;Update proxyScheme assignment

==

scrapy/core/downloader/handlers/http11.py
==================
66e20042;Andrey Rahmatullin;2021-06-14 18:58:35 +0500;Fix a flake8 problem

==

tests/test_http_request.py
==================
16be658a;Andrey Rahmatullin;2021-06-14 18:45:33 +0500;Merge branch 'master' into duplicate_key

==
==================
9f81de2a;Andrey Rahmatullin;2021-06-11 17:11:19 +0500;Merge pull request #5171 from elacuesta/request-types
Type hints for Request and subclasses
==
==================
28858574;pdt1931;2021-06-11 00:49:41 -0700;Add FAQ to code of Conduct (#5177)
* added to CODE_OF_CONDUCT.md to include link to FAQ about the code of conduct

* added to CODE_OF_CONDUCT.md to include link to FAQ about the code of conduct
==

CODE_OF_CONDUCT.md
==================
e876d8e3;Veniamin Gvozdikov;2021-06-11 09:22:04 +0300;Rename scrapy-crawlera to scrapy-zyte-smartproxy (#5074)

==

scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/http2.py
==================
ce644773;Eugenio Lacuesta;2021-06-07 13:25:04 -0300;Replace return type

==

scrapy/http/request/__init__.py
scrapy/http/request/json_request.py
==================
479260dc;Eugenio Lacuesta;2021-06-01 12:52:46 -0300;Type hints for Request subclasses

==

scrapy/http/request/json_request.py
scrapy/http/request/rpc.py
==================
c9fecca0;Eugenio Lacuesta;2021-06-01 12:25:26 -0300;More type hints

==

scrapy/http/request/form.py
==================
85f88a57;Eugenio Lacuesta;2021-06-01 12:02:16 -0300;More type hints for private functions used by FormRequest

==

scrapy/http/request/form.py
==================
c594017e;Eugenio Lacuesta;2021-06-01 11:27:21 -0300;Type hints for private functions used by FormRequest

==

scrapy/http/request/form.py
==================
216dd379;Eugenio Lacuesta;2021-06-01 11:16:40 -0300;Type hints for FormRequest

==

scrapy/http/request/form.py
==================
c92e8ad0;Eugenio Lacuesta;2021-06-01 11:01:23 -0300;Merge branch 'master' into request-types

==
==================
23cfdb05;Vostretsov Nikita;2021-05-28 09:45:06 +0000;Reducing amount of warnings during test run (#5162)
* put flake8 options into separate file to remove pytest warnings

* remove ResourceLeaked warning in pypy

* suppress warnings from twisted

* ignore deprecation warnings here

* ignore deprecation warning in tests of deprecated methods

* ignore deprecation warnings here

* update test classes

* don`t use deprecated method call

* ignore deprecation warnings here

* proper warning class

* more selective ignoring

* Revert "don`t use deprecated method call"

This reverts commit 59216ab5603c4b47574382768614ef4c39d36747.
==

.flake8
.gitignore
conftest.py
pytest.ini
tests/test_exporters.py
tests/test_feedexport.py
tests/test_http_response.py
tests/test_item.py
tests/test_utils_deprecate.py
tests/test_utils_python.py
==================
ee682af3;Bhavesh;2021-05-12 01:53:02 +0530;[Fix] Change the truncation limit of Proxy TunnelError from 32 to 1000 (#5007)
* [Fix] Change the truncation limit oof Proxy TunnelError from 32 to 64

* [Fix] Change the truncation limit for Proxy tunnel error

* [Fix] flake8 check

* [Fix] formatting issues

* [Remove] coverage report

* [Fix] truncation error issue

* [Fix] formatting issues

* [Remove] coverage report
==

scrapy/core/downloader/handlers/http11.py
==================
c5b1ee81;Adrián Chaves;2021-05-11 09:04:53 +0200;Make Twisted[http2] installation optional (#5113)
Co-authored-by: Eugenio Lacuesta <eugenio.lacuesta@gmail.com>
==

conftest.py
docs/topics/settings.rst
setup.py
tests/test_downloader_handlers_http2.py
tests/test_http2_client_protocol.py
tox.ini
==================
bd60c3f4;Shinichi Takayanagi;2021-05-11 04:58:04 +0900;More documentation for setting spider atributes
* docs: require sphinx-rtd-theme>=0.5.2 and the latest pip to prevent installing breaking docutils>=0.17

* Update feed-exports.rst

* Update feed-exports.rst

* Reflects the comments

* Remove redundant newline

* Update docs/topics/feed-exports.rst

Co-authored-by: Adrián Chaves <adrian@chaves.io>

* Apply suggestions from code review

Co-authored-by: Adrián Chaves <adrian@chaves.io>

Co-authored-by: Adrián Chaves <adrian@chaves.io>
Co-authored-by: Eugenio Lacuesta <eugenio.lacuesta@gmail.com>
==

docs/topics/feed-exports.rst
docs/topics/spiders.rst
==================
cec36a92;Eugenio Lacuesta;2021-05-10 13:00:08 -0300;Refactor request to/from dict (#5130)

==

docs/topics/request-response.rst
scrapy/http/request/__init__.py
scrapy/http/request/json_request.py
scrapy/squeues.py
scrapy/utils/reqser.py
scrapy/utils/request.py
tests/test_request_dict.py
==================
34b21628;Renne Rocha;2021-05-06 11:34:05 -0300;Update link for reasoning value of URLLENGTH_LIMIT (#5134)

==

docs/topics/settings.rst
==================
19c7415a;Eugenio Lacuesta;2021-05-01 16:34:39 -0300;Request type hints

==

scrapy/downloadermiddlewares/retry.py
scrapy/http/request/__init__.py
scrapy/utils/curl.py
==================
e27eff47;Andrey Rahmatullin;2021-04-28 17:28:04 +0500;Merge pull request #5122 from hrnciar/patch-1
Require setuptools, scrapy/cmdline.py, /setup.py and tests/test_webclient.py import pkg_resources
==
==================
4f500342;Tomáš Hrnčiar;2021-04-28 11:57:44 +0200;Require setuptools, scrapy/cmdline.py, /setup.py and tests/test_webclient.py import pkg_resources

==

setup.py
==================
02ae1dea;Eugenio Lacuesta;2021-04-27 09:41:44 -0300;Deprecate unused squeues (#5117)

==

scrapy/squeues.py
tests/test_squeues.py
==================
ddea6b7b;Eugenio Lacuesta;2021-04-26 16:16:14 -0300;Scheduler: minimal interface, API docs (#3559)

==

docs/index.rst
docs/topics/architecture.rst
docs/topics/scheduler.rst
docs/topics/settings.rst
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/utils/job.py
tests/test_scheduler_base.py
==================
68379197;Eugenio Lacuesta;2021-04-26 14:55:02 -0300;Add peek method to queues (#5112)

==

pylintrc
scrapy/pqueues.py
scrapy/squeues.py
tests/test_pqueues.py
tests/test_squeues_request.py
==================
7095df15;Andrey Rahmatullin;2021-04-21 14:30:50 +0500;Merge pull request #5082 from storymode7/shell-fix
Find bash from PATH instead of /bin/bash
==
==================
e779ed7d;Eugenio Lacuesta;2021-04-20 16:39:07 -0300;Dupefilter type hints (#5108)

==

scrapy/dupefilters.py
scrapy/utils/request.py
==================
e3f81d8d;Eugenio Lacuesta;2021-04-20 11:46:43 -0300;Engine: remove unnecessary parameter (#5106)

==

scrapy/core/engine.py
==================
7e23677b;Eugenio Lacuesta;2021-04-20 08:45:28 -0300;Engine: deprecations and type hints (#5090)

==

docs/topics/telnetconsole.rst
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/downloadermiddlewares/robotstxt.py
scrapy/extensions/memusage.py
scrapy/pipelines/media.py
scrapy/shell.py
scrapy/utils/engine.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_engine.py
==================
5b78a64f;Andrey Rahmatullin;2021-04-15 14:50:59 +0500;Merge pull request #5070 from ric2b/patch-1

==
==================
06f3d12c;Andrey Rahmatullin;2021-04-14 20:58:51 +0500;Merge pull request #5100 from wRAR/more-scraper-typing
Additional typing for scraper and a small code change.
==
==================
309a637f;Andrey Rakhmatullin;2021-04-14 20:26:37 +0500;Small changes.

==

scrapy/core/scraper.py
==================
77bff0db;Andrey Rakhmatullin;2021-04-14 19:10:13 +0500;Additional typing for scraper and a small code change.

==

scrapy/core/scraper.py
==================
9bf9ab72;Andrey Rahmatullin;2021-04-13 23:29:49 +0500;Merge pull request #5077 from wRAR/deferred-typing
Add typing for middleware and coroutine related code.
==
==================
08e4eaf9;Andrey Rakhmatullin;2021-04-13 22:41:01 +0500;Import Deferred directly in scrapy/utils/defer.py.

==

scrapy/utils/defer.py
==================
cef0a8b3;Andrey Rakhmatullin;2021-04-13 21:07:07 +0500;Import Deferred directly in scrapy/middleware.py.

==

scrapy/middleware.py
==================
a8de04c8;Andrey Rahmatullin;2021-04-13 21:05:30 +0500;Update scrapy/utils/defer.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/utils/defer.py
==================
b0e75125;Andrey Rahmatullin;2021-04-13 21:05:25 +0500;Update scrapy/middleware.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/middleware.py
==================
335a2567;Andrey Rahmatullin;2021-04-13 21:05:20 +0500;Update scrapy/core/spidermw.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/core/spidermw.py
==================
76fa2257;Andrey Rakhmatullin;2021-04-13 20:01:18 +0500;Add typing also for return values, other small fixes.

==

scrapy/core/spidermw.py
scrapy/middleware.py
scrapy/utils/defer.py
==================
5b547f08;Andrey Rakhmatullin;2021-04-13 19:47:20 +0500;Merge remote-tracking branch 'origin/master' into deferred-typing

==
==================
15edb3f6;Andrey Rahmatullin;2021-04-13 19:46:26 +0500;Merge pull request #5095 from wRAR/scraper-slot-cleanup
Cleanup of slot handling in Scraper.
==
==================
38010997;Andrey Rahmatullin;2021-04-13 18:52:10 +0500;Merge pull request #5098 from storymode7/docs-update
Add DataURI download handler in DOWNLOAD_HANDLERS_BASE documentation
==
==================
a4415e4e;Mayank Singhal;2021-04-13 17:20:55 +0530;Add DataURI download handler in DOWNLOAD_HANDLERS_BASE documentation

==

docs/topics/settings.rst
==================
18502981;Adrián Chaves;2021-04-13 11:07:15 +0200;Merge pull request #5094 from elacuesta/fix-item-class-in-engine-tests
Engine tests: fix item class spider, add minimal type hints
==
==================
d8d1dc5b;Eugenio Lacuesta;2021-04-12 10:43:02 -0300;Ignore typing warning in test

==

tests/test_engine.py
tox.ini
==================
4673f05d;Andrey Rakhmatullin;2021-04-09 23:42:24 +0500;Cleanup of slot handling in Scraper.

==

scrapy/core/scraper.py
==================
b6f77806;Eugenio Lacuesta;2021-04-09 12:19:30 -0300;Engine tests: fix item class spider, add minimal type hints

==

setup.cfg
tests/test_engine.py
==================
91f81445;Eugenio Lacuesta;2019-11-20 00:30:18 -0300;Remove deprecated Spider.make_requests_from_url method

==

scrapy/spiders/__init__.py
tests/test_spider.py
==================
5a75b14a;Adrián Chaves;2021-04-07 12:33:37 +0200;docs: require sphinx-rtd-theme>=0.5.2 and the latest pip to prevent installing breaking docutils>=0.17

==

.readthedocs.yml
docs/pip.txt
docs/requirements.txt
==================
8603f9d7;Ricardo Amendoeira;2021-04-06 20:23:07 +0100;Apply changes to other examples in the same section.

==

docs/topics/practices.rst
==================
e63188cb;Andrey Rakhmatullin;2021-04-06 19:13:32 +0500;Bump version: 2.4.1 → 2.5.0

==

.bumpversion.cfg
scrapy/VERSION
==================
a71d6ef2;Adrián Chaves;2021-04-06 16:09:07 +0200;2.5.0 release notes (#5028)
Co-authored-by: Eugenio Lacuesta <1731933+elacuesta@users.noreply.github.com>
==

docs/news.rst
docs/topics/request-response.rst
docs/topics/settings.rst
docs/topics/signals.rst
tests/test_webclient.py
==================
e7d51886;Mayank Singhal;2021-04-06 02:21:18 +0530;Find bash from PATH instead of /bin/bash

==

docs/Makefile
==================
7dc85766;Andrey Rakhmatullin;2021-04-04 16:15:33 +0500;Also some typing for Scraper.

==

scrapy/core/scraper.py
==================
a0101361;Andrey Rakhmatullin;2021-04-04 16:01:47 +0500;Merge remote-tracking branch 'origin/master' into deferred-typing

==
==================
099fb6ea;Andrey Rahmatullin;2021-04-04 15:52:32 +0500;Merge pull request #5076 from wRAR/qualname
Use __qualname__ in middleware handling.
==
==================
414dd111;Andrey Rakhmatullin;2021-04-03 17:54:55 +0500;Drop an unused import.

==

scrapy/core/spidermw.py
==================
a9e96f99;Andrey Rakhmatullin;2021-04-03 17:40:45 +0500;Add typing for middleware and coroutine related code.

==

scrapy/core/downloader/middleware.py
scrapy/core/spidermw.py
scrapy/middleware.py
scrapy/utils/asyncgen.py
scrapy/utils/defer.py
scrapy/utils/python.py
==================
9e3b868d;Andrey Rakhmatullin;2021-04-03 17:04:09 +0500;Use __qualname__ in middleware handling.

==

scrapy/core/downloader/middleware.py
scrapy/core/spidermw.py
==================
8c5a3a51;Mikhail Korobov;2021-04-02 00:51:15 +0500;Merge pull request #5073 from elacuesta/fix-urlencode-doseq-arg
Fix type for urlencode's doseq argument
==
==================
9e7cbc05;Eugenio Lacuesta;2021-04-01 15:22:51 -0300;Fix type for urlencode's doseq argument

==

scrapy/commands/bench.py
tests/spiders.py
==================
127a8586;Mikhail Korobov;2021-04-01 22:47:59 +0500;Merge pull request #5063 from noviluni/update_usageError_message
Update UsageError message
==
==================
12f2006b;Mikhail Korobov;2021-04-01 22:47:24 +0500;Merge pull request #4799 from GeorgeA92/patch-2
httpcompression stats added
==
==================
f0c8d311;Mikhail Korobov;2021-04-01 22:43:45 +0500;Merge pull request #4694 from Jgaldos/improve-httpstatus-all-meta
Improve http status all on http error middleware
==
==================
cc095aa8;Akshay Sharma;2021-04-01 23:09:33 +0530;Windows pip installation guide (#4736)
* added initial steps

* fixing link

* python3 -> python

* remaining steps

* steps updated

* Update docs/intro/install.rst

Co-authored-by: Adrián Chaves <adrian@chaves.io>

* added link to Visual Studio

* removed 'install V'

* Update docs/intro/install.rst

Co-authored-by: Adrián Chaves <adrian@chaves.io>

Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/intro/install.rst
==================
0007a4c1;Mikhail Korobov;2021-04-01 22:36:33 +0500;Merge pull request #4895 from elacuesta/minimal-type-hints
Some type hints
==
==================
ad745674;Kader DJEHAF;2021-04-01 19:33:56 +0200;Fix argument type (int -> bool) (#4950)
* Fix warning: Expected type 'bool', got 'int' instead

* Update defer.py

* Fix warning: Expected type 'bool', got 'int' instead

Co-authored-by: Eugenio Lacuesta <eugenio.lacuesta@gmail.com>
==

scrapy/http/request/form.py
==================
5492972d;anay2103;2021-04-01 20:30:48 +0300;added customized filtering examples in logging.rst (#4965)
* added customized filtering examples in logging.rst

* Update logging.rst

* Update docs/topics/logging.rst

Co-authored-by: Adrián Chaves <adrian@chaves.io>

* Update docs/topics/logging.rst

Co-authored-by: Adrián Chaves <adrian@chaves.io>

* Update docs/topics/logging.rst

Co-authored-by: Adrián Chaves <adrian@chaves.io>

* Update docs/topics/logging.rst

Co-authored-by: Adrián Chaves <adrian@chaves.io>

* Update logging.rst

Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/logging.rst
==================
b09ff99d;Mikhail Korobov;2021-04-01 22:27:59 +0500;Merge pull request #4974 from Gallaecio/ul-margin
Move lists closer to their introducing paragraph
==
==================
e0a2d2b3;Mikhail Korobov;2021-04-01 22:26:20 +0500;Merge pull request #5014 from jpmckinney/patch-1
docs: Clarify there's one extension instance per crawler
==
==================
d0e23486;Mikhail Korobov;2021-04-01 22:23:56 +0500;Merge pull request #4902 from Gallaecio/retry-request
Implement a retry request function
==
==================
d458ccff;Eugenio Lacuesta;2021-04-01 12:27:35 -0300;Retry request: priority_adjust cannot be float (Request.priority is int)

==

scrapy/downloadermiddlewares/retry.py
==================
9a91586f;Mikhail Korobov;2021-04-01 20:26:11 +0500;Merge pull request #5072 from zloidemon/rebranding_update_ga
Updated GA code for docs, remove Segment tracking
==
==================
90fe494b;Veniamin Gvozdikov;2021-04-01 11:11:28 +0300;Rebranding, updated GA code

==

docs/_templates/layout.html
==================
b247fa99;Ricardo Amendoeira;2021-03-29 01:48:28 +0100;Include loading settings in `Running multiple spiders in the same process` section
The example in the documentation doesn't take into account the project settings
==

docs/topics/practices.rst
==================
1d200258;Eugenio Lacuesta;2021-03-26 10:45:26 -0300;Adjust h2 version requirement (#5066)

==

setup.py
tox.ini
==================
9c9e1a31;Eugenio Lacuesta;2021-03-25 11:58:39 -0300;[HTTP/1.1] Skip Content-Length header if its value is UNKNOWN_LENGTH (#5062)

==

scrapy/core/downloader/handlers/http11.py
==================
f0e1a332;Pratik Mahankal;2021-03-23 22:46:50 +0530;Sort the list of Request.meta alphabetically #5061 (#5065)

==

docs/topics/request-response.rst
==================
64d4ae1a;Marc;2021-03-22 21:46:05 +0100;Update UsageError message

==

scrapy/commands/crawl.py
==================
72e8cea8;Eugenio Lacuesta;2021-03-22 11:51:11 -0300;Avoid exceptions in is_generator_with_return_value (#4935)

==

scrapy/utils/misc.py
tests/test_utils_misc/test_return_with_argument_inside_generator.py
==================
ec5a7918;Adrián Chaves;2021-03-22 11:25:40 +0100;Include Content-Length in HTTP/1.1 responses (#5057)

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
==================
2973d8d5;Adrián Chaves;2021-03-22 11:24:10 +0100;Remove unnecessary reference to private parsel.Selector._default_type (#5006)

==

scrapy/selector/unified.py
==================
0e7ee125;Mikhail Korobov;2021-03-20 00:55:33 +0500;Merge pull request #5036 from dmiwell/urllength-dont-skip-silently
UrlLengthMiddleware: don't skip silently
==
==================
308a58aa;Adrián Chaves;2021-03-19 18:39:44 +0100;Update CI to support Twisted 21.2.0 (#5027)

==

scrapy/pipelines/images.py
tests/test_commands.py
tests/test_crawler.py
tests/test_pipeline_crawl.py
tests/test_pipeline_images.py
tests/test_pipeline_media.py
tox.ini
==================
0dad0fce;Adrián Chaves;2021-03-19 11:13:05 +0100;Use pip<20.3 to fix ReadTheDocs builds (#5052)

==

.readthedocs.yml
docs/pip.txt
==================
8e302f29;Adrián Chaves;2021-03-19 10:34:36 +0100;Merge pull request #5053 from Gallaecio/constraints
Fix master CI issues due to pip backtracking
==
==================
a390b934;Adrián Chaves;2021-03-18 23:53:58 +0100;Do not install mitmproxy in Python 3.9

==

tox.ini
==================
8e73e1df;Adrián Chaves;2021-03-18 23:42:29 +0100;upper-constraints.txt: restrict botocore further

==

tests/upper-constraints.txt
==================
94201612;Adrián Chaves;2021-03-18 23:35:47 +0100;Simplify the get_retry_request code example

==

scrapy/downloadermiddlewares/retry.py
==================
1d836979;Adrián Chaves;2021-03-18 22:18:12 +0100;Merge pull request #4769 from scrapy/http2
Implement experimental HTTP/2 support
==
==================
42e4dbb2;vinayak;2021-03-18 18:10:03 +0530;Support Python 3.9  (#4759)
* Update .travis.yml

* Update .travis.yml

* updage travis.yml

* Make 3.9 support official

* Upgrade mitmproxy for Python 3.9

* Restore the Pylint job

* Undo unintended change to mitmproxy requirement

* Enable Python 3.9 in GitHub Actions

* Work around reppy’s Python version limitation

* Disable tests in Windows / Python 3.9 due to a Twisted bug

Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

.github/workflows/checks.yml
.github/workflows/publish.yml
.github/workflows/tests-macos.yml
.github/workflows/tests-ubuntu.yml
.github/workflows/tests-windows.yml
.readthedocs.yml
setup.py
tox.ini
==================
2f61d7cc;Eugenio Lacuesta;2021-03-15 14:25:46 -0300;Remove unnecesary del statement

==

scrapy/core/http2/agent.py
==================
9cc4513b;Dmitriy Pomazunovskiy;2021-03-15 21:38:03 +0600;simpler stats access

==

tests/test_spidermiddleware_urllength.py
==================
c0f3ca19;Adrián Chaves;2021-03-12 14:02:48 +0100;get_retry_request: add typing information

==

scrapy/downloadermiddlewares/retry.py
==================
0f254a6a;Dmitriy Pomazunovskiy;2021-03-12 17:11:50 +0600;Test from_settings

==

tests/test_spidermiddleware_urllength.py
==================
d4b2b612;Dmitriy Pomazunovskiy;2021-03-12 16:59:37 +0600;Use from_settings for backward compatibility

==

scrapy/spidermiddlewares/urllength.py
tests/test_spidermiddleware_urllength.py
==================
6e5ea792;Dmitriy Pomazunovskiy;2021-03-12 11:08:41 +0600;Log skipped urls by length to INFO, add skipped stats

==

scrapy/spidermiddlewares/urllength.py
tests/test_spidermiddleware_urllength.py
==================
ab037ab7;Mikhail Korobov;2021-03-12 04:18:56 +0500;Merge pull request #5016 from deepang17/scrapy-4996
DOCS: Cover scrapy-bench in the documentation
==
==================
0c160882;Eugenio Lacuesta;2021-03-11 11:52:35 -0300;headers_received signal (#4897)

==

docs/faq.rst
docs/topics/exceptions.rst
docs/topics/request-response.rst
docs/topics/signals.rst
scrapy/core/downloader/handlers/http11.py
scrapy/signals.py
tests/spiders.py
tests/test_crawl.py
tests/test_engine.py
tests/test_engine_stop_download_bytes.py
tests/test_engine_stop_download_headers.py
==================
3bea5e1a;Adrián Chaves;2021-03-09 16:19:51 +0100;Remove unused _is_data_lost method

==

scrapy/core/http2/stream.py
==================
5b2d3e17;Adrián Chaves;2021-03-09 14:59:17 +0100;Merge branch 'master' into http2

==
==================
2d41c77e;deepang17;2021-03-09 17:33:05 +0530;Merge branch 'master' of https://github.com/scrapy/scrapy into scrapy-4996

==
==================
3d88ac60;deepang17;2021-03-09 17:19:34 +0530;FIX: Updated benchmarking.rst

==

.vscode/settings.json
docs/topics/benchmarking.rst
==================
954c4b48;Andrey Rahmatullin;2021-03-05 20:16:37 +0500;Merge pull request #3667 from Gallaecio/long-allowed-domains
Add a FAQ entry on how to deal with long lists of allowed domains
==
==================
dfd4ab2b;Adrián Chaves;2021-03-03 16:30:08 +0100;Merge pull request #3 from elacuesta/retry-request-customization
Allow logger/stats customization in get_retry_request
==
==================
d50bedbe;Andrey Rahmatullin;2021-03-03 16:45:00 +0500;Merge pull request #5022 from Gallaecio/fix-ci
Limit tests to Twisted < 21
==
==================
4fe26ae9;Adrián Chaves;2021-03-02 19:46:34 +0100;Limit tests to Twisted < 21

==

tox.ini
==================
36f1dbf6;deepang17;2021-03-02 22:12:44 +0530;DOCS: Covered scrapy-bench

==

.vscode/settings.json
docs/topics/benchmarking.rst
==================
9e623552;Eugenio Lacuesta;2021-03-02 12:09:10 -0300;Allow logger/stats customization in get_retry_request

==

scrapy/downloadermiddlewares/retry.py
tests/test_downloadermiddleware_retry.py
==================
3c5668d0;James McKinney;2021-03-01 22:00:33 -0500;docs: Clarify there's one extension instance per spider

==

docs/topics/extensions.rst
==================
b25616d1;deepang17;2021-02-28 16:26:46 +0530;DOCS: Cover scrapy-bench in the documentation

==

docs/topics/benchmarking.rst
==================
7a545806;deepang17;2021-02-28 15:33:09 +0530;DOCS:Cover scrapy-bench in the documentation

==

docs/topics/benchmarking.rst
==================
f95ebd8f;Mikhail Korobov;2021-02-25 02:00:55 +0500;Merge pull request #5002 from djikoSal/refactor-curl-to-request-kwargs
Refactor curl_to_request_kwargs #5001
==
==================
bda54729;Mikhail Korobov;2021-02-25 01:49:59 +0500;Merge pull request #5008 from Gallaecio/close-file
Close files in the PerYearXmlExportPipeline documentation example
==
==================
f689615e;Adrián Chaves;2021-02-24 12:54:56 +0100;Close files in the PerYearXmlExportPipeline documentation example

==

docs/topics/exporters.rst
==================
3894ebb1;Djiar;2021-02-23 15:34:53 +0100;Refactor curl_to_request_kwargs #5001 Co-authored-by: alkazaz alkazaz@kth.se Co-authored-by: swill swill@kth.se Co-authored-by: lerjevik lerjevik@kth.se Co-authored-by: aljica aljica@kth.se

==

scrapy/utils/curl.py
==================
386e2a51;Adrián Chaves;2021-02-24 10:41:01 +0100;tests/test_downloader_handlers_http2.py: fix style issue

==

tests/test_downloader_handlers_http2.py
==================
12064d79;Adrián Chaves;2021-02-24 10:37:38 +0100;HTTP/2: improve header handling

==

scrapy/core/http2/stream.py
tests/test_downloader_handlers_http2.py
==================
a36f9521;Wehzie;2021-02-24 08:15:44 +0100;fixed typo "an quotes.json" -> "a quotes.json" (#5005)

==

docs/intro/tutorial.rst
==================
51010942;Adrián Chaves;2021-02-24 07:33:39 +0100;HTTP/2: test a CONNECT request

==

tests/test_downloader_handlers_http2.py
==================
5ba31cd1;Adrián Chaves;2021-02-23 11:57:33 +0100;HTTP/2 stream close reason handling: Use else + assert instead of elif

==

scrapy/core/http2/stream.py
==================
bd29f32d;Adrián Chaves;2021-02-23 06:42:28 +0100;HTTP/2: do not make conn_lost_deferred optional

==

scrapy/core/http2/protocol.py
==================
7605f19e;Adrián Chaves;2021-02-23 05:54:48 +0100;HTTP/2: test 2 concurrent requests to the same domain

==

tests/test_downloader_handlers_http2.py
==================
6326178b;Eugenio Lacuesta;2021-02-22 12:50:51 -0300;http2: acceptable protocol update, tests (#4994)

==

scrapy/core/http2/protocol.py
tests/test_http2_client_protocol.py
==================
1f7665c4;Adrián Chaves;2021-02-22 16:48:10 +0100;Silence a PyLint check on a mistake made for testing purposes

==

tests/test_downloadermiddleware_retry.py
==================
722a33a2;Adrián Chaves;2021-02-22 16:42:38 +0100;Fix style issues

==

tests/test_downloadermiddleware_retry.py
==================
80f5003c;Adrián Chaves;2021-02-22 16:38:38 +0100;Add tests for get_retry_request

==

scrapy/downloadermiddlewares/retry.py
tests/test_downloadermiddleware_retry.py
==================
6ab99018;Adrián Chaves;2021-02-22 14:48:03 +0100;Document get_retry_requests

==

docs/topics/downloader-middleware.rst
docs/topics/settings.rst
scrapy/downloadermiddlewares/retry.py
==================
ec836dcc;Adrián Chaves;2021-02-22 14:15:28 +0100;Solve style issues

==

scrapy/downloadermiddlewares/retry.py
==================
3f5a1956;Adrián Chaves;2021-02-22 14:10:26 +0100;Merge remote-tracking branch 'upstream/master' into retry-request

==
==================
82546261;Adrián Chaves;2021-02-22 14:09:48 +0100;get_retry_request: set the default retry reason to “unspecified”

==

scrapy/downloadermiddlewares/retry.py
==================
5fc27b1e;Adrián Chaves;2021-02-22 14:09:06 +0100;Remove RetrySpiderMixin and retry_request

==

scrapy/downloadermiddlewares/retry.py
==================
fa3ebb1c;Andrey Rahmatullin;2021-02-18 18:34:25 +0500;Merge pull request #4987 from wRAR/asyncdef-tests
Making sure we can run async def tests
==
==================
49af7c4c;Andrey Rakhmatullin;2021-02-18 17:10:30 +0500;Drop pytest-twisted, use Scrapy code to install the reactor.

==

conftest.py
pytest.ini
tests/requirements-py3.txt
==================
4418f789;Eugenio Lacuesta;2021-02-17 18:36:52 -0300;Simplify check for negotiated protocol
negotiatedProtocol's type is Optional[bytes]

See https://github.com/twisted/twisted/blob/twisted-20.3.0/src/twisted/protocols/tls.py#L563-L587
and https://www.pyopenssl.org/en/20.0.1/api/ssl.html#OpenSSL.SSL.Connection.get_alpn_proto_negotiated

Note that OpenSSL.SSL.Connection.get_next_proto_negotiated is deprecated:
https://www.pyopenssl.org/en/20.0.0/changelog.html#backward-incompatible-changes

==

scrapy/core/http2/protocol.py
==================
e80f37bd;Eugenio Lacuesta;2021-02-17 16:34:29 -0300;Test http2 agent for unsupported scheme

==

tests/test_downloader_handlers_http2.py
==================
ac82a4a8;Eugenio Lacuesta;2021-02-17 16:33:57 -0300;Merge remote-tracking branch 'upstream/master' into http2

==
==================
abbbfbbb;Andrey Rakhmatullin;2021-02-12 22:41:16 +0500;Add tests for deferred_f_from_coro_f.

==

tests/test_utils_defer.py
==================
ea92b49a;Adrián Chaves;2021-02-11 12:07:28 +0100;Merge pull request #4986 from wRAR/uvloop-py36
Skip uvloop 0.15.0+ on py36.
==
==================
54fd3714;Andrey Rakhmatullin;2021-02-11 14:24:11 +0500;Skip uvloop 0.15.0+ on py36.

==

tests/requirements-py3.txt
==================
15b501c0;Adrián Chaves;2021-02-10 18:10:57 +0100;Do not force string interpolation while logging

==

scrapy/core/http2/protocol.py
==================
9ac5b1d0;Adrián Chaves;2021-02-08 22:31:20 +0100;Adjust test constraints

==

tests/upper-constraints.txt
==================
bb72bba1;Adrián Chaves;2021-02-08 21:51:57 +0100;tox: apply upper constraints to all non-pinned package installations

==

tests/upper-constraints.txt
tox.ini
==================
45345ba6;Adrián Chaves;2021-02-08 17:56:29 +0100;Use constraints.txt to limit pip resolver backtracking

==

tests/constraints.txt
tox.ini
==================
de82ca85;Adrián Chaves;2021-02-08 21:27:21 +0100;Merge pull request #4982 from wRAR/refactor-spidermiddlewaremanager
Refactor SpiderMiddlewareManager.scrape_response.
==
==================
1e9b52c3;Andrey Rakhmatullin;2021-02-08 22:02:03 +0500;Refactor SpiderMiddlewareManager.scrape_response.

==

scrapy/core/spidermw.py
==================
8527b53e;Adrián Chaves;2021-02-05 13:06:27 +0100;Revert "Use --use-deprecated=legacy-resolver"
This reverts commit 7b11b74c77d1535f943baebbf5c794a63d147a13.

==

tox.ini
==================
7afcd634;Adrián Chaves;2021-02-05 13:04:54 +0100;Remove unused import

==

scrapy/core/http2/stream.py
==================
7b11b74c;Adrián Chaves;2021-02-04 11:08:01 +0100;Use --use-deprecated=legacy-resolver
Let’s see how test results change

==

tox.ini
==================
0e4b2917;Adrián Chaves;2021-02-03 21:28:04 +0100;HTTP/2: fix canceling a request before a connection has been established

==

scrapy/core/http2/stream.py
==================
24880032;Adrián Chaves;2021-02-03 21:13:43 +0100;Fix test_pinned_twisted_version

==

tests/test_dependencies.py
==================
4c801551;Adrián Chaves;2021-02-03 21:11:46 +0100;Document that the bytes_received signal is not yet implemented for HTTP/2

==

docs/topics/settings.rst
==================
1773eaf5;Adrián Chaves;2021-02-03 11:43:18 +0100;Move lists closer to their introducing paragraph

==

docs/_static/custom.css
docs/conf.py
docs/topics/exceptions.rst
docs/topics/feed-exports.rst
docs/topics/selectors.rst
docs/topics/shell.rst
==================
1a7bde0d;Adrián Chaves;2021-02-03 10:55:11 +0100;Document that HTTP/2 server pushes are ignored

==

docs/topics/settings.rst
==================
c8d8b180;Adrián Chaves;2021-02-03 09:37:35 +0100;Merge remote-tracking branch 'upstream/master' into http2

==
==================
536e749e;Adrián Chaves;2021-02-03 09:22:02 +0100;HTTP/2: remove verbose protocol-handling logging

==

scrapy/core/http2/protocol.py
==================
d1024566;Adrián Chaves;2021-02-03 09:13:45 +0100;setup.py: Twisted → Twisted[http2]

==

setup.py
==================
2ce8e0c7;Adrián Chaves;2021-02-03 09:09:53 +0100;Document the (hard-coded) maximum HTTP/2 frame size accepted from servers

==

docs/topics/settings.rst
==================
904a5013;Mikhail Korobov;2021-02-03 01:10:52 +0500;Merge pull request #4973 from Gallaecio/zyte
Scrapinghub → Zyte
==
==================
f30f53b3;Adrián Chaves;2021-02-02 15:03:20 +0100;Scrapinghub → Zyte

==

AUTHORS
CODE_OF_CONDUCT.md
README.rst
docs/intro/install.rst
docs/topics/deploy.rst
docs/topics/logging.rst
docs/topics/practices.rst
docs/topics/selectors.rst
scrapy/core/downloader/handlers/http11.py
==================
28262d4b;Mikhail Korobov;2021-01-14 19:58:52 +0500;Merge pull request #4956 from Gallaecio/readme-contributors
Mention contributors in the README
==
==================
6e7ae789;Adrián Chaves;2021-01-14 11:59:38 +0100;Reuse the text from https://scrapy.org/

==

README.rst
==================
0a1e2fef;M Ikram Ullah Khan;2021-01-04 18:30:23 +0500;Docs: fix typo in news.rst (#4942)

==

docs/news.rst
==================
80db569a;Eugenio Lacuesta;2021-01-01 19:13:39 -0300;Migrate CI to GitHub actions (#4924)

==

.github/workflows/checks.yml
.github/workflows/main.yml
.github/workflows/publish.yml
.github/workflows/tests-macos.yml
.github/workflows/tests-ubuntu.yml
.github/workflows/tests-windows.yml
.travis.yml
README.rst
tests/requirements-py3.txt
tox.ini
==================
e494a3f7;Eugenio Lacuesta;2020-12-31 11:50:15 -0300;protocol attribute for h2 responses

==

docs/topics/request-response.rst
scrapy/core/http2/stream.py
tests/test_downloader_handlers_http2.py
==================
d698b514;Eugenio Lacuesta;2020-12-31 11:13:25 -0300;Merge branch 'master' into http2

==
==================
44a7ab5b;Kader DJEHAF;2020-12-30 15:22:27 +0100;Fix warning: Expected type 'bool', got 'int' instead (#4940)
* Fix warning: Expected type 'bool', got 'int' instead

* Update defer.py
==

scrapy/pipelines/media.py
scrapy/utils/defer.py
==================
39bc9a4d;Adrián Chaves;2020-12-24 15:31:42 +0100;Merge pull request #4814 from dswij/tox-pip20.2
add pip 20.2 test for tox
==
==================
24e1b350;Adrián Chaves;2020-12-22 13:57:03 +0100;Merge pull request #4936 from timgates42/bugfix_typo_without
docs: fix simple typo, wihout -> without
==
==================
6dccf82e;Tim Gates;2020-12-22 07:49:13 +1100;docs: fix simple typo, wihout -> without
There is a small typo in scrapy/http/request/form.py.

Should read `without` rather than `wihout`.

==

scrapy/http/request/form.py
==================
b83a1a6f;Eugenio Lacuesta;2020-12-16 18:02:47 -0300;Disable test under pypy

==

tests/test_webclient.py
==================
45eb099e;Adrián Chaves;2020-12-21 15:37:02 +0100;Maybe it’s about having a newer libssl

==

.travis.yml
==================
1c1255a7;Adrián Chaves;2020-12-21 14:41:02 +0100;Use sudo for apt-get

==

.travis.yml
==================
798a818c;Adrián Chaves;2020-12-21 13:35:40 +0100;Move apt-get command from Tox to Travis CI

==

.travis.yml
tox.ini
==================
0dff5781;Adrián Chaves;2020-12-21 11:13:14 +0100;Blind attempt to fix the build of the cryptography-provided OpenSSL

==

tox.ini
==================
0567fdc5;Adrián Chaves;2020-12-21 11:02:05 +0100;Merge remote-tracking branch 'upstream/master' into tox-pip20.2

==
==================
d0af0086;Adrián Chaves;2020-12-16 15:27:40 +0100;Merge pull request #4878 from elacuesta/response-protocol-attribute
Response.protocol attribute
==
==================
212163e1;Mikhail Korobov;2020-12-04 01:36:47 +0500;Merge pull request #4912 from elacuesta/remove_deprecated_pickled_settings_to_override
Remove deprecated SCRAPY_PICKLED_SETTINGS_TO_OVERRIDE
==
==================
db10aaf9;gunadhya;2020-12-03 15:26:36 +0530;Update links in installation guide (#4899)

==

docs/conf.py
docs/intro/install.rst
==================
ef09e0d1;Eugenio Lacuesta;2020-11-19 10:35:49 -0300;Some type hints

==

scrapy/__init__.py
scrapy/commands/__init__.py
scrapy/commands/parse.py
scrapy/contracts/__init__.py
scrapy/http/cookies.py
scrapy/item.py
scrapy/mail.py
scrapy/spidermiddlewares/referer.py
scrapy/utils/httpobj.py
scrapy/utils/request.py
scrapy/utils/response.py
scrapy/utils/trackref.py
setup.cfg
==================
6091f3cc;Eugenio Lacuesta;2020-12-01 10:26:21 -0300;Remove unused pickle import

==

scrapy/utils/project.py
==================
a80bafe5;Eugenio Lacuesta;2020-11-30 19:03:13 -0300;Remove deprecated SCRAPY_PICKLED_SETTINGS_TO_OVERRIDE

==

scrapy/utils/project.py
==================
7fec9f99;Kader DJEHAF;2020-11-30 21:47:28 +0100;[Cleaned] PEP 8: E251 unexpected spaces around keyword / parameter equals (#4911)
[Cleaned] PEP 8: E251 unexpected spaces around keyword / parameter equals
==

setup.py
==================
487e1952;Adrián Chaves;2020-11-30 14:41:40 +0100;Merge pull request #4901 from elacuesta/remove_deprecated_stuff
Remove deprecated stuff
==
==================
aed1707f;Mikhail Korobov;2020-11-29 23:09:20 +0500;Merge pull request #4909 from etimoz/exporters-doc-super-fix
Removed wrong super argument in overriding serialize_fields code example
==
==================
95d39d5c;etimoz;2020-11-29 13:24:04 +0100;removed wrong super argument in overriding serialize_fields code example

==

docs/topics/exporters.rst
==================
440e45d1;Andrey Rahmatullin;2020-11-24 23:59:00 +0500;Merge pull request #4900 from elacuesta/deprecate_utils_py36
Deprecate scrapy.utils.py36 module
==
==================
f6879c68;Adrián Chaves;2020-11-23 23:53:03 +0100;SCRAPY_PINNED → _SCRAPY_PINNED

==

tests/test_dependencies.py
tox.ini
==================
a752fa07;Adrián Chaves;2020-11-23 22:58:54 +0100;Implement retry request functions and mixin

==

scrapy/downloadermiddlewares/retry.py
==================
0dc3e635;Adrián Chaves;2020-11-23 22:10:45 +0100;Add a test to check the Twisted version in pinned environments

==

tests/test_dependencies.py
tox.ini
==================
fe8bb6bd;Eugenio Lacuesta;2020-11-23 16:51:04 -0300;Fix import

==

scrapy/utils/spider.py
==================
18b05af8;Eugenio Lacuesta;2020-11-23 16:18:58 -0300;Remove tests/test_utils_http.py

==

tests/test_utils_http.py
==================
0a93df9e;Eugenio Lacuesta;2020-11-23 16:16:18 -0300;Move collect_asyncgen to utils.asyncgen

==

scrapy/utils/asyncgen.py
scrapy/utils/py36.py
scrapy/utils/python.py
==================
462014bc;Eugenio Lacuesta;2020-11-23 15:51:59 -0300;Scheduler: remove support for deprecated queuelib.PriorityQueue

==

scrapy/core/scheduler.py
==================
51ca4d01;Eugenio Lacuesta;2020-11-23 15:47:08 -0300;Remove deprecated scrapy.utils.gz.is_gzipped function

==

scrapy/utils/gz.py
tests/test_utils_gz.py
==================
4075e1ea;Eugenio Lacuesta;2020-11-23 15:07:56 -0300;Remove deprecated modules (utils.http/markup/multipart)

==

pytest.ini
scrapy/utils/http.py
scrapy/utils/markup.py
scrapy/utils/multipart.py
==================
075ab156;Eugenio Lacuesta;2020-11-23 11:59:59 -0300;Deprecate scrapy.utils.py36 module

==

scrapy/utils/py36.py
scrapy/utils/python.py
scrapy/utils/spider.py
setup.cfg
==================
e17c890b;Adrián Chaves;2020-11-19 20:31:57 +0100;Merge pull request #4898 from scrapy/2.4
Scrapy 2.4.1
==
==================
08f5ed71;Adrián Chaves;2020-11-18 17:38:18 +0100;Fix memory issue due to unexpectedly large server frames

==

scrapy/core/http2/protocol.py
==================
bde96a5a;Adrián Chaves;2020-11-18 16:42:44 +0100;Ignore server-initiated events

==

scrapy/core/http2/protocol.py
==================
6ef3dc20;Adrián Chaves;2020-11-17 22:28:20 +0100;Use the new pip resolver for Tox environments with pinned dependencies

==

tox.ini
==================
63becd1b;Adrián Chaves;2020-11-17 21:58:08 +0100;Update news.rst

==

docs/news.rst
==================
26836c4e;Adrián Chaves;2020-11-17 09:17:39 +0100;Bump version: 2.4.0 → 2.4.1

==

.bumpversion.cfg
scrapy/VERSION
==================
15d301e9;Adrián Chaves;2020-11-17 09:16:08 +0100;Cover Scrapy 2.4.1 in the release notes (#4884)
Co-authored-by: Mikhail Korobov <kmike84@gmail.com>
==

docs/news.rst
==================
2405df49;Eugenio Lacuesta;2020-11-16 12:50:33 -0300;Add tests for Response.protocol=None

==

tests/test_downloader_handlers.py
==================
85604e10;joaquin garmendia;2020-11-11 15:16:01 -0500;Add failed and success count stats to feedstorage backends (#4850)

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
034d61e6;Adrián Chaves;2020-11-11 16:46:03 +0100;Restrict pip’s --use-feature=2020-resolver to the extra-deps environment

==

tox.ini
==================
b0368228;Eugenio Lacuesta;2020-11-11 11:18:03 -0300;Add exception to catch

==

scrapy/core/downloader/handlers/http11.py
==================
5e9a99e6;Eugenio Lacuesta;2020-11-11 11:15:29 -0300;Reponse.protocol as string

==

docs/topics/request-response.rst
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/webclient.py
tests/test_downloader_handlers.py
==================
22424125;Eugenio Lacuesta;2020-11-11 10:50:54 -0300;Docs: placeholder for versionadded directive

==

docs/topics/request-response.rst
==================
61d08948;Eugenio Lacuesta;2020-11-11 01:31:15 -0300;Docs: sort versionadded directives

==

docs/topics/request-response.rst
==================
0fb7bcb2;Eugenio Lacuesta;2020-11-11 01:26:03 -0300;Style adjustment

==

scrapy/http/response/__init__.py
==================
587b4dd7;Eugenio Lacuesta;2020-11-11 01:20:50 -0300;Docs for the Response.protocol attribute

==

docs/topics/request-response.rst
==================
5b6b5624;Eugenio Lacuesta;2020-11-11 01:08:37 -0300;Test Response.protocol attribute

==

tests/test_downloader_handlers.py
==================
99cc853d;Eugenio Lacuesta;2020-09-29 23:53:37 -0300;Response.protocol attribute

==

scrapy/core/downloader/handlers/http11.py
scrapy/http/response/__init__.py
==================
c20b3426;Eugenio Lacuesta;2020-11-10 15:35:09 -0300;Remove unnecessary pytest-azurepipelines package (#4876)

==

tests/requirements-py3.txt
==================
91a8451c;Mikhail Korobov;2020-11-10 17:23:28 +0500;Merge pull request #4874 from stummjr/fix-missing-fstring-prefix-genspider
Fix incorrect output on the genspider command
==
==================
27b07c69;Mikhail Korobov;2020-11-10 17:22:20 +0500;Merge pull request #4872 from elacuesta/asyncio_get_event_loop
Call asyncio.get_event_loop when installing the asyncio reactor
==
==================
b20cfef1;Eugenio Lacuesta;2020-11-09 13:58:52 -0300;Remove unnecessary line from test

==

tests/CrawlerProcess/asyncio_deferred_signal.py
==================
7e98a76a;Eugenio Lacuesta;2020-11-09 12:17:15 -0300;Use deferred_from_coro in asyncio test

==

tests/CrawlerProcess/asyncio_deferred_signal.py
==================
a2c4a7f9;Valdir Stumm Junior;2020-11-08 19:12:18 -0300;Add missing f-string prefix to genspider output

==

scrapy/commands/genspider.py
tests/test_commands.py
==================
114229eb;Eugenio Lacuesta;2020-11-06 13:29:14 -0300;Docs: add a note about asyncio.set_event_loop

==

docs/topics/settings.rst
==================
4b28da43;Adrián Chaves;2020-11-06 16:46:22 +0100;Fix syntax error

==

tests/test_utils_signal.py
==================
f3064254;Adrián Chaves;2020-11-06 16:42:58 +0100;Merge branch 'patch-2' of github.com:GeorgeA92/scrapy into patch-2

==
==================
ee98771f;Adrián Chaves;2020-11-06 16:42:32 +0100;Remove unused variable

==

tests/test_downloadermiddleware_httpcompression.py
==================
1941f607;Adrián Chaves;2020-11-06 16:25:56 +0100;Skip 2 additional tests with older Twisted versions

==

tests/test_utils_signal.py
==================
3095d397;Eugenio Lacuesta;2020-11-06 12:16:10 -0300;Test: disable asyncio reactor on Windows for Py>=3.8

==

tests/test_crawler.py
==================
5d2a9cf5;Adrián Chaves;2020-11-06 14:17:54 +0100;Merge branch 'master' into patch-2

==
==================
a3e53027;Adrián Chaves;2020-11-06 14:16:26 +0100;Test HttpCompressionMiddleware subclasses with custom, parameterless __init__

==

scrapy/downloadermiddlewares/httpcompression.py
tests/test_downloadermiddleware_httpcompression.py
==================
fea5a118;Adrián Chaves;2020-11-06 12:59:46 +0100;Also skip test_asyncdef_asyncio on old Twisted versions

==

tests/test_downloadermiddleware.py
==================
ea851b91;Adrián Chaves;2020-11-06 12:34:29 +0100;Clean up Twisted version check

==

tests/test_downloadermiddleware.py
==================
5b5478ae;Eugenio Lacuesta;2020-11-05 14:01:34 -0300;Call asyncio.get_event_loop when installing the asyncio reactor

==

scrapy/utils/reactor.py
tests/CrawlerProcess/asyncio_deferred_signal.py
tests/test_crawler.py
==================
c292957c;Eugenio Lacuesta;2020-11-05 11:15:58 -0300;Run Windows tests on GitHub actions (#4869)

==

.github/workflows/main.yml
azure-pipelines.yml
==================
6eaf0c5c;Adrián Chaves;2020-11-04 21:54:00 +0100;Use Ubuntu Bionic for PyPy tests to try to get a newer OpenSSL version recognized

==

.travis.yml
==================
906626cf;Adrián Chaves;2020-11-04 21:50:12 +0100;Skip MiddlewareUsingCoro::test_asyncdef on asyncio and old Twisted

==

tests/test_downloadermiddleware.py
==================
8e7b7567;Adrián Chaves;2020-11-04 21:26:55 +0100;Solve Flake8-reported issues

==

tests/test_proxy_connect.py
==================
7327145b;Adrián Chaves;2020-10-30 21:34:15 +0100;Remove mitmproxy from pinned environments

==

tests/requirements-py3.txt
tests/test_proxy_connect.py
tox.ini
==================
e9c31881;Georgiy Zatserklianyi;2020-10-30 21:23:29 +0200;Update scrapy/downloadermiddlewares/httpcompression.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/downloadermiddlewares/httpcompression.py
==================
a5872a0f;Georgiy Zatserklianyi;2020-10-30 20:36:39 +0200;Fix output file overwrite with -O (FeedExporter updated) (#4859)

==

scrapy/extensions/feedexport.py
tests/test_commands.py
==================
3e5bc777;Adrián Chaves;2020-10-30 10:31:33 +0100;Remove pinning from the PyPy job

==

tox.ini
==================
13bcdc9f;Adrián Chaves;2020-10-30 10:28:42 +0100;Restore pinned dependencies in tox.ini

==

tox.ini
==================
7187247c;Adrián Chaves;2020-10-30 10:23:59 +0100;Add PyDispatcher>=2.0.5 back to dependencies for old pip

==

setup.py
==================
75f35f55;Andrey Rahmatullin;2020-10-20 13:55:07 +0500;Merge pull request #4803 from elacuesta/instantiate-resolution-receiver
CachingHostnameResolver
==
==================
585e4a8a;Eugenio Lacuesta;2020-10-09 10:41:19 -0300;Replace local server address

==

tests/test_crawler.py
==================
872b2e4c;GeorgeA92;2020-10-13 18:41:58 +0300;testcase added for COMPRESSION_ENABLED setting

==

tests/test_downloadermiddleware_httpcompression.py
==================
d32d0d27;GeorgeA92;2020-10-13 18:36:41 +0300;testcase added for HttpCompressionMiddleware with no stats

==

tests/test_downloadermiddleware_httpcompression.py
==================
fd663fd4;GeorgeA92;2020-10-13 18:35:06 +0300;__init__ stats parameter - optional, stats==None - covered.

==

scrapy/downloadermiddlewares/httpcompression.py
==================
c340e729;Adrián Chaves;2020-10-11 22:12:45 +0200;Bump version: 2.3.0 → 2.4.0

==

.bumpversion.cfg
scrapy/VERSION
==================
47eac837;Adrián Chaves;2020-10-11 22:11:14 +0200;Set a release date for Scrapy 2.4.0

==

docs/news.rst
==================
015c82b9;Adrián Chaves;2020-10-11 22:09:45 +0200;Scrapy 2.4 release notes (#4808)

==

docs/news.rst
docs/topics/asyncio.rst
docs/topics/feed-exports.rst
docs/topics/media-pipeline.rst
docs/topics/settings.rst
==================
868826b3;Eugenio Lacuesta;2020-10-02 15:16:58 -0300;CachingHostnameResolver tests

==

tests/CrawlerProcess/alternative_name_resolver.py
tests/CrawlerProcess/caching_hostname_resolver.py
tests/CrawlerProcess/caching_hostname_resolver_ipv6.py
tests/CrawlerProcess/default_name_resolver.py
tests/test_crawler.py
==================
8fe58765;Eugenio Lacuesta;2020-09-30 14:56:17 -0300;HostResolution implementation

==

scrapy/resolver.py
==================
b55c911d;Eugenio Lacuesta;2020-09-21 10:59:55 -0300;Fix CachingHostnameResolver

==

scrapy/resolver.py
==================
da426fb3;Andrey Rahmatullin;2020-10-09 00:39:05 +0500;Merge pull request #4839 from elacuesta/pytest_xfail_strict
Add xfail_strict=true to pytest.ini
==
==================
13ae17ae;Eugenio Lacuesta;2020-10-08 14:04:52 -0300;Add xfail_strict=true to pytest.ini

==

pytest.ini
==================
9f8c3938;Andrey Rahmatullin;2020-10-08 20:20:32 +0500;Merge pull request #4823 from elacuesta/cookies-revert-header
Do not process cookies from headers
==
==================
45c06cfd;Andrey Rahmatullin;2020-10-08 14:08:18 +0500;Merge pull request #4831 from starrify/downloadermw-support-zstd
Adding support for zstd in HttpCompressionMiddleware
==
==================
8fc4e2e0;Andrey Rahmatullin;2020-10-07 16:00:38 +0500;Merge pull request #4836 from OfirD1/patch-1
moved the sentence about processing pending requests when a spider is closed onto a generic note.
==
==================
ded9a5a0;Andrey Rahmatullin;2020-10-07 14:50:28 +0500;Merge pull request #4835 from Gallaecio/about-url-support
Do not consider about: URLs invalid
==
==================
9461414b;dswij;2020-10-07 11:26:53 +0700;minor changes to remove unnecessary lines

==

.travis.yml
tox.ini
==================
269fe35d;Adrián Chaves;2020-10-06 21:05:10 +0200;Merge branch 'master' into http2

==
==================
1a597d5e;OfirD1;2020-10-06 21:54:42 +0300;moved the sentence about processing pending requests when a spider is closed onto a generic note.

==

docs/topics/extensions.rst
==================
156bb0a1;P. Chen;2020-10-06 19:53:40 +0100;Fixing the minor typo on test file path in tests/test_downloadermiddleware_httpcompression.py

==

tests/test_downloadermiddleware_httpcompression.py
==================
2e734e6b;P. Chen;2020-10-06 19:51:05 +0100;Minor update on the import order in scrapy/downloadermiddlewares/httpcompression.py

==

scrapy/downloadermiddlewares/httpcompression.py
==================
9f02df20;dswij;2020-10-07 01:10:01 +0700;Remove PyDispatcher from general requirements

==

setup.py
tox.ini
==================
e4078815;Adrián Chaves;2020-10-06 19:13:29 +0200;Do not consider about: URLs invalid

==

scrapy/http/request/__init__.py
tests/test_http_request.py
==================
6050604f;GeorgeA92;2020-10-06 18:59:57 +0300;httocompression/response_bytes tests added

==

tests/test_downloadermiddleware_httpcompression.py
==================
b1255b01;Andrey Rahmatullin;2020-10-06 20:14:04 +0500;Merge pull request #4746 from Gallaecio/fix_iternodes
Fix iternodes
==
==================
9b1f86b6;Andrey Rahmatullin;2020-10-06 18:50:55 +0500;Use f-strings

==

scrapy/utils/iterators.py
==================
137c8ba6;Eugenio Lacuesta;2020-10-06 10:50:17 -0300;Docs: mention limitation about Cookie header

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
docs/topics/settings.rst
==================
1aeda664;Andrey Rahmatullin;2020-10-06 18:23:01 +0500;Merge pull request #4804 from Gallaecio/mock-s3
Use mocking for S3 tests that currently need server credentials
==
==================
ce6884d5;dswij;2020-10-06 19:51:42 +0700;Update tox.ini

==

tox.ini
==================
371bb808;dswij;2020-10-06 19:44:48 +0700;Explicitly declare PyDispatcher as dependencies

==

.travis.yml
tox.ini
==================
6032a9a3;P. Chen;2020-10-05 23:55:48 +0100;Minor adjustment to the test case in tests/test_downloadermiddleware_httpcompression.py

==

tests/test_downloadermiddleware_httpcompression.py
==================
50e1f35d;P. Chen;2020-10-05 23:43:12 +0100;Adding test cases for the zstd content encoding

==

tests/requirements-py3.txt
tests/sample_data/compressed/html-zstd-static-content-size.bin
tests/sample_data/compressed/html-zstd-static-no-content-size.bin
tests/sample_data/compressed/html-zstd-streaming-no-content-size.bin
tests/test_downloadermiddleware_httpcompression.py
==================
da3171d4;P. Chen;2020-10-05 23:18:58 +0100;Using the `zstandard` package than `zstd` for supporting frames both with and without the content size info
See also: https://github.com/sergey-dryabzhinsky/python-zstd/issues/53

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/httpcompression.py
==================
c6c3f2ce;P. Chen;2020-10-05 21:10:40 +0100;Updating the doc entry for the HTTP compress downloader middleware on zstd

==

docs/topics/downloader-middleware.rst
==================
892dd9da;P. Chen;2020-10-05 21:00:58 +0100;Adding support for zstd in HttpCompressionMiddleware

==

scrapy/downloadermiddlewares/httpcompression.py
==================
004b40a7;Adrián Chaves;2020-10-03 00:53:55 +0200;as soon as → as long as (#4825)

==

docs/contributing.rst
==================
797a6690;Eugenio Lacuesta;2020-10-01 23:11:11 -0300;Tests: use classes instead of paths in settings (#4817)

==

tests/test_dupefilters.py
tests/test_logformatter.py
tests/test_pipelines.py
tests/test_request_attribute_binding.py
tests/test_request_cb_kwargs.py
tests/test_spidermiddleware_output_chain.py
==================
4f27c5f8;Mikhail Korobov;2020-10-02 00:10:05 +0500;Merge pull request #4768 from maranqz/feature/4606-exporter-from-FEEDS
Pass info from FEEDS to ItemExporter
==
==================
f173af6b;Mikhail Korobov;2020-10-01 23:57:00 +0500;Merge pull request #4778 from drs-11/unparseable-no-proxy-fix
Check for unparseable no_proxy values
==
==================
159e2b2e;Akshay Sharma;2020-10-02 00:23:08 +0530;allowing to run .pyw files  (#4646)
* allow .pyw in scrapy/commands/runspider.py

* aesthetics

* added tests for '.pyw'

* created class for testing .pyw files

* name=None parameter in get_log

* small fix

* .pyw tests for non-windows

* used @skipIf for tests

* two more tests skipped
==

scrapy/commands/runspider.py
tests/test_commands.py
==================
f47b120e;Habeeb Shopeju;2020-10-01 19:50:11 +0100;Documentation of link extractor usage (#4775)
* Added description when using link extractor outside crawlspiders and created reference documentation for scrapy.link.Link class

* Added link.rst to toctree

* Corrected spelling errors, moved docs to Link doctstring to use autoclass

* Moved link docs to link_extractors

* Update docs/topics/link-extractors.rst

Co-authored-by: Adrián Chaves <adrian@chaves.io>

* Update link.py

Improvements to URL description

* Update link.py

* Update link.py

Fixed line length Flake issue

* Update link.py

Fixed trailing whitespace

Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/index.rst
docs/topics/link-extractors.rst
scrapy/link.py
==================
7b1bc9b7;Mikhail Korobov;2020-10-01 23:46:14 +0500;Merge pull request #4816 from sashreek1/master
removed datatype specification for *args & ** kwargs
==
==================
872f68a9;Mikhail Korobov;2020-10-01 23:45:14 +0500;Merge pull request #4818 from elacuesta/crawl-rule-remove-deprecated-code
Crawl rule: remove deprecated code
==
==================
e42d8252;Andrey Rahmatullin;2020-10-01 23:22:17 +0500;Drop the conditional code for old Twisted (#4820)

==

scrapy/core/downloader/tls.py
==================
44f0fde9;Andrey Rahmatullin;2020-10-01 23:21:09 +0500;Simplify TLS logging for the modern pyOpenSSL. (#4822)

==

scrapy/core/downloader/tls.py
==================
95b2e944;dswij;2020-10-02 01:05:45 +0700;fix comment error on tox and re-add cache for travis

==

.travis.yml
tox.ini
==================
cc81f9ed;dswij;2020-10-02 00:56:59 +0700;add download setting for tox

==

.travis.yml
tox.ini
==================
744f352d;Eugenio Lacuesta;2020-10-01 14:52:23 -0300;Do not process cookies from headers

==

scrapy/downloadermiddlewares/cookies.py
tests/test_downloadermiddleware_cookies.py
==================
c83a1689;dswij;2020-10-01 20:59:05 +0700;try removing cache in travis to install pip

==

.travis.yml
==================
392b489a;dswij;2020-10-01 20:32:49 +0700;travis

==

.travis.yml
==================
f7201b14;dswij;2020-10-01 19:59:23 +0700;travis and deps

==

.travis.yml
tox.ini
==================
0ea6ff11;dswij;2020-10-01 16:14:36 +0700;travis pip version and deps

==

.travis.yml
tox.ini
==================
66201737;dswij;2020-10-01 15:47:19 +0700;fix travis and deps

==

.travis.yml
tox.ini
==================
f4629fe2;dswij;2020-10-01 14:58:14 +0700;Update travis-pip and tox deps conflict for pip20.2

==

.travis.yml
tox.ini
==================
9661a8dc;Sashreek Shankar;2020-10-01 06:46:12 +0530;removed datatype specification for *args & ** kwargs

==

scrapy/crawler.py
==================
774ebe87;Adrián Chaves;2020-09-30 14:17:30 +0200;Mention contributors in the README

==

README.rst
==================
894b509d;Eugenio Lacuesta;2020-09-29 23:37:28 -0300;Crawl rule: remove deprecated code
Remove the compatibility layer that handles 'process_request'
methods that do not receive a 'response' parameter

==

scrapy/spiders/crawl.py
tests/test_spider.py
==================
9186e5a6;dswij;2020-09-29 00:27:39 +0700;add pip 20.2 test for tox

==

tox.ini
==================
5a386393;Andrey Rahmatullin;2020-09-28 18:26:43 +0500;Merge pull request #4809 from madeny/patch-1
Correct some typos
==
==================
eff96038;madeny;2020-09-26 22:50:38 +0200;Correct some typos
This won't be an issue if **your** spider doesn't rely on cookies.
==

docs/topics/jobs.rst
==================
6ef7c440;Adrián Chaves;2020-09-22 12:45:21 +0200;Fix timezone test issue

==

tests/test_pipeline_files.py
==================
c22e8106;GeorgeA92;2020-09-22 07:47:37 +0300;httocompression tests added

==

scrapy/downloadermiddlewares/httpcompression.py
tests/test_downloadermiddleware_httpcompression.py
==================
07c1d9c2;Adrián Chaves;2020-09-21 23:32:55 +0200;Remove boto3 as a dependency for tests

==

tox.ini
==================
8f46e845;Adrián Chaves;2020-09-21 23:28:16 +0200;Fix style issues

==

scrapy/utils/test.py
tests/test_feedexport.py
tests/test_pipeline_files.py
==================
c3b740f0;Adrián Chaves;2020-09-21 23:25:37 +0200;Use mocking for tests/test_pipeline_files.py::TestS3FilesStore::test_persist

==

scrapy/utils/test.py
tests/test_pipeline_files.py
==================
35726da4;Adrián Chaves;2020-09-21 22:55:25 +0200;tests/test_feedexport.py: remove unused import

==

tests/test_feedexport.py
==================
17e13537;Adrián Chaves;2020-09-21 22:54:39 +0200;Use mocking for tests/test_feedexport.py::BatchDeliveriesTest::test_s3_export

==

tests/test_feedexport.py
==================
56f05fb1;Adrián Chaves;2020-09-21 22:01:09 +0200;Use mocking for tests/test_feedexport.py::S3FeedStorageTest::test_store

==

tests/test_feedexport.py
==================
008cf1c7;Adrián Chaves;2020-09-21 20:45:21 +0200;Remove a test that has never been executed in Python 3

==

tests/test_downloader_handlers.py
==================
3989f64b;Mirwaisse Djanbaz;2020-09-21 14:40:00 +0200;dependecies → dependencies (#4801)

==

docs/intro/install.rst
==================
7f1e74da;Mirwaisse Djanbaz;2020-09-21 14:38:16 +0200;dependencides → dependencies (#4800)

==

docs/intro/install.rst
==================
70c82d33;Georgiy Zatserklianyi;2020-09-20 16:24:05 +0300;httpcompression stats added (#4797)

==

scrapy/downloadermiddlewares/httpcompression.py
==================
5e997587;Andrey Rahmatullin;2020-09-20 18:06:46 +0500;Remove dead boto2 code, deprecate is_botocore() (#4776)

==

scrapy/core/downloader/handlers/s3.py
scrapy/extensions/feedexport.py
scrapy/pipelines/files.py
scrapy/utils/boto.py
scrapy/utils/test.py
tests/test_feedexport.py
tests/test_pipeline_files.py
==================
6e8d20a0;Eugenio Lacuesta;2020-09-16 04:57:07 -0300;HTTP/2: add some type hints (#4785)

==

scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/agent.py
scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
setup.cfg
tests/test_downloader_handlers.py
tests/test_http2_client_protocol.py
==================
85e13aff;Mikhail Korobov;2020-09-15 01:17:46 +0500;Merge pull request #4782 from sripriyesha/patch-1
add mention of FTP server storage in media storage intro
==
==================
4d6359df;Adrián Chaves;2020-09-11 13:51:05 +0200;Mark HTTP/2 as experimental

==

docs/topics/asyncio.rst
docs/topics/commands.rst
docs/topics/settings.rst
==================
82ba7c8b;drs-11;2020-09-10 20:56:39 +0530;created separate test for invalid no-proxy values

==

tests/test_downloadermiddleware_httpproxy.py
==================
7a83474c;KAILASA's Sri Nithya Priyeshananda;2020-09-08 17:16:31 +0200;add mention of FTP server storage in media storage intro
At the beginning of this doc, in "Specifying where to store the media" feature details, FTP server storage mention was missing
==

docs/topics/media-pipeline.rst
==================
959222df;drs-11;2020-09-05 21:32:05 +0530;check for unparseable no_proxy values

==

scrapy/downloadermiddlewares/httpproxy.py
tests/test_downloadermiddleware_httpproxy.py
==================
c1cc3f2f;Andrey Rahmatullin;2020-09-02 13:37:44 +0500;Merge pull request #4761 from Gallaecio/on-the-fly-certificates
Generate localhost keys for tests on the fly
==
==================
9731d91f;Adrián Chaves;2020-09-01 12:38:37 +0200;Merge branch 'master' into fix_iternodes

==
==================
ddc26f3f;Adrián Chaves;2020-09-01 11:26:07 +0200;Revert Travis CI changes

==

.travis.yml
==================
307e35c6;Eugenio Lacuesta;2020-09-01 06:04:00 -0300;Improve check for invalid cookie in CookiesMiddleware (#4772)

==

scrapy/downloadermiddlewares/cookies.py
tests/test_downloadermiddleware_cookies.py
==================
d10464ca;Ilia Sergunin;2020-09-01 10:13:40 +0300;Update docs/topics/feed-exports.rst
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/feed-exports.rst
==================
8a3ba34a;Adrián Chaves;2020-08-31 16:43:32 +0200;Merge remote-tracking branch 'upstream/master' into http2

==
==================
e6dcfd3c;Adrián Chaves;2020-08-31 16:35:35 +0200;Merge pull request #4610 from adityaa30/h2-client-protocol
Add H2ClientProtocol
==
==================
a41c2059;Jose Galdos;2020-08-21 12:16:37 -0500;Update httpstatus documentation.

==

docs/topics/spider-middleware.rst
==================
eff33a2e;Aditya;2020-08-30 23:54:43 +0530;fix(h2): Mockserver test uses H2DownloadHandler

==

tests/test_downloader_handlers.py
tests/test_downloader_handlers_http2.py
==================
71d2c2f1;maranqz;2020-08-30 12:43:44 +0300;improve view of dict

==

tests/test_feedexport.py
==================
fc3c66ce;maranqz;2020-08-30 11:44:48 +0300;fix tests:  * FeedExportConfigTestCase.test_feed_complete_default_values_from_settings_empty  * FeedExportConfigTestCase.test_feed_complete_default_values_from_settings_non_empty

==

tests/test_utils_conf.py
==================
a8e895e6;maranqz;2020-08-30 10:57:22 +0300;kwargs for Item exporters classes test docs

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
scrapy/utils/conf.py
tests/test_feedexport.py
==================
be655b85;Mikhail Korobov;2020-08-29 13:31:20 +0500;Merge pull request #4765 from scrapy/simplify-test_crawl
Simplify tests/test_crawl
==
==================
5e9cc329;Mikhail Korobov;2020-08-29 13:28:38 +0500;Merge pull request #4324 from ammarnajjar/4307-use-f-strings
refactor: use f-strings
==
==================
90ca9350;Ammar Najjar;2020-08-29 08:03:03 +0000;Update scrapy/commands/check.py
Co-authored-by: Mikhail Korobov <kmike84@gmail.com>
==

scrapy/commands/check.py
==================
8123c427;Andrey Rakhmatullin;2020-08-28 18:31:09 +0500;Simplify running spiders in CrawlSpiderTestCase.

==

tests/test_crawl.py
==================
a8aedbeb;Aditya;2020-08-29 12:12:18 +0530;chore: rearrange imports

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
ffdf6fe1;Ammar Najjar;2020-08-29 07:21:48 +0200;use f-strings for the newly merged code from master
Issue: #4324

==

tests/spiders.py
==================
defeaacb;Ammar Najjar;2020-08-29 07:12:44 +0200;Merge branch 'master' into 4307-use-f-strings
Conflicts resolved:
- delete tests/py36/_test_crawl.py

==
==================
7e6476ff;Mikhail Korobov;2020-08-29 00:12:53 +0500;Merge pull request #4764 from scrapy/test_crawl-move-py36
Merge back tests/py36/_test_crawl.py.
==
==================
59a0157e;Andrey Rahmatullin;2020-08-28 18:41:02 +0500;Merge pull request #4722 from Gallaecio/umask
Do not let umask affect the permissions of startproject-generated files
==
==================
de640f41;Andrey Rakhmatullin;2020-08-28 18:27:36 +0500;Merge back tests/py36/_test_crawl.py.

==

conftest.py
tests/py36/_test_crawl.py
tests/spiders.py
tests/test_crawl.py
==================
0e579182;Ammar Najjar;2020-08-28 13:58:32 +0200;test(Slot): cover __repr__
Issue: #4324

==

scrapy/core/downloader/__init__.py
tests/test_core_downloader.py
==================
64905e33;Mikhail Korobov;2020-08-28 00:03:40 +0500;Merge pull request #4691 from elacuesta/typing-spider-attributes
Typing: annotate a few Spider attributes
==
==================
3f0a677c;Adrián Chaves;2020-08-27 20:56:58 +0200;Cover version directive usage in the documentation policy (#4310)
* Cover version directives in the documentation policy

* Remove version directives in preparation for Scrapy 2.0

* Update the policy based on the deprecation policy

* Only remove version directives after 3 years
==

docs/contributing.rst
docs/topics/api.rst
docs/topics/autothrottle.rst
docs/topics/benchmarking.rst
docs/topics/commands.rst
docs/topics/contracts.rst
docs/topics/downloader-middleware.rst
docs/topics/extensions.rst
docs/topics/feed-exports.rst
docs/topics/request-response.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
==================
195f738b;Adrián Chaves;2020-08-27 12:43:43 +0200;Update Python version references after dropping support for 3.5 (#4742)
* Update Python version references after dropping support for 3.5

* Remove outdated test

* Undo change affecting collect_asyncgen

* Undo change to be handled by #4743

* Remove unused import

* Remove unused import

* Update tests/requirements-py3.txt

Co-authored-by: Mikhail Korobov <kmike84@gmail.com>

Co-authored-by: Mikhail Korobov <kmike84@gmail.com>
==

README.rst
docs/intro/install.rst
docs/intro/tutorial.rst
docs/topics/coroutines.rst
scrapy/__init__.py
scrapy/utils/defer.py
scrapy/utils/gz.py
setup.py
tests/requirements-py3.txt
tests/test_crawl.py
tests/test_item.py
tests/test_proxy_connect.py
tox.ini
==================
5e36f539;Aditya;2020-08-27 15:12:22 +0530;chore: remove typing-extensions dependency

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
scrapy/core/http2/types.py
setup.py
tox.ini
==================
dd378b4b;Adrián Chaves;2020-08-27 11:07:58 +0200;Generate localhost keys for tests on the fly

==

.gitignore
conftest.py
tests/keys/__init__.py
tests/keys/localhost.crt
tests/keys/localhost.key
==================
a6b67cf4;Mikhail Korobov;2020-08-27 12:51:53 +0500;Merge pull request #4755 from maranqz/csv-item-exporter-errors
Add errors parameter for CsvItemExporter with tests
==
==================
5ab1a318;Ammar Najjar;2020-08-26 15:11:46 +0200;test: list appears in ValueError Exception message
Issue #4324

==

scrapy/utils/conf.py
tests/test_utils_conf.py
==================
a8114d37;Eugenio Lacuesta;2020-08-26 09:00:36 -0300;Typing: annotate a few Spider attributes

==

scrapy/spiders/__init__.py
scrapy/spiders/crawl.py
setup.cfg
tests/spiders.py
==================
450ba6b5;Aditya;2020-08-26 17:20:59 +0530;fix(typo): stream -> streams, use isinstance

==

scrapy/core/http2/protocol.py
==================
2ca8dfb4;Ammar Najjar;2020-08-26 13:49:39 +0200;revert f-string changes for files under sep/
Issue #4324

==

sep/sep-002.rst
sep/sep-004.rst
sep/sep-014.rst
sep/sep-018.rst
==================
7597193d;Ammar Najjar;2020-08-26 13:46:26 +0200;Merge branch 'master' into 4307-use-f-strings
Resolve Conflicts:
	tests/test_middleware.py

==
==================
9aaddcde;Ammar Najjar;2020-08-26 11:44:20 +0000;Update scrapy/utils/conf.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/utils/conf.py
==================
ea03e425;Ammar Najjar;2020-08-26 11:43:52 +0000;Update scrapy/http/request/form.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/http/request/form.py
==================
92dfa717;Ammar Najjar;2020-08-26 11:43:40 +0000;Update scrapy/extensions/statsmailer.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/extensions/statsmailer.py
==================
c7745099;Ammar Najjar;2020-08-26 11:41:24 +0000;Update scrapy/commands/version.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/commands/version.py
==================
29725e4b;maranqz;2020-08-26 14:38:37 +0300;Fix tabulation of rst and change documentation link.

==

docs/topics/exporters.rst
==================
cf50561b;nyov;2020-08-26 11:08:14 +0000;Allow passing classes directly in Settings (#3873)
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/settings.rst
scrapy/utils/deprecate.py
scrapy/utils/misc.py
tests/test_crawler.py
tests/test_downloader_handlers.py
tests/test_feedexport.py
tests/test_middleware.py
tests/test_settings/__init__.py
tests/test_spidermiddleware_referer.py
tests/test_utils_misc/__init__.py
==================
560c335c;maranqz;2020-08-26 14:00:51 +0300;Add errors parameter in documentation.

==

docs/topics/exporters.rst
==================
58ca8bbf;Ammar Najjar;2020-08-22 22:32:03 +0200;Use f-strings (#4307)

==

docs/conf.py
docs/intro/tutorial.rst
docs/topics/developer-tools.rst
docs/topics/exporters.rst
docs/topics/item-pipeline.rst
docs/topics/leaks.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/spiders.rst
extras/qps-bench-server.py
extras/qpsclient.py
scrapy/cmdline.py
scrapy/commands/__init__.py
scrapy/commands/bench.py
scrapy/commands/check.py
scrapy/commands/edit.py
scrapy/commands/genspider.py
scrapy/commands/parse.py
scrapy/commands/runspider.py
scrapy/commands/startproject.py
scrapy/commands/version.py
scrapy/contracts/__init__.py
scrapy/contracts/default.py
scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/s3.py
scrapy/core/downloader/middleware.py
scrapy/core/downloader/webclient.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/core/spidermw.py
scrapy/downloadermiddlewares/cookies.py
scrapy/downloadermiddlewares/httpproxy.py
scrapy/downloadermiddlewares/retry.py
scrapy/downloadermiddlewares/robotstxt.py
scrapy/downloadermiddlewares/stats.py
scrapy/exporters.py
scrapy/extensions/corestats.py
scrapy/extensions/debug.py
scrapy/extensions/httpcache.py
scrapy/extensions/memdebug.py
scrapy/extensions/memusage.py
scrapy/extensions/statsmailer.py
scrapy/http/common.py
scrapy/http/headers.py
scrapy/http/request/__init__.py
scrapy/http/request/form.py
scrapy/http/response/__init__.py
scrapy/http/response/text.py
scrapy/item.py
scrapy/link.py
scrapy/logformatter.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/pipelines/media.py
scrapy/pqueues.py
scrapy/responsetypes.py
scrapy/selector/unified.py
scrapy/settings/__init__.py
scrapy/settings/default_settings.py
scrapy/shell.py
scrapy/spiderloader.py
scrapy/spidermiddlewares/depth.py
scrapy/spidermiddlewares/httperror.py
scrapy/spidermiddlewares/offsite.py
scrapy/spidermiddlewares/referer.py
scrapy/spiders/__init__.py
scrapy/spiders/feed.py
scrapy/utils/benchserver.py
scrapy/utils/conf.py
scrapy/utils/curl.py
scrapy/utils/decorators.py
scrapy/utils/deprecate.py
scrapy/utils/engine.py
scrapy/utils/ftp.py
scrapy/utils/iterators.py
scrapy/utils/log.py
scrapy/utils/misc.py
scrapy/utils/project.py
scrapy/utils/python.py
scrapy/utils/reactor.py
scrapy/utils/reqser.py
scrapy/utils/response.py
scrapy/utils/serialize.py
scrapy/utils/ssl.py
scrapy/utils/test.py
scrapy/utils/testproc.py
scrapy/utils/testsite.py
scrapy/utils/trackref.py
scrapy/utils/url.py
sep/sep-002.rst
sep/sep-004.rst
sep/sep-014.rst
sep/sep-018.rst
tests/CrawlerRunner/ip_address.py
tests/mockserver.py
tests/py36/_test_crawl.py
tests/spiders.py
tests/test_cmdline/extensions.py
tests/test_command_check.py
tests/test_command_parse.py
tests/test_command_shell.py
tests/test_command_version.py
tests/test_commands.py
tests/test_contracts.py
tests/test_crawl.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware.py
tests/test_downloadermiddleware_decompression.py
tests/test_downloadermiddleware_httpcache.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_retry.py
tests/test_engine.py
tests/test_feedexport.py
tests/test_loader_deprecated.py
tests/test_logformatter.py
tests/test_middleware.py
tests/test_pipeline_crawl.py
tests/test_pipeline_files.py
tests/test_pipeline_images.py
tests/test_proxy_connect.py
tests/test_request_attribute_binding.py
tests/test_responsetypes.py
tests/test_selector.py
tests/test_signals.py
tests/test_spidermiddleware_output_chain.py
tests/test_utils_curl.py
tests/test_utils_datatypes.py
tests/test_utils_defer.py
tests/test_utils_iterators.py
tests/test_utils_url.py
tests/test_webclient.py
==================
0ccaf89a;Mikhail Korobov;2020-08-26 00:10:43 +0500;Merge pull request #4756 from ivanprado/master
Support for delegated methods as callbacks
==
==================
2f28cee3;Adrián Chaves;2020-08-25 17:49:17 +0200;Add a test to cover searching for a missing node name

==

tests/test_utils_iterators.py
==================
6eb1fc4a;Adrián Chaves;2020-08-25 17:01:54 +0200;Merge remote-tracking branch 'upstream/master' into fix_iternodes

==
==================
0524df86;Iván de Prado;2020-08-25 14:36:38 +0100;Code simplification.
Thanks @victor-torres for the suggestion

==

scrapy/utils/reqser.py
==================
067125c3;Andrey Rahmatullin;2020-08-25 18:35:50 +0500;Merge pull request #4752 from drs-11/master
DOWNLOAD_MAXSIZE logger level changed from Error to Warning
==
==================
39affea9;Adrián Chaves;2020-08-25 13:57:48 +0200;Fix style issues

==

tests/test_utils_reqser.py
==================
a2d6fa5a;maranqz;2020-08-25 13:34:43 +0300;Add errors parameter for CsvItemExporter with tests

==

scrapy/exporters.py
tests/test_exporters.py
==================
3e726b9d;Iván de Prado;2020-08-25 11:22:05 +0100;Support for delegated methods as callbacks
It can be useful to structure the spiders code around some helper classes.

==

scrapy/utils/reqser.py
tests/test_utils_reqser.py
==================
64e0ea4e;Andrey Rahmatullin;2020-08-25 11:48:31 +0500;Merge pull request #4735 from wRAR/ciphers-tests
Re-enable TLS 1.2 in cipher tests.
==
==================
0b3881d6;drs-11;2020-08-24 20:26:06 +0530;Reverted maxsize warning log message

==

scrapy/core/downloader/handlers/http11.py
==================
2d8ec9d4;WinterComes;2019-07-17 22:50:34 +0300;Change DOWNLOAD_MAXSIZE logger level from Error to Warning

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
==================
14321614;Aditya;2020-08-24 15:40:01 +0530;fix: bump min typing-extensions version to 3.7.4
- typing-extensions>=3.7.4 only supports TypedDict

==

setup.py
tox.ini
==================
26d344b7;Aditya;2020-08-24 14:58:23 +0530;Merge branch 'http2' of https://github.com/scrapy/scrapy into h2-client-protocol

==
==================
f1250177;Eugenio Lacuesta;2020-08-22 04:33:35 -0300;Remove Python 3.5 from CI (#4743)

==

.travis.yml
azure-pipelines.yml
tests/test_utils_python.py
tox.ini
==================
ba0e7f3c;Mikhail Korobov;2020-08-21 23:18:51 +0500;Merge pull request #4747 from Gallaecio/pylint-update
Skip checks introduced in Pylint 2.6.0
==
==================
7c076122;Adrián Chaves;2020-08-21 17:06:54 +0200;Skip checks introduced in Pylint 2.6.0

==

pylintrc
==================
afd3a4d1;Adrián Chaves;2020-08-21 17:04:02 +0200;Fix style issue

==

scrapy/utils/iterators.py
==================
e90be0d8;Adrián Chaves;2020-08-21 14:09:52 +0200;Mark the new test as xfail for xmliter_lxml

==

tests/test_utils_iterators.py
==================
d711eca4;Adrián Chaves;2020-08-21 13:52:52 +0200;Merge remote-tracking branch 'upstream/master' into fix_iternodes

==
==================
07b0c591;Andrey Rahmatullin;2020-08-21 12:36:13 +0500;Merge pull request #4745 from Yogendra0Sharma/fix4741
Removed appveyor.xml no longer needed
==
==================
2fbfe2c2;yogendra0sharma;2020-08-21 12:18:15 +0530;Removed appveyor.xml no longer needed

==

appveyor.yml
==================
d68aab99;Grisha Temchenko;2020-08-20 09:22:07 -0400;Smarter generator check for combined return/yield statements (#4721)

==

scrapy/utils/misc.py
tests/test_utils_misc/test_return_with_argument_inside_generator.py
==================
a57db9e3;Hugo van Kemenade;2020-08-19 18:45:24 +0300;Bitbucket no longer supports Mercurial repositories (#4738)

==

.travis.yml
setup.py
==================
42383cc2;sakshamb2113;2020-08-19 12:48:14 +0530;Add a setting to customize the asyncio event loop (#4414)

==

docs/topics/asyncio.rst
docs/topics/settings.rst
scrapy/crawler.py
scrapy/settings/default_settings.py
scrapy/utils/log.py
scrapy/utils/reactor.py
tests/CrawlerProcess/asyncio_custom_loop.py
tests/requirements-py3.txt
tests/test_commands.py
tests/test_crawler.py
==================
2f00666d;Aditya;2020-08-19 07:31:52 +0530;refactor: move agents & context-factory

==

scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/agent.py
==================
30eb0056;Aditya;2020-08-19 06:25:04 +0530;fix: InvalidNegotiatedProtocol __str__ method

==

scrapy/core/http2/agent.py
scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
e3233b79;Aditya;2020-08-19 05:10:19 +0530;refactor(h2-stream): alphabetical order of imports

==

scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/stream.py
==================
a206ac5f;Aditya;2020-08-18 07:36:00 +0530;tests: disable python 3.5 for travis and azure

==

.travis.yml
azure-pipelines.yml
==================
a87ab71d;Aditya;2020-08-18 04:47:09 +0530;refactor(http2): metadata for Stream
- Add Note about HTTP/2 Cleartext not supported in settings.rst

==

docs/topics/settings.rst
scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
scrapy/core/http2/types.py
setup.py
tests/test_downloader_handlers.py
==================
d9e69bfb;Andrey Rakhmatullin;2020-08-17 19:46:24 +0500;Re-enable TLS 1.2 in cipher tests.

==

tests/mockserver.py
==================
e70975f0;Adrián Chaves;2020-08-17 15:10:08 +0200;Allow overwriting feeds (#4512)
Co-authored-by: Yuval Hager <yhager@yhager.com>
==

docs/faq.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/feed-exports.rst
scrapy/commands/__init__.py
scrapy/extensions/feedexport.py
scrapy/utils/conf.py
scrapy/utils/ftp.py
scrapy/utils/python.py
tests/ftpserver.py
tests/mockserver.py
tests/requirements-py3.txt
tests/test_commands.py
tests/test_feedexport.py
tests/test_utils_conf.py
tests/test_utils_python.py
==================
282a6d4f;Mikhail Korobov;2020-08-17 14:06:58 +0500;Merge pull request #4727 from wRAR/mitmproxy-ca
Use a longer key in mitmproxy-ca.pem.
==
==================
61459de4;Mikhail Korobov;2020-08-17 13:58:32 +0500;Merge pull request #4688 from ashellunts/obsolete-s3feednokeys
Remove obsolete S3FeedStorage instancing without AWS credentials
==
==================
792d2938;Adrián Chaves;2020-08-17 10:54:58 +0200;Merge Twisted’s deprecated HTTPClientFactory into ScrapyHTTPClientFactory (#4165)
* Port code from Twisted’s deprecated HTTPClientFactory into ScrapyHTTPClientFactory

* Mention that ScrapyHTTPClientFactory has Twisted code
==
==================
5ac135f0;Mikhail Korobov;2020-08-17 13:54:45 +0500;Merge pull request #4718 from Gallaecio/support-pinned-3.6
Upgrade minimum dependencies for Python 3.6 support
==
==================
55edf8d3;Grammy Jiang;2020-08-17 18:50:52 +1000;Add typing hint to httpcache downloadermiddlewares (#4243)

==

scrapy/downloadermiddlewares/httpcache.py
==================
a8e08d51;Ajay Mittur;2020-08-17 14:15:52 +0530;Check if file is already present on running `scrapy genspider` and terminate if so (#4623)

==

scrapy/commands/genspider.py
tests/test_commands.py
==================
2aa4f3cb;Eugenio Lacuesta;2020-08-17 05:39:59 -0300;Conditional request attribute binding for responses (#4632)

==

docs/topics/signals.rst
scrapy/core/engine.py
scrapy/core/scraper.py
setup.cfg
tests/test_request_attribute_binding.py
==================
75fe3d13;adityaa30;2020-08-17 03:47:17 +0530;fix: increase timeout to 0.5 seconds
- In Windows specifically the reactor was left unclean by the
  HostnameEndpoint due to the tearDown method of
  test_downloader_handlers.py::HttpTestCase due to
  which the following 2 tests were failing:
  1. test_timeout_download_from_spider_server_hangs
  2. test_timeout_download_from_spider_nodata_rcvd
- Increasing the timeout fixed the test (in local)

==

setup.cfg
tests/test_downloader_handlers.py
tests/test_downloader_handlers_http2.py
==================
38d36179;Aditya;2020-08-16 17:55:16 +0530;fix: typing & pylint errors
- Ignore typing check for http2 test files

==

scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/protocol.py
setup.cfg
==================
f9f008e9;Aditya;2020-08-16 17:04:40 +0530;test: add typing-extensions

==

.travis.yml
setup.py
tox.ini
==================
d97cf973;Aditya;2020-08-16 11:31:10 +0530;Merge branch 'master' of https://github.com/scrapy/scrapy into h2-client-protocol

==
==================
af73f141;Aditya;2020-08-16 11:26:10 +0530;refactor: move all http2 tests in separate files

==

tests/test_download_handlers_http2.py
tests/test_downloader_handlers.py
==================
756c368a;Andrey Rakhmatullin;2020-08-14 22:09:24 +0500;Use a longer key in mitmproxy-ca.pem.

==

tests/keys/mitmproxy-ca.pem
==================
acb3b443;Andrey Rahmatullin;2020-08-14 14:47:55 +0500;Merge pull request #4724 from Gallaecio/feed-uri-params
Document FEED_URI_PARAMS
==
==================
61653418;Mikhail Korobov;2020-08-14 00:58:06 +0500;Merge pull request #4090 from Gallaecio/documentation-build
Fix references to Python types in parameter type fields
==
==================
cd0d3fd4;Mikhail Korobov;2020-08-14 00:27:37 +0500;Merge pull request #4705 from Gallaecio/deprecation-policy
Cover our deprecation policy in the documentation
==
==================
1f44464a;Mikhail Korobov;2020-08-14 00:23:55 +0500;Merge pull request #4723 from Gallaecio/windows
test_utils_iterators.py: support Windows the right way
==
==================
65e0abae;Adrián Chaves;2020-08-13 09:05:51 +0200;Document FEED_URI_PARAMS

==

docs/topics/feed-exports.rst
==================
24ba5a71;Adrián Chaves;2020-08-13 06:35:09 +0200;Maybe the problem is not in the code after all

==

.gitattributes
tests/__init__.py
==================
5f4df622;Adrián Chaves;2020-08-13 05:41:06 +0200;test_utils_iterators.py: support Windows the right way

==

tests/__init__.py
tests/test_utils_iterators.py
==================
4c0afb60;Adrián Chaves;2020-08-12 17:45:26 +0200;Update permission expectations

==

tests/test_commands.py
==================
125a0583;Adrián Chaves;2020-08-12 17:07:21 +0200;Do not let umask affect the permissions of startproject-generated files

==

scrapy/utils/template.py
tests/test_commands.py
==================
b1de55d3;Adrián Chaves;2020-08-12 12:34:40 +0200;Fix marker syntax

==

tests/requirements-py3.txt
==================
8e393a0b;Adrián Chaves;2020-08-12 12:29:51 +0200;Do not change the mitmproxy version for no-3.6 Python versions

==

tests/requirements-py3.txt
==================
394631fc;Adrián Chaves;2020-08-12 12:08:09 +0200;Restore 3.5 support for mitmproxy-based tests

==

tests/requirements-py3.txt
==================
1c4b4cc6;Ajay Mittur;2020-08-11 17:42:44 +0530;Support defining file path based on item in media pipelines (#4686)

==

docs/topics/media-pipeline.rst
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/pipelines/media.py
tests/test_pipeline_files.py
tests/test_pipeline_media.py
==================
b2f4df5c;Adrián Chaves;2020-08-11 13:16:14 +0200;Merge remote-tracking branch 'upstream/master' into documentation-build

==
==================
aefd43a6;Adrián Chaves;2020-08-11 12:52:54 +0200;Upgrade minimum dependencies for Python 3.6 support

==

tests/requirements-py3.txt
tox.ini
==================
90f85a2b;Adrián Chaves;2020-08-11 10:20:30 +0200;Enable Travis CI

==

.travis.yml
==================
c67d6dea;Aditya;2020-08-11 04:39:41 +0530;fix: H2 docs, NotImplementedError for H2 Tunnel

==

docs/topics/settings.rst
scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/stream.py
tests/test_downloader_handlers.py
==================
0cf1340c;Andrey Rahmatullin;2020-08-10 16:18:29 +0500;Merge pull request #4663 from ajaymittur28/scrapy-check-test
Add Tests to `scrapy check` command
==
==================
702de048;Andrey Rahmatullin;2020-08-10 16:14:42 +0500;Merge pull request #4564 from jacty/patch-1
Unnecessary update when value is None
==
==================
e0c3019d;Aditya;2020-08-09 16:19:35 +0530;fix: ScrapyProxyH2Agent
- add required test cases

BREAKING CHANGES
Presently the tests (in test_downloader_handlers.py)
1. test_download_without_proxy
2. test_download_with_proxy_https_timeout

collide with each other when run together. However, if both of the tests
are ran individually then both pass.

==

scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/agent.py
scrapy/core/http2/stream.py
tests/test_downloader_handlers.py
==================
13181ba7;Jose Galdos;2020-07-23 18:45:45 -0500;Improve http status all on http error middleware

==

scrapy/spidermiddlewares/httperror.py
tests/test_spidermiddleware_httperror.py
==================
1cc8d582;Adrián Chaves;2020-08-06 13:52:47 +0200;Remove unneeded try-except
Exceptions only happen when find_spec gets a 2nd parameter.

==

scrapy/commands/startproject.py
==================
cad84458;Andrey Rahmatullin;2020-08-06 12:17:04 +0500;Merge pull request #4714 from linchiwei123/fix
Remove duplicated install_requires
==
==================
4dc09f09;linchiwei123;2020-08-05 22:23:19 +0800;Update setup.py

==

setup.py
==================
1f0722c8;Andrey Rahmatullin;2020-08-05 17:48:41 +0500;Merge pull request #4701 from kshitijcode/weakkeycache-cleanup-4684
Code cleanup scrapy.utils.python.WeakKeyCache #4684
==
==================
983b7ddf;Kshitij Sharma;2020-08-05 16:13:52 +0530;aesthetic fixes

==

scrapy/utils/python.py
==================
b35d1f2b;Kshitij Sharma;2020-08-05 09:14:04 +0530;deleted tester.py

==

scrapy/utils/tester.py
==================
9d842891;Kshitij Sharma;2020-08-05 09:11:59 +0530;deprecated weakkeycache by specifying in __init__

==

scrapy/utils/python.py
scrapy/utils/tester.py
tests/test_utils_python.py
==================
336f19f5;Marc Hernández;2020-08-04 20:42:01 +0200;Change super syntax (#4707)

==

extras/qpsclient.py
scrapy/commands/view.py
scrapy/contracts/default.py
scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/tls.py
scrapy/core/spidermw.py
scrapy/crawler.py
scrapy/downloadermiddlewares/redirect.py
scrapy/exceptions.py
scrapy/exporters.py
scrapy/http/headers.py
scrapy/http/request/form.py
scrapy/http/request/json_request.py
scrapy/http/request/rpc.py
scrapy/http/response/text.py
scrapy/item.py
scrapy/linkextractors/__init__.py
scrapy/linkextractors/lxmlhtml.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/resolver.py
scrapy/selector/unified.py
scrapy/settings/__init__.py
scrapy/spidermiddlewares/httperror.py
scrapy/spiders/crawl.py
scrapy/spiders/init.py
scrapy/spiders/sitemap.py
scrapy/squeues.py
scrapy/statscollectors.py
scrapy/utils/datatypes.py
scrapy/utils/deprecate.py
scrapy/utils/log.py
scrapy/utils/serialize.py
scrapy/utils/testsite.py
tests/spiders.py
tests/test_command_parse.py
tests/test_commands.py
tests/test_contracts.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_httpcache.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_exporters.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_item.py
tests/test_linkextractors.py
tests/test_loader.py
tests/test_loader_deprecated.py
tests/test_logformatter.py
tests/test_middleware.py
tests/test_pipeline_media.py
tests/test_request_left.py
tests/test_robotstxt_interface.py
tests/test_scheduler.py
tests/test_spidermiddleware_httperror.py
==================
4ee538e4;Adrián Chaves;2020-08-04 20:34:11 +0200;Update unicode references from Python 2 times in the documentation (#4703)

==

docs/topics/exporters.rst
docs/topics/loaders.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
==================
1278e76d;Adrián Chaves;2020-08-04 20:07:02 +0200;Bump version: 2.2.0 → 2.3.0

==

.bumpversion.cfg
scrapy/VERSION
==================
3600582f;Adrián Chaves;2020-08-04 20:05:56 +0200;Cover Scrapy 2.2.1 and 2.3 in the release notes (#4708)

==

docs/news.rst
docs/topics/commands.rst
docs/topics/developer-tools.rst
docs/topics/feed-exports.rst
scrapy/utils/curl.py
==================
015b71d8;Mikhail Korobov;2020-07-31 01:23:00 +0500;Merge pull request #4704 from Gallaecio/python2-u-prefixes
Remove the u prefix from strings
==
==================
5ec66be4;Artur Shellunts;2020-07-30 22:18:00 +0200;Merge branch 'master' into obsolete-s3feednokeys

==
==================
d707f8b5;Aditya;2020-07-30 18:06:21 +0530;docs: mention H2DownloadHandler in settings.rst

==

docs/topics/settings.rst
==================
6f4ccec5;Adrián Chaves;2020-07-30 14:03:14 +0200;Cover our deprecation policy in the documentation

==

docs/contributing.rst
docs/versioning.rst
==================
890b2138;Adrián Chaves;2020-07-30 13:39:30 +0200;Remove the u prefix from strings

==

docs/_ext/scrapydocs.py
docs/topics/loaders.rst
docs/topics/selectors.rst
docs/utils/linkfix.py
scrapy/http/request/form.py
scrapy/linkextractors/lxmlhtml.py
scrapy/logformatter.py
tests/test_cmdline/__init__.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_cookies.py
tests/test_downloadermiddleware_httpproxy.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_exporters.py
tests/test_feedexport.py
tests/test_http_headers.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_item.py
tests/test_linkextractors.py
tests/test_loader.py
tests/test_loader_deprecated.py
tests/test_logformatter.py
tests/test_mail.py
tests/test_responsetypes.py
tests/test_robotstxt_interface.py
tests/test_selector.py
tests/test_spider.py
tests/test_utils_iterators.py
tests/test_utils_python.py
tests/test_utils_reqser.py
tests/test_utils_template.py
==================
a3fecaf0;Aditya;2020-07-30 15:45:27 +0530;test: fix host-name H2DownloadHandler tests

==

tests/test_downloader_handlers.py
==================
49337bd2;Kshitij Sharma;2020-07-30 12:25:21 +0530;Code cleanup scrapy.utils.python.WeakKeyCache #4684 and fixing ci alerts

==

scrapy/utils/python.py
==================
33ddc3d4;Kshitij Sharma;2020-07-30 09:47:08 +0530;Trigger CI

==
==================
5e2d1bd1;Mikhail Korobov;2020-07-29 23:03:28 +0500;Merge pull request #4434 from BroodingKangaroo/ISSUE-4250-add_batch_deliveries
Feed exports: add batch deliveries
==
==================
403bc702;Kshitij Sharma;2020-07-29 18:05:33 +0530;Code cleanup scrapy.utils.python.WeakKeyCache #4684 and fixing ci alerts

==

tests/test_utils_python.py
==================
19f2b4b5;Aditya;2020-07-29 17:25:59 +0530;refactor: AcceptableProtocolsContextFactory
- rename H2WrappedContextFactory to AcceptableProtocolsContextFactory
- AcceptableProtocolsContextFactory accepts an argument
acceptable_protocols which can be used to override the context factory
priority list of protocols during ALPN or NPN

==

scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/agent.py
scrapy/core/http2/stream.py
==================
e8342996;Aditya;2020-07-29 13:51:01 +0530;test: H2DownloadHandler
Following tests are skipped as Content-Length header not matching the
data received is considered as a ProtocolError
- test_download_broken_content_cause_data_loss
- test_download_broken_chunked_content_cause_data_loss
- test_download_broken_content_allow_data_loss
- test_download_broken_chunked_content_allow_data_loss
- test_download_broken_content_allow_data_loss_via_setting
- test_download_broken_chunked_content_allow_data_loss_via_setting

BREAKING CHANGES
The following tests currently fail
- test_content_length_zero_bodyless_post_request_headers
- test_host_header_seted_in_request_headers
- test_download_with_maxsize_very_large_file

==

tests/test_downloader_handlers.py
==================
92bec385;Aditya;2020-07-29 13:43:59 +0530;feat: MethodNotAllowed405, Content-Length header
- add tests to check for Content-Length header
- raise MethodNotAllowed405 when remote send 'HTTP/2.0 405 Method Not
Allowed'

==

scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/agent.py
scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
e7a58fe1;Kshitij Sharma;2020-07-29 10:16:18 +0530;Code cleanup scrapy.utils.python.WeakKeyCache #4684

==

scrapy/utils/python.py
tests/test_utils_python.py
==================
52658539;Eugenio Lacuesta;2020-07-28 06:15:14 -0300;Use ItemAdapter.field_names when writing header in CsvItemExporter (#4668)

==

scrapy/exporters.py
tests/test_exporters.py
==================
a6c1d79b;BroodingKangaroo;2020-07-28 11:53:05 +0300;pep8 tiny changes

==

docs/topics/feed-exports.rst
==================
ce0c25fc;Mikhail Korobov;2020-07-23 17:56:08 +0500;Merge pull request #4690 from elacuesta/typing-setup-remove-monkeypatches
Remove monkeypatches module from mypy section in setup.cfg
==
==================
8fae3d5b;Eugenio Lacuesta;2020-07-22 16:08:35 -0300;Remove monkeypatches module from mypy section in setup.cfg

==

setup.cfg
==================
031bfc9c;Aditya;2020-07-22 15:01:59 +0530;feat(wip): ScrapyH2Agent, ScrapyProxyH2Agent

==

scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/agent.py
==================
62ce842a;Aditya;2020-07-15 07:50:53 +0530;fix: multiple h2 connections to same uri
- When multiple requests are sent to H2ConnectionPool to the same uri
while the connection is in connecting state -- multiple connections were
establised.
- Fixed the bug using a deque of all the request deferred's which fire
with the H2ClientProtocol (connection) instance when connection is
established

==

scrapy/core/http2/agent.py
==================
8252a6f8;Aditya;2020-07-15 04:58:59 +0530;fix: H2Agent not able to connect via SSL
- add H2WrappedContextFactory class which wraps the context factory
passed to H2Agent and updates the SSL context acceptable protocols list
to only h2

==

scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/agent.py
==================
9fffb801;Aditya;2020-07-08 20:18:38 +0530;feat: H2Agent, H2ConnectionPool base implementation

==

scrapy/core/downloader/handlers/http2.py
scrapy/core/http2/agent.py
==================
3685e99c;Aditya;2020-07-22 14:47:20 +0530;test: http2 connection timeout

==

tests/test_http2_client_protocol.py
==================
316620b5;Aditya;2020-07-22 13:53:46 +0530;chore: pass spider as argument for request method
- download_maxsize and download_warnsize can now be extracted from the
spider directly and passed to the stream
- remove `partial` flag from the response as per RFC 7540 - Section
8.1.2.6

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
430d22e4;Artur Shellunts;2020-07-21 23:39:04 +0200;Remove not used import warnings

==

tests/test_feedexport.py
==================
2829cd42;nyov;2020-03-17 10:19:13 +0000;Allow use without credentials

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
98e8086d;nyov;2020-03-07 19:21:09 +0000;Adapt S3FeedStorage testcase

==

tests/test_feedexport.py
==================
234c8b8c;nyov;2020-03-07 19:31:56 +0000;Removing deprecated S3FeedStorage without AWS keys instancing.

==

scrapy/extensions/feedexport.py
==================
ece4fa6c;nyov;2020-03-07 19:21:45 +0000;Fix ignored testcase: boto is never installed

==

tests/test_feedexport.py
==================
f3372a37;Andrey Rahmatullin;2020-07-21 17:37:54 +0500;Merge pull request #4254 from elacuesta/spider.parse
Change Scraper API to call internal `_parse` method
==
==================
de297a3a;Akshay Sharma;2020-07-20 17:53:38 +0530;enable ANSI color (instead of ANSI color codes) in the Windows terminal #4393 (#4403)
* changed ie. -> i.e.(spelling error) on lines 667, 763 (issue scrapy#4332)

* updated all text files for issue #4332 (ie. -> i.e.)

* Apply ie. → i.e. in source comments

* ie → e.g.

* modified scrapy/utils/display.py to stop ANSI color sequences in the Windows terminal (issue #4393)

* modified scrapy/utils/display.py to stop ANSI color sequences in the Windows terminal (issue #4393)

* enabled virtual terminal processing (pr #4403)

* check for specific windows 10 version (pr #4403)

* fixing flake-8 test (pr #4403)

* added error handling for terminal info (pr #4403)

* corrected stderr (pr #4403)

* changed orientation, removed unwanted spaces (pr #4403)

* no need for style variable (pr #4403)

* fixing trailing whitespaces

* commenting windows check

* Update scrapy/utils/display.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update scrapy/utils/display.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update scrapy/utils/display.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update scrapy/utils/display.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* small fixes

* Shifting _color_support_info() function

* enabled virtual terminal processing (pr #4403)

* check for specific windows 10 version (pr #4403)

* fixing flake-8 test (pr #4403)

* added error handling for terminal info (pr #4403)

* corrected stderr (pr #4403)

* changed orientation, removed unwanted spaces (pr #4403)

* no need for style variable (pr #4403)

* fixing trailing whitespaces

* commenting windows check

* Update scrapy/utils/display.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update scrapy/utils/display.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update scrapy/utils/display.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update scrapy/utils/display.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* small fixes

* Shifting _color_support_info() function

* error handling

* error handlingy

* raise ValueError

* added in-built function for version comparison

* recommit changes

* changed check -> parse

* version comparison -> parse_version

* added scrapy/utils/display.py in pytest.ini

* Trigger

* Add simple test for scrapy.utils.display._colorize

* Flake8: E501 for tests/test_utils_display.py

* assertEquals -> assertEqual

* Normal formatter for all platforms

* separate test for windows

* all curses under try block

* added global TestStr

* more test added

* small fix

* covering exceptions

* windows test failing

* Refactor output color handling

* Fix pprint test

* fix flake8

Co-authored-by: Adrián Chaves <adrian@chaves.io>
Co-authored-by: Eugenio Lacuesta <eugenio.lacuesta@gmail.com>
==

scrapy/utils/display.py
tests/test_utils_display.py
==================
3e049274;BroodingKangaroo;2020-07-19 00:10:29 +0300;Another try to fix test errors on Windows

==

tests/test_feedexport.py
==================
86f7ac2f;BroodingKangaroo;2020-07-17 17:48:25 +0300;Try to fix error at Windows

==

tests/test_feedexport.py
==================
62a4ede5;Artur Shellunts;2020-07-17 12:40:04 +0200;Remove deprecated classes BaseSgmlLinkExtractor, RegexLinkExtractor and SgmlLinkExtractor (#4356)

==

scrapy/linkextractors/regex.py
scrapy/linkextractors/sgml.py
tests/ignores.txt
tests/sample_data/link_extractor/linkextractor.html
tests/sample_data/link_extractor/linkextractor_latin1.html
==================
d29bec60;Adrián Chaves;2020-07-16 23:19:24 +0200;Upgrade PyPy for CI, and test both 3.5 (oldest) and 3.6 (newest) (#4504)
* Upgrade PyPy for CI, and test both 3.5 (oldest) and 3.6 (newest)

* Log a detailed error message to discover why MockServer is not working

* Go for all lines!

* Disable tests based on mitmproxy while running on PyPy

* Fix test_get_func_args for PyPy 3.6+

* Make testPayloadDefaultCiphers work regardless of OpenSSL default ciphers

* Crossing fingers…

* Rename: testPayloadDefaultCiphers → testPayloadDisabledCipher

* Test the PyPy version currently documented as the minimum required version

* Fix the PYPY_VERSION tag

* Update the documentation about supported PyPy versions

* Also test the latest 3.5 Python version with PyPy

* Fix the PYPY_VERSION value for the latest 3.5 version

* Use pinned dependencies for asyncio and PyPy tests against oldest supported Python versions

* Fix PyPy installation for the pypy3-pinned Tox environment

* Try installing Cython

* Maybe PyPy requires lxml 3.6.0?

* install.rst: minor clarification

* lxml 4.0.0 is required on PyPy

* Require setuptools 18.5+

* Revert "Require setuptools 18.5+"

This reverts commit 017ec33ac2d237523cdd53be9be8169dd540759e.

* Maintain lxml as a dependency if setuptools < 18.5 is used
==

.travis.yml
docs/faq.rst
docs/intro/install.rst
setup.py
tests/test_proxy_connect.py
tests/test_utils_python.py
tests/test_webclient.py
tox.ini
==================
9a74a71c;Mikhail Korobov;2020-07-16 23:58:58 +0500;Merge pull request #4682 from noviluni/remove_python2_reminiscence
remove python 2 reminiscence in cookies
==
==================
c4f92502;Adrián Chaves;2020-07-16 17:44:18 +0200;Merge branch 'master' into ISSUE-4250-add_batch_deliveries

==
==================
41263f61;BroodingKangaroo;2020-07-16 18:41:45 +0300;Change single quotes to double in example in docs

==

docs/topics/feed-exports.rst
==================
b97a39fd;Marc Hernández;2020-07-16 17:38:22 +0200;deprecate retry_on_eintr (#4683)

==

scrapy/utils/python.py
==================
07470e1a;Mikhail Korobov;2020-07-16 18:11:19 +0500;Merge pull request #3608 from ejulio/feat-685
[MRG+1] Fix for #685 Add Google Cloud Storage Feed Export
==
==================
0f2f1acf;Mikhail Korobov;2020-07-16 18:09:31 +0500;Merge pull request #4458 from scrapy/azure-pipelines
Set up CI with Azure Pipelines
==
==================
0e0d1ad6;Marc;2020-07-16 14:19:46 +0200;remove python 2 reminiscence in cookies

==

scrapy/http/cookies.py
tests/test_http_cookies.py
==================
8bdcdb0a;BroodingKangaroo;2020-07-16 09:13:54 +0300;Add quotes to example in docs

==

docs/topics/feed-exports.rst
==================
38496a00;Júlio César Batista;2020-07-15 07:08:36 -0300;Use the itemlaoders library (#4516)

==

docs/conf.py
docs/topics/loaders.rst
scrapy/loader/__init__.py
scrapy/loader/common.py
scrapy/loader/processors.py
scrapy/utils/misc.py
setup.cfg
setup.py
tests/requirements-py3.txt
tests/test_loader.py
tests/test_loader_deprecated.py
==================
eb1bc744;Andrey Rahmatullin;2020-07-15 12:51:42 +0500;Merge pull request #4674 from ashellunts/delete_deprecated_htmlparserlinkextractor
Remove deprecated class HtmlParserLinkExtractor
==
==================
e662762e;Aditya;2020-07-15 03:45:32 +0530;chore: Handle ConnectionTerminated event

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
1dd27a92;Aditya;2020-07-14 17:58:22 +0530;feat: Idle Timeout for H2Connection (240s)

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
ed5247ca;Artur Shellunts;2020-07-14 18:06:11 +0200;Remove htmlparser.py from tests/ignore.txt

==

tests/ignores.txt
==================
6e119bd3;Adrián Chaves;2020-07-14 11:26:19 +0200;Merge branch 'master' into azure-pipelines

==
==================
aeaeb738;Aditya;2020-07-14 03:55:14 +0530;feat: assert negotiated protocol as h2
- implement IHandshakeListener in H2ClientProtocol to know when
handshake is completed
- implement IProtocolNegotiationFactory in H2ClientFactory to provide
information about the acceptableProtols (h2) during NPN or ALPN protocol

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
544c1f6e;Adrián Chaves;2020-07-13 16:30:34 +0200;Fix the issue

==

scrapy/commands/startproject.py
tests/test_commands.py
==================
07709610;Adrián Chaves;2020-07-13 16:05:57 +0200;Write a test for #4665

==

tests/test_commands.py
==================
53c323b1;Adrián Chaves;2020-07-13 15:29:30 +0200;_is_path → _is_filesystem_path

==

scrapy/utils/url.py
tests/test_utils_url.py
==================
d54c4496;Adrián Chaves;2020-07-13 14:36:33 +0200;Refactor guess_scheme

==

scrapy/utils/url.py
tests/test_utils_url.py
==================
0ebba175;Andrey Rahmatullin;2020-07-13 16:01:06 +0500;Merge pull request #4666 from Gallaecio/execution-access
Fix permission handling on project generation from template files
==
==================
b6f8693d;Andrey Rahmatullin;2020-07-13 11:14:00 +0500;Merge pull request #4673 from elacuesta/remove-backslash
Remove backslash
==
==================
64c6af10;Aditya;2020-07-13 00:57:49 +0530;refactor: use str instead of to_unicode

==

scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
3f7e8635;Aditya Kumar;2020-07-11 12:18:24 +0530;Allow the parse command to write data to a file  (#4377)

==

docs/topics/commands.rst
scrapy/commands/__init__.py
scrapy/commands/parse.py
tests/test_command_parse.py
==================
a6a5fa91;Artur Shellunts;2020-07-10 23:10:49 +0200;Remove deprecated class HtmlParserLinkExtractor
Issue #4356

==

scrapy/linkextractors/htmlparser.py
==================
cbe4dc57;Ajay Mittur;2020-07-10 18:22:43 +0530;Update pytest.ini

==

pytest.ini
==================
9aea1f09;Eugenio Lacuesta;2020-07-09 11:04:46 -0300;Remove backslash (tests)

==

tests/test_downloadermiddleware_httpcompression.py
tests/test_downloadermiddleware_redirect.py
tests/test_selector.py
tests/test_settings/__init__.py
tests/test_spider.py
tests/test_spidermiddleware_referer.py
tests/test_utils_curl.py
tests/test_utils_defer.py
tests/test_utils_iterators.py
tests/test_utils_request.py
tests/test_utils_response.py
tests/test_utils_sitemap.py
tests/test_utils_url.py
tests/test_webclient.py
==================
9e99be98;Eugenio Lacuesta;2020-06-17 15:52:57 -0300;Remove backslash

==

scrapy/cmdline.py
scrapy/commands/crawl.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/startproject.py
scrapy/commands/view.py
scrapy/core/engine.py
scrapy/downloadermiddlewares/redirect.py
scrapy/downloadermiddlewares/retry.py
scrapy/extensions/memusage.py
scrapy/http/request/form.py
scrapy/http/response/text.py
scrapy/link.py
scrapy/settings/__init__.py
scrapy/utils/benchserver.py
scrapy/utils/conf.py
scrapy/utils/curl.py
scrapy/utils/ossignal.py
scrapy/utils/response.py
scrapy/utils/spider.py
==================
2be2bdd2;Eugenio Lacuesta;2020-07-08 14:00:54 -0300;Merge remote-tracking branch 'upstream/master' into spider.parse

==
==================
75bff7b6;ajaymittur28;2020-07-08 19:48:42 +0530;Update url contract value

==

tests/test_command_check.py
==================
2ea7d825;Aditya;2020-07-08 18:57:13 +0530;feat: H2ClientFactory

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
scrapy/core/http2/types.py
tests/test_http2_client_protocol.py
==================
3e98ed24;ajaymittur28;2020-07-08 17:13:57 +0530;Convert f-string to .format()

==

tests/test_command_check.py
==================
b6d4f28e;Ajay Mittur;2020-07-08 15:13:37 +0530;Merge branch 'master' into scrapy-check-test

==
==================
7e386157;Adrián Chaves;2020-07-07 15:30:19 +0200;Remove unused import

==

tests/test_commands.py
==================
ca77ca1f;Adrián Chaves;2020-07-07 14:44:03 +0200;Generate read-only files on the fly

==

scrapy/commands/startproject.py
tests/sample_data/read_only_templates/project/module/__init__.py
tests/sample_data/read_only_templates/project/module/items.py.tmpl
tests/sample_data/read_only_templates/project/module/middlewares.py.tmpl
tests/sample_data/read_only_templates/project/module/pipelines.py.tmpl
tests/sample_data/read_only_templates/project/module/settings.py.tmpl
tests/sample_data/read_only_templates/project/module/spiders/__init__.py
tests/sample_data/read_only_templates/project/scrapy.cfg
tests/sample_data/read_only_templates/spiders/basic.tmpl
tests/sample_data/read_only_templates/spiders/crawl.tmpl
tests/sample_data/read_only_templates/spiders/csvfeed.tmpl
tests/sample_data/read_only_templates/spiders/xmlfeed.tmpl
tests/test_commands.py
==================
e1450799;Adrián Chaves;2020-07-07 14:11:37 +0200;Remove debug test case variable

==

tests/test_commands.py
==================
a3afff4a;Adrián Chaves;2020-07-07 14:11:02 +0200;Fix style issue

==

tests/test_commands.py
==================
79b4dfc5;Adrián Chaves;2020-07-07 14:07:04 +0200;Fix permission handling on project generation from template files

==

scrapy/commands/startproject.py
tests/sample_data/read_only_templates/project/module/__init__.py
tests/sample_data/read_only_templates/project/module/items.py.tmpl
tests/sample_data/read_only_templates/project/module/middlewares.py.tmpl
tests/sample_data/read_only_templates/project/module/pipelines.py.tmpl
tests/sample_data/read_only_templates/project/module/settings.py.tmpl
tests/sample_data/read_only_templates/project/module/spiders/__init__.py
tests/sample_data/read_only_templates/project/scrapy.cfg
tests/sample_data/read_only_templates/spiders/basic.tmpl
tests/sample_data/read_only_templates/spiders/crawl.tmpl
tests/sample_data/read_only_templates/spiders/csvfeed.tmpl
tests/sample_data/read_only_templates/spiders/xmlfeed.tmpl
tests/test_commands.py
==================
1c40dfa7;Aditya;2020-07-07 00:44:09 +0530;fix: handle CONNECTION_LOST & RESET separately

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
scrapy/utils/log.py
tests/test_http2_client_protocol.py
tox.ini
==================
d0148406;ajaymittur28;2020-07-07 15:24:33 +0530;Ignore flake8 E501 for `scrapy check` tests`

==

pytest.ini
==================
770a8127;ajaymittur28;2020-07-07 15:23:29 +0530;Added basic `scrapy check` tests

==

tests/test_command_check.py
==================
54e4228c;Eugenio Lacuesta;2020-07-06 14:10:45 -0300;refactor: use protocol
- H2ClientProtocol.close_stream
- Fix and add missing type hints
- More adjustments
- Rename stream id generator
- Simplify decrement
==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
f1020e0e;BroodingKangaroo;2020-07-06 15:40:53 +0300;Tiny changes

==

scrapy/extensions/feedexport.py
==================
17aec594;Adrián Chaves;2020-07-06 10:47:25 +0200;Update tests/CrawlerRunner/ip_address.py
Co-authored-by: Eugenio Lacuesta <1731933+elacuesta@users.noreply.github.com>
==

tests/CrawlerRunner/ip_address.py
==================
ec06cf79;Adrián Chaves;2020-07-06 10:47:11 +0200;Update tests/CrawlerRunner/ip_address.py
Co-authored-by: Eugenio Lacuesta <1731933+elacuesta@users.noreply.github.com>
==

tests/CrawlerRunner/ip_address.py
==================
7f5bb6b3;Aditya;2020-07-06 13:08:14 +0530;chore: add h2 to setup.py, tox.ini
- Change log level for hpack to ERROR

==

scrapy/utils/log.py
setup.py
tox.ini
==================
a94b3034;Aditya;2020-07-06 12:49:12 +0530;test: reduce test data size to 1MB

==

scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
6454d456;BroodingKangaroo;2020-07-03 08:29:54 +0300;Make check of placeholder less strict

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
eb937742;Adrián Chaves;2020-07-03 01:41:47 +0200;TrackrefTestCase.test_get_oldest: protect from lack of precision

==

tests/test_utils_trackref.py
==================
31990485;Adrián Chaves;2020-07-02 20:10:08 +0200;Complete Azure Pipelines CI setup

==

azure-pipelines.yml
tests/CrawlerRunner/ip_address.py
tests/mockserver.py
tests/test_commands.py
tests/test_crawler.py
tests/test_feedexport.py
tests/test_proxy_connect.py
tests/test_spiderloader/__init__.py
tests/test_utils_asyncio.py
tox.ini
==================
6e58da1d;Adrián Chaves;2020-07-02 17:49:42 +0200;Merge branch 'master' into azure-pipelines

==
==================
1e245046;BroodingKangaroo;2020-07-02 12:38:08 +0300;Change setting name. Add leading zeroes to batch_id. Minor fixes.

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
scrapy/utils/conf.py
tests/test_feedexport.py
tests/test_utils_conf.py
==================
56a6d223;Mikhail Korobov;2020-07-01 23:28:52 +0500;Merge pull request #4653 from scrapy/openssl-man-update
Update the OpenSSL cipher list format link
==
==================
af55d231;Andrey Rahmatullin;2020-07-01 19:46:54 +0500;Update the OpenSSL cipher list format link
OpenSSL `ciphers(1)` is now almost empty: https://www.openssl.org/docs/manmaster/man1/ciphers.html

Alternative would be linking to 1.1.1 docs specifically.
==

docs/topics/settings.rst
==================
4acdc2e5;Aditya;2020-07-01 20:15:33 +0530;refactor: use __qualname__, () for large strings

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
c361fe0d;Aditya;2020-07-01 18:14:44 +0530;feat: check for invalid hostname
- Initiating requests having hostname or (ip_address, port) different
from the peer to which HTTP/2 connection is made can lead to closing the
whole connection and close out all the pending streams.
- This change aims to fix that problem
- Add required tests
- Save hostname & port in H2ConnectionMetadataDict

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
scrapy/core/http2/types.py
tests/test_http2_client_protocol.py
==================
0379df86;Andrey Rahmatullin;2020-07-01 17:35:33 +0500;Merge pull request #4652 from elacuesta/docs-loaders-dataclass
Docs: Simplify dataclass example in item loader page
==
==================
065b9b11;ajaymittur28;2020-07-01 15:53:29 +0530;Update regex import

==

scrapy/core/downloader/webclient.py
==================
7b1d3c35;BroodingKangaroo;2020-07-01 11:54:39 +0300;Minor updates

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
scrapy/utils/conf.py
tests/test_feedexport.py
tests/test_utils_conf.py
==================
006a9452;ajaymittur28;2020-07-01 13:32:58 +0530;Update schemaless http proxy test

==

tests/test_downloader_handlers.py
==================
7fc80671;ajaymittur28;2020-07-01 13:32:17 +0530;Update schemaless URI support

==

scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/webclient.py
==================
7b1ad995;Aditya;2020-07-01 10:45:36 +0530;test: query params, certificate & ip_address
- refactor from str.format() to f-strings

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
scrapy/core/http2/types.py
setup.py
tests/test_http2_client_protocol.py
==================
5b88c522;Eugenio Lacuesta;2020-06-30 12:18:21 -0300;Simplify dataclass example in item loader docs

==

docs/topics/loaders.rst
==================
50dd9271;Aditya;2020-06-30 07:17:48 +0530;fix: disable redundant logs
- while testing the job exceeded the maximum log length
and was terminated
- reduce the number of requests from 20 to 10

==

scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
26ab3e41;Aditya;2020-06-30 06:44:20 +0530;feat: FIFO policy to handle large no. of requests
- add required test -- test by sending 1000 requests
- increase test timeout to 180 seconds to account for tests taking long
time

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
d17417b0;Aditya;2020-06-29 18:43:42 +0530;Merge branch 'master' of https://github.com/scrapy/scrapy into h2-client-protocol

==
==================
e46b47c3;Aditya Kumar;2020-06-29 18:35:13 +0530;Renew the localhost certificate for tests (#4650)
Validity
  Not Before: Jun 28 12:54:15 2020 GMT
  Not After : Jun 28 12:54:15 2021 GMT
Subject: C = IE, O = Scrapy, CN = localhost
==

tests/keys/localhost.crt
tests/keys/localhost.key
==================
90a7007f;Aditya;2020-06-29 18:29:31 +0530;test: warnsize logs, no content header, dataloss

==

tests/test_http2_client_protocol.py
==================
23906b6b;Aditya;2020-06-29 18:21:05 +0530;refactor: move TypedDict types to types.py
- rename LOGGER -> logger
- remove self._write_to_transport from Stream class and handle all
transport related activities inside HTTP2ClientProtocol class

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
scrapy/core/http2/types.py
setup.py
==================
464f24f8;Marc Hernández;2020-06-29 14:20:29 +0200;Add --data-raw to utils.curl and fix missing method with data (#4612)

==

scrapy/utils/curl.py
tests/test_utils_curl.py
==================
6387445e;Aditya;2020-06-28 18:44:57 +0530;test(tox.ini): change Twisted -> Twisted[http2]

==

tox.ini
==================
690dd7f3;Aditya;2020-06-28 16:35:04 +0530;test: GET & POST request test for h2 client
- Remove repeated dependency Twisted from setup.py
- Test for both GET & POST when
  - Only 1 request
  - Large number (=20) of requests
and
  - Small Data (10 KB) per request
  - Large Data (10 MB) per request
- Test when request is cancelled by the client'

BREAKING CHANGES
Tests raises OpenSSL.SSL.Error when run using tox. However, all tests
passes when ran using `python -m unittest`.

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
setup.py
tests/test_http2_client_protocol.py
==================
05c2587c;BroodingKangaroo;2020-06-28 09:45:45 +0300;Docs update and tiny fixes

==

docs/topics/feed-exports.rst
tests/test_feedexport.py
==================
f53f0602;ajaymittur28;2020-06-27 23:28:40 +0530;Test http schemaless proxy

==

tests/test_downloader_handlers.py
==================
23da8e10;ajaymittur28;2020-06-27 20:36:45 +0530;Add schemaless http proxy support

==

scrapy/core/downloader/handlers/http11.py
==================
88a52198;BroodingKangaroo;2020-06-27 11:50:26 +0300;Add batch_item_count support in FEEDS setting

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
c3cee74f;BroodingKangaroo;2020-06-26 18:45:21 +0300;Change default value of FEED_STORAGE_BATCH_ITEM_COUNT to 0

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
77333666;BroodingKangaroo;2020-06-26 14:55:46 +0300;resolve conflicts

==
==================
0c8d8c5e;Mikhail Korobov;2020-06-25 18:36:43 +0500;Merge pull request #4645 from Lukas0907/fix-starturlsspider
Spider constructor expects name as argument, not start_urls.
==
==================
9f604813;Adrián Chaves;2020-06-24 12:27:39 +0200;Bump version: 2.1.0 → 2.2.0

==

.bumpversion.cfg
scrapy/VERSION
==================
6f4c964a;Adrián Chaves;2020-06-24 12:26:38 +0200;Cover Scrapy 2.2.0 in the release notes (#4630)

==

docs/contributing.rst
docs/news.rst
docs/topics/media-pipeline.rst
docs/topics/request-response.rst
scrapy/http/response/text.py
scrapy/utils/misc.py
==================
065b3153;Aditya;2020-06-24 07:51:41 +0530;Merge branch 'master' of https://github.com/scrapy/scrapy into h2-client-protocol

==
==================
69f6d038;Aditya;2020-06-24 07:06:32 +0530;feat: TypedDict for Stream._response
- remove test_protocol.py as working testing environment is setup 🙂🙃
- Add typing_extensions as dependency to support TypedDict for
python<3.8

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
scrapy/core/http2/test_protocol.py
setup.py
==================
a97ac0ad;Aditya;2020-06-24 06:40:20 +0530;test: GET request for HTTP2Client using mockserver

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
tests/test_http2_client_protocol.py
==================
3672f5f9;Lukas Anzinger;2020-06-23 14:51:21 +0200;Spider constructor expects name as argument, not start_urls.
Fixes #4644

==

tests/test_scheduler.py
==================
536643ef;Andrey Rahmatullin;2020-06-23 15:33:48 +0500;Merge pull request #4629 from StasDeep/fix/duplicated-feed-logs
Fix duplicated feed logs
==
==================
4bee73cf;Andrey Rahmatullin;2020-06-23 15:31:37 +0500;Merge pull request #4637 from elacuesta/typing
Typing: Tox env, CI job
==
==================
374d9960;Andrey Rahmatullin;2020-06-23 15:30:48 +0500;Merge pull request #4642 from elacuesta/docs-loaders-dataclass
Docs: add note about dataclass items and loaders
==
==================
cfd039ae;Adrián Chaves;2020-06-22 19:28:33 +0200;Remove a duplicate GCS_PROJECT_ID reference target

==

docs/topics/media-pipeline.rst
==================
73b6ce8c;Eugenio Lacuesta;2020-06-22 14:13:37 -0300;Update docs about dataclass items and loaders

==

docs/topics/loaders.rst
==================
1335d905;Eugenio Lacuesta;2020-06-22 14:05:44 -0300;Update docs/topics/loaders.rst
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/loaders.rst
==================
3efea98e;Eugenio Lacuesta;2020-06-22 12:41:14 -0300;Docs: add note about dataclass items and loaders

==

docs/topics/loaders.rst
==================
c74ef660;Aditya;2020-06-21 09:34:23 +0530;feat: handle response for different reasons
- Add StreamCloseReason enum
- Send response for different cases considering download_warnsize,
download_maxsize, fail_on_data_loss, connection lost, etc.

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
303485a9;Aditya;2020-06-21 00:33:34 +0530;fix(http2): POST request not sending large body

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
b99fe4aa;Eugenio Lacuesta;2020-06-19 21:41:15 -0300;Add google-cloud-storage to the 'pinned' tox environment

==

tox.ini
==================
c7f1c7e3;Eugenio Lacuesta;2020-06-19 21:30:54 -0300;Merge branch 'master' into feat-685

==
==================
a4bfd5ab;Stanislau Hluboki;2020-06-13 18:04:38 +0300;Fix duplicated feed logs

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
7babf359;Eugenio Lacuesta;2020-06-18 13:52:04 -0300;Typing: Tox env, CI job

==

.gitignore
.travis.yml
setup.cfg
tox.ini
==================
88ade196;Adrián Chaves;2020-06-18 14:01:02 +0200;Merge branch 'master' into spider-name-collision

==
==================
5d541731;Devi Sandeep;2020-06-18 05:01:38 -0500;Update docs on accessing callback arguments in errback (#4634)

==

docs/topics/request-response.rst
==================
700df3ee;Aditya;2020-06-17 21:02:14 +0530;test: mockserver with h2 protocol for tests
- add Twisted[http2] in setup.py requirements
- add test_protocol.py to test the current implementation

BREAKING CHANGES
test_download times out because of no protocol negotiated between
Mockserver and HTTP/2 client

==

scrapy/core/http2/test_protocol.py
setup.py
tests/test_http2_client_protocol.py
==================
089dbc75;Aditya;2020-06-17 20:57:03 +0530;chore: use deque for pending request pool
- Use itertools.count to generate next stream_id

BREAKING CHANGES
When sending data/body more than the local flow control window -- no
window update occurs to send the remaining data frames. Hence, the
complete body is not send resulting in no response received.

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
3d027fb5;Stas Glubokiy;2020-06-17 18:08:14 +0300;Fix missing storage.store calls in FeedExporter.close_spider (#4626)

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
89e900e0;Andrey Rahmatullin;2020-06-17 18:54:10 +0500;Merge pull request #4635 from cool-RR/patch-1
Use chain.from_iterable in python.py
==
==================
214da8e5;Ram Rachum;2020-06-17 13:50:54 +0300;Use chain.from_iterable in python.py

==

scrapy/utils/python.py
==================
01ad8b31;Aditya;2020-06-15 05:14:00 +0530;refactor(http2): clean up
- make separate function to parse http headers from Request instance

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
de4a3436;Aditya;2020-06-14 22:40:49 +0530;fix: large data chunk not received
Every data chunk received needs to be acknowledged to
- update the flow control window size
- get furthur data chunks from the server

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
ec98dabf;Eugenio Lacuesta;2020-06-14 06:45:27 -0300;Support for dataclass and attrs items (#3881)

==

docs/conf.py
docs/faq.rst
docs/topics/architecture.rst
docs/topics/coroutines.rst
docs/topics/exporters.rst
docs/topics/feed-exports.rst
docs/topics/item-pipeline.rst
docs/topics/items.rst
docs/topics/leaks.rst
docs/topics/loaders.rst
docs/topics/media-pipeline.rst
docs/topics/settings.rst
docs/topics/signals.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
scrapy/commands/parse.py
scrapy/contracts/default.py
scrapy/core/scraper.py
scrapy/exporters.py
scrapy/item.py
scrapy/loader/__init__.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/shell.py
scrapy/spiders/feed.py
scrapy/templates/project/module/middlewares.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/utils/serialize.py
setup.py
tests/requirements-py3.txt
tests/test_engine.py
tests/test_loader.py
tests/test_pipeline_files.py
tests/test_pipeline_images.py
tests/test_utils_serialize.py
tox.ini
==================
d06bb12e;Aditya;2020-06-13 22:29:16 +0530;refactor: move H2Connection instance to stream
- Remove all wrapper funtions made such that stream can send header/data
to H2Connection as they were not necessary

BREAKING CHANGES
Looks like, for small set of response data the StreamEnded event is
emitted and everything works well -- tested for both GET & POST request.
Maybe some issue with window size and/or flow control as when the
response data needs to be broken into separate chunks -- not all chunks
are received everytime which leads to indefinite waiting for next data
chunk and the connection is lost due to timeout. 😥

Working on setting up testing environment now. After testing is setup
I'll debug the above bug furthur.

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
d09ccf8d;Aditya;2020-06-13 20:40:01 +0530;feat(http2): support for POST requests
BREAKING CHANGES
- Request is sent successfully with its Response received as well.
However, the StreamEnded event is not received which do not fires the
response deferred

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
8b549392;Eugenio Lacuesta;2020-06-11 09:53:59 -0300;Bump minimum Python version to 3.5.2 (#4615)

==

.travis.yml
README.rst
docs/faq.rst
docs/intro/install.rst
scrapy/__init__.py
setup.py
==================
b6c5289f;Eugenio Lacuesta;2020-06-10 12:11:49 -0300;Close page in pyppeteer example, mention asyncio reactor

==

docs/topics/dynamic-content.rst
==================
092f6fde;Andrey Rahmatullin;2020-06-10 11:58:16 +0500;Merge pull request #4604 from MMesch/fix-startproject-permissions
give write access to template files after copying with startproject
==
==================
76a2cbf0;Adrián Chaves;2020-06-09 21:30:19 +0200;Apply minor style changes

==

scrapy/commands/startproject.py
==================
78aa1b2b;Eugenio Lacuesta;2020-06-08 11:19:15 -0300;Fix typo

==

docs/topics/dynamic-content.rst
==================
9ff9caec;Aditya;2020-06-07 14:04:53 +0530;feat(http2): support for GET requests

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
bdabc500;Eugenio Lacuesta;2020-06-06 16:32:43 -0300;Update headless browser docs

==

docs/topics/dynamic-content.rst
==================
2df3b54c;Matthias Meschede;2020-06-05 09:29:05 +0200;refactor

==

scrapy/commands/startproject.py
==================
0cabf406;Matthias Meschede;2020-06-01 17:41:52 +0200;set write permission to startproject folder

==

scrapy/commands/startproject.py
==================
63929e75;Andrey Rahmatullin;2020-06-03 12:06:12 +0500;Merge pull request #4552 from jay24rajput/common_commands
Code sharing between crawl and runspider command
==
==================
91e505ed;Eugenio Lacuesta;2020-06-02 05:32:14 -0300;Return single element from coroutine callback (#4609)

==

scrapy/utils/spider.py
tests/spiders.py
tests/test_crawl.py
==================
79129233;Aditya;2020-06-02 09:13:31 +0530;chore(http2): Stream class

==

scrapy/core/http2/protocol.py
scrapy/core/http2/stream.py
==================
1d2b6926;Mikhail Korobov;2020-06-02 02:30:33 +0500;Merge pull request #4596 from sharmarohit/remove-unneeded-escape-sequence
remove unneeded escape sequence
==
==================
c86a1035;Adrián Chaves;2020-06-01 07:18:13 +0200;Merge pull request #4563 from willbeaufoy/hoverxref
Extend hoverxref_roles to custom crossrefs (#4495)
==
==================
5cef9279;Bulat Khabibullin;2020-06-01 07:57:23 +0300;Implement TextResponse.json() (#4574)

==

docs/topics/request-response.rst
scrapy/http/response/text.py
tests/test_http_response.py
==================
9408c77a;Aditya Kumar;2020-05-31 13:09:56 +0530;feat(http2): IH2EventsHandler, http2 module

==

scrapy/core/http2/__init__.py
scrapy/core/http2/protocol.py
==================
6aab3bad;Mikhail Korobov;2020-05-30 00:07:50 +0500;Merge pull request #4568 from elacuesta/remove-monkeypatches-flake8-e402
Remove _monkeypatches, import-related Flake8 codes
==
==================
13215cfb;Mikhail Korobov;2020-05-27 21:46:00 +0500;Merge pull request #4559 from elacuesta/cancel-request-download
Stop response download from signal handler
==
==================
ff699eb1;Andrey Rahmatullin;2020-05-27 21:42:04 +0500;Merge pull request #4599 from elacuesta/LocalWeakReferencedCache-getitem-fix
Fix KeyError in LocalWeakReferencedCache
==
==================
7bf37509;Andrey Rahmatullin;2020-05-27 21:41:43 +0500;Merge pull request #2400 from elacuesta/keep_cookie_header
[MRG+1] CookiesMiddleware: keep cookies from 'Cookie' request header, fix encoding
==
==================
44d5801b;Eugenio Lacuesta;2020-05-27 11:13:21 -0300;Fix KeyError in LocalWeakReferencedCache

==

scrapy/utils/datatypes.py
tests/test_utils_datatypes.py
==================
492197e4;Eugenio Lacuesta;2020-05-27 10:45:07 -0300;StopDownload: store response in the exception instead of the failure

==

docs/topics/exceptions.rst
scrapy/core/downloader/handlers/http11.py
scrapy/core/scraper.py
tests/test_crawl.py
==================
634ad5eb;Eugenio Lacuesta;2020-05-27 10:27:45 -0300;Merge remote-tracking branch 'upstream/master' into cancel-request-download

==
==================
898bdd3f;Will Beaufoy;2020-05-10 13:49:43 +0100;Update docs README with build instructions using tox
None of the existing commands built the docs properly for me (I had to
revert the changes in 901892d to docs/conf.py to get them to build
properly, and even then no tooltips displayed).

Building them with tox worked for me, but other developers say they
can still use the original method, so the docs now contain both.

==

docs/README.rst
==================
b82a480e;Mikhail Korobov;2020-05-26 01:38:53 +0500;Merge pull request #4588 from altendky/patch-1
Incompatible with pytest 5.4 and 5.4.1
==
==================
0cc0e51c;Rohit Sharma;2020-05-24 13:38:44 -0700;remove uneeded escape sequence
removed uneeded wscape sequences from method arguments in the docs
folder

==

docs/topics/api.rst
docs/topics/contracts.rst
docs/topics/exporters.rst
docs/topics/loaders.rst
docs/topics/spiders.rst
==================
dd96f94e;BroodingKangaroo;2020-05-22 23:30:33 +0300;Push datetime.utcnow() to its own variable

==

scrapy/extensions/feedexport.py
==================
5b2af852;Kyle Altendorf;2020-05-22 15:09:58 -0400;Link to issue describing troublesome pytest versions

==

tests/requirements-py3.txt
==================
3e854a69;Mikhail Korobov;2020-05-22 23:12:58 +0500;Merge pull request #4593 from Gallaecio/4514
Fix the description of the ScreenshotPipeline example item pipeline
==
==================
08756cd8;Adrián Chaves;2020-05-22 18:06:54 +0200;Fix the description of the ScreenshotPipeline example item pipeline

==

docs/topics/item-pipeline.rst
==================
f6ed5edc;Eugenio Lacuesta;2016-11-18 09:14:54 -0300;CookiesMiddleware: keep cookies from 'Cookie' request header

==

docs/topics/downloader-middleware.rst
docs/topics/logging.rst
scrapy/downloadermiddlewares/cookies.py
tests/test_downloadermiddleware_cookies.py
==================
677e619d;BroodingKangaroo;2020-05-21 14:57:03 +0300;Fix too long lines

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
5f6c1dce;BroodingKangaroo;2020-05-21 12:43:04 +0300;Merge remote-tracking branch 'upstream/master' into ISSUE-4250-add_batch_deliveries

==
==================
fbe915d9;Eugenio Lacuesta;2020-05-20 20:20:30 -0300;StopDownload: check partial response contents

==

tests/spiders.py
tests/test_crawl.py
==================
9514393b;Eugenio Lacuesta;2020-05-20 15:28:54 -0300;Reduce amount of lines

==

scrapy/core/downloader/handlers/http11.py
==================
276721a5;Eugenio Lacuesta;2020-05-09 22:02:40 -0300;Stop response download

==

docs/faq.rst
docs/topics/exceptions.rst
docs/topics/request-response.rst
docs/topics/signals.rst
scrapy/core/downloader/handlers/http11.py
scrapy/core/scraper.py
scrapy/exceptions.py
scrapy/utils/signal.py
tests/spiders.py
tests/test_crawl.py
tests/test_engine.py
==================
6f3e3411;Mikhail Korobov;2020-05-20 22:23:42 +0500;Merge pull request #4587 from Gallaecio/4510
logging.rst: remove unused, misleading import
==
==================
eb8493f0;Kyle Altendorf;2020-05-20 09:21:34 -0400;Incompatible with pytest 5.4 and 5.4.1

==

tests/requirements-py3.txt
==================
f418c6d5;Adrián Chaves;2020-05-19 20:04:47 +0200;logging.rst: remove unused, misleading import

==

docs/topics/logging.rst
==================
6e792164;Mikhail Korobov;2020-05-19 20:45:20 +0500;Merge pull request #4585 from nsirletti/fix-readthedocs-build
Make doc downloadable on ReadTheDocs.org
==
==================
c2a0cca0;nsirletti;2020-05-16 15:07:16 +0200;Suppress Sphinx warnings about MIME types other than .rst

==

docs/conf.py
==================
afb2e501;nsirletti;2020-05-16 12:48:21 +0200;Allow doc to be downloadable on readthedocs.org

==

.readthedocs.yml
==================
a7d070f3;BroodingKangaroo;2020-05-18 22:25:29 +0300;Change log level to error

==

scrapy/extensions/feedexport.py
==================
febe82a9;Mikhail Korobov;2020-05-18 22:30:30 +0500;Merge pull request #4486 from ilias-ant/add-file-status-on-media-pipelines-file-info
Add status (downloaded, uptodate) to files information
==
==================
bcc40c40;Mikhail Korobov;2020-05-18 22:12:31 +0500;better deprecation warning for Response.body_as_unicode() (#4579)

==

scrapy/http/response/text.py
==================
a22f9705;Eugenio Lacuesta;2020-05-15 21:18:26 -0300;Cleanup import in selector module

==

pytest.ini
scrapy/selector/__init__.py
==================
a915af2e;Eugenio Lacuesta;2020-05-11 16:13:54 -0300;Remove monkeypatches module, E402 flake8 code

==

pytest.ini
scrapy/__init__.py
scrapy/_monkeypatches.py
scrapy/linkextractors/__init__.py
scrapy/spiders/__init__.py
==================
314adf6c;Mikhail Korobov;2020-05-16 03:26:45 +0500;Merge pull request #4237 from elacuesta/flake8-max-line-length
Set flake8-max-line-length to 119
==
==================
14612fc3;Mikhail Korobov;2020-05-16 03:24:06 +0500;Merge pull request #4534 from elacuesta/deprecate-baseitem
Deprecate scrapy.item.BaseItem
==
==================
604fe33b;Jay Rajput;2020-05-16 01:53:49 +0530;Update scrapy/commands/__init__.py
Changed typo in a comment for BaseRunSpiderCommand

Co-authored-by: Eugenio Lacuesta <1731933+elacuesta@users.noreply.github.com>
==

scrapy/commands/__init__.py
==================
10ae1a28;BroodingKangaroo;2020-05-15 22:50:54 +0300;Minor fixes

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
tests/test_feedexport.py
tox.ini
==================
cd32a9d9;Jay Rajput;2020-05-16 00:27:02 +0530;Merge branch 'common_commands' of https://github.com/jay24rajput/scrapy into common_commands

==
==================
4cdd00e2;Jay Rajput;2020-05-16 00:25:57 +0530;Changed BaseRunSpiderCommands to BaseRunSpiderCommand

==

scrapy/commands/__init__.py
scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
36c3c971;Adrián Chaves;2020-05-15 19:37:56 +0200;Run tests with Python 3.5.0 (#4518)
* Run tests with Python 3.5.0

* Use Ubuntu Trusty 14.04 to test Python 3.5.0

* Use mitmproxy<3.0.0 on Python 3.5.0

* Skip tests requiring mitmproxy in Python 3.5.0

* Change the minimum Python version from 3.5 to 3.5.1

* Do not prevent Scrapy from working with Python 3.5.0

* Force system Python 3.5.1

* Do not install a non-system Python in Python 3.5.1 jobs

* Switch to Trusty to be able to test Xenial’s Python version ¯\_(ツ)_/¯

* Add missing trusty

* Stop breaking old PyPy

* Allow installing Scrapy on Python 3.5.0
==

.travis.yml
README.rst
docs/faq.rst
docs/intro/install.rst
tests/test_proxy_connect.py
==================
1cdcf8b0;BroodingKangaroo;2020-05-15 19:46:36 +0300;Minor fixes

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
==================
3eeecb42;Eugenio Lacuesta;2020-05-15 11:11:20 -0300;Merge branch 'master' into flake8-max-line-length

==
==================
fffb0a5b;Marc Hernández;2020-05-15 15:23:09 +0200;replace set constructor with set literals (#4573)

==

tests/test_engine.py
tests/test_http_request.py
tests/test_pipeline_crawl.py
tests/test_pipeline_images.py
tests/test_spiderloader/__init__.py
tests/test_utils_datatypes.py
tests/test_utils_misc/__init__.py
tests/test_utils_url.py
==================
7701c396;Adrián Chaves;2020-05-15 13:44:45 +0200;Merge branch 'master' into common_commands

==
==================
0627bf47;BroodingKangaroo;2020-05-14 20:59:22 +0300;Merge remote-tracking branch 'upstream/master' into ISSUE-4250-add_batch_deliveries

==
==================
ee13c3e9;Eugenio Lacuesta;2020-05-14 13:31:16 -0300;Merge branch 'master' into deprecate-baseitem

==
==================
3d58e5e3;Eugenio Lacuesta;2020-05-14 13:28:50 -0300;Merge pull request #4545 from elacuesta/flake8-remove-e128
Flake8: Remove E128
==
==================
89d0c98f;Eugenio Lacuesta;2020-05-14 11:35:30 -0300;Merge remote-tracking branch 'upstream/master' into flake8-remove-e128

==
==================
602bb13b;Eugenio Lacuesta;2020-05-14 11:26:59 -0300;Merge pull request #4558 from elacuesta/flake8-remove-e741
Flake8: Remove E741
==
==================
df8a1d1c;Eugenio Lacuesta;2020-05-08 20:09:35 -0300;Flake8: Remove E741

==

pytest.ini
scrapy/shell.py
scrapy/spiders/sitemap.py
scrapy/utils/log.py
tests/test_command_version.py
tests/test_crawl.py
tests/test_downloadermiddleware_cookies.py
tests/test_dupefilters.py
tests/test_pipeline_media.py
tests/test_proxy_connect.py
tests/test_squeues.py
tests/test_utils_log.py
tests/test_utils_misc/__init__.py
tests/test_utils_signal.py
==================
cfe4bf7e;Eugenio Lacuesta;2020-05-14 10:38:55 -0300;Merge pull request #4572 from noviluni/add_missed_flake8_rules
Flake8: remove E306 and F523
==
==================
69c005f0;BroodingKangaroo;2020-05-14 10:35:56 +0300;Documentation indent fix

==

docs/topics/feed-exports.rst
==================
111a58fe;BroodingKangaroo;2020-05-14 00:19:52 +0300;Merge remote-tracking branch 'upstream/master' into ISSUE-4250-add_batch_deliveries

==
==================
8662d358;BroodingKangaroo;2020-05-13 23:41:01 +0300;Documentation and code refactoring

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
==================
e31b6ccc;Adrián Chaves;2020-05-13 22:39:45 +0200;Merge branch 'master' into flake8-remove-e128

==
==================
2327ecea;BroodingKangaroo;2020-05-13 22:50:04 +0300;Rename FEED_STORAGE_BATCH_SIZE to FEED_STORAGE_BATCH_ITEM_COUNT

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
7dac99bb;Adrián Chaves;2020-05-13 20:35:03 +0200;Merge branch 'master' into deprecate-baseitem

==
==================
8971878c;marc;2020-05-13 14:11:10 +0200;fix new detected flake8 cases

==

scrapy/core/spidermw.py
scrapy/utils/console.py
scrapy/utils/python.py
==================
519f752d;Andrey Rahmatullin;2020-05-13 11:46:48 +0500;Merge pull request #4566 from elacuesta/flake8-remove-f841
Flake8: remove F841
==
==================
33ab0a36;Jacty;2020-05-13 06:11:07 +0800;Update __init__.py

==

scrapy/settings/__init__.py
==================
8d1269bc;Aditya Kumar;2020-05-13 00:12:28 +0530;Cover chompjs in documentation (#4562)

==

docs/topics/dynamic-content.rst
==================
97532a91;Aditya Kumar;2020-05-12 20:40:09 +0530;test(spiderloader): no duplicate spider names (#4560)

==

tests/test_spiderloader/__init__.py
==================
07e125f4;Jay Rajput;2020-05-12 16:31:56 +0530;Travis CI fixes in __init__.py

==

scrapy/commands/__init__.py
==================
28d223dd;Jay Rajput;2020-05-12 15:28:22 +0530;Update __init__.py

==

scrapy/commands/__init__.py
==================
e01c30f0;Jay Rajput;2020-05-12 01:05:20 +0530;Update scrapy/commands/__init__.py
Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

scrapy/commands/__init__.py
==================
cf9be534;willbeaufoy;2020-05-11 19:35:25 +0100;Prevent create_instance() returning None (#4532)
Currently create_instance() can return None if an extension is
incorrectly implemented, but the extension will still show up as
enabled in the logs. This can cause confusion, as in the linked bug.

This change prevents this occurring by throwing an error if
create_instance() will return None.
==

scrapy/utils/misc.py
tests/test_utils_misc/__init__.py
==================
cb8140a4;nsirletti;2020-05-11 20:20:31 +0200;Deprecate Response.body_as_unicode() (#4555)
Co-authored-by: Nicolas Sirletti <n.sirletti@gmail.com>
==

docs/topics/request-response.rst
scrapy/http/response/text.py
tests/test_http_response.py
==================
6f875862;Eugenio Lacuesta;2020-05-11 13:50:34 -0300;Flake8: remove F841

==

pytest.ini
tests/pipelines.py
tests/test_crawler.py
tests/test_dependencies.py
tests/test_extension_telnet.py
tests/test_feedexport.py
tests/test_item.py
tests/test_pipeline_images.py
tests/test_spidermiddleware_referer.py
tests/test_utils_defer.py
tests/test_utils_deprecate.py
tests/test_utils_signal.py
==================
25e9bc2d;Eugenio Lacuesta;2020-05-11 13:23:57 -0300;Merge branch 'master' into flake8-remove-e128

==
==================
abfdc1b5;Eugenio Lacuesta;2020-05-11 13:20:06 -0300;Update docstring for Item class

==

scrapy/item.py
==================
fb7ba696;Eugenio Lacuesta;2020-05-11 10:21:56 -0300;Merge branch 'master' into deprecate-baseitem

==
==================
892467cb;Mikhail Korobov;2020-05-11 15:16:14 +0500;Merge pull request #4541 from elacuesta/pickle-adjustments
Pickle: use protocol 4, update tests
==
==================
b1835795;Mikhail Korobov;2020-05-11 15:09:55 +0500;Merge pull request #4205 from elacuesta/bytes_received_signal
Add bytes_received signal
==
==================
b5684909;Jacty;2020-05-11 11:18:25 +0800;Unnecessary update when value is None
When value is None, it is not necessary to invoke update and run other methods and conditions to make the code complicated there.
==

scrapy/settings/__init__.py
==================
1bfbcc61;Will Beaufoy;2020-05-10 13:48:09 +0100;Extend hoverxref_roles to custom crossrefs (#4495)

==

docs/conf.py
==================
02ac6664;Jay Rajput;2020-05-10 00:26:48 +0530;Travis CI fixes

==

scrapy/commands/__init__.py
==================
ed4f4f84;Jay Rajput;2020-05-10 00:08:34 +0530;Applied suggested format changes

==

scrapy/commands/__init__.py
scrapy/commands/crawl.py
==================
e07708e3;Adrián Chaves;2020-05-09 15:54:31 +0200;request-response: update the consequences of str(b'')

==

docs/topics/request-response.rst
==================
c6746f0e;Adrián Chaves;2020-05-09 15:51:11 +0200;bytes array → bytes object

==

docs/topics/request-response.rst
==================
92792cc3;Jay Rajput;2020-05-09 17:28:10 +0530;Moved common_commands.py to __init__.py

==

scrapy/commands/__init__.py
scrapy/commands/common_commands.py
scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
f689e917;Eugenio Lacuesta;2020-05-08 19:44:05 -0300;Update Item docstring

==

scrapy/item.py
==================
9485724d;Eugenio Lacuesta;2020-05-08 19:32:47 -0300;Merge branch 'master' into deprecate-baseitem

==
==================
be39f274;Eugenio Lacuesta;2020-05-08 18:33:29 -0300;Merge branch 'master' into flake8-remove-e128

==
==================
794ab196;Mikhail Korobov;2020-05-09 02:22:54 +0500;Merge pull request #3727 from Gallaecio/pylint
Use pylint
==
==================
333910f6;Mikhail Korobov;2020-05-09 02:11:59 +0500;Merge pull request #4554 from elacuesta/linkextractor-remove-lambdas
Remove lambda attributes in default link extractor
==
==================
707f5917;Mikhail Korobov;2020-05-09 02:08:27 +0500;Merge pull request #4557 from elacuesta/flake8-remove-e1xx
Flake8: remove E111, E114, E116, E117, E121
==
==================
c2c3054a;Eugenio Lacuesta;2020-05-08 16:32:02 -0300;Flake8: remove E121

==

pytest.ini
tests/test_spidermiddleware_httperror.py
==================
83ce82f4;Eugenio Lacuesta;2020-05-08 16:28:26 -0300;Flake8: remove E114 and E117 (unused)

==

pytest.ini
==================
1a157f2e;Eugenio Lacuesta;2020-05-08 16:27:21 -0300;Flake8: remove E116

==

pytest.ini
scrapy/pipelines/files.py
==================
81d0b2f6;Eugenio Lacuesta;2020-05-08 16:23:53 -0300;Flake8: remove E111

==

pytest.ini
scrapy/selector/unified.py
==================
3ebf2a0d;Eugenio Lacuesta;2020-05-08 15:17:33 -0300;Remove lambdas in link extractor

==

scrapy/linkextractors/lxmlhtml.py
tests/test_linkextractors.py
==================
b852fff6;Eugenio Lacuesta;2020-05-08 15:19:22 -0300;Style changes in link extractor

==

scrapy/linkextractors/lxmlhtml.py
==================
cf09af78;Antonio Gordillo Toledo;2020-05-08 06:45:19 -0700;Remove Python 2 encoding header from files (#4553)

==

docs/conf.py
scrapy/downloadermiddlewares/ajaxcrawl.py
scrapy/spiderloader.py
scrapy/templates/project/module/items.py.tmpl
scrapy/templates/project/module/middlewares.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/templates/project/module/settings.py.tmpl
scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
scrapy/utils/log.py
scrapy/utils/ssl.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_http_response.py
tests/test_pipeline_crawl.py
tests/test_responsetypes.py
tests/test_utils_deprecate.py
tests/test_utils_iterators.py
tests/test_utils_log.py
tests/test_utils_url.py
==================
dcf7235f;Jay Rajput;2020-05-08 01:48:23 +0530;Code sharing between crawl and runspider command

==

scrapy/commands/common_commands.py
scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
38f01dd2;Eugenio Lacuesta;2020-05-07 14:52:31 -0300;Merge remote-tracking branch 'upstream/master' into flake8-remove-e128

==
==================
61603709;Eugenio Lacuesta;2020-05-07 14:38:54 -0300;Merge remote-tracking branch 'upstream/master' into deprecate-baseitem

==
==================
5256eae6;Eugenio Lacuesta;2020-05-07 14:37:41 -0300;Meta class to handle isinstance checks for BaseItem

==

pytest.ini
scrapy/commands/parse.py
scrapy/contracts/default.py
scrapy/core/scraper.py
scrapy/exporters.py
scrapy/item.py
scrapy/shell.py
scrapy/utils/misc.py
scrapy/utils/serialize.py
tests/test_item.py
==================
77492cd9;Mikhail Korobov;2020-05-07 22:14:51 +0500;Merge pull request #4543 from elacuesta/flake8-remove-e126
Flake8: remove E126
==
==================
8b448513;Eugenio Lacuesta;2020-05-07 12:50:20 -0300;Merge branch 'flake8-remove-e126' into flake8-remove-e128

==
==================
e0127a31;Eugenio Lacuesta;2020-05-07 12:48:43 -0300;Refactor warnings in spiderloader

==

scrapy/spiderloader.py
==================
8659b0d8;Eugenio Lacuesta;2020-05-07 09:24:38 -0300;Merge remote-tracking branch 'upstream/master' into flake8-remove-e126

==
==================
422e6429;Eugenio Lacuesta;2020-05-07 09:22:14 -0300;Add mising len check in spiderloader

==

scrapy/spiderloader.py
==================
b59dfb75;Adrián Chaves;2020-05-07 14:14:59 +0200;Update disabled Pylint checks

==

pylintrc
==================
a8f61e90;Mikhail Korobov;2020-05-07 15:08:11 +0500;Merge pull request #4544 from elacuesta/flake8-remove-e129
Flake8: remove E129
==
==================
a18bfcca;Mikhail Korobov;2020-05-07 15:05:01 +0500;Merge pull request #4542 from elacuesta/flake8-remove-e122-e124
Flake8: remove E122 and E124
==
==================
bbd9d05d;Adrián Chaves;2020-05-07 11:44:43 +0200;request-response.rst: review type references around body mentions

==

docs/topics/request-response.rst
==================
7fd20857;Eugenio Lacuesta;2020-05-06 22:41:16 -0300;Merge remote-tracking branch 'upstream/master' into bytes_received_signal

==
==================
d472402a;Eugenio Lacuesta;2020-05-06 14:39:17 -0300;Fix pickle test for pypy

==

pytest.ini
tests/test_squeues.py
==================
881b4f41;Eugenio Lacuesta;2020-05-06 19:33:22 -0300;Flake8: Remove E128 (tests, part 3)

==

pytest.ini
tests/test_settings/__init__.py
tests/test_spiderloader/__init__.py
tests/test_utils_conf.py
tests/test_utils_iterators.py
tests/test_utils_reqser.py
tests/test_utils_request.py
tests/test_utils_sitemap.py
tests/test_webclient.py
==================
bf56517a;Eugenio Lacuesta;2020-05-06 19:18:29 -0300;Flake8: Remove E128 (tests, part 2)

==

pytest.ini
tests/test_item.py
tests/test_linkextractors.py
tests/test_logformatter.py
tests/test_mail.py
tests/test_middleware.py
tests/test_pipeline_crawl.py
tests/test_pipeline_media.py
tests/test_spidermiddleware_httperror.py
tests/test_spidermiddleware_offsite.py
==================
2da952b9;Mikhail Korobov;2020-05-07 03:12:19 +0500;Merge pull request #4519 from Gallaecio/test-ubuntu-bionic
Test the latest Ubuntu along the latest Python
==
==================
9c6d1307;Eugenio Lacuesta;2020-05-06 18:56:14 -0300;Flake8: Remove E128 (tests, part 1)

==

pytest.ini
tests/test_command_parse.py
tests/test_command_shell.py
tests/test_contracts.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_httpproxy.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_retry.py
tests/test_dupefilters.py
tests/test_http_request.py
tests/test_http_response.py
==================
2851f641;Eugenio Lacuesta;2020-05-06 18:35:50 -0300;Flake8: Remove E128 (item, mail, responsetypes)

==

pytest.ini
scrapy/item.py
scrapy/mail.py
scrapy/responsetypes.py
==================
2fbbca56;Eugenio Lacuesta;2020-05-06 18:34:40 -0300;pytest.ini: remove unnecessary E128 lines

==

pytest.ini
==================
4171b3f6;Eugenio Lacuesta;2020-05-06 18:28:12 -0300;Flake8: Remove E128 (extensions module)

==

pytest.ini
scrapy/extensions/httpcache.py
==================
a72f5aad;Eugenio Lacuesta;2020-05-06 17:38:39 -0300;Flake8: Remove E128 (utils module)

==

pytest.ini
scrapy/utils/defer.py
scrapy/utils/log.py
scrapy/utils/response.py
scrapy/utils/signal.py
scrapy/utils/url.py
==================
7383b2b4;Eugenio Lacuesta;2020-05-06 17:27:44 -0300;Flake8: Remove E128 (core module)

==

pytest.ini
scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/engine.py
==================
2af34873;Eugenio Lacuesta;2020-05-06 17:10:10 -0300;Flake8: Remove E128 (commands module)

==

pytest.ini
scrapy/commands/__init__.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/parse.py
scrapy/commands/settings.py
scrapy/commands/shell.py
scrapy/commands/startproject.py
scrapy/commands/version.py
==================
0a7581df;Mikhail Korobov;2020-05-07 00:54:17 +0500;Merge pull request #4537 from Gallaecio/restric-travis-ci-tests
Travis CI: do not run security and Flake8 on multiple jobs
==
==================
25eeb77b;Eugenio Lacuesta;2020-05-06 16:52:17 -0300;Merge remote-tracking branch 'upstream/master' into flake8-max-line-length

==
==================
88efc988;Eugenio Lacuesta;2020-05-06 16:42:47 -0300;Flake8: remove E129

==

pytest.ini
tests/test_utils_iterators.py
==================
4c12a234;Eugenio Lacuesta;2020-05-06 16:10:21 -0300;Flake8: Remove E126

==

pytest.ini
scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/handlers/s3.py
scrapy/core/downloader/webclient.py
scrapy/downloadermiddlewares/retry.py
scrapy/spiderloader.py
tests/test_downloadermiddleware_cookies.py
tests/test_downloadermiddleware_retry.py
tests/test_http_request.py
tests/test_pipeline_crawl.py
tests/test_webclient.py
==================
a19d1501;Adrián Chaves;2020-05-06 20:52:36 +0200;Merge remote-tracking branch 'upstream/master' into spider-name-collision

==
==================
cc23d1cb;Eugenio Lacuesta;2020-05-06 15:40:37 -0300;Flake8: Remove E124

==

pytest.ini
tests/test_dupefilters.py
tests/test_exporters.py
tests/test_linkextractors.py
tests/test_utils_sitemap.py
==================
d71804ef;Eugenio Lacuesta;2020-05-06 15:23:36 -0300;Flake8: Remove E122

==

pytest.ini
tests/test_webclient.py
==================
0e382c81;Eugenio Lacuesta;2020-05-06 14:09:10 -0300;Remove unused import

==

tests/test_squeues.py
==================
93436f9d;Eugenio Lacuesta;2020-05-06 14:05:27 -0300;Chain pickling exception, test_squeues.py updates

==

scrapy/squeues.py
tests/test_squeues.py
==================
b1ddd7bd;Eugenio Lacuesta;2020-05-06 13:44:02 -0300;Refactor test_squeues.py

==

tests/test_squeues.py
==================
b76d280c;Andrey Rahmatullin;2020-05-06 21:38:04 +0500;Merge pull request #4540 from elacuesta/flake8-remove-e123
Flake8: remove E123
==
==================
d0bb04f0;Eugenio Lacuesta;2020-05-06 13:37:23 -0300;Switch to pickle protocol 4

==

scrapy/exporters.py
scrapy/extensions/httpcache.py
scrapy/extensions/spiderstate.py
scrapy/squeues.py
==================
4957a0a1;Andrey Rahmatullin;2020-05-06 21:36:20 +0500;Merge pull request #4539 from elacuesta/flake8-remove-e125
Flake8: remove E125
==
==================
977ce9f7;Andrey Rahmatullin;2020-05-06 21:34:24 +0500;Merge pull request #4538 from elacuesta/flake8-remove-e127
Flake8: remove E127
==
==================
8643e8d3;Eugenio Lacuesta;2020-05-06 12:26:04 -0300;Flake8: remove E123 (Closing bracket does not match indentation of opening bracket's line)

==

pytest.ini
scrapy/extensions/closespider.py
scrapy/http/request/form.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_httpcompression.py
tests/test_http_request.py
tests/test_scheduler.py
tests/test_utils_url.py
tests/test_webclient.py
==================
628c4a53;Michał Panek;2020-05-06 17:09:20 +0200;Add a warning/error in case of incorrect gcs permissions (#4508)

==

scrapy/pipelines/files.py
==================
a79cfce5;Adrián Chaves;2020-05-06 16:24:13 +0200;Merge branch 'master' into pylint

==
==================
286fca73;Adrián Chaves;2020-05-06 16:20:33 +0200;Fix parameter name, broken by copy-pasting

==

scrapy/settings/__init__.py
==================
63600243;Eugenio Lacuesta;2020-05-06 10:21:01 -0300;Flake8: remove E125 (Continuation line with same indent as next logical line)
Also remove E401 from pytest.ini - no occurrences in the codebase

==

pytest.ini
scrapy/pipelines/media.py
tests/test_spidermiddleware_referer.py
tests/test_utils_url.py
==================
fe0c582e;Eugenio Lacuesta;2020-05-06 09:49:10 -0300;Flake8: remove E127 in tests (continuation line over-indented for visual indent)

==

pytest.ini
tests/spiders.py
tests/test_closespider.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_decompression.py
tests/test_downloadermiddleware_redirect.py
tests/test_http_request.py
tests/test_selector.py
tests/test_spidermiddleware_httperror.py
tests/test_utils_url.py
==================
49e8a337;Eugenio Lacuesta;2020-05-06 09:37:01 -0300;Flake8: remove E127 (continuation line over-indented for visual indent)

==

pytest.ini
scrapy/core/downloader/handlers/ftp.py
scrapy/core/engine.py
scrapy/utils/deprecate.py
scrapy/utils/request.py
==================
8d1e3ee0;Eugenio Lacuesta;2020-05-06 09:24:32 -0300;Remove deprecated BaseItem from the docs

==

docs/topics/items.rst
==================
98835a0d;Adrián Chaves;2020-05-06 13:59:01 +0200;Merge branch 'master' into test-ubuntu-bionic

==
==================
418b9b5f;Adrián Chaves;2020-05-06 11:15:02 +0200;Travis CI: do not run security and Flake8 on multiple jobs

==

.travis.yml
tox.ini
==================
17c0cf64;Eugenio Lacuesta;2020-05-05 19:14:48 -0300;Flake8: remove W504 code (#4525)
Co-authored-by: Mikhail Korobov <kmike84@gmail.com>
==

pytest.ini
scrapy/contracts/__init__.py
scrapy/downloadermiddlewares/redirect.py
scrapy/extensions/telnet.py
scrapy/linkextractors/__init__.py
scrapy/spidermiddlewares/referer.py
scrapy/utils/gz.py
tests/test_utils_http.py
==================
7988c676;Eugenio Lacuesta;2020-05-05 13:11:01 -0300;Update Item docstring, update BaseItem occurrences

==

docs/faq.rst
pytest.ini
scrapy/item.py
scrapy/spiders/feed.py
tests/test_loader.py
tests/test_utils_spider.py
==================
622ce860;Eugenio Lacuesta;2020-05-04 16:22:24 -0300;Test: make sure scrapy.item.Item does not issue a deprecation warning

==

tests/test_item.py
==================
8f72b70f;Mikhail Korobov;2020-05-04 23:51:40 +0500;Merge pull request #4533 from scrapy/doc-old-twisted
Don't mention unsupported package versions in docs
==
==================
fe6154e4;Mikhail Korobov;2020-05-04 18:18:38 +0500;clarify DOWNLOADER_HTTPCLIENTFACTORY docs

==

docs/topics/settings.rst
==================
e1948b49;Eugenio Lacuesta;2020-05-04 09:07:27 -0300;Add example about bytes_received signal

==

docs/topics/signals.rst
==================
f75941f7;Eugenio Lacuesta;2020-04-30 11:56:52 -0300;Deprecate scrapy.item.BaseItem

==

scrapy/item.py
tests/test_item.py
==================
83d7360b;Mikhail Korobov;2020-05-04 02:00:11 +0500;Don't mention unsupported package versions in docs

==

docs/topics/settings.rst
==================
dad2ea75;BroodingKangaroo;2020-05-02 01:21:03 +0300;Change time_id to batch_time

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
4d625afd;Eugenio Lacuesta;2020-05-01 16:11:32 -0300;Merge branch 'master' into bytes_received_signal

==
==================
df81870f;BroodingKangaroo;2020-05-01 12:18:39 +0300;Merge branch 'master' of https://github.com/scrapy/scrapy into ISSUE-4250-add_batch_deliveries

==
==================
3f9874fa;BroodingKangaroo;2020-05-01 11:52:16 +0300;Add test s3 export

==

tests/test_feedexport.py
tox.ini
==================
b6eae22b;Mikhail Korobov;2020-04-29 00:26:00 +0500;Merge pull request #4522 from Gallaecio/travis-tox-py
Remove TOXENV from .travis.yml unless needed
==
==================
6c69b03a;Mikhail Korobov;2020-04-29 00:25:42 +0500;Merge pull request #4521 from Gallaecio/tox-asyncio
Simplify the asyncio Tox environment
==
==================
65ba9e10;Mikhail Korobov;2020-04-29 00:19:55 +0500;Merge pull request #4517 from Gallaecio/run-quick-tests-first
Run quick tests first in Travis CI
==
==================
ec0a0eb3;Adrián Chaves;2020-04-28 21:13:08 +0200;Merge branch 'master' into spider-name-collision

==
==================
1006db1e;Adrián Chaves;2020-04-28 21:07:14 +0200;Merge branch 'master' into documentation-build

==
==================
f2bbdb43;Adrián Chaves;2020-04-28 18:24:16 +0200;Merge branch 'master' into remove-deprecated-http-client-factory

==
==================
f787b848;Eugenio Lacuesta;2020-04-20 12:05:15 -0300;IPv6 test: check for the absence of DNSLookupError

==

tests/test_crawler.py
==================
3a64f3eb;Adrián Chaves;2020-04-28 17:44:19 +0200;Remove TOXENV from .travis.yml unless needed

==

.travis.yml
==================
5c0f11b4;Adrián Chaves;2020-04-28 17:32:53 +0200;Simplify the asyncio Tox environment

==

.travis.yml
tox.ini
==================
15d96ab8;Adrián Chaves;2020-04-28 17:09:05 +0200;Test the latest Ubuntu along the latest Python

==

.travis.yml
==================
e3c3ec2b;Adrián Chaves;2020-04-28 13:48:50 +0200;Run quick tests first in Travis CI

==

.travis.yml
==================
c207dbf9;Ashe;2020-04-28 02:45:19 +0900;Remove the asyncio warning from coroutines page (#4513)

==

docs/topics/coroutines.rst
==================
20473704;BroodingKangaroo;2020-04-27 12:52:18 +0300;Extract the slot closing functionality to the function; minor changes

==

scrapy/extensions/feedexport.py
==================
a1862155;BroodingKangaroo;2020-04-27 10:34:36 +0300;Merge branch 'master' of https://github.com/BroodingKangaroo/scrapy into ISSUE-4250-add_batch_deliveries

==
==================
2eee6c81;BroodingKangaroo;2020-04-27 09:58:14 +0300;Documentation spelling fix

==

docs/topics/feed-exports.rst
==================
f0f1be76;BroodingKangaroo;2020-04-27 09:56:57 +0300;Using time_id instead of time as a timestamp

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
3878b67a;Adrián Chaves;2020-04-24 11:46:54 +0200;Bump version: 2.0.0 → 2.1.0

==

.bumpversion.cfg
scrapy/VERSION
==================
ffe576c4;Adrián Chaves;2020-04-24 11:44:36 +0200;Cover Scrapy 2.1 in the release notes (#4499)
Co-authored-by: Mikhail Korobov <kmike84@gmail.com>
==

docs/news.rst
docs/topics/request-response.rst
==================
efb6f13d;Eugenio Lacuesta;2020-04-23 07:40:10 -0300;Remove assertions from production code (#4440)

==

scrapy/commands/__init__.py
scrapy/contracts/default.py
scrapy/core/downloader/middleware.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/crawler.py
scrapy/http/request/__init__.py
scrapy/pipelines/files.py
scrapy/utils/iterators.py
scrapy/utils/reactor.py
tests/test_utils_iterators.py
==================
e4750f2f;Aditya Kumar;2020-04-20 21:17:57 +0530;async/deferred signal handlers (#4390)
* [docs] async/deferred signal handlers

* [docs] update deferred signals example

* [docs] add subsections for built-in signals

* docs(signals): update signal handler example

* docs(signals): update signal handler example
==

docs/topics/signals.rst
==================
1fecacbb;Eugenio Lacuesta;2020-04-20 12:05:15 -0300;IPv6 test: check for the absence of DNSLookupError

==

tests/test_crawler.py
==================
773ddf77;ilias-ant;2020-04-19 14:14:17 +0300;added more tests to cover the (downloaded, uptodate, cached) status functionality

==

tests/test_pipeline_files.py
==================
bfeb2c8c;sakshamb2113;2020-04-18 20:51:26 +0530;Added warning to use double quotes in Windows for scrapy shell in shell.rst (#4450)
* modified debugging memory leaks with guppy in leaks.rst

* modified leaks.rst(issue #4285)

* removed guppy from telnet.py

* Fix undefined name error

* removed hpy key from telnet_vars in telnet.py

* updated shell.rst

* Update docs/topics/shell.rst

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

Co-authored-by: Adrián Chaves <adrian@chaves.io>
==

docs/topics/shell.rst
==================
66ab3347;Mikhail Korobov;2020-04-18 20:19:01 +0500;Merge pull request #4507 from elacuesta/docs-update-deprecated-feed-settings
Docs: replace deprecated FEED_FORMAT and FEED_URI settings
==
==================
ec76445d;BroodingKangaroo;2020-04-18 09:29:23 +0300;Update tests

==

tests/test_feedexport.py
==================
04b6295a;Eugenio Lacuesta;2020-04-17 20:50:17 -0300;Docs: replace deprecated FEED_* settings

==

docs/topics/practices.rst
==================
209ab053;Mikhail Korobov;2020-04-17 18:58:28 +0500;Merge pull request #4500 from victor-torres/reference-callback
Serialize requests with callback references as spider attribute
==
==================
1ade3fc7;Victor Torres;2020-04-17 10:34:34 -0300;trying to improve test coverage

==

tests/test_utils_reqser.py
==================
7926da4b;Eugenio Lacuesta;2020-04-16 16:05:09 -0300;Merge branch 'master' into flake8-max-line-length

==
==================
cf39602c;Mikhail Korobov;2020-04-16 23:17:31 +0500;Merge pull request #4471 from elacuesta/fix-pycodestyle-e731
Fix pycodestyle E731 ("do not assign a lambda expression, use a def")
==
==================
c33fd47a;Mikhail Korobov;2020-04-16 21:05:41 +0500;Merge pull request #3940 from elacuesta/response_ip_address
Get server IP address for HTTP/1.1 Responses
==
==================
ea3e6758;Adrián Chaves;2020-04-16 17:10:45 +0200;test_utils_iterators: use os.linesep

==

tests/test_utils_iterators.py
==================
cf418030;Adrián Chaves;2020-04-16 17:07:29 +0200;Skip test_reactor_poll on Windows

==

tests/test_crawler.py
==================
7cc96010;Adrián Chaves;2020-04-16 16:57:48 +0200;Improve reporting on test_ipv6_alternative_name_resolver

==

tests/test_crawler.py
==================
c9229922;Eugenio Lacuesta;2020-04-16 11:37:37 -0300;Tests: Move code inside __main__ block

==

tests/CrawlerRunner/ip_address.py
==================
94c95020;Victor Torres;2020-04-16 11:37:03 -0300;add comment to explain the use of __func__ instead of instance method objects

==

scrapy/utils/reqser.py
==================
1f2e2a60;Eugenio Lacuesta;2020-04-16 11:32:37 -0300;Merge branch 'master' into response_ip_address

==
==================
e0921cab;Victor Torres;2020-04-16 11:18:56 -0300;remove not used code
This code is not needed anymore because we're getting the
already mangled name when matching func with spider attributes.

==

scrapy/utils/reqser.py
tests/test_utils_reqser.py
==================
94ee6869;Adrián Chaves;2020-04-16 15:36:56 +0200;Mock server: use 127.0.0.1 also for HTTPS
Windows throws an error about 0.0.0.0 being external:
https://stackoverflow.com/a/23857995/939364

==

tests/mockserver.py
==================
fe7043a6;Mikhail Korobov;2020-04-16 18:19:46 +0500;Merge pull request #4503 from Gallaecio/hoverxref-configuration
Fix the hoverxref configuration
==
==================
1d77eac9;Adrián Chaves;2020-04-16 14:57:55 +0200;Fix Flake8-reported issues

==

scrapy/http/request/form.py
tests/test_http_request.py
==================
901892da;Adrián Chaves;2020-04-16 14:48:38 +0200;Fix the hoverxref configuration

==

docs/conf.py
tox.ini
==================
5980ae72;BroodingKangaroo;2020-04-16 10:13:39 +0300;Some minor fixes and refactoring

==

tests/test_feedexport.py
==================
cac1f3a6;BroodingKangaroo;2020-04-16 10:06:56 +0300;Update documentation

==

docs/topics/feed-exports.rst
==================
47a99261;Victor Torres;2020-04-15 19:57:34 -0300;serialize requests with callback references as spider attribute
You could define a spider attribute that references a callback method
but if this method has a different name than your spider attribute,
the request serializer is not able to find it on the spider class.

With this commit we're fixing this behavior as we're searching for
callback references in the spider object itself instead of looking
for attributes with the same function's name, that could be different.

==

scrapy/utils/reqser.py
tests/test_utils_reqser.py
==================
16836e9e;BroodingKangaroo;2020-04-16 00:13:28 +0300;Merge branch 'ISSUE-4250-add_batch_deliveries' of https://github.com/BroodingKangaroo/scrapy into ISSUE-4250-add_batch_deliveries

==
==================
96358046;BroodingKangaroo;2020-04-15 20:14:33 +0300;Update tests

==

tests/test_feedexport.py
==================
ffa8a533;BroodingKangaroo;2020-03-28 11:40:16 +0300;Set batch_id in _get_uri_params

==

scrapy/extensions/feedexport.py
==================
39d0d13d;BroodingKangaroo;2020-03-26 14:18:35 +0300;Add partial deliveries tests

==

tests/test_feedexport.py
==================
d11411b4;BroodingKangaroo;2020-03-21 10:48:13 +0300;fix comments

==

scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
==================
0723e3f4;BroodingKangaroo;2020-03-19 21:17:02 +0300;add batch_id, add error if uri is specified incorrectly

==

scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
==================
8b4566ff;BroodingKangaroo;2020-03-18 14:21:21 +0300;fix wrong name of first file in partial deliveries

==

scrapy/extensions/feedexport.py
==================
e5b23f4b;BroodingKangaroo;2020-03-18 11:26:59 +0300;fix #4250: add batch deliveries

==

scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
==================
2f510fd4;Adrián Chaves;2020-04-15 21:10:05 +0200;Fix ShellTest.test_local_file on Windows

==

scrapy/utils/url.py
tests/test_command_shell.py
==================
36abe923;Mikhail Korobov;2020-04-15 23:13:55 +0500;Merge pull request #4445 from adityaa30/docs-redirect-links
update redirect links to python3
==
==================
066c02d0;Mikhail Korobov;2020-04-15 23:12:33 +0500;Merge pull request #4455 from aditi137/docs-curl2scrapy
[Docs] mention curl2scrapy in Request.from_curl
==
==================
2d46777d;Mikhail Korobov;2020-04-15 22:45:52 +0500;Merge pull request #4489 from elacuesta/remove-returnValue-function
Remove twisted.internet.defer.returnValue occurrences
==
==================
885b0ad2;Mikhail Korobov;2020-04-15 22:42:49 +0500;Merge pull request #4480 from elacuesta/pin-sphinx-versions
Pin version for Sphinx and extensions, configure hoverxref
==
==================
ac869181;Eugenio Lacuesta;2020-04-15 13:42:35 -0300;Update docs/topics/downloader-middleware.rst
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

docs/topics/downloader-middleware.rst
==================
c28dd0ce;Adrián Chaves;2020-04-15 16:22:59 +0200;Merge branch 'master' into duplicate_key

==
==================
f242751b;Eugenio Lacuesta;2020-04-15 09:39:28 -0300;Remove empty line

==

pytest.ini
==================
01d73dd3;Eugenio Lacuesta;2020-04-15 09:24:33 -0300;Merge branch 'master' into flake8-max-line-length

==
==================
c3257dc6;santoshkosgi;2020-04-15 17:54:10 +0530;Change Content-type to Content-Type (#4481)
Co-authored-by: santosh <santosh@acalvio.com>
==

scrapy/responsetypes.py
==================
d323a573;Adrián Chaves;2020-04-15 14:16:15 +0200;Merge branch 'master' into fix-pycodestyle-e731

==
==================
94d7ad76;Eugenio Lacuesta;2020-04-15 09:11:37 -0300;Fix pycodestyle E2XX (whitespace) (#4468)

==

pytest.ini
scrapy/core/downloader/tls.py
scrapy/dupefilters.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/pipelines/media.py
tests/test_crawl.py
tests/test_downloadermiddleware_cookies.py
tests/test_http_response.py
tests/test_spidermiddleware_referer.py
tests/test_utils_iterators.py
tests/test_utils_url.py
tests/test_webclient.py
==================
ee4ee486;Eugenio Lacuesta;2020-04-14 15:06:54 -0300;Revert unnecessary changes to docs/conf.py

==

docs/conf.py
==================
0a4ef97f;Eugenio Lacuesta;2020-04-14 14:57:20 -0300;Loose restrictions for docs requirements

==

docs/requirements.txt
==================
4023d5db;Eugenio Lacuesta;2020-04-13 06:35:17 -0300;Replace _DefGen_Return exception handling
Handle StopIteration instead

==

scrapy/pipelines/media.py
tests/test_pipeline_media.py
==================
1bd8f392;Eugenio Lacuesta;2020-04-13 06:12:30 -0300;Initial removal of twisted.internet.defer.returnValue

==

scrapy/core/downloader/middleware.py
tests/test_feedexport.py
tests/test_spidermiddleware_output_chain.py
==================
83a0cc6c;ilias-ant;2020-04-12 23:22:17 +0300;Add status to files information

==

docs/topics/media-pipeline.rst
scrapy/pipelines/files.py
tests/test_pipeline_crawl.py
==================
2205f046;Eugenio Lacuesta;2020-04-10 18:08:04 -0300;Docs: Add hoverxref_role_types setting

==

docs/conf.py
==================
34e81d0d;Eugenio Lacuesta;2020-04-10 17:29:02 -0300;Docs: remove duplicated setting definitions

==

docs/topics/downloader-middleware.rst
docs/topics/settings.rst
==================
4383f452;Eugenio Lacuesta;2020-04-10 16:49:14 -0300;Replace os.path with pathlib in docs config

==

docs/conf.py
==================
24a1d9ac;Eugenio Lacuesta;2020-04-10 16:48:42 -0300;Get version in docs config

==

docs/conf.py
==================
f97fec5e;Eugenio Lacuesta;2020-04-10 16:02:53 -0300;Pin Sphinx version, including extensions

==

docs/requirements.txt
==================
950a5246;Eugenio Lacuesta;2020-04-10 15:24:22 -0300;Merge branch 'master' into flake8-max-line-length

==
==================
2265c1fd;Eugenio Lacuesta;2020-04-10 14:32:30 -0300;Merge branch 'master' into fix-pycodestyle-e731

==
==================
39b01b68;Mikhail Korobov;2020-04-10 22:03:39 +0500;Merge pull request #4469 from elacuesta/fix-pycodestyle-e502
Fix pycodestyle E502 ("the backslash is redundant between brackets")
==
==================
49357ccc;Andrey Rahmatullin;2020-04-06 19:48:20 +0500;Merge pull request #4472 from elacuesta/remove-request-body-producer-empty-body
Remove empty _RequestBodyProducer for POST requests
==
==================
c4a5e3f0;Eugenio Lacuesta;2020-04-06 09:26:13 -0300;Simplify bytes_received signal
Remove "source" parameter

==

docs/topics/signals.rst
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/s3.py
tests/test_engine.py
==================
e3342669;Eugenio Lacuesta;2020-04-06 09:17:35 -0300;Merge branch 'master' into bytes_received_signal

==
==================
862f0301;Eugenio Lacuesta;2020-04-05 00:53:10 -0300;Remove empty _RequestBodyProducer for POST requests

==

scrapy/core/downloader/handlers/http11.py
==================
c887fe37;Eugenio Lacuesta;2020-04-04 22:15:36 -0300;Simplify parse command

==

scrapy/commands/parse.py
==================
4270e0a0;Eugenio Lacuesta;2020-04-04 21:51:02 -0300;Fix E731: do not assign a lambda expression

==

pytest.ini
scrapy/commands/fetch.py
scrapy/commands/parse.py
scrapy/core/downloader/webclient.py
scrapy/linkextractors/__init__.py
scrapy/linkextractors/lxmlhtml.py
tests/test_downloadermiddleware_cookies.py
tests/test_exporters.py
tests/test_pipeline_media.py
tests/test_utils_python.py
tests/test_utils_signal.py
==================
e2d5d357;Eugenio Lacuesta;2020-04-01 13:45:00 -0300;Fix pycodestyle E502

==

pytest.ini
scrapy/commands/genspider.py
scrapy/commands/shell.py
scrapy/core/downloader/middleware.py
scrapy/core/engine.py
scrapy/mail.py
scrapy/utils/deprecate.py
tests/test_pipeline_media.py
==================
bdb28ac6;Adrián Chaves;2020-03-30 20:25:40 +0200;Merge remote-tracking branch 'origin/sybil' into azure-pipelines

==
==================
3fb00271;Adrián Chaves;2020-03-28 17:36:50 +0100;Require sybil ≥ 1.3.0 for tests

==

tests/requirements-py3.txt
==================
8845773d;Mikhail Korobov;2020-03-27 14:11:03 +0500;Merge pull request #4456 from whalebot-helmsman/project_links
Project URLs in machine-readable format for showing in pypi
==
==================
0699e6bb;Daniel Graña;2020-03-27 02:22:05 -0300;no need to install requirements.txt

==

azure-pipelines.yml
==================
02206e5f;Daniel Graña;2020-03-27 02:20:39 -0300;Run tox

==

azure-pipelines.yml
tests/requirements-py3.txt
==================
a175b6ef;Daniel Graña;2020-03-27 02:10:10 -0300;Set up CI with Azure Pipelines
[skip ci]
==

azure-pipelines.yml
==================
b1904729;Aditya;2020-03-27 04:37:26 +0530;[docs] change mod to doc redirect link

==

docs/topics/request-response.rst
==================
16f2cb4a;Vostretsov Nikita;2020-03-26 12:57:39 +0000;project URLs in machine-readable format for showing in pypi

==

setup.py
==================
010edfe8;Aditi Dutta;2020-03-25 14:38:22 -0400;[Docs] mention curl2scrapy in Request.from_curl

==

docs/topics/developer-tools.rst
docs/topics/dynamic-content.rst
scrapy/http/request/__init__.py
==================
ee510cf0;elacuesta;2020-03-24 13:31:44 -0300;Update scrapy/spiders/crawl.py
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

scrapy/spiders/crawl.py
==================
80c69d68;Aditya;2020-03-24 05:52:07 +0530;[docs] refactor python docs links using intersphinx

==

docs/intro/tutorial.rst
docs/topics/coroutines.rst
docs/topics/downloader-middleware.rst
docs/topics/dynamic-content.rst
docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/items.rst
docs/topics/logging.rst
docs/topics/request-response.rst
docs/topics/settings.rst
==================
4663f0b9;Eugenio Lacuesta;2020-03-22 23:38:51 -0300;Update pytest.ini after removing E501

==

pytest.ini
==================
182394bc;Eugenio Lacuesta;2020-03-22 23:29:30 -0300;E501 compliance (tests)

==

pytest.ini
tests/test_command_shell.py
tests/test_crawler.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_httpcompression.py
tests/test_downloadermiddleware_redirect.py
tests/test_exporters.py
tests/test_feedexport.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_linkextractors.py
tests/test_pipeline_files.py
tests/test_pipeline_images.py
tests/test_request_cb_kwargs.py
tests/test_responsetypes.py
tests/test_selector.py
tests/test_spider.py
tests/test_spidermiddleware_output_chain.py
tests/test_spidermiddleware_referer.py
tests/test_utils_iterators.py
tests/test_utils_request.py
tests/test_utils_sitemap.py
tests/test_utils_url.py
==================
36a3913a;Eugenio Lacuesta;2020-03-22 21:34:20 -0300;E501 compliance

==

pytest.ini
scrapy/cmdline.py
scrapy/core/downloader/middleware.py
scrapy/robotstxt.py
scrapy/spiders/crawl.py
==================
0ee04e1e;Mikhail Korobov;2020-03-20 23:18:42 +0500;Merge pull request #4448 from adityaa30/fix-zope
[fix] zope interface 5.0.0 unsupported
==
==================
c26308dd;Mikhail Korobov;2020-03-20 18:30:50 +0500;Merge pull request #4438 from seregaxvm/master
edit zsh completion
==
==================
532cd1d9;Aditya;2020-03-20 17:36:49 +0530;[fix] zope interface 5.0.0 unsupported

==

scrapy/crawler.py
==================
f37b1bdc;Aditya;2020-03-20 05:22:51 +0530;[docs] update redirect links to python3

==

docs/intro/tutorial.rst
docs/topics/contracts.rst
docs/topics/downloader-middleware.rst
docs/topics/dynamic-content.rst
docs/topics/email.rst
docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/items.rst
docs/topics/logging.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
docs/topics/telnetconsole.rst
scrapy/item.py
==================
ca08e041;Aditya;2020-03-20 02:31:35 +0530;[docs] update redirect links python2 -> python3

==

docs/topics/downloader-middleware.rst
docs/topics/email.rst
docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/items.rst
docs/topics/logging.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
==================
34d60719;Eugenio Lacuesta;2020-03-18 21:19:34 -0300;Merge branch 'master' into feat-685

==
==================
6c747953;Adrián Chaves;2020-03-18 18:33:41 +0100;Cover 2.0.1 in the release notes (#4437)

==

docs/news.rst
==================
9ab45325;Matsievskiy S.V;2020-03-17 18:45:00 +0300;edit zsh completion
- Fix bug introduced in https://github.com/scrapy/scrapy/pull/4291
- Enforce `[command] [options] [arguments]` syntax. Do not allow options after arguments
- Exclude already used option aliases from completion list

==

extras/scrapy_zsh_completion
==================
533131a3;sakshamb2113;2020-03-17 14:42:49 +0530;Remove Guppy-specific code and documentation (#4343)

==

docs/topics/leaks.rst
scrapy/extensions/telnet.py
==================
dfbe1d95;elacuesta;2020-03-16 16:12:46 -0300;Remove object base class (#4430)

==

docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/item-pipeline.rst
docs/topics/leaks.rst
docs/topics/settings.rst
docs/topics/stats.rst
scrapy/commands/__init__.py
scrapy/commands/bench.py
scrapy/contracts/__init__.py
scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/core/scraper.py
scrapy/downloadermiddlewares/ajaxcrawl.py
scrapy/downloadermiddlewares/cookies.py
scrapy/downloadermiddlewares/decompression.py
scrapy/downloadermiddlewares/defaultheaders.py
scrapy/downloadermiddlewares/downloadtimeout.py
scrapy/downloadermiddlewares/httpauth.py
scrapy/downloadermiddlewares/httpcache.py
scrapy/downloadermiddlewares/httpcompression.py
scrapy/downloadermiddlewares/httpproxy.py
scrapy/downloadermiddlewares/redirect.py
scrapy/downloadermiddlewares/retry.py
scrapy/downloadermiddlewares/robotstxt.py
scrapy/downloadermiddlewares/stats.py
scrapy/downloadermiddlewares/useragent.py
scrapy/dupefilters.py
scrapy/exporters.py
scrapy/extensions/closespider.py
scrapy/extensions/corestats.py
scrapy/extensions/debug.py
scrapy/extensions/feedexport.py
scrapy/extensions/httpcache.py
scrapy/extensions/logstats.py
scrapy/extensions/memdebug.py
scrapy/extensions/memusage.py
scrapy/extensions/spiderstate.py
scrapy/extensions/statsmailer.py
scrapy/extensions/throttle.py
scrapy/http/cookies.py
scrapy/link.py
scrapy/linkextractors/__init__.py
scrapy/linkextractors/lxmlhtml.py
scrapy/loader/__init__.py
scrapy/loader/processors.py
scrapy/logformatter.py
scrapy/mail.py
scrapy/middleware.py
scrapy/pipelines/files.py
scrapy/pipelines/media.py
scrapy/pqueues.py
scrapy/responsetypes.py
scrapy/settings/__init__.py
scrapy/shell.py
scrapy/signalmanager.py
scrapy/spiderloader.py
scrapy/spidermiddlewares/depth.py
scrapy/spidermiddlewares/httperror.py
scrapy/spidermiddlewares/offsite.py
scrapy/spidermiddlewares/referer.py
scrapy/spidermiddlewares/urllength.py
scrapy/spiders/crawl.py
scrapy/statscollectors.py
scrapy/templates/project/module/middlewares.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/utils/datatypes.py
scrapy/utils/deprecate.py
scrapy/utils/iterators.py
scrapy/utils/log.py
scrapy/utils/python.py
scrapy/utils/reactor.py
scrapy/utils/sitemap.py
scrapy/utils/testproc.py
scrapy/utils/testsite.py
scrapy/utils/trackref.py
tests/pipelines.py
tests/test_cmdline/extensions.py
tests/test_cmdline_crawl_with_pipeline/test_spider/pipelines.py
tests/test_command_parse.py
tests/test_contracts.py
tests/test_crawler.py
tests/test_downloadermiddleware.py
tests/test_dupefilters.py
tests/test_engine.py
tests/test_feedexport.py
tests/test_item.py
tests/test_loader.py
tests/test_logformatter.py
tests/test_middleware.py
tests/test_request_cb_kwargs.py
tests/test_scheduler.py
tests/test_spidermiddleware_referer.py
tests/test_squeues.py
tests/test_utils_deprecate.py
tests/test_utils_python.py
tests/test_utils_reqser.py
==================
e5711127;elacuesta;2020-03-16 15:43:02 -0300;Remove deprecated ChunkedTransferMiddleware (#4431)

==

scrapy/downloadermiddlewares/chunked.py
==================
ecd3a976;Andrey Rahmatullin;2020-03-16 17:21:07 +0500;Merge pull request #4398 from nyov/remove-crawler-spiders
Remove deprecated Crawler.spiders property
==
==================
1d862e0d;Andrey Rahmatullin;2020-03-16 17:18:48 +0500;Merge pull request #4404 from nyov/obsolete2
Remove obsolete DEPRECATED_SETTINGS (deprecated.py)
==
==================
aa6075e0;Eugenio Lacuesta;2020-03-15 18:05:04 -0300;Merge branch 'master' into bytes_received_signal

==
==================
bde0384d;Eugenio Lacuesta;2020-03-14 19:53:36 -0300;Merge branch 'master' into spider.parse

==
==================
f9bf4b8d;Aditya Kumar;2020-03-14 15:09:00 +0530;Remove all top-level imports for twisted.internet.reactor (#4406)

==

docs/topics/settings.rst
scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http10.py
scrapy/core/downloader/handlers/http11.py
scrapy/extensions/closespider.py
scrapy/mail.py
scrapy/utils/benchserver.py
scrapy/utils/testproc.py
scrapy/utils/testsite.py
==================
0afe3da3;Andrey Rahmatullin;2020-03-13 18:28:11 +0500;Merge pull request #4422 from Gallaecio/pin-working-pytest
Restrict pytest to versions prior to 5.4
==
==================
3f6cdcab;Adrián Chaves;2020-03-13 13:25:53 +0100;Restrict pytest to versions prior to 5.4

==

tests/requirements-py3.txt
==================
ccc4d887;Lukas Anzinger;2020-03-12 20:42:14 +0100;Ignore a domain in allowed_domains with port and issue a warning (#4413)

==

scrapy/spidermiddlewares/offsite.py
tests/test_spidermiddleware_offsite.py
==================
3b0820d7;nyov;2020-03-12 19:15:49 +0000;Deprecate Spider.make_requests_from_url, part 2 (#4412)

==

scrapy/spiders/__init__.py
tests/test_spider.py
==================
db9198bc;Mikhail Korobov;2020-03-12 18:46:47 +0500;Merge pull request #4409 from nyov/remove-deprecation-warning
Remove a 'twisted.test.proto_helpers' deprecation warning
==
==================
ae5f5985;Mikhail Korobov;2020-03-12 18:44:49 +0500;Merge pull request #4420 from elacuesta/response_follow_all_empty_generator
Response.follow_all: return empty generators for empty sequences
==
==================
8d30dc08;Eugenio Lacuesta;2020-03-12 09:36:15 -0300;Response.follow_all: return empty generators for empty sequences

==

scrapy/http/response/text.py
tests/test_http_response.py
==================
388f23c3;Andrey Rahmatullin;2020-03-12 14:31:57 +0500;Merge pull request #3858 from elacuesta/multiple_feed_export_formats
[MRG+1] Support for exporting to multiple feeds in a single crawl
==
==================
21f1eddc;Eugenio Lacuesta;2020-03-11 21:16:35 -0300;Merge branch 'master' into bytes_received_signal

==
==================
c886a70e;Eugenio Lacuesta;2020-03-11 21:06:51 -0300;Use dict.setdefault in scrapy.utils.conf.feed_complete_default_values_from_settings

==

scrapy/utils/conf.py
==================
f3bab819;Eugenio Lacuesta;2020-03-11 20:56:25 -0300;Add tests for scrapy.utils.conf.feed_complete_default_values_from_settings

==

tests/test_utils_conf.py
==================
49156f2e;Eugenio Lacuesta;2020-03-11 20:45:54 -0300;[doc] Feed exports: full local path as example

==

docs/topics/feed-exports.rst
==================
17850957;Eugenio Lacuesta;2020-03-11 20:41:59 -0300;Remove single-use variable

==

scrapy/core/downloader/handlers/http11.py
==================
2eb990a2;Andrey Rahmatullin;2020-03-11 23:11:35 +0500;Merge pull request #4410 from Lukas0907/fix-offsite-middleware-tests
Fix handling of None in allowed_domains
==
==================
91a78eef;Eugenio Lacuesta;2020-03-08 22:32:17 -0300;Pass callback results as dicts instead of tuples

==

scrapy/core/downloader/handlers/http11.py
==================
ac73bcc7;Eugenio Lacuesta;2020-03-08 22:30:59 -0300;Merge branch 'master' into response_ip_address

==
==================
9d9dea0d;Lukas Anzinger;2020-03-07 19:54:25 +0100;Fix handling of None in allowed_domains.
Nones in allowed_domains ought to be ignored and there are also tests
for that scenario. This commit fixes the handling of None and also the
accompanying tests which are now executed again.

==

scrapy/spidermiddlewares/offsite.py
tests/test_spidermiddleware_offsite.py
==================
915e363d;nyov;2020-03-07 18:03:25 +0000;Remove a 'twisted.test.proto_helpers' deprecation warning

==

tests/test_webclient.py
==================
c2c6ea37;nyov;2020-03-04 21:30:32 +0000;Remove obsolete DEPRECATED_SETTINGS (deprecated.py)

==

scrapy/cmdline.py
scrapy/settings/deprecated.py
==================
ada37c54;Eugenio Lacuesta;2019-07-06 22:37:31 -0300;Export to multiple formats in a single crawl

==

docs/topics/feed-exports.rst
scrapy/commands/crawl.py
scrapy/commands/runspider.py
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
scrapy/utils/conf.py
tests/test_commands.py
tests/test_feedexport.py
tests/test_utils_conf.py
==================
c57512fa;Daniel Graña;2020-03-04 19:02:36 -0300;Merge pull request #4384 from nyov/nodeb
Drop horribly outdated deb package build files
==
==================
b1566a69;nyov;2020-03-02 23:01:26 +0000;Remove deprecated Crawler.spiders property
Deprecated since 419026615 (2014, Scrapy 0.25)

==

scrapy/crawler.py
tests/test_crawler.py
==================
ff8e826d;Mikhail Korobov;2020-03-05 00:04:29 +0500;Merge pull request #4385 from nyov/obsolete
Obsolete REDIRECT_MAX_METAREFRESH_DELAY, LOG_UNSERIALIZABLE_REQUESTS
==
==================
29f957d8;Mikhail Korobov;2020-03-04 23:56:36 +0500;Merge pull request #4400 from nyov/obsolete-datatypes
Remove deprecated SiteNode and MultiValueDict classes
==
==================
6c35baae;nyov;2020-03-04 00:40:11 +0000;Remove deprecated SiteNode and MultiValueDict classes

==

scrapy/utils/datatypes.py
==================
3aa5eab9;Eugenio Lacuesta;2020-03-03 13:53:43 -0300;Merge branch 'master' into response_ip_address

==
==================
64002255;nyov;2020-02-28 00:06:11 +0000;Drop horribly outdated deb package build files

==

Makefile.buildbot
debian/changelog
debian/compat
debian/control
debian/copyright
debian/pyversions
debian/rules
debian/scrapy.docs
debian/scrapy.install
debian/scrapy.lintian-overrides
debian/scrapy.manpages
==================
1b591ff0;nyov;2020-02-28 02:10:13 +0000;Obsolete deprecated settings
Obsolete REDIRECT_MAX_METAREFRESH_DELAY
  which has been deprecated since Scrapy 0.18

Obsolete LOG_UNSERIALIZABLE_REQUESTS
  which has been deprecated since Scrapy 1.2.0
  and is replaced by SCHEDULER_DEBUG

==

scrapy/core/scheduler.py
scrapy/downloadermiddlewares/redirect.py
scrapy/settings/deprecated.py
tests/test_scheduler.py
==================
a4dbb775;Adrián Chaves;2020-03-03 09:13:00 +0100;Bump version: 1.8.0 → 2.0.0

==

.bumpversion.cfg
scrapy/VERSION
==================
6aa0ba45;Adrián Chaves;2020-03-03 09:11:11 +0100;Write release notes for Scrapy 2.0.0 (#4329)

==

docs/index.rst
docs/intro/install.rst
docs/news.rst
docs/topics/asyncio.rst
docs/topics/coroutines.rst
docs/topics/downloader-middleware.rst
docs/topics/exporters.rst
docs/topics/feed-exports.rst
docs/topics/item-pipeline.rst
docs/topics/jobs.rst
docs/topics/link-extractors.rst
docs/topics/loaders.rst
docs/topics/media-pipeline.rst
docs/topics/request-response.rst
docs/topics/settings.rst
docs/topics/signals.rst
docs/topics/spiders.rst
scrapy/http/response/__init__.py
scrapy/logformatter.py
scrapy/utils/reactor.py
tests/test_crawl.py
==================
431f6e7d;Adrián Chaves;2020-03-01 18:17:18 +0100;Merge branch 'master' into patch-1

==
==================
ef00f8eb;MaliCN;2020-02-28 22:42:07 +0300;updated with new macOS name (#4308) (#4323)
* changed for new name as "macOS"  (issue #4308)

* updated macOS name

* update macOS name

* updated macOS name

* update for new macOS name

* docs/intro/install.rst: fix macOS header symbols

Co-Authored-By: elacuesta <elacuesta@users.noreply.github.com>

Co-authored-by: Adrián Chaves <adrian@chaves.io>
Co-authored-by: elacuesta <elacuesta@users.noreply.github.com>

==

README.rst
docs/intro/install.rst
docs/news.rst
scrapy/extensions/memusage.py
==================
231c9dde;Adrián Chaves;2020-02-28 18:50:45 +0100;Update docs/intro/install.rst

==

docs/intro/install.rst
==================
c411a51f;sakshamb2113;2020-02-28 17:47:02 +0530;Fix random failures from test_fixed_delay in some machines (#4372)

==

tests/test_crawl.py
==================
09d9e75c;Andrey Rahmatullin;2020-02-28 13:26:17 +0500;Merge pull request #4375 from Gallaecio/env-warn-whitelist
Stop deprecation warnings on arbitrary SCRAPY-prefixed env vars
==
==================
9aae4c0b;Adrián Chaves;2020-02-27 16:31:43 +0100;Add tests for envvar setting warnings

==

scrapy/utils/project.py
tests/test_utils_project.py
==================
2acaa862;Adrián Chaves;2020-02-27 15:39:49 +0100;Do not warn about valid environment variables

==

scrapy/utils/project.py
==================
6109ad9a;HEndo12345;2020-02-27 23:15:30 +0900;Clean up the deprecated settings list (#4378)

==

scrapy/settings/deprecated.py
==================
647cba0f;Mikhail Korobov;2020-02-26 02:27:02 +0500;Merge pull request #4373 from Gallaecio/fix-readthedocs
Fix the ReadTheDocs build
==
==================
77881371;Adrián Chaves;2020-02-25 21:58:28 +0100;Use ReadTheDocs install.path

==

.readthedocs.yml
docs/requirements.txt
setup.py
==================
a9d7d8f0;Adrián Chaves;2020-02-25 21:41:07 +0100;Add Scrapy dependencies back to docs/requirements.txt

==

docs/requirements.txt
setup.py
==================
7291173f;Adrián Chaves;2020-02-25 21:35:21 +0100;Have ReadTheDocs builds fail on warning

==

.readthedocs.yml
==================
034e2c31;gunblues;2020-02-26 03:46:05 +0800;Use a non-zero exit code when a pipeline's open_spider method throws an exception (#4207)
* fix issue 4175 - Scrapy does not use a non-zero exit code when pipeline's open_spider throws the exception

* remove extra blank lines

* remove redundant code

* remove blank line at end of file

* more suitable naming for response and make if-condition shorter

* avoid error - AttributeError: 'Deferred' object has no attribute 'result'

* use getattr to make code concisely

* add test

* remove useless file

* modify test class name

* remove unneccessary files

* Fix Flake8-reported issue

* fix these items which are suggested by Gallaecio
・Sort those imports at tests/test_cmdline_crawl_with_pipeline/__init__.py
・Remove the unused setUp method.
・Remove comments generated by Scrapy’s project generation tool.
・Remove the [deploy] section from the scrapy.cfg file (I don’t think it’s needed here)
・Remove BOT_NAME and NEWSPIDER_MODULE from settings.py (I think there are not needed either, although I’m less sure about NEWSPIDER_MODULE)

* have to reserve BOT_NAME, SPIDER_MODULES in settings.py

* Remove unneeded empty lines

* Empty __init__.py file with unneeded comments

* Remove an unneeded empty line at the end

* Remove unneeed empty line from __init__.py file

* Update __init__.py

* Update __init__.py

* Update exception.py

* Update normal.py

* Update __init__.py

* Update __init__.py

* fix W391 blank line at end of file

Co-authored-by: Adrián Chaves <adrian@chaves.io>

==

scrapy/commands/crawl.py
tests/test_cmdline_crawl_with_pipeline/__init__.py
tests/test_cmdline_crawl_with_pipeline/scrapy.cfg
tests/test_cmdline_crawl_with_pipeline/test_spider/__init__.py
tests/test_cmdline_crawl_with_pipeline/test_spider/pipelines.py
tests/test_cmdline_crawl_with_pipeline/test_spider/settings.py
tests/test_cmdline_crawl_with_pipeline/test_spider/spiders/__init__.py
tests/test_cmdline_crawl_with_pipeline/test_spider/spiders/exception.py
tests/test_cmdline_crawl_with_pipeline/test_spider/spiders/normal.py
==================
ea6ab179;Mikhail Korobov;2020-02-25 22:30:44 +0500;Merge pull request #4361 from nyov/linkfix
Documentation linkcheck run, fixing some links.
==
==================
a34c366f;nyov;2020-02-21 08:15:51 +0000;DOC linkcheck run; https and 301 link updates.
Closes #4359

==

docs/conf.py
docs/contributing.rst
docs/faq.rst
docs/intro/install.rst
docs/intro/tutorial.rst
docs/news.rst
docs/topics/broad-crawls.rst
docs/topics/downloader-middleware.rst
docs/topics/dynamic-content.rst
docs/topics/item-pipeline.rst
docs/topics/items.rst
docs/topics/leaks.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/shell.rst
docs/topics/spiders.rst
==================
caa1dea8;Mikhail Korobov;2020-02-25 13:12:01 +0500;Merge pull request #4370 from Gallaecio/dont-fail-kw-only
Make BaseItemExporter’s dont_fail parameter keyword-only
==
==================
7417a987;Adrián Chaves;2020-02-24 13:28:15 +0100;Make BaseItemExporter’s dont_fail parameter keyword-only

==

scrapy/exporters.py
==================
31f35c9c;elacuesta;2020-02-24 08:02:00 -0300;Remove unnecessary comma (#4369)

==

scrapy/resolver.py
==================
889b4718;Eugenio Lacuesta;2020-02-23 18:40:43 -0300;Import changes

==

scrapy/core/downloader/handlers/http11.py
tests/test_crawl.py
==================
f85bf77d;Eugenio Lacuesta;2020-02-23 18:31:13 -0300;Restore unrelated change

==

scrapy/resolver.py
==================
a44942d2;Eugenio Lacuesta;2020-02-23 18:13:52 -0300;Merge branch 'master' into response_ip_address

==
==================
49480225;Mikhail Korobov;2020-02-23 15:52:52 +0500;Merge pull request #4365 from noviluni/fix_flake8_E701_E271
Fix flake8 E131, E211, E251, E271, E701
==
==================
9d983c1b;elacuesta;2020-02-22 09:20:31 -0300;Expose certificate for HTTPS responses (#4054)
* Expose certificate for HTTPS responses

* Fix test (missing inlineCallbacks decorator)

* Note about Response.certificate

* Explicitly cover None as the default value of Response.certificate

Co-authored-by: Adrián Chaves <adrian@chaves.io>

==

docs/topics/request-response.rst
scrapy/core/downloader/handlers/http11.py
scrapy/http/response/__init__.py
tests/test_crawl.py
==================
67ee0b09;Vostretsov Nikita;2020-02-22 17:02:57 +0500;Remove specifics of downstream request queues from scheduler (#3884)
* move serialization/deserialization logic to downstream queues

* make memory queues conform to common interface

* make ScrapyPriorityQueue conform common interface

* ScrapyPriorityQueue works with disk

* make key as string

* return list instead of dict as earlier

* downloader aware pq works with new interface

* we don`t need these methods anymore

* create directories for files

* remove dummy priority

* remove priority as parameter, let every queue decide for itself

* rename obj to request

* DownloaderAwarePriorityQueue is too thin wrapper around _SlotPriorityQueues, just remove second one

* remove priority as parameter, let every queue decide for itself

* rename argument

* more granular class separation

* python2 compatible

* one more argument for common interface

* more simple downstream queue interface

* single place for easier customization

* rename function

* shorter

* shorter

* use named arguments

* fix typo

* add docstring

* Update scrapy/pqueues.py

Co-Authored-By: Mikhail Korobov <kmike84@gmail.com>

* Update scrapy/pqueues.py

Co-Authored-By: Mikhail Korobov <kmike84@gmail.com>

* 4 spaces indentation

* we ok with existing directories

* remove unused import

* rename method

* remove unused imports

* it has no sense now

* relining

* note about queues

* add value

* Revert "it has no sense now"

This reverts commit b61604275ba090ebd8e30a6d3a6fbe281c74c189.

* pep8 E261

* pep8 E303

* pep8 E501

* pep8 E123

* pep8 E123

* use create instance

* remove excessive import

Co-authored-by: Mikhail Korobov <kmike84@gmail.com>

==

scrapy/core/scheduler.py
scrapy/pqueues.py
scrapy/squeues.py
tests/test_squeues.py
==================
6e8e117a;Marc Hernandez Cabot;2020-02-21 09:14:55 +0100;fix flake E211

==

pytest.ini
tests/test_utils_url.py
==================
69a8648b;Marc Hernandez Cabot;2020-02-21 09:13:28 +0100;fix E251

==

pytest.ini
tests/test_downloadermiddleware_httpcompression.py
==================
9ad10bb6;Marc Hernandez Cabot;2020-02-21 09:05:42 +0100;fix E131

==

pytest.ini
tests/test_pipeline_crawl.py
==================
b49ece0b;Marc Hernandez Cabot;2020-02-21 08:58:32 +0100;fix E701 and E271 flake8

==

pytest.ini
scrapy/utils/iterators.py
tests/test_item.py
tests/test_pipeline_files.py
tests/test_squeues.py
tests/test_utils_python.py
==================
e551bc51;Mikhail Korobov;2020-02-21 23:50:01 +0500;Merge pull request #4318 from wRAR/asyncio-parse-asyncgen
Support yield in async def callbacks.
==
==================
b0a7efb8;Mikhail Korobov;2020-02-21 23:45:27 +0500;Merge pull request #4360 from noviluni/fix_flake8_E22X
fix E22X flake8
==
==================
1be1101f;Mikhail Korobov;2020-02-21 23:44:44 +0500;Merge pull request #4362 from noviluni/delete_deprecated_functions
delete old deprecated functions from scrapy.utils.python
==
==================
03ed9e17;Marc Hernandez Cabot;2020-02-21 09:29:29 +0100;delete old deprecated functions from scrapy.utils.python

==

scrapy/utils/python.py
==================
6fb85951;Marc Hernandez Cabot;2020-02-20 16:32:58 +0100;fix E22X flake8

==

pytest.ini
scrapy/commands/parse.py
scrapy/core/downloader/webclient.py
scrapy/core/spidermw.py
scrapy/downloadermiddlewares/ajaxcrawl.py
scrapy/exporters.py
scrapy/linkextractors/lxmlhtml.py
scrapy/settings/default_settings.py
scrapy/spiderloader.py
scrapy/utils/datatypes.py
scrapy/utils/http.py
scrapy/utils/misc.py
scrapy/utils/reactor.py
tests/pipelines.py
tests/test_command_parse.py
tests/test_downloader_handlers.py
tests/test_dupefilters.py
tests/test_pipeline_files.py
tests/test_spidermiddleware.py
tests/test_spidermiddleware_output_chain.py
tests/test_utils_defer.py
tests/test_utils_log.py
tests/test_utils_signal.py
tests/test_utils_url.py
tests/test_webclient.py
==================
91bbc70b;Marc Hernández;2020-02-21 06:05:31 +0100;fix E30X flake8 (#4355)

==

pytest.ini
scrapy/core/downloader/tls.py
scrapy/core/engine.py
scrapy/responsetypes.py
scrapy/utils/console.py
scrapy/utils/gz.py
tests/test_command_parse.py
tests/test_crawler.py
tests/test_dependencies.py
tests/test_downloadermiddleware_cookies.py
tests/test_downloadermiddleware_httpcache.py
tests/test_downloadermiddleware_redirect.py
tests/test_exporters.py
tests/test_http_response.py
tests/test_item.py
tests/test_mail.py
tests/test_pipeline_files.py
tests/test_pipeline_images.py
tests/test_pipeline_media.py
tests/test_responsetypes.py
tests/test_utils_conf.py
tests/test_utils_defer.py
tests/test_utils_deprecate.py
tests/test_utils_iterators.py
tests/test_utils_python.py
tests/test_utils_request.py
tests/test_utils_template.py
tests/test_utils_url.py
tests/test_webclient.py
==================
c4ee4b60;Mikhail Korobov;2020-02-20 02:56:34 +0500;Merge pull request #4347 from noviluni/deprecate_sel_shortcut
Remove deprecated `sel` shortcut in scrapy shell
==
==================
0f78a591;Adrián Chaves;2020-02-19 19:09:39 +0100;Fix Flake8-reported “Too many blank lines”

==

scrapy/core/scraper.py
==================
6972a197;Adrián Chaves;2020-02-19 18:59:09 +0100;Remove unused imports

==

scrapy/shell.py
==================
88179027;Andrey Rahmatullin;2020-02-19 22:40:14 +0500;Merge pull request #4331 from Gallaecio/response-cb-kwargs
Implement Response.cb_kwargs
==
==================
eb21dae5;Marc Hernandez Cabot;2020-02-19 17:49:42 +0100;deprecare sel shortcut in scrapy shell

==

scrapy/shell.py
==================
f558df25;Andrey Rahmatullin;2020-02-19 19:05:08 +0500;Merge pull request #4188 from elacuesta/logformatter-error-formatting
LogFormatter error formatting
==
==================
528b894f;Andrey Rahmatullin;2020-02-19 18:19:21 +0500;Merge pull request #4321 from Gallaecio/link-extractor-encoding
Use safe_url_string in link extraction
==
==================
182445f9;Akshay Sharma;2020-02-18 22:28:31 +0530;Fix a spelling error: ie. → i.e. (#4338)

==

docs/intro/tutorial.rst
docs/topics/downloader-middleware.rst
docs/topics/extensions.rst
docs/topics/feed-exports.rst
docs/topics/jobs.rst
docs/topics/link-extractors.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/signals.rst
scrapy/shell.py
scrapy/utils/misc.py
scrapy/utils/request.py
scrapy/utils/spider.py
sep/sep-003.rst
sep/sep-013.rst
sep/sep-021.rst
==================
320cea62;Mikhail Korobov;2020-02-18 19:56:35 +0500;Merge pull request #4309 from Gallaecio/virtualenv-doc
Update installation instructions regarding Python 3 and virtual environments
==
==================
6d6243af;leobalestri;2020-02-16 23:45:41 -0800;Update install.rst
Minor grammar and typo fixes
==

docs/intro/install.rst
==================
a04dd13c;Adrián Chaves;2020-02-14 22:31:30 +0100;ie. → i.e.

==

docs/topics/request-response.rst
==================
5ae3e167;Adrián Chaves;2020-02-14 22:30:36 +0100;ie. → i.e.
Co-Authored-By: elacuesta <elacuesta@users.noreply.github.com>
==

docs/topics/request-response.rst
==================
43b43654;Adrián Chaves;2020-02-13 22:39:58 +0100;Add tests for meta and cb_kwargs not being available

==

tests/test_http_response.py
==================
5ff9eb90;Adrián Chaves;2020-02-13 22:36:18 +0100;Add a test for the copy of cb_kwargs from Request to Response

==

tests/test_http_response.py
==================
df937d82;Adrián Chaves;2020-02-13 22:33:36 +0100;Implement Response.cb_kwargs

==

docs/topics/request-response.rst
scrapy/http/response/__init__.py
==================
b4958358;Adrián Chaves;2020-02-12 19:00:04 +0100;Update tests to account for link extractors escaping spaces

==

tests/test_linkextractors.py
==================
e1be078e;Adrián Chaves;2020-02-12 17:38:06 +0100;Fix Flake8-reported issues

==

scrapy/utils/test.py
tests/test_feedexport.py
==================
73e88d03;Adrián Chaves;2020-02-12 17:17:38 +0100;Import mock from unittest

==

scrapy/utils/test.py
==================
2d6d4fb2;Drew Seibert;2020-02-11 03:35:23 -0600;Deprecate overriding settings with SCRAPY-prefixed environment variables (#4300)

==

scrapy/utils/project.py
==================
a6ef065e;Mikhail Korobov;2020-02-11 02:05:45 +0500;Merge pull request #4271 from wRAR/asyncio-signals
async def support for signal handlers that already supported Deferreds
==
==================
61e74bac;Adrián Chaves;2020-02-10 21:57:21 +0100;Extract links with safe_url_string
canonicalize_url changes links in undesirable ways.

==

scrapy/linkextractors/lxmlhtml.py
==================
1f0f52cb;Andrey Rakhmatullin;2020-02-11 01:05:45 +0500;Improve async signal tests.

==

tests/test_signals.py
==================
36dcf901;Andrey Rakhmatullin;2020-02-11 00:57:58 +0500;Also test non-default async callbacks.

==

tests/py36/_test_crawl.py
tests/test_crawl.py
==================
037ae5b2;Adrián Chaves;2020-02-10 19:54:47 +0100;Explicitly indicate None as ip_address’s default value

==

docs/topics/request-response.rst
==================
4626e90d;Abhishek Pratap Singh;2020-02-10 18:48:31 +0000;Allow updating flags in follow and follow_all (#4279)

==

scrapy/http/response/__init__.py
scrapy/http/response/text.py
tests/test_http_response.py
==================
96bb3b51;Adrián Chaves;2020-02-10 19:45:09 +0100;Merge branch 'master' into feat-685

==
==================
7025c18b;Adrián Chaves;2020-02-10 19:43:23 +0100;Clear line of spaces

==

docs/topics/feed-exports.rst
==================
13ba9bc6;Eugenio Lacuesta;2020-02-10 12:29:39 -0300;Note about Response.ip_address

==

docs/topics/request-response.rst
==================
42b4e9b3;Eugenio Lacuesta;2020-02-10 11:23:38 -0300;Reword signal docs

==

docs/topics/signals.rst
==================
122ce6d6;Eugenio Lacuesta;2020-02-10 10:20:26 -0300;Check bytes are received in order (bytes_received signal)

==

tests/test_engine.py
==================
a64fa2f0;Eugenio Lacuesta;2020-02-10 10:16:05 -0300;Keyword arguments when creating a _ResponseReader

==

scrapy/core/downloader/handlers/http11.py
==================
35723d76;Adrián Chaves;2020-02-07 22:59:53 +0100;Use canonicalize_url in link extraction

==

scrapy/linkextractors/lxmlhtml.py
tests/test_linkextractors.py
==================
c2f484de;Adrián Chaves;2020-02-07 21:49:38 +0100;Merge branch 'master' into response_ip_address

==
==================
4c6993f2;Adrián Chaves;2020-02-07 21:34:54 +0100;Merge branch 'master' into asyncio-parse-asyncgen

==
==================
aae49356;Adrián Chaves;2020-02-07 21:17:56 +0100;Merge branch 'master' into spider.parse

==
==================
59653eba;Adrián Chaves;2020-02-07 21:07:57 +0100;Update installation instructions regarding Python 3 and virtual environments

==

docs/intro/install.rst
==================
b0eaf114;Mikhail Korobov;2020-02-07 23:51:15 +0500;Merge pull request #4197 from elacuesta/sphinx-twisted-api
[Docs] Fix Twisted links
==
==================
bd778027;Mikhail Korobov;2020-02-07 23:44:15 +0500;Merge pull request #4275 from abhishekh2001/master
Fixed artwork/README formatting
==
==================
7e341e0f;Mikhail Korobov;2020-02-07 23:42:10 +0500;Merge pull request #4291 from seregaxvm/master
add zsh -h autocomplete option
==
==================
c3b690a5;Mikhail Korobov;2020-02-07 23:41:31 +0500;Merge pull request #4290 from dekimsey/patch-1
FilesPipeline.file_path has optional arguments
==
==================
957681bc;Mikhail Korobov;2020-02-07 23:40:50 +0500;Merge pull request #4272 from elacuesta/spider-middleware
Spider middleware: catch spider callback exceptions early
==
==================
afbaf9d4;Mikhail Korobov;2020-02-07 23:33:51 +0500;Merge pull request #4303 from whalebot-helmsman/request_left_downloader_signal
request_left_downloader signal
==
==================
0f62e44d;Mikhail Korobov;2020-02-07 23:22:19 +0500;Merge pull request #4316 from wRAR/asyncio-parse-request-tests
Add a test for an async callbacks that returns requests.
==
==================
7323780c;Andrey Rakhmatullin;2019-12-31 16:15:41 +0500;Support yield in async def callbacks.

==

conftest.py
scrapy/utils/py36.py
scrapy/utils/spider.py
tests/py36/_test_crawl.py
tests/test_crawl.py
==================
31f6c711;Andrey Rakhmatullin;2020-02-07 17:14:52 +0500;Add a test for an async callbacks that returns requests.

==

tests/spiders.py
tests/test_crawl.py
==================
4a7c7340;Andrey Rakhmatullin;2020-02-07 16:58:59 +0500;Merge remote-tracking branch 'origin/master' into asyncio-signals

==
==================
153b78e5;Vostretsov Nikita;2020-02-07 11:08:55 +0500;Update docs/topics/signals.rst
Co-Authored-By: elacuesta <elacuesta@users.noreply.github.com>
==

docs/topics/signals.rst
==================
8817b9e8;Vostretsov Nikita;2020-02-07 11:07:53 +0500;Update docs/topics/signals.rst
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

docs/topics/signals.rst
==================
2f83f3e2;Vostretsov Nikita;2020-02-07 11:07:43 +0500;Update docs/topics/signals.rst
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

docs/topics/signals.rst
==================
84b55b73;Vostretsov Nikita;2020-02-07 11:07:35 +0500;Update docs/topics/signals.rst
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

docs/topics/signals.rst
==================
6c333491;Eugenio Lacuesta;2020-02-06 18:53:11 -0300;Merge branch 'master' into response_ip_address

==
==================
4f31c3ce;Joy Bhalla;2020-02-07 02:51:33 +0530;Document a backward incompatibility that may affect custom schedulers (#4274)

==

docs/news.rst
==================
7f2d3051;Eugenio Lacuesta;2020-02-06 18:19:40 -0300;Fix Flake8 issue

==

tests/test_crawl.py
==================
3263441f;Lane Shaw;2020-02-06 16:14:40 -0500;Update RFPDupeFilter line separator for correct universal newlines mode usage (#4283)

==

scrapy/dupefilters.py
tests/test_dupefilters.py
==================
24bb9fd5;Adrián Chaves;2020-02-06 21:39:09 +0100;Merge branch 'master' into spider.parse

==
==================
042e71e2;Mikhail Korobov;2020-02-06 23:40:45 +0500;Merge pull request #4311 from Gallaecio/metarefresh-ignore-tags
Make METAREFRESH_IGNORE_TAGS an empty list by default
==
==================
8d2705f2;Mikhail Korobov;2020-02-06 23:17:28 +0500;Merge pull request #4305 from Respawnz/patch-1
fix a typo in devloper-tools.rst
==
==================
35dafef7;elacuesta;2020-02-06 14:42:34 -0300;Specify Twisted reactor (TWISTED_REACTOR setting) (#4294)
* Add the ability to install a specific reactor

* Add docs for the TWISTED_REACTOR setting

* Add tests for the TWISTED_REACTOR setting

* Update asyncio reactor test

* Ignore W503 globally

W503 is not PEP8-compliant:
https://github.com/python/peps/commit/c59c4376ad233a62ca4b3a6060c81368bd21e85b

* Line length adjustment

* Adjust asyncio reactor tests

* Merge ASYNCIO_ENABLED and TWISTED_REACTOR settings

* More docs about TWISTED_REACTOR

* Fix asyncio reactor test

* Docs: fix title

* Reword docs

* Check the TWISTED_REACTOR setting outside of the installing function

* Remove unrelated change

* Update scrapy/utils/log.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update docs/topics/settings.rst

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update docs/topics/settings.rst

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

Co-authored-by: Adrián Chaves <adrian@chaves.io>

==

docs/faq.rst
docs/topics/broad-crawls.rst
docs/topics/settings.rst
pytest.ini
scrapy/crawler.py
scrapy/settings/default_settings.py
scrapy/utils/asyncio.py
scrapy/utils/defer.py
scrapy/utils/log.py
scrapy/utils/reactor.py
tests/CrawlerProcess/asyncio_enabled_no_reactor.py
tests/CrawlerProcess/asyncio_enabled_reactor.py
tests/CrawlerProcess/twisted_reactor_asyncio.py
tests/CrawlerProcess/twisted_reactor_poll.py
tests/CrawlerProcess/twisted_reactor_select.py
tests/test_commands.py
tests/test_crawler.py
tests/test_utils_asyncio.py
==================
489ffcda;Andrey Rakhmatullin;2020-02-06 22:39:00 +0500;Add a test for an async item_scraped handler.

==

tests/test_signals.py
==================
4be19e44;Vostretsov Nikita;2020-02-06 13:46:23 +0000;name signla catcher in accord with signal name

==

tests/test_request_left.py
==================
4bcc0933;Vostretsov Nikita;2020-02-06 13:45:00 +0000;Merge branch 'request_left_downloader_signal' of github.com:whalebot-helmsman/scrapy into request_left_downloader_signal

==
==================
4a91a542;Vostretsov Nikita;2020-02-06 13:44:51 +0000;fix typo

==

tests/test_request_left.py
==================
6733f4d9;Vostretsov Nikita;2020-02-06 18:40:42 +0500;Update docs/topics/signals.rst
Co-Authored-By: elacuesta <elacuesta@users.noreply.github.com>
==

docs/topics/signals.rst
==================
bbbb8f14;Mikhail Korobov;2020-02-06 17:09:57 +0500;Merge pull request #4304 from elacuesta/remove-six-from-tox-ini
Remove elusive six occurrence from tox.ini
==
==================
576663e5;Adrián Chaves;2020-02-06 10:43:20 +0100;Make METAREFRESH_IGNORE_TAGS an empty list by default

==

docs/topics/downloader-middleware.rst
scrapy/settings/default_settings.py
tests/test_downloadermiddleware_redirect.py
==================
c2cca368;Respawnz;2020-02-06 05:39:15 +0800;typo

==

docs/topics/developer-tools.rst
==================
11941c32;Eugenio Lacuesta;2020-02-05 13:27:54 -0300;Remove elusive six occurrence from tox.ini

==

tox.ini
==================
3769f753;Vostretsov Nikita;2020-02-05 12:08:08 +0000;pep8 E302

==

tests/test_request_left.py
==================
aab39f63;Vostretsov Nikita;2020-02-05 11:35:03 +0000;docummentation for new signal

==

docs/topics/signals.rst
==================
9916f6e5;Vostretsov Nikita;2020-02-05 11:32:54 +0000;tests for new signal

==

tests/test_request_left.py
==================
ae041748;Vostretsov Nikita;2020-02-05 11:32:31 +0000;emit new signal

==

scrapy/core/downloader/__init__.py
==================
898bc008;Vostretsov Nikita;2020-02-05 11:31:27 +0000;new signal

==

scrapy/signals.py
==================
fbea370c;Eugenio Lacuesta;2020-02-05 01:35:13 -0300;Rename function parameter

==

scrapy/core/spidermw.py
==================
ad704974;Eugenio Lacuesta;2020-02-04 13:30:13 -0300;Remove unnecessary parentheses in class definition

==

tests/mockserver.py
==================
13670f03;Eugenio Lacuesta;2020-02-03 16:16:43 -0300;Ignore tests/CrawlerRunner directory

==

conftest.py
==================
e0ef8ad2;Eugenio Lacuesta;2020-02-03 15:52:15 -0300;CrawlerRunner test for Response.ip_address

==

tests/CrawlerProcess/ip_address.py
tests/CrawlerRunner/ip_address.py
tests/mockserver.py
tests/test_crawler.py
==================
4851efdf;Eugenio Lacuesta;2020-02-03 14:50:54 -0300;Flake8 adjustments

==

tests/mockserver.py
==================
bb8f7dc6;Eugenio Lacuesta;2020-02-03 14:50:14 -0300;Mock DNS server

==

tests/mockserver.py
==================
a2ae380e;Eugenio Lacuesta;2020-02-03 13:23:52 -0300;Remove unnecessary commas

==

scrapy/resolver.py
tests/CrawlerProcess/ip_address.py
==================
b9e3a620;Eugenio Lacuesta;2020-02-03 04:07:44 -0300;Merge branch 'master' into response_ip_address

==
==================
0641ba0f;faizan2700;2020-02-02 16:54:22 +0530;SCRAPY_CHECK will be set while running contact

==

scrapy/commands/check.py
==================
22f7934f;Mikhail Korobov;2020-01-31 23:50:19 +0500;Merge pull request #4269 from wRAR/asyncio-parse
Support for async def callbacks.
==
==================
7687564c;Andrey Rakhmatullin;2020-01-30 17:42:03 +0500;Merge remote-tracking branch 'origin/master' into asyncio-signals

==
==================
cc825c21;Andrey Rakhmatullin;2020-01-30 16:17:06 +0500;Test returning items from an async def callback.

==

tests/spiders.py
tests/test_crawl.py
==================
47b9de93;Mikhail Korobov;2020-01-30 03:15:18 +0500;Merge pull request #4288 from petervandenabeele/patch-1
[Docs] 2 typos + 1 clarification in docs
==
==================
534ce07b;Mikhail Korobov;2020-01-30 00:19:40 +0500;Merge pull request #4293 from edorofeev/fix-accept-encoding-delimiter
[HttpCompressionMiddleware] fix delimiter for Accept-Encoding header
==
==================
6f02a8dc;Eugenio Lacuesta;2020-01-29 14:53:23 -0300;Add source parameter to bytes_received signal

==

docs/topics/signals.rst
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
tests/test_engine.py
==================
a499f38b;Eugenio Lacuesta;2020-01-29 14:35:17 -0300;Remove object parent class

==

scrapy/core/downloader/handlers/http11.py
==================
2c9643d3;Eugenio Lacuesta;2020-01-29 14:11:56 -0300;Test: bytes_received signal fired multiple times

==

tests/test_engine.py
==================
4e56571a;Evgeny Dorofeev;2020-01-29 15:48:47 +0300;[HttpCompressionMiddleware] fix delimiter for Accept-Encoding header

==

scrapy/downloadermiddlewares/httpcompression.py
tests/test_downloadermiddleware_httpcompression.py
==================
752e8f70;Daniel Kimsey;2020-01-26 13:21:31 -0600;FilesPipeline.file_path has optional arguments
Documented signature doesn't match the actual interface in [files.py](https://github.com/scrapy/scrapy/blob/master/scrapy/pipelines/files.py#L520).

Specifically, it looks like it may be [called](https://github.com/scrapy/scrapy/blob/master/scrapy/pipelines/files.py#L422) without a response value.

I found this when I was implementing the pipeline with the signature `file_path(self, request, response, info)` and the following error was being return in my results :

    [(False, <twisted.python.failure.Failure builtins.TypeError: file_path() missing 1 required positional argument: 'response'>)]

Scrapy==1.8.0

==

docs/topics/media-pipeline.rst
==================
a3b16894;Kevin Lloyd Bernal;2020-01-29 04:53:25 +0800;Log an error when giving up requests after too many retries (#3566)

==

scrapy/downloadermiddlewares/retry.py
==================
ad4477d3;Eugenio Lacuesta;2020-01-27 14:16:43 -0300;Remove unnecessary else

==

scrapy/core/spidermw.py
==================
4ffd18fb;Eugenio Lacuesta;2020-01-27 13:29:33 -0300;[docs] Mention that signals.bytes_received could be fired multiple times

==

docs/topics/signals.rst
==================
613fd41f;Eugenio Lacuesta;2020-01-27 12:30:26 -0300;bytes_received signal: improve test performance

==

tests/test_engine.py
==================
a6bf8954;Mikhail Korobov;2020-01-27 20:57:22 +0500;Merge pull request #4286 from petervandenabeele/fix-documentation
[Docs] Fix variable name `author_page_links`
==
==================
dbe20a86;Eugenio Lacuesta;2020-01-27 12:21:18 -0300;bytes_received signal: send spider argument

==

docs/topics/signals.rst
scrapy/core/downloader/handlers/http11.py
tests/test_engine.py
==================
c9d36522;Matsievskiy S.V;2020-01-27 18:24:57 +0300;add zsh -h autocomplete option

==

extras/scrapy_zsh_completion
==================
89483ce9;Adrián Chaves;2019-12-03 12:06:08 +0100;Fix Flake8 issues

==

tests/test_engine.py
==================
bda37e38;Eugenio Lacuesta;2019-11-29 12:02:27 -0300;[Tests] bytes_received signal

==

tests/test_engine.py
==================
cab449b1;Eugenio Lacuesta;2019-11-29 11:37:40 -0300;Typo fix

==

tests/test_engine.py
==================
72b8613e;Eugenio Lacuesta;2019-11-27 14:46:20 -0300;bytes_received signal (no tests)

==

docs/topics/signals.rst
scrapy/core/downloader/handlers/http11.py
scrapy/signals.py
==================
8529dff4;Eugenio Lacuesta;2020-01-26 18:00:56 -0300;Update docs regarding Response.ip_address and IPv6

==

docs/topics/request-response.rst
==================
e8da7e29;Eugenio Lacuesta;2020-01-26 17:53:39 -0300;Test DNS resolution using CrawlerProcess

==

tests/CrawlerProcess/ip_address.py
tests/test_crawl.py
tests/test_crawler.py
==================
80925ab8;Eugenio Lacuesta;2019-08-05 11:39:07 -0300;Get server IP address for HTTP/1.1 responses

==

docs/topics/request-response.rst
scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/http11.py
scrapy/http/response/__init__.py
tests/test_crawl.py
==================
f72d4e93;Peter Vandenabeele;2020-01-26 10:48:28 +0100;[Docs] 2 typos + 1 clarification in docs
Fixing 2 small typos and adding 1 word as clarification in the downloader-middlewares.

Also, I was confused with the entries like `ref:Reppy <reppy-parser>` and similar entries.
Are these supposed to be links to other parts of the doc, or is this the intended way of showing these references ?
==

docs/topics/downloader-middleware.rst
==================
f3374a50;Peter Vandenabeele;2020-01-25 16:52:30 +0100;Fix variable name `author_page_links`
I did not test this code, but the change from `href` to this
author_page_links seems to have a typo ?

==

docs/intro/tutorial.rst
==================
8b8df319;Mikhail Korobov;2020-01-25 05:03:13 +0500;Merge pull request #4227 from elacuesta/name-resolver
Name resolver with IPv6 support
==
==================
5f407cf6;Mikhail Korobov;2020-01-25 04:58:23 +0500;Merge pull request #3961 from OmarFarrag/ftp_files#3928
Add FTPFileStore to FilesPipeline
==
==================
7a62bd31;Mikhail Korobov;2020-01-25 04:52:56 +0500;Merge pull request #4126 from elacuesta/from_crawler_downloader_handlers
Download handlers: from_crawler factory method, take crawler in __init__
==
==================
9e6d5573;OmarFarrag;2020-01-24 15:58:52 +0200;Fix Flake8 errors

==

scrapy/pipelines/files.py
scrapy/utils/test.py
==================
40e0a11a;OmarFarrag;2020-01-24 15:51:48 +0200;Fix Flake8 errors

==

scrapy/extensions/feedexport.py
scrapy/pipelines/files.py
scrapy/utils/ftp.py
scrapy/utils/test.py
tests/test_pipeline_files.py
==================
f5d9eb15;OmarFarrag;2020-01-24 15:06:40 +0200;use `__future__` imports at the begining of the file

==

scrapy/utils/test.py
==================
fc98aa6b;OmarFarrag;2020-01-24 14:52:40 +0200;Merge branch 'master' into ftp_files#3928

==
==================
c544c0d2;OmarFarrag;2020-01-24 14:36:16 +0200;Use context management with `FTP`

==

scrapy/utils/ftp.py
==================
98994143;Eugenio Lacuesta;2020-01-23 18:06:59 -0300;Name resolver: return result directly

==

scrapy/resolver.py
==================
bd54f22f;Mikhail Korobov;2020-01-24 02:01:22 +0500;Merge pull request #4282 from petervandenabeele/patch-1
fix logical documentation error with PER_DOMAIN or PER_DOMAIN
==
==================
6a98d660;Mikhail Korobov;2020-01-23 23:40:05 +0500;Merge pull request #3551 from jpbalarini/change_scraper_slot
[MRG+1] Add ability to change max_active_size by setting
==
==================
f80c7776;Mikhail Korobov;2020-01-23 23:12:44 +0500;Merge pull request #4008 from elacuesta/docs_request_errback
Request: remove restriction about errback without callback
==
==================
7d5cebcf;Peter Vandenabeele;2020-01-23 09:08:21 +0100;fix logical documentation error with PER_DOMAIN or PER_DOMAIN

==

docs/faq.rst
==================
c0a7dfbc;Mikhail Korobov;2020-01-23 02:15:24 +0500;Merge pull request #4057 from elacuesta/response_follow_all
Response.follow_all
==
==================
c75cf15b;Eugenio Lacuesta;2020-01-22 10:38:59 -0300;Update CSS selectors in tutorial

==

docs/intro/tutorial.rst
==================
06ab668e;OmarFarrag;2020-01-22 03:48:07 +0200;Use kwargs-only parameters in `ftp_store_file`

==

scrapy/extensions/feedexport.py
scrapy/pipelines/files.py
scrapy/utils/ftp.py
==================
8ea8f148;OmarFarrag;2020-01-20 18:19:36 +0200;Update scrapy/utils/ftp.py
Co-Authored-By: Mikhail Korobov <kmike84@gmail.com>
==

scrapy/utils/ftp.py
==================
0f2d871d;JP Balarini;2019-05-22 16:26:27 -0300;Use PEP 515 style for SCRAPER_SLOT_MAX_ACTIVE_SIZE documentation

==

docs/topics/settings.rst
==================
eaa8ed02;Juan Pablo Balarini;2018-12-26 13:11:23 -0300;Add ability to change max_active_size by settings

==

docs/topics/settings.rst
scrapy/core/scraper.py
scrapy/settings/default_settings.py
==================
b471765d;Eugenio Lacuesta;2020-01-18 01:52:29 -0300;[doc] FAQ entry about the IPv6 and the DNS_RESOLVER setting

==

docs/faq.rst
==================
302d3f55;Eugenio Lacuesta;2020-01-18 01:41:57 -0300;[doc] DNS_RESOLVER setting

==

docs/topics/settings.rst
==================
41f7ebf3;Eugenio Lacuesta;2020-01-17 12:40:49 -0300;CachingThreadedResolver: No need to store the reactor as an instance attribute
It's already done in the parent class

==

scrapy/resolver.py
==================
dee420a6;Eugenio Lacuesta;2020-01-16 23:48:16 -0300;Fix name resolvers tests

==

tests/test_crawler.py
==================
d487498c;Eugenio Lacuesta;2020-01-16 22:02:01 -0300;Update name resolvers tests

==

tests/test_crawler.py
==================
90e3bd87;Eugenio Lacuesta;2020-01-16 20:32:40 -0300;[test] Name resolvers

==

tests/CrawlerProcess/alternative_name_resolver.py
tests/CrawlerProcess/default_name_resolver.py
tests/test_crawler.py
==================
1040f581;Eugenio Lacuesta;2020-01-16 20:14:52 -0300;Name resolvers: do not pass the reactor to the install method

==

scrapy/crawler.py
scrapy/resolver.py
==================
3cfa73b8;Eugenio Lacuesta;2020-01-16 18:01:18 -0300;Name resolvers: install_on_reactor as instance method

==

scrapy/crawler.py
scrapy/resolver.py
==================
f45b4c7f;Eugenio Lacuesta;2020-01-16 10:09:34 -0300;from_crawler support for name resolvers

==

scrapy/crawler.py
scrapy/resolver.py
==================
0f155b05;Eugenio Lacuesta;2020-01-16 04:27:13 -0300;Make Flake8 happy (remove unused import)

==

scrapy/crawler.py
==================
e69cf415;Eugenio Lacuesta;2020-01-16 03:58:07 -0300;Ability to choose name resolver

==

scrapy/crawler.py
scrapy/resolver.py
scrapy/settings/default_settings.py
==================
50310fc0;Mikhail Korobov;2020-01-16 03:28:09 +0500;Merge pull request #4270 from wRAR/asyncio-pipelines
async def support in pipelines
==
==================
8c3de288;Eugenio Lacuesta;2020-01-15 12:31:36 -0300;Remove non-working DNS timeout code

==

scrapy/crawler.py
scrapy/resolver.py
==================
55babf9a;Eugenio Lacuesta;2020-01-15 12:25:20 -0300;Cache resolution only if the DNS request was successful

==

scrapy/resolver.py
==================
f1c18463;Eugenio Lacuesta;2019-12-11 17:44:05 -0300;Name resolver: timeout

==

scrapy/resolver.py
==================
735c0ceb;Eugenio Lacuesta;2019-09-09 16:20:58 -0300;Custom name resolver implementing twisted.internet.interfaces.IHostnameResolver

==

pytest.ini
scrapy/crawler.py
scrapy/resolver.py
==================
03241aa4;abhishekh2001;2020-01-15 08:54:25 +0400;Fixed artwork/README formatting

==

artwork/README.rst
==================
9770ca35;Eugenio Lacuesta;2020-01-10 18:45:39 -0300;Spider middleware: simplify deferred errback handling

==

scrapy/core/spidermw.py
==================
d6e928f4;Eugenio Lacuesta;2020-01-10 04:40:03 -0300;Remove object as base class for MutableChain
Plus some minor styling adjustments

==

scrapy/utils/python.py
==================
c088c04f;Eugenio Lacuesta;2020-01-10 04:20:55 -0300;Spider middleware: catch exceptions right after the spider callback

==

scrapy/core/spidermw.py
scrapy/utils/python.py
==================
6ce1ad31;Eugenio Lacuesta;2020-01-10 04:20:37 -0300;[test] Spider middleware: catch exceptions right after the spider callback

==

tests/test_spidermiddleware_output_chain.py
==================
a91a13b4;Andrey Rakhmatullin;2019-11-12 23:09:00 +0500;Support for async def callbacks.

==

scrapy/utils/spider.py
tests/spiders.py
tests/test_crawl.py
==================
3faef2d0;Andrey Rakhmatullin;2019-09-12 20:10:58 +0500;Add async def support to signal handlers that already supported Deferreds.

==

scrapy/utils/defer.py
scrapy/utils/signal.py
tests/test_utils_signal.py
==================
7d859848;Andrey Rakhmatullin;2020-01-09 14:48:07 +0500;Use get_from_asyncio_queue in the pipeline test.

==

tests/test_pipelines.py
==================
9d8c54c0;Andrey Rakhmatullin;2019-12-16 22:43:55 +0500;Fix/ignore flake8 problems.

==

pytest.ini
scrapy/pipelines/__init__.py
==================
bdef948a;Andrey Rakhmatullin;2019-12-16 23:15:43 +0500;Mark the asyncio pipelines test as only_asyncio.

==

tests/test_pipelines.py
==================
bfdd552a;Andrey Rakhmatullin;2019-09-10 14:57:07 +0500;Add a test for pipelines using asyncio.

==

tests/test_pipelines.py
==================
1f9cef78;Andrey Rakhmatullin;2019-09-10 14:26:21 +0500;Add async def support to pipelines.

==

scrapy/pipelines/__init__.py
tests/test_pipelines.py
==================
81175669;Andrey Rakhmatullin;2019-12-16 22:12:27 +0500;Add utils.defer.deferred_f_from_coro_f.

==

scrapy/utils/defer.py
==================
2e405d2d;Eugenio Lacuesta;2020-01-05 00:33:19 -0300;Merge branch 'master' into response_follow_all

==
==================
ce618fb6;Mikhail Korobov;2020-01-03 22:28:41 +0500;Merge pull request #4259 from scrapy/asyncio-mw
Asyncio support in downloader middlewares
==
==================
b2dd379b;Andrey Rakhmatullin;2020-01-03 21:38:05 +0500;Remove the py35-asyncio env for 3.5 from Travis.

==

.travis.yml
==================
2b9254c2;Andrey Rakhmatullin;2019-12-31 17:54:41 +0500;Add a test function that uses asyncio.Queue().

==

scrapy/utils/test.py
tests/test_downloadermiddleware.py
==================
e3b8ba61;Andrey Rakhmatullin;2019-12-31 17:54:01 +0500;Run py35-asyncio also on 3.5.2 to test Xenial.

==

.travis.yml
==================
16787f5b;Andrey Rakhmatullin;2019-12-30 12:02:19 +0500;Merge middleware tests back as we don't need to set the setting anymore.

==

tests/test_downloadermiddleware.py
==================
50aa6ef2;Andrey Rakhmatullin;2019-12-21 14:36:11 +0500;Add deferred_from_coro.

==

scrapy/utils/defer.py
==================
5cf1ac00;Andrey Rakhmatullin;2019-12-16 19:24:44 +0500;Move the asyncio downloader mw test to a separate class.

==

tests/test_downloadermiddleware.py
==================
36036445;Andrey Rakhmatullin;2019-09-12 20:25:29 +0500;Add a non-asyncio async def middleware test.

==

tests/test_downloadermiddleware.py
==================
21f50c79;Andrey Rakhmatullin;2019-07-30 19:46:18 +0500;Add async def support to downloader middlewares.

==

scrapy/core/downloader/middleware.py
tests/test_downloadermiddleware.py
==================
14d4428e;1um0s;2019-12-30 01:26:22 +0530;Rephrasing documentation for image and file pipelines (#4252)
* scrapy#4034 Clarify documentation for image and file pipelines

* scrapy#4034 Clarify documentation for file pipeline

* scrapy#4034 Simplify documentation for pipeline

* scrapy#4034 Simplify documentation for pipeline

* scrapy#4034 Clarify documentation for image and file pipelines

* scrapy#4034 Clarify documentation for file pipeline

* scrapy#4034 Simplify documentation for pipeline

* scrapy#4034 Simplify documentation for pipeline

* scrapy#4034 Revert image, file pipeline docs. Enhance custom media pipeline docs.

* scrapy#4034 rebase master

* scrapy#4034 Clarify documentation for image and file pipelines

* scrapy#4034 Clarify documentation for file pipeline

* scrapy#4034 Simplify documentation for pipeline

* scrapy#4034 Simplify documentation for pipeline

* scrapy#4034 Clarify documentation for image and file pipelines

* scrapy#4034 Clarify documentation for file pipeline

* scrapy#4034 Simplify documentation for pipeline

* scrapy#4034 Simplify documentation for pipeline

* scrapy#4034 Revert image, file pipeline docs. Enhance custom media pipeline docs.

* scrapy#4034 rebase master

* Rebase master

* Add class to media pipeline docs

Co-Authored-By: elacuesta <elacuesta@users.noreply.github.com>

Co-authored-by: elacuesta <elacuesta@users.noreply.github.com>

==

docs/topics/media-pipeline.rst
==================
f0ae6734;Mikhail Korobov;2019-12-30 00:55:15 +0500;Merge pull request #4258 from atul-g/patch-1
Edited the link provided to homepage of lxml's website
==
==================
bb991cd3;Mikhail Korobov;2019-12-30 00:51:28 +0500;Merge pull request #4010 from scrapy/asyncio-base
Base support for asyncio
==
==================
82861c73;Atul Gopinathan;2019-12-27 22:57:58 +0530;Edited the link of the homepage of lxml website
The link "https://lxml.de" is redirecting to a completely different and unintended website. I changed the link to the index page of lxml's official website. I thought of changing it to the PyPi page of lxml, but even they are providing the same "https://lxml.de" link which doesn't seem to be working now.
==

docs/intro/install.rst
==================
dc1ee094;Andrey Rakhmatullin;2019-12-27 21:55:58 +0500;Rename ASYNCIO_ENABLED to ASYNCIO_REACTOR, change the logic accordingly.

==

docs/topics/settings.rst
scrapy/crawler.py
scrapy/settings/default_settings.py
scrapy/utils/log.py
tests/CrawlerProcess/asyncio_enabled_no_reactor.py
tests/CrawlerProcess/asyncio_enabled_reactor.py
tests/test_commands.py
tests/test_crawler.py
==================
f75ccc99;Andrey Rakhmatullin;2019-12-27 19:48:54 +0500;FIx a typo in the only_asyncio fixture.

==

conftest.py
==================
30ebd05a;Andrey Rakhmatullin;2019-12-27 00:05:14 +0500;Simplify the tox asyncio entries.

==

tox.ini
==================
8a1dc26d;Eugenio Lacuesta;2019-12-26 15:14:47 -0300;[doc] Note about the 'parse' method for CrawlSpider/XMLFeedSpider

==

docs/topics/spiders.rst
==================
c54df825;Eugenio Lacuesta;2019-12-26 15:12:19 -0300;[test] Handle keyword args in CrawlSpider.parse

==

tests/spiders.py
tests/test_crawl.py
==================
8d4948f6;Eugenio Lacuesta;2019-12-26 14:38:11 -0300;[test] Override CrawlSpider.parse

==

tests/spiders.py
tests/test_crawl.py
==================
37ac47ff;Andrey Rakhmatullin;2019-12-26 20:46:54 +0500;Fix a deprecation warning.

==

tests/test_utils_asyncio.py
==================
87ece066;Andrey Rakhmatullin;2019-12-26 20:41:06 +0500;Remove conditional asyncio imports.

==

scrapy/utils/asyncio.py
==================
ab54e0d3;Eugenio Lacuesta;2019-12-23 20:37:18 -0300;Keyword-only args for S3DownloadHandler

==

scrapy/core/downloader/handlers/s3.py
==================
982a66f9;Eugenio Lacuesta;2019-12-23 20:28:17 -0300;[test] Download handler: avoid passing settings if not necessary

==

tests/test_downloader_handlers.py
==================
9a75b46f;Eugenio Lacuesta;2019-12-23 20:26:58 -0300;Explicit argument names

==

scrapy/core/downloader/handlers/http10.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/s3.py
==================
2fb160e3;Eugenio Lacuesta;2019-12-23 20:24:16 -0300;Use settings instead of crawler

==

scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http10.py
==================
4d594b8c;Mikhail Korobov;2019-12-23 23:52:43 +0500;Merge pull request #4193 from Gallaecio/lgtm
Use super().__init__ in BaseItemExporter subclasses
==
==================
5982e347;Eugenio Lacuesta;2019-12-23 14:12:21 -0300;Take keyword arguments in base parsing methods

==

docs/topics/spiders.rst
scrapy/spiders/__init__.py
scrapy/spiders/crawl.py
scrapy/spiders/feed.py
==================
b9a58798;nyov;2014-05-24 20:24:01 +0000;change Scraper API to call internal `_parse` method
A Spider class using internal pre-processing can have first dibs
at this and then call a public `parse` method for subclass hooking.

==

scrapy/core/scraper.py
scrapy/spiders/__init__.py
scrapy/spiders/crawl.py
scrapy/spiders/feed.py
tests/test_spider.py
==================
e2e15d66;Eugenio Lacuesta;2019-12-23 10:48:19 -0300;Downloader handlers: sort imports

==

scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/datauri.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http10.py
scrapy/core/downloader/handlers/http11.py
==================
a6ec8925;Eugenio Lacuesta;2019-12-23 10:40:16 -0300;Downloader handlers: crawler=None in __init__

==

scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http10.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
8a567e98;Eugenio Lacuesta;2019-12-23 10:05:49 -0300;Remove unnecessary __init__ methods in downloader handler tests

==

tests/test_downloader_handlers.py
==================
7e6387de;Eugenio Lacuesta;2019-12-23 10:02:58 -0300;Use create_instance in FTPDownloadHandler/DataURIDownloadHandler tests

==

tests/test_downloader_handlers.py
==================
fa21d868;Eugenio Lacuesta;2019-12-23 10:00:25 -0300;Use create_instance in S3DownloadHandler tests

==

tests/test_downloader_handlers.py
==================
9e5d945e;Eugenio Lacuesta;2019-12-23 09:55:47 -0300;Use create_instance in downloader handler tests

==

tests/test_downloader_handlers.py
==================
342bf3cd;Eugenio Lacuesta;2019-12-23 09:52:55 -0300;Explicit keyword arguments

==

scrapy/core/downloader/handlers/__init__.py
==================
931b7e68;Eugenio Lacuesta;2019-12-23 09:50:28 -0300;Update FileDownloadHandler test

==

scrapy/core/downloader/handlers/file.py
tests/test_downloader_handlers.py
==================
310cc081;Eugenio Lacuesta;2019-12-21 17:24:45 -0300;Merge branch 'master' into from_crawler_downloader_handlers

==
==================
8de80f59;Andrey Rakhmatullin;2019-12-21 13:08:29 +0500;Raise an exception if ASYNCIO_ENABLED but the reactor is wrong.

==

scrapy/crawler.py
scrapy/utils/log.py
tests/test_crawler.py
==================
5577d4d2;Mikhail Korobov;2019-12-20 22:46:46 +0500;Merge pull request #3869 from elacuesta/detect_return_in_generator_callbacks
[MRG+1][Py3] Check for 'return' with arguments inside generators
==
==================
e342de50;Andrey Rakhmatullin;2019-12-20 19:37:50 +0500;Remove a stray newline.

==

tests/mockserver.py
==================
40697dcb;Andrey Rakhmatullin;2019-12-20 19:33:44 +0500;Remove deferred_from_coro from this PR.

==

scrapy/utils/defer.py
==================
20289be8;Andrey Rakhmatullin;2019-12-20 19:31:20 +0500;Merge remote-tracking branch 'origin/master' into asyncio-base

==
==================
fb3fb17c;Mikhail Korobov;2019-12-20 02:01:45 +0500;Merge pull request #4045 from Gallaecio/documentation-coverage
Deprecate FilteringLinkExtractor direct usage; add API docs for scrapy.linkextractors
==
==================
6a32a36e;Mikhail Korobov;2019-12-20 01:59:07 +0500;Merge pull request #4143 from Gallaecio/undent-rst-doctests
Do not indent doctests from the documentation unnecessarily
==
==================
1213c0e5;Mikhail Korobov;2019-12-20 01:56:36 +0500;Merge pull request #4247 from noviluni/fix_typos
fix typos
==
==================
a611a7c0;Mikhail Korobov;2019-12-20 01:54:26 +0500;Merge pull request #4249 from Gallaecio/docs-py37
Use Python 3.7 to build the documentation
==
==================
c7f9b955;Adrián Chaves;2019-12-19 12:44:52 +0100;Pylint: ignore not-an-iterable

==

pylintrc
==================
b4a2d985;Adrián Chaves;2019-12-19 12:39:17 +0100;Merge branch 'master' into undent-rst-doctests

==
==================
e22c0c27;Adrián Chaves;2019-12-19 12:15:54 +0100;Revert "Improve FilteringLinkExtractor.__new__"
This reverts commit ee9881d2704798c9cd61b6da503bb0694227c58c.

==

scrapy/linkextractors/__init__.py
==================
f6bc1940;Adrián Chaves;2019-12-19 12:06:15 +0100;Use Python 3.7 to build the documentation

==

.readthedocs.yml
.travis.yml
==================
c841a1f3;Andrey Rahmatullin;2019-12-19 14:09:02 +0500;Merge pull request #4140 from Gallaecio/docs-py38
Use the latest Python version to build the documentation
==
==================
16b363de;Marc Hernandez Cabot;2019-12-19 10:02:21 +0100;Merge branch 'master' into fix_typos

==
==================
23a67cec;Marc Hernandez Cabot;2019-12-19 09:57:17 +0100;fix first letter capitalization for Raring and Scrapy

==

docs/contributing.rst
docs/index.rst
docs/intro/install.rst
docs/news.rst
docs/topics/autothrottle.rst
docs/topics/commands.rst
docs/topics/contracts.rst
docs/topics/debug.rst
docs/topics/developer-tools.rst
docs/topics/logging.rst
docs/topics/settings.rst
docs/topics/shell.rst
docs/topics/telnetconsole.rst
sep/sep-004.rst
==================
3bcb14fe;Mikhail Korobov;2019-12-18 23:56:56 +0500;Merge pull request #4164 from Gallaecio/speed-up-tests-2
Improve the performance of the DOWNLOAD_DELAY test
==
==================
8f7faaa6;Mikhail Korobov;2019-12-18 23:40:21 +0500;Merge pull request #4190 from Gallaecio/doctest
Make developer-tools doctests pass
==
==================
c0d84f09;Marc Hernandez Cabot;2019-12-18 19:39:21 +0100;fix typos

==

docs/contributing.rst
docs/faq.rst
docs/news.rst
docs/topics/jobs.rst
docs/topics/leaks.rst
docs/topics/media-pipeline.rst
docs/topics/settings.rst
docs/topics/telnetconsole.rst
sep/sep-001.rst
sep/sep-019.rst
==================
c976230b;Mikhail Korobov;2019-12-18 23:39:04 +0500;Merge pull request #4246 from noviluni/fix_W293_blank_line_contains_whitespace
Fix W291, W292 and W293 flake8 issues (whitespaces)
==
==================
a5de2c64;Marc Hernandez Cabot;2019-12-18 16:24:48 +0100;fix W291, W292, W293 (whitespaces)

==

pytest.ini
scrapy/http/response/__init__.py
scrapy/http/response/text.py
scrapy/logformatter.py
scrapy/utils/markup.py
scrapy/utils/multipart.py
tests/test_contracts.py
tests/test_downloadermiddleware_retry.py
tests/test_dupefilters.py
tests/test_pipeline_files.py
tests/test_robotstxt_interface.py
tests/test_spidermiddleware_offsite.py
tests/test_spidermiddleware_output_chain.py
==================
916382e1;elacuesta;2019-12-18 12:05:33 -0300;Add errback parameter to scrapy.spiders.crawl.Rule (#4000)
* Add errback parameter to scrapy.spiders.crawl.Rule

* CrawlSpider: optimize by reducing iterations

* [test] Rule.errback

* [doc] Rule.errback

* [doc] Use autoclass in docs/topics/spiders.rst

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Rule.process_links takes a list

* Fix aesthetic issue reported by Flake8

==

docs/topics/spiders.rst
scrapy/spiders/crawl.py
tests/mockserver.py
tests/spiders.py
tests/test_crawl.py
==================
0e8ee22a;Andrey Rahmatullin;2019-12-18 20:00:36 +0500;Merge pull request #4244 from wRAR/split-EngineTest
Split a long test in test_engine.py into three.
==
==================
00517ec2;Adrián Chaves;2019-12-18 15:50:49 +0100;Merge branch 'master' into docs-py38

==
==================
8c5a8a02;Adrián Chaves;2019-12-18 15:43:40 +0100;Merge branch 'master' into pylint

==
==================
7ccb169a;Andrey Rakhmatullin;2019-12-18 19:41:16 +0500;Split a long test in test_engine.py into three.

==

tests/test_engine.py
==================
05331933;Mikhail Korobov;2019-12-18 18:35:19 +0500;Merge pull request #4179 from Gallaecio/user-friendlier-tox
Make tox configuration more user friendly
==
==================
e2b5cdeb;Andrey Rahmatullin;2019-12-18 18:27:09 +0500;Merge pull request #4242 from whalebot-helmsman/single_place_for_dependencies
Remove requirements-py3.txt
==
==================
01253392;Vostretsov Nikita;2019-12-18 11:13:36 +0000;remove requirements from here too

==

docs/requirements.txt
==================
e90f2769;Mikhail Korobov;2019-12-18 16:11:24 +0500;Merge pull request #4198 from wRAR/deprecate-noconnect
Deprecate the HTTPS proxy noconnect mode.
==
==================
1f689b50;Adrián Chaves;2019-12-18 12:09:34 +0100;Merge remote-tracking branch 'origin/documentation-coverage' into documentation-coverage

==
==================
174769a3;Adrián Chaves;2019-12-18 12:09:03 +0100;Use a better name for the LxmlLinkExtractor subclassing test

==

tests/test_linkextractors.py
==================
ee9881d2;Adrián Chaves;2019-12-18 12:08:34 +0100;Improve FilteringLinkExtractor.__new__

==

scrapy/linkextractors/__init__.py
==================
12f9ffeb;Vostretsov Nikita;2019-12-18 10:53:27 +0000;remove requirements-py3.txt

==

requirements-py3.txt
tox.ini
==================
ac302c3f;Andrey Rakhmatullin;2019-12-18 15:43:05 +0500;Fix a flake8 problem.

==

tests/test_downloader_handlers.py
==================
bb2ff13e;Andrey Rakhmatullin;2019-12-18 15:39:08 +0500;Skip Http10ProxyTestCase.test_download_with_proxy_https_noconnect

==

tests/test_downloader_handlers.py
==================
2d92a390;Andrey Rakhmatullin;2019-12-18 12:07:08 +0500;Restore test_download_with_proxy_https_noconnect, check for a warning there.

==

tests/test_downloader_handlers.py
==================
607815df;Adrián Chaves;2019-12-17 16:54:27 +0100;Merge branch 'master' into documentation-coverage

==
==================
b8cf5229;Adrián Chaves;2019-12-17 16:53:08 +0100;Merge branch 'master' into user-friendlier-tox

==
==================
4be2bbfe;Andrey Rahmatullin;2019-12-17 19:43:30 +0500;Merge pull request #4239 from Apuyuseng/master
Fix mail attachs tcmime *** (#4229)
==
==================
bb3f1642;Andrey Rahmatullin;2019-12-17 19:38:06 +0500;Merge pull request #4236 from wRAR/pipeline-tests
Add simple tests for pipelines.
==
==================
63cf5c75;Marc Hernández;2019-12-17 13:53:15 +0100;Fix E502: backslash is redundant between brackets (#4238)

==

pytest.ini
scrapy/cmdline.py
scrapy/commands/fetch.py
scrapy/commands/startproject.py
scrapy/contracts/default.py
scrapy/core/downloader/handlers/s3.py
scrapy/core/downloader/webclient.py
scrapy/core/spidermw.py
scrapy/downloadermiddlewares/httpcompression.py
scrapy/extensions/closespider.py
scrapy/linkextractors/__init__.py
scrapy/middleware.py
scrapy/utils/conf.py
tests/test_cmdline/__init__.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_retry.py
tests/test_engine.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_utils_http.py
==================
7d0096da;apu;2019-12-17 09:47:01 +0800;Fix mail attachs tcmime *** (#4229)
When the file name consists of alphanumeric characters, it is normal to receive the attachment name.
However，However, problems will occur if the file name is changed to Chinese.
This has nothing to do with the file type
==

scrapy/mail.py
==================
5980d3bb;Andrey Rakhmatullin;2019-09-10 14:23:11 +0500;Add simple tests for pipelines.

==

tests/test_pipelines.py
==================
e9b24d62;Mikhail Korobov;2019-12-16 21:56:43 +0500;Merge pull request #4231 from noviluni/docs_fix
Docs fix
==
==================
900de7c1;Andrey Rakhmatullin;2019-12-16 21:11:58 +0500;Fix the reactor_pytest fixture.

==

conftest.py
==================
039e6fe6;Andrey Rakhmatullin;2019-12-16 20:17:41 +0500;Refactor install_asyncio_reactor slightly.

==

scrapy/utils/asyncio.py
==================
451e7a61;Eugenio Lacuesta;2019-07-12 00:26:01 -0300;Scan callbacks/errbacks for return statements with values different than None

==

scrapy/core/scraper.py
scrapy/utils/datatypes.py
scrapy/utils/misc.py
tests/test_utils_datatypes.py
tests/test_utils_misc/test_return_with_argument_inside_generator.py
==================
2db7d453;Andrey Rakhmatullin;2019-12-16 19:24:25 +0500;Enable skipping tests based on --reactor.

==

conftest.py
pytest.ini
==================
a59bb279;marc;2019-12-15 17:33:00 +0100;add year through code

==

docs/conf.py
==================
1aab20e1;marc;2019-12-14 10:37:31 +0100;update copyright notice year

==

docs/conf.py
==================
e3a3ad4a;marc;2019-12-14 10:34:31 +0100;remove reference to old (Python 2.7) environment

==

docs/contributing.rst
==================
a1605cad;Andrey Rakhmatullin;2019-12-13 19:35:09 +0500;Hide utils.defer.isfuture().

==

scrapy/utils/defer.py
==================
afc886e5;Andrey Rakhmatullin;2019-12-13 19:34:47 +0500;Simplify tox.ini asyncio entries.

==

tox.ini
==================
a4ef9750;Adrián Chaves;2019-12-13 14:32:06 +0100;Fix Flake8-reported issues

==

pytest.ini
tests/test_linkextractors.py
==================
b5c4c2ca;Adrián Chaves;2019-12-13 14:20:48 +0100;Keep 2 spaces between code and inline comments (#4195)

==

pytest.ini
scrapy/core/downloader/webclient.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/exporters.py
scrapy/settings/default_settings.py
scrapy/spiders/feed.py
scrapy/utils/console.py
tests/test_command_fetch.py
tests/test_downloader_handlers.py
tests/test_engine.py
tests/test_http_request.py
tests/test_pipeline_media.py
tests/test_spidermiddleware_referer.py
tests/test_utils_defer.py
tests/test_utils_spider.py
==================
bfb78b8d;Andrey Rakhmatullin;2019-12-13 18:12:07 +0500;Add CrawlerProcess tests for ASYNCIO_ENABLED.

==

tests/CrawlerProcess/asyncio_enabled_no_reactor.py
tests/CrawlerProcess/asyncio_enabled_reactor.py
tests/test_crawler.py
==================
855bbebc;Andrey Rakhmatullin;2019-12-13 18:11:49 +0500;Move install_asyncio_reactor() from commands to CrawlerProcess.

==

scrapy/commands/crawl.py
scrapy/commands/runspider.py
scrapy/crawler.py
==================
69cd2e24;Andrey Rakhmatullin;2019-12-07 00:09:53 +0500;Move a bunch of "from twisted.internet import reactor" inside functions.

==

scrapy/cmdline.py
scrapy/commands/shell.py
scrapy/crawler.py
scrapy/shell.py
scrapy/utils/defer.py
scrapy/utils/ossignal.py
scrapy/utils/reactor.py
==================
35601230;Andrey Rakhmatullin;2019-12-05 19:06:51 +0500;Rename ASYNCIO_SUPPORT to ASYNCIO_ENABLED.

==

docs/topics/settings.rst
scrapy/commands/crawl.py
scrapy/commands/runspider.py
scrapy/settings/default_settings.py
scrapy/utils/log.py
tests/test_commands.py
tests/test_crawler.py
==================
352ddbb3;Andrey Rakhmatullin;2019-12-13 18:07:23 +0500;Merge remote-tracking branch 'origin/master' into asyncio-base

==
==================
02cdc53f;Andrey Rahmatullin;2019-12-13 18:04:05 +0500;Add a test for a CrawlerProcess script. (#4218)
* Add a test for a CrawlerProcess script.

* Add tests/CrawlerProcess to collect_ignore.

* Remove an extra line.

* Fix/improve conftest.py.

==

conftest.py
tests/CrawlerProcess/simple.py
tests/test_crawler.py
==================
21a2f8c6;Eugenio Lacuesta;2019-12-10 17:30:59 -0300;Merge branch 'master' into response_follow_all

==
==================
07b8cd28;Adrián Chaves;2019-12-05 14:48:31 +0100;Mark bandit’s 402 check as addressed by #4180 (#4181)

==

.bandit.yml
==================
1fc2b140;Adrián Chaves;2019-12-05 14:43:36 +0100;Merge branch 'master' into documentation-coverage

==
==================
076f0764;Andrey Rahmatullin;2019-12-05 18:20:14 +0500;Merge pull request #4121 from scrapy/remove-six-code
Remove six-related code and __future__ imports
==
==================
d7b1c138;Adrián Chaves;2019-12-05 14:02:24 +0100;Merge branch 'master' into user-friendlier-tox

==
==================
83b8046f;Adrián Chaves;2019-11-08 16:26:46 +0100;Do not indent doctests from the documentation unnecessarily

==

docs/intro/tutorial.rst
docs/news.rst
docs/topics/developer-tools.rst
docs/topics/dynamic-content.rst
docs/topics/items.rst
docs/topics/leaks.rst
docs/topics/loaders.rst
docs/topics/selectors.rst
docs/topics/shell.rst
docs/topics/stats.rst
==================
250da289;Mikhail Korobov;2019-12-05 17:47:03 +0500;Merge pull request #4170 from mabelvj/4133-handle-start_url
Raise error when start_url found instead of start_urls.
==
==================
57e36b5f;Adrián Chaves;2019-12-05 13:03:43 +0100;Merge branch 'master' into spider-name-collision

==
==================
7079d12c;Andrey Rahmatullin;2019-12-05 12:44:22 +0500;Merge pull request #4212 from grammy-jiang/fix-imports
Convert the relative imports to absolute imports
==
==================
aaf94aff;Andrey Rahmatullin;2019-12-05 12:43:24 +0500;Merge pull request #4213 from dqwerter/patch-1
Update overview.rst | Fix an inconsistency
==
==================
af624ef4;Wang Qin;2019-12-05 09:29:12 +0800;Update overview.rst | Fix an inconsistency
There exists an inconsistency between the code (line 37 - 38) and the output 'quotes.json' (line 56 - 68). 

Note that even though according to line 53 - 54  'quotes.json' is "reformatted here for better readability", it cannot explain why the "author" field precedes the "text" field. 

Intended output for the code BEFORE change: 
    [{
        "text": "\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\u201d",
        "author": "Jane Austen"
    },
    {
        "text": "\u201cOutside of a dog, a book is man's best friend. Inside of a dog it's too dark to read.\u201d",
        "author": "Groucho Marx"
    },
    {
        "text": "\u201cA day without sunshine is like, you know, night.\u201d",
        "author": "Steve Martin"
    },
    ...]

Intended output for the code After change (the inconsistency is fixed): 
    [{
        "author": "Jane Austen",
        "text": "\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\u201d"
    },
    {
        "author": "Groucho Marx",
        "text": "\u201cOutside of a dog, a book is man's best friend. Inside of a dog it's too dark to read.\u201d"
    },
    {
        "author": "Steve Martin",
        "text": "\u201cA day without sunshine is like, you know, night.\u201d"
    },
    ...]
==

docs/intro/overview.rst
==================
9b4b43f8;Grammy Jiang;2019-12-05 11:25:19 +1100;Convert the relative imports to absolute imports
This commits converts the relative imports to absolute imports in the
entire package

==

scrapy/__init__.py
scrapy/contracts/default.py
scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/handlers/s3.py
scrapy/linkextractors/__init__.py
scrapy/linkextractors/regex.py
==================
2c010152;Eugenio Lacuesta;2019-12-04 15:43:02 -0300;Merge remote-tracking branch 'upstream/master' into remove-six-code

==
==================
0b9f2921;Andrey Rakhmatullin;2019-12-04 22:06:35 +0500;Update .travis.yml.

==

.travis.yml
==================
97fb61ce;Andrey Rakhmatullin;2019-12-04 21:53:07 +0500;Move an import to postpone another "import twisted.internet.reactor".

==

scrapy/commands/shell.py
==================
ed34ce14;Andrey Rakhmatullin;2019-12-04 21:32:16 +0500;Add the ASYNCIO_SUPPORT setting, reshuffle other logic accordingly.

==

docs/topics/settings.rst
scrapy/cmdline.py
scrapy/commands/crawl.py
scrapy/commands/runspider.py
scrapy/settings/default_settings.py
scrapy/utils/asyncio.py
scrapy/utils/defer.py
scrapy/utils/log.py
tests/test_commands.py
tests/test_crawler.py
tests/test_utils_asyncio.py
==================
c079d500;Andrey Rakhmatullin;2019-11-21 23:40:16 +0500;Run tests without asyncio support by default, add py35-asyncio and py38-asyncio envs.

==

pytest.ini
tox.ini
==================
794cf718;Andrey Rakhmatullin;2019-11-14 13:27:21 +0500;Fix or ignore flake8 problems.

==

pytest.ini
scrapy/cmdline.py
scrapy/utils/asyncio.py
==================
3ba25ccb;Andrey Rakhmatullin;2019-11-08 00:09:28 +0500;Don't use asyncio.iscoroutine, as it is True for generators.

==

scrapy/utils/defer.py
==================
f41c2f38;Andrey Rakhmatullin;2019-08-22 21:24:30 +0500;Add py38-no-asyncio to Travis.

==

.travis.yml
==================
cc19ab54;Andrey Rakhmatullin;2019-08-22 18:15:02 +0500;Add tests that check asyncio support.

==

conftest.py
tests/test_commands.py
tests/test_crawler.py
tests/test_utils_asyncio.py
tox.ini
==================
2fbe7d49;Andrey Rakhmatullin;2019-08-21 17:16:33 +0500;Log asyncio support on spider start.

==

scrapy/utils/log.py
==================
b04b5413;Andrey Rakhmatullin;2019-08-21 17:14:46 +0500;Install the asyncio reactor only in scrapy.cmdline.

==

scrapy/__init__.py
scrapy/cmdline.py
scrapy/utils/asyncio.py
scrapy/utils/defer.py
tests/mockserver.py
==================
8d8fbddb;Andrey Rakhmatullin;2019-08-21 00:07:08 +0500;Switch to the released version of pytest-twisted.

==

tests/requirements-py3.txt
==================
63c3c623;Andrey Rakhmatullin;2019-07-30 19:45:56 +0500;Add utils.deferred_from_coro.

==

scrapy/utils/defer.py
==================
97776395;Andrey Rakhmatullin;2019-07-30 19:02:59 +0500;Run tests using the asyncio reactor.

==

pytest.ini
tests/mockserver.py
tests/requirements-py3.txt
==================
1b437bbe;Andrey Rakhmatullin;2019-07-30 19:02:16 +0500;Install the asyncio reactor on "import scrapy".

==

scrapy/__init__.py
==================
1b352606;Andrey Rakhmatullin;2019-07-25 18:18:34 +0500;Add a test for downloader middlewares using Deferreds.

==

tests/test_downloadermiddleware.py
==================
74627033;Grammy Jiang;2019-12-05 00:24:14 +1100;Remove the used import and re-arrange the imports (#4208)
This commit removes unused import and re-arrange the imports in cookies
module
==

scrapy/downloadermiddlewares/cookies.py
==================
70233347;Grammy Jiang;2019-12-05 00:23:28 +1100;Re-arrange the imports in httpcache module (#4209)
This commit re-arrange the imports in httpcache module to follow pep8
==

scrapy/downloadermiddlewares/httpcache.py
==================
5d8d4bb7;Grammy Jiang;2019-12-05 00:22:10 +1100;Re-arrange the imports in the httpproxy module (#4210)
This commit re-arranges the imports in the httpproxy module to follow
pep8
==

scrapy/downloadermiddlewares/httpproxy.py
==================
62778cf2;Eugenio Lacuesta;2019-09-11 15:40:44 -0300;Request: remove restriction about errback without callback

==

scrapy/http/request/__init__.py
tests/test_http_request.py
==================
2a9f5a0a;Eugenio Lacuesta;2019-12-03 15:56:50 -0300;Skip invalid links when passing SelectorLists to Response.follow_all

==

scrapy/http/response/text.py
tests/test_http_response.py
==================
9b745221;Mikhail Korobov;2019-12-03 13:14:45 +0500;Merge pull request #4099 from BurnzZ/itemloader-docs
update docs of scrapy.loader.ItemLoader.item
==
==================
e43f37ff;Eugenio Lacuesta;2019-11-05 16:18:42 -0300;Pass args/kwargs in S3DownloadHandler.from_crawler, update tests

==

scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
3d77f74e;Eugenio Lacuesta;2019-11-05 00:54:46 -0300;Download handlers: from_crawler factory method, take crawler instead of settings in __init__

==

scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/datauri.py
scrapy/core/downloader/handlers/file.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http10.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
5980b0f2;Adrián Chaves;2019-12-02 16:47:44 +0100;Don’t use follow_all where a single item is expected (#4)

==

docs/intro/tutorial.rst
==================
d1cdfb47;Grammy Jiang;2019-11-29 19:13:57 +1100;Use pprint.pformat on overridden settings (#4199)
Keeps consistency with scrapy.middleware

==

scrapy/crawler.py
==================
3a5b8622;Mikhail Korobov;2019-11-28 17:36:19 +0500;Merge pull request #4194 from Gallaecio/intersphinx
Use InterSphinx for coverage links
==
==================
048cd74a;Eugenio Lacuesta;2019-11-27 19:16:18 -0300;Add separate mapping for Twisted API docs

==

docs/conf.py
==================
17e64818;Eugenio Lacuesta;2019-11-27 18:42:42 -0300;[Docs] Fix Twisted links

==

docs/conf.py
==================
63546cbf;Andrey Rakhmatullin;2019-11-27 22:42:52 +0500;Deprecate the HTTPS proxy noconnect mode.

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
tests/test_proxy_connect.py
==================
b73fc99b;Adrián Chaves;2019-11-26 10:31:55 +0100;Use InterSphinx for coverage links

==

docs/conf.py
docs/contributing.rst
==================
dd12f5fd;Adrián Chaves;2019-11-25 15:59:59 +0100;Use Response.follow_all in the documentation where appropiate

==

docs/intro/tutorial.rst
==================
ed1e5776;Adrián Chaves;2019-11-25 13:35:29 +0100;Use super().__init__ in BaseItemExporter subclasses

==

scrapy/exporters.py
==================
54b056c4;Adrián Chaves;2019-11-25 12:13:31 +0100;Make developer-tools doctests pass

==

docs/_tests/quotes.html
docs/topics/developer-tools.rst
pytest.ini
==================
6d9ed614;Adrián Chaves;2019-11-25 10:34:21 +0100;Merge branch 'master' into remove-six-code

==
==================
8a1c9967;Andrey Rahmatullin;2019-11-25 13:47:58 +0500;Merge pull request #3899 from elacuesta/py3_single_argument_processors
[Py3] Item loaders: allow single argument functions as processors
==
==================
03af8885;Eugenio Lacuesta;2019-11-23 20:02:44 -0300;LogFormatter.download_error

==

scrapy/core/scraper.py
scrapy/logformatter.py
tests/test_logformatter.py
==================
4756e7c5;Eugenio Lacuesta;2019-11-23 19:33:29 -0300;LogFormatter.spider_error

==

scrapy/core/scraper.py
scrapy/logformatter.py
tests/test_logformatter.py
==================
facb9265;Eugenio Lacuesta;2019-11-23 19:16:41 -0300;Remove quotes from item_error message

==

scrapy/logformatter.py
tests/test_logformatter.py
==================
7a7d13b1;Eugenio Lacuesta;2019-11-23 19:04:02 -0300;Rename LogFormatter.error to item_error

==

scrapy/core/scraper.py
scrapy/logformatter.py
tests/test_logformatter.py
==================
40b5cfc0;Eugenio Lacuesta;2019-07-23 18:33:19 -0300;Item loaders: allow single-argument processors (unbound methods)

==

docs/topics/loaders.rst
scrapy/loader/__init__.py
tests/test_loader.py
==================
6fa8f06b;Eugenio Lacuesta;2019-11-22 13:05:06 -0300;Merge remote-tracking branch 'upstream/master' into response_follow_all

==
==================
55cc5c90;Eugenio Lacuesta;2019-11-22 12:41:31 -0300;Skip pickle in bandit check

==

.bandit.yml
==================
5bab3c02;Eugenio Lacuesta;2019-11-22 12:12:29 -0300;Merge remote-tracking branch 'upstream/master' into remove-six-code

==
==================
16e0636d;Mikhail Korobov;2019-11-22 12:28:29 +0500;Merge pull request #4186 from Gallaecio/lgtm
Remove unused imports
==
==================
9b5053c5;Adrián Chaves;2019-11-21 22:00:34 +0100;Undo unintended tox.ini changes

==

tox.ini
==================
0d416c61;Mikhail Korobov;2019-11-21 23:27:57 +0500;Merge pull request #4185 from Gallaecio/intersphinx
Use InterSphinx for links to the pytest and tox documentation
==
==================
070b3a4e;Mabel Villalba;2019-11-21 17:10:31 +0100;Merge branch 'master' into 4133-handle-start_url

==
==================
1718e450;Mabel Villalba;2019-11-18 12:33:55 +0100;[start_url] Fixes #4133: Raise AttributeError error when empty 'start_urls' and 'start_url' found. Added test.

==

scrapy/spiders/__init__.py
tests/test_spider.py
==================
82c01c26;Mikhail Korobov;2019-11-21 20:53:56 +0500;Merge pull request #4184 from Gallaecio/doctest
Make debug doctests pass
==
==================
bf503869;Eugenio Lacuesta;2019-11-21 10:58:24 -0300;Merge remote-tracking branch 'upstream/master' into remove-six-code

==
==================
b2328813;Adrián Chaves;2019-11-21 14:30:10 +0100;Restore intentional import of unused objects

==

scrapy/utils/url.py
==================
91c95766;Mikhail Korobov;2019-11-21 18:25:21 +0500;Merge pull request #4183 from Gallaecio/sphinx-extensions-2
Enable sphinx-hoverxref for all references
==
==================
d2b73b8e;Mikhail Korobov;2019-11-21 18:22:10 +0500;Merge pull request #4114 from scrapy/remove-py2-tests
Remove py2 tests
==
==================
a2bf340b;Adrián Chaves;2019-11-21 14:18:49 +0100;Remove unused imports

==

pytest.ini
scrapy/commands/check.py
scrapy/commands/view.py
scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/handlers/s3.py
scrapy/extensions/httpcache.py
scrapy/linkextractors/__init__.py
scrapy/selector/__init__.py
scrapy/selector/unified.py
scrapy/spiders/__init__.py
scrapy/utils/boto.py
scrapy/utils/console.py
scrapy/utils/curl.py
scrapy/utils/engine.py
scrapy/utils/http.py
scrapy/utils/markup.py
scrapy/utils/multipart.py
scrapy/utils/url.py
tests/mockserver.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_httpcache.py
tests/test_downloadermiddleware_httpcompression.py
tests/test_downloadermiddleware_httpproxy.py
tests/test_extension_telnet.py
tests/test_feedexport.py
tests/test_http_request.py
tests/test_pipeline_images.py
tests/test_robotstxt_interface.py
tests/test_selector.py
tests/test_spider.py
tests/test_spidermiddleware_output_chain.py
tests/test_spidermiddleware_referer.py
tests/test_utils_reqser.py
tests/test_utils_url.py
tox.ini
==================
fcfcabf1;Adrián Chaves;2019-11-21 12:15:13 +0100;Use InterSphinx for links to the pytest and tox documentation

==

docs/conf.py
docs/contributing.rst
==================
f251dda2;Adrián Chaves;2019-11-21 11:59:10 +0100;Make debug doctests pass

==

docs/topics/debug.rst
pytest.ini
==================
4f80eff1;Adrián Chaves;2019-11-21 10:30:21 +0100;Enable sphinx-hoverxref for all references

==

docs/conf.py
==================
714e0d3a;Eugenio Lacuesta;2019-11-20 12:41:38 -0300;Merge remote-tracking branch 'upstream/master' into remove-six-code

==
==================
f1fd7ec3;Mikhail Korobov;2019-11-20 19:47:22 +0500;Merge pull request #4171 from Gallaecio/doctest
Make command doctests pass
==
==================
65e2fb7d;Mikhail Korobov;2019-11-20 19:46:20 +0500;Merge pull request #4153 from Gallaecio/lgtm
MutableChain: return self from __iter__
==
==================
d69e788f;Mikhail Korobov;2019-11-20 19:38:50 +0500;Merge pull request #4172 from Gallaecio/intersphinx
Use InterSphinx to link to the Twisted documentation
==
==================
1f61b6b9;Mikhail Korobov;2019-11-20 19:38:05 +0500;Merge pull request #4173 from Gallaecio/sphinx-extensions-2
Add tooltips to documentation cross-references
==
==================
1b4afa28;Mikhail Korobov;2019-11-20 19:36:43 +0500;Merge pull request #4169 from Gallaecio/sphinx-extensions
Include /requirements-py3.txt from /docs/requirements.txt
==
==================
e96ca89a;Mikhail Korobov;2019-11-20 19:34:04 +0500;Merge pull request #4174 from Gallaecio/flake8
Add missing blank lines between functions and classes
==
==================
6781d2f5;Eugenio Lacuesta;2019-11-20 09:58:25 -0300;Update sample file references

==

tests/test_linkextractors.py
tests/test_linkextractors_deprecated.py
==================
6f4e84ec;Eugenio Lacuesta;2019-11-20 09:55:15 -0300;PEP8 adjustments for scrapy.http.response module

==

scrapy/http/response/__init__.py
scrapy/http/response/html.py
scrapy/http/response/text.py
scrapy/http/response/xml.py
==================
48223c10;Eugenio Lacuesta;2019-11-20 09:41:42 -0300;Merge remote-tracking branch 'upstream/master' into response_follow_all

==
==================
b602c61e;Eugenio Lacuesta;2019-11-20 09:38:54 -0300;[Test] Rename outdated sample files

==

tests/sample_data/link_extractor/linkextractor.html
tests/sample_data/link_extractor/linkextractor_no_href.html
tests/test_http_response.py
==================
e6c5292a;Eugenio Lacuesta;2019-11-20 09:29:55 -0300;Response.follow_all: Specific exception for invalid selectors

==

scrapy/http/response/text.py
==================
42954d0d;Adrián Chaves;2019-11-20 08:16:33 +0100;Mention that ScrapyHTTPClientFactory has Twisted code

==

scrapy/core/downloader/webclient.py
==================
fc3af54d;Adrián Chaves;2019-11-20 07:57:09 +0100;Make tox configuration more user friendly

==

.travis.yml
docs/contributing.rst
tox.ini
==================
6f642655;Eugenio Lacuesta;2019-11-19 11:04:46 -0300;Merge remote-tracking branch 'upstream/remove-py2-tests' into remove-six-code

==
==================
05785c1c;Eugenio Lacuesta;2019-11-19 11:01:34 -0300;Merge remote-tracking branch 'upstream/master' into remove-six-code

==
==================
78ad0163;Andrey Rahmatullin;2019-11-19 14:43:30 +0500;Fix flake8 problems in PR #3989 (#4176)

==

tests/test_logformatter.py
==================
beb7d80d;Andrey Rakhmatullin;2019-11-14 22:47:35 +0500;Add a comment about the noconnect tests.

==

tests/test_proxy_connect.py
==================
922a66cf;Andrey Rakhmatullin;2019-11-14 22:36:58 +0500;Fix or ignore flake8 problems.

==

pytest.ini
tests/test_proxy_connect.py
tests/test_utils_python.py
==================
a7b64099;Andrey Rakhmatullin;2019-11-01 19:52:57 +0500;Rename tests/py3-ignores.txt to tests/ignores.txt.

==

conftest.py
tests/ignores.txt
==================
8b730a36;Andrey Rakhmatullin;2019-11-01 19:50:56 +0500;Use self.proc.communicate() after killing mitmdump.

==

tests/test_proxy_connect.py
==================
5970d00e;Andrey Rakhmatullin;2019-11-01 19:46:38 +0500;Only xfail test_https_connect_tunnel_error on 3.6+.

==

tests/test_proxy_connect.py
==================
5080180c;Andrey Rakhmatullin;2019-11-01 19:46:19 +0500;Improve the test_https_tunnel_without_leak_proxy_authorization_header change.

==

tests/test_proxy_connect.py
==================
c4ef950e;Andrey Rakhmatullin;2019-10-31 23:21:30 +0500;Use an older mitmproxy for py3.5.

==

tests/requirements-py3.txt
==================
3ec69607;Andrey Rakhmatullin;2019-10-31 23:21:14 +0500;Fix test_proxy_connect.py for py3.5.

==

tests/test_proxy_connect.py
==================
c327ad9b;Andrey Rakhmatullin;2019-10-31 15:20:28 +0500;Remove an unused six import.

==

tests/test_downloader_handlers.py
==================
cbb6d0c6;Andrey Rakhmatullin;2019-09-03 15:23:24 +0500;Mark failing proxy tests.

==

tests/test_proxy_connect.py
==================
f066257e;Andrey Rakhmatullin;2019-09-03 15:17:03 +0500;Restore tests/test_proxy_connect.py and update it to modern mitmproxy.

==

tests/requirements-py3.txt
tests/test_proxy_connect.py
==================
e18014d8;Andrey Rakhmatullin;2019-07-22 20:51:03 +0500;Remove Python 2-only tests.

==

conftest.py
tests/py3-ignores.txt
tests/test_downloader_handlers.py
tests/test_linkextractors_deprecated.py
tests/test_proxy_connect.py
tests/test_utils_python.py
tests/test_webclient.py
==================
25cd7ac7;Andrey Rahmatullin;2019-11-19 13:50:08 +0500;Merge pull request #4094 from victor-torres/invalid-url
Improve URL schema validation on scrapy.Request initialization
==
==================
3408b757;Andrey Rahmatullin;2019-11-19 13:44:43 +0500;Merge pull request #3989 from elacuesta/logformatter_error_method
LogFormatter improvements
==
==================
e829c47e;Andrey Rahmatullin;2019-11-19 11:20:56 +0500;Merge pull request #3937 from sbs2001/patch-10
Update reactor.py, updated 'if' sequencing .
==
==================
f261cf65;Adrián Chaves;2019-11-18 17:16:09 +0100;Add missing blank lines between functions and classes
Also fixed 2 unrelated Flake8 issues

==

pytest.ini
scrapy/commands/fetch.py
scrapy/commands/list.py
scrapy/commands/settings.py
scrapy/commands/view.py
scrapy/core/downloader/handlers/datauri.py
scrapy/downloadermiddlewares/ajaxcrawl.py
scrapy/dupefilters.py
scrapy/exceptions.py
scrapy/extension.py
scrapy/extensions/spiderstate.py
scrapy/http/response/html.py
scrapy/http/response/xml.py
scrapy/interfaces.py
scrapy/loader/common.py
scrapy/pipelines/__init__.py
scrapy/resolver.py
scrapy/robotstxt.py
scrapy/utils/console.py
scrapy/utils/decorators.py
scrapy/utils/defer.py
scrapy/utils/display.py
scrapy/utils/engine.py
scrapy/utils/ftp.py
scrapy/utils/gz.py
scrapy/utils/httpobj.py
scrapy/utils/job.py
scrapy/utils/python.py
scrapy/utils/reactor.py
scrapy/utils/request.py
scrapy/utils/response.py
scrapy/utils/spider.py
scrapy/utils/template.py
scrapy/utils/test.py
scrapy/utils/versions.py
tests/mocks/dummydbm.py
tests/pipelines.py
tests/spiders.py
tests/test_cmdline/extensions.py
tests/test_command_parse.py
tests/test_dependencies.py
tests/test_downloadermiddleware_ajaxcrawlable.py
tests/test_downloadermiddleware_httpcache.py
tests/test_dupefilters.py
tests/test_http_headers.py
tests/test_logformatter.py
tests/test_mail.py
tests/test_middleware.py
tests/test_responsetypes.py
tests/test_robotstxt_interface.py
tests/test_spiderloader/__init__.py
tests/test_spiderloader/test_spiders/nested/spider4.py
tests/test_spiderloader/test_spiders/spider0.py
tests/test_spiderloader/test_spiders/spider1.py
tests/test_spiderloader/test_spiders/spider2.py
tests/test_spiderloader/test_spiders/spider3.py
tests/test_spidermiddleware_offsite.py
tests/test_spidermiddleware_output_chain.py
tests/test_spidermiddleware_referer.py
tests/test_squeues.py
tests/test_utils_console.py
tests/test_utils_defer.py
tests/test_utils_http.py
tests/test_utils_httpobj.py
tests/test_utils_iterators.py
tests/test_utils_request.py
tests/test_utils_signal.py
tests/test_utils_sitemap.py
tests/test_utils_spider.py
tests/test_utils_url.py
==================
fed93515;Adrián Chaves;2019-11-18 16:11:03 +0100;Add tooltips to documentation cross-references

==

docs/conf.py
docs/requirements.txt
==================
e84cb18c;Adrián Chaves;2019-11-18 15:50:45 +0100;Use InterSphinx to link to the Twisted documentation

==

docs/conf.py
docs/contributing.rst
docs/topics/api.rst
docs/topics/architecture.rst
docs/topics/email.rst
docs/topics/item-pipeline.rst
docs/topics/media-pipeline.rst
docs/topics/practices.rst
docs/topics/request-response.rst
docs/topics/signals.rst
scrapy/core/downloader/contextfactory.py
scrapy/crawler.py
scrapy/signalmanager.py
==================
74589df0;Adrián Chaves;2019-11-18 14:51:44 +0100;Make command doctests pass

==

docs/topics/commands.rst
pytest.ini
==================
e1af8561;Adrián Chaves;2019-11-18 11:06:25 +0100;Add a configuration file for Read the Docs

==

.readthedocs.yml
==================
6d1667d5;Adrián Chaves;2019-11-07 18:32:33 +0100;Use the latest Python version to build the documentation

==

.travis.yml
tox.ini
==================
99d8b05a;Adrián Chaves;2019-11-18 10:58:47 +0100;Deprecate scrapy.utils.python.MutableChain.next

==

scrapy/utils/python.py
tests/test_utils_python.py
==================
393a2a19;Adrián Chaves;2019-11-18 09:15:48 +0100;Include /requirements-py3.txt from /docs/requirements.txt

==

docs/requirements.txt
==================
a78e58af;Andrey Rahmatullin;2019-11-17 16:46:15 +0500;Merge pull request #4167 from noviluni/fix_E711_and_E713
fix E711 and E713
==
==================
0e252f5a;Marc Hernandez Cabot;2019-11-15 19:12:43 +0100;fix E711 and E713

==

pytest.ini
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_httpcache.py
==================
786a55b2;Andrey Rahmatullin;2019-11-15 15:39:27 +0500;Merge pull request #4059 from josealberto4444/master
Make punctuation consistent
==
==================
77a84f62;José Alberto / Speedy;2019-11-15 11:09:24 +0100;Fix string
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

README.rst
==================
a541c329;Mikhail Korobov;2019-11-15 00:36:56 +0500;Merge pull request #4152 from Gallaecio/sphinx-extensions
Install the sphinx-notfound-page Sphinx extension
==
==================
7b4637d0;Mikhail Korobov;2019-11-15 00:19:20 +0500;Merge pull request #4146 from Gallaecio/doctest
Make tutorial doctests pass
==
==================
49b5251e;Mikhail Korobov;2019-11-15 00:16:39 +0500;Merge pull request #4147 from Gallaecio/intersphinx
Use intersphinx for links to the Sphinx documentation
==
==================
cc0026f7;Mikhail Korobov;2019-11-14 23:43:44 +0500;Merge pull request #4148 from Gallaecio/doc-view-code
Allow opening the source code from the API documentation
==
==================
550d8046;Mikhail Korobov;2019-11-14 23:42:06 +0500;Merge pull request #4157 from Gallaecio/flake8
Add missing whitespace after ‘,’, ‘;’ or ‘:’
==
==================
298d709e;Mikhail Korobov;2019-11-14 23:40:01 +0500;Merge pull request #4162 from Gallaecio/bandit
Add bandit to CI
==
==================
d61088f4;Mikhail Korobov;2019-11-14 23:35:21 +0500;Merge pull request #4163 from Gallaecio/speed-up-tests
Have CI record the 10 slowest tests
==
==================
494f38a9;Mikhail Korobov;2019-11-14 23:33:58 +0500;Merge pull request #4115 from scrapy/remove-py2-code
Remove py2 code
==
==================
3b2289ad;Andrey Rakhmatullin;2019-11-14 22:53:28 +0500;Rename test_non_str_url_py2 to test_bytes_url.

==

tests/test_link.py
==================
fe3a121f;Andrey Rakhmatullin;2019-11-14 22:50:53 +0500;Use kwargs when calling get_func_args.

==

tests/test_utils_python.py
==================
0946eb33;Adrián Chaves;2019-11-14 17:56:21 +0100;Port code from Twisted’s deprecated HTTPClientFactory into ScrapyHTTPClientFactory

==

scrapy/core/downloader/webclient.py
==================
058bdda0;Adrián Chaves;2019-11-14 16:51:47 +0100;Improve the performance of the DOWNLOAD_DELAY test

==

tests/test_crawl.py
==================
5ee5508c;Adrián Chaves;2019-11-14 15:42:34 +0100;Have CI record the 10 slowest tests

==

tox.ini
==================
b8ef12cd;Adrián Chaves;2019-11-14 12:10:25 +0100;Add bandit to CI

==

.bandit.yml
.travis.yml
tox.ini
==================
5a2b0573;Andrey Rahmatullin;2019-11-14 15:26:03 +0500;Merge pull request #4066 from akhterwahab/update-ignored-extensions
Add .dmg, .iso & .apk to ignored other extensions
==
==================
e291460d;Andrey Rakhmatullin;2019-11-14 15:24:37 +0500;Fix flake8-detected errors.

==

scrapy/crawler.py
scrapy/exporters.py
scrapy/http/cookies.py
scrapy/link.py
tests/test_pipeline_media.py
==================
3631453b;Andrey Rahmatullin;2019-11-14 15:07:53 +0500;Remove spaces on a blank line.

==

scrapy/linkextractors/__init__.py
==================
be6da520;Adrián Chaves;2019-11-14 10:31:55 +0100;Include extensions from #2067

==

scrapy/linkextractors/__init__.py
==================
1a4a77d4;Adrián Chaves;2019-11-14 10:24:31 +0100;Remove Python 2 check from MutableChainTest

==

tests/test_utils_python.py
==================
dd367438;Andrey Rakhmatullin;2019-11-01 20:05:37 +0500;Improve the dbm module ref.
Co-Authored-By: Adrián Chaves <adrian@chaves.io>

==

docs/topics/downloader-middleware.rst
==================
a9c89139;Andrey Rakhmatullin;2019-10-31 22:55:58 +0500;Fix a duplicate ref name in docs.

==

docs/topics/downloader-middleware.rst
==================
87c23ba2;Andrey Rakhmatullin;2019-08-28 16:29:53 +0500;Remove Py2-only code that checks sys.version_info.

==

tests/test_utils_reqser.py
==================
a138fb05;Andrey Rakhmatullin;2019-08-20 21:35:13 +0500;Replace to_native_str calls with to_unicode.

==

scrapy/core/downloader/handlers/http11.py
scrapy/downloadermiddlewares/cookies.py
scrapy/downloadermiddlewares/robotstxt.py
scrapy/exporters.py
scrapy/http/cookies.py
scrapy/http/response/text.py
scrapy/linkextractors/lxmlhtml.py
scrapy/responsetypes.py
scrapy/robotstxt.py
scrapy/spidermiddlewares/referer.py
scrapy/utils/reqser.py
scrapy/utils/request.py
scrapy/utils/response.py
scrapy/utils/ssl.py
tests/test_command_parse.py
tests/test_commands.py
tests/test_feedexport.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_robotstxt_interface.py
==================
92ffd2f2;Andrey Rakhmatullin;2019-08-20 21:27:52 +0500;Simplify some more imports.

==

scrapy/downloadermiddlewares/httpproxy.py
scrapy/loader/processors.py
tests/__init__.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_extension_telnet.py
tests/test_feedexport.py
tests/test_http_request.py
tests/test_item.py
tests/test_pipeline_files.py
tests/test_settings/__init__.py
tests/test_spider.py
tests/test_spidermiddleware.py
tests/test_stats.py
tests/test_utils_deprecate.py
tests/test_utils_misc/__init__.py
tests/test_utils_trackref.py
==================
cfa633f5;Andrey Rakhmatullin;2019-08-20 21:13:01 +0500;Some text function messages cleanup, deprecate to_native_str.

==

scrapy/http/response/__init__.py
scrapy/utils/python.py
==================
85e79ae7;Andrey Rakhmatullin;2019-08-20 21:09:49 +0500;Remove cStringIO imports.

==

scrapy/downloadermiddlewares/decompression.py
scrapy/mail.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/utils/gz.py
scrapy/utils/iterators.py
tests/test_cmdline/__init__.py
tests/test_pipeline_media.py
==================
065fe29d;Andrey Rakhmatullin;2019-08-20 21:06:52 +0500;Deprecate scrapy.utils.gz.read1.

==

scrapy/utils/gz.py
==================
0e696ed0;Andrey Rakhmatullin;2019-08-20 20:56:26 +0500;Remove unneeded and unused code from XmlItemExporter.

==

scrapy/exporters.py
==================
1d7c8cb0;Andrey Rakhmatullin;2019-07-22 22:27:29 +0500;Remove six.PY2 and six.PY3 conditionals.

==

docs/topics/downloader-middleware.rst
scrapy/_monkeypatches.py
scrapy/commands/fetch.py
scrapy/crawler.py
scrapy/exporters.py
scrapy/extensions/feedexport.py
scrapy/http/request/form.py
scrapy/http/response/text.py
scrapy/item.py
scrapy/link.py
scrapy/mail.py
scrapy/settings/__init__.py
scrapy/settings/default_settings.py
scrapy/utils/boto.py
scrapy/utils/conf.py
scrapy/utils/datatypes.py
scrapy/utils/gz.py
scrapy/utils/iterators.py
scrapy/utils/python.py
tests/__init__.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_item.py
tests/test_link.py
tests/test_middleware.py
tests/test_request_cb_kwargs.py
tests/test_settings/__init__.py
tests/test_utils_datatypes.py
tests/test_utils_python.py
==================
33ef24c7;Adrián Chaves;2019-11-13 10:52:05 +0100;Add missing whitespace after ‘,’, ‘;’ or ‘:’

==

pytest.ini
scrapy/core/spidermw.py
tests/test_http_request.py
tests/test_item.py
tests/test_linkextractors.py
tests/test_logformatter.py
tests/test_utils_conf.py
tests/test_utils_console.py
tests/test_utils_misc/__init__.py
==================
a3a3107b;Adrián Chaves;2019-11-13 09:46:54 +0100;MutableChain: return self from __iter__

==

scrapy/utils/python.py
==================
76c31094;Adrián Chaves;2019-11-13 09:28:48 +0100;Install the sphinx-notfound-page Sphinx extension

==

docs/conf.py
docs/requirements.txt
==================
b642a1fc;Adrián Chaves;2019-11-13 09:14:20 +0100;Fix doctest skipping based on the running Python version

==

docs/intro/tutorial.rst
==================
414e6e2f;Adrián Chaves;2019-11-13 07:56:45 +0100;Skip a doctest in Python 3.5- because of dictionary changes

==

docs/intro/tutorial.rst
==================
c911e802;Andrey Rahmatullin;2019-11-12 21:48:16 +0500;Merge pull request #4088 from ammarnajjar/4086-constructor-initializer-docs
docs: use __init__ method instead of constructor
==
==================
c9139055;Andrey Rahmatullin;2019-11-12 21:43:28 +0500;Merge pull request #4074 from purvaudai/master
Added Pathlib.Path support: Issue #3731
==
==================
4c9a1cd2;Andrey Rahmatullin;2019-11-12 18:45:29 +0500;Merge pull request #4097 from Gallaecio/test-coverage
Remove unused method from scrapy.pqueues._SlotPriorityQueues
==
==================
4b8b0345;purvaudai;2019-11-12 18:17:15 +0530;Mades Changes as per review

==

requirements-py3.txt
tests/test_feedexport.py
==================
d8098350;Andrey Rahmatullin;2019-11-12 16:17:49 +0500;Merge pull request #3960 from thernstig/issue_2149
Update documentation for logging manually
==
==================
93385e64;Andrey Rahmatullin;2019-11-12 16:05:22 +0500;Merge pull request #4123 from elacuesta/utils-local-cache-limit
Fix LocalCache limit issue, add tests
==
==================
8a6a0637;Adrián Chaves;2019-11-12 10:23:19 +0100;Allow opening the source code from the API documentation

==

docs/conf.py
==================
7b7bb028;Adrián Chaves;2019-11-12 08:49:06 +0100;Use intersphinx for links to the Sphinx documentation

==

docs/conf.py
docs/contributing.rst
==================
79d2f999;Adrián Chaves;2019-11-12 08:08:50 +0100;Make tutorial doctests pass

==

docs/_tests/quotes1.html
docs/conftest.py
docs/intro/tutorial.rst
pytest.ini
==================
50eaabe1;purvaudai;2019-11-11 20:00:26 +0530;Added Test

==

tests/test_feedexport.py
==================
f39ff494;purvaudai;2019-11-11 18:54:21 +0530;Added Test

==

tests/test_feedexport.py
==================
0c2dcd50;purvaudai;2019-11-11 18:35:50 +0530;Added Test

==

requirements-py2.txt
==================
970c3be1;purvaudai;2019-11-11 18:34:15 +0530;Added Test

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
9e6e2dde;purvaudai;2019-11-11 16:10:37 +0530;Adding test

==

tests/test_feedexport.py
==================
0042c389;purvaudai;2019-11-11 15:57:58 +0530;Adding test

==

tests/test_feedexport.py
==================
084a1cda;purvaudai;2019-11-11 15:41:00 +0530;Adding test

==

tests/test_feedexport.py
==================
ecc46ac7;Adrián Chaves;2019-11-11 10:45:25 +0100;Merge branch 'master' into pylint

==
==================
07fa768d;Eugenio Lacuesta;2019-11-08 22:17:12 -0300;Merge branch 'remove-six-code' of github.com:scrapy/scrapy into remove-six-code

==
==================
b6bbb281;Eugenio Lacuesta;2019-11-08 22:13:03 -0300;PEP8 adjustments

==

scrapy/crawler.py
scrapy/exporters.py
scrapy/http/cookies.py
scrapy/link.py
tests/test_pipeline_media.py
tests/test_proxy_connect.py
tests/test_utils_python.py
==================
d267e183;Andrey Rahmatullin;2019-11-08 22:49:33 +0500;Merge pull request #4139 from Gallaecio/jobdir-pickle-documentation
Improve the details about request serialization requirements for JOBDIR
==
==================
ea411172;Andrey Rahmatullin;2019-11-08 22:44:52 +0500;Merge pull request #4142 from Gallaecio/doctest
Set the bases for testing code examples from the documentation
==
==================
342e3b5b;Eugenio Lacuesta;2019-11-08 12:29:15 -0300;Merge remote-tracking branch 'upstream/master' into remove-six-code

==
==================
6cde428a;Eugenio Lacuesta;2019-11-08 12:26:40 -0300;Remove deprecated MergeDict class

==

scrapy/utils/datatypes.py
==================
1df57556;Adrián Chaves;2019-11-08 16:00:10 +0100;Set the bases for testing code examples from the documentation

==

docs/conftest.py
pytest.ini
tests/requirements-py3.txt
tox.ini
==================
44f19df3;elacuesta;2019-11-08 11:32:50 -0300;[test] Update mitmproxy version
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

tests/requirements-py3.txt
==================
40ed1849;Adrián Chaves;2019-11-07 18:40:58 +0100;Merge branch 'master' into pylint

==
==================
aef98188;Adrián Chaves;2019-11-07 18:06:55 +0100;Improve the details about request serialization requirements for JOBDIR

==

docs/topics/jobs.rst
==================
d874c4d9;Andrey Rahmatullin;2019-11-07 22:02:17 +0500;Remove the old Python 2 PyPy installation code from .travis.yml (#4138)

==

.travis.yml
==================
c377c14e;Marc Hernández;2019-11-07 17:47:35 +0100;Fix W391 Blank line at end of file (#4137)

==

pytest.ini
scrapy/commands/check.py
scrapy/commands/startproject.py
scrapy/commands/version.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/webclient.py
scrapy/core/scraper.py
scrapy/http/headers.py
scrapy/interfaces.py
scrapy/link.py
scrapy/spiders/feed.py
scrapy/spiders/init.py
scrapy/statscollectors.py
scrapy/utils/http.py
tests/test_cmdline/extensions.py
tests/test_settings/default_settings.py
tests/test_spidermiddleware_depth.py
tests/test_spidermiddleware_urllength.py
tests/test_utils_datatypes.py
tests/test_utils_http.py
tests/test_utils_spider.py
==================
e8b1e46e;Marc Hernández;2019-11-07 14:05:01 +0100;Add pytest-flake8 (#3945)

==

.travis.yml
conftest.py
pytest.ini
tox.ini
==================
98caf055;Adrián Chaves;2019-11-06 11:53:46 +0100;Fix a typo: specifiy → specify (#4128)

==

scrapy/utils/misc.py
==================
fe31695b;elacuesta;2019-11-05 15:36:19 -0300;Remove unused import (urllib.parse.unquote)
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

tests/test_http_request.py
==================
698aa704;seregaxvm;2019-11-05 18:30:01 +0300;Fix zsh completion file extension (#4122)

==

extras/scrapy_zsh_completion
==================
613c66a0;Eugenio Lacuesta;2019-11-05 09:45:51 -0300;Do not override built-in max function

==

tests/test_utils_datatypes.py
==================
fed9fbe6;elacuesta;2019-11-04 15:34:27 -0300;Update tests/test_utils_datatypes.py
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

tests/test_utils_datatypes.py
==================
439a3e59;Eugenio Lacuesta;2019-11-04 10:35:58 -0300;Fix scrapy.utils.datatypes.LocalCache limit issue

==

scrapy/utils/datatypes.py
tests/test_utils_datatypes.py
==================
0c4e5b68;Eugenio Lacuesta;2019-11-03 12:30:34 -0300;Remove six from requirements and setup files

==

requirements-py3.txt
setup.py
==================
00b793dc;Eugenio Lacuesta;2019-11-03 12:26:38 -0300;Remove elluding six occurrences

==

scrapy/robotstxt.py
tests/test_contracts.py
tests/test_pipeline_files.py
tests/test_utils_curl.py
==================
5797aefd;Eugenio Lacuesta;2019-11-03 12:18:35 -0300;Remove six.assertCountEqual

==

tests/test_cmdline/__init__.py
tests/test_settings/__init__.py
==================
586b25d2;Eugenio Lacuesta;2019-11-03 12:10:37 -0300;Remove six types

==

scrapy/downloadermiddlewares/ajaxcrawl.py
scrapy/utils/python.py
tests/test_utils_trackref.py
==================
7f3cb05d;Eugenio Lacuesta;2019-11-03 12:03:02 -0300;Remove metaclass-related six code

==

scrapy/item.py
tests/test_item.py
==================
e461570f;Eugenio Lacuesta;2019-11-02 23:13:54 -0300;Remove protego from requirements file

==

requirements-py3.txt
==================
cca1959c;Eugenio Lacuesta;2019-11-03 01:20:08 -0300;Merge remote-tracking branch 'upstream/remove-py2-tests' into remove-six-code

==
==================
d72444b9;Eugenio Lacuesta;2019-11-03 01:11:23 -0300;Remove more six imports

==

scrapy/core/downloader/middleware.py
scrapy/core/spidermw.py
scrapy/utils/reqser.py
tests/test_exporters.py
tests/test_http_response.py
tests/test_loader.py
tests/test_logformatter.py
tests/test_toplevel.py
tests/test_utils_iterators.py
tests/test_utils_reqser.py
tests/test_utils_url.py
tests/test_webclient.py
==================
eaeaa40b;Eugenio Lacuesta;2019-11-03 01:08:08 -0300;Remove six.PY* checks

==

conftest.py
tests/test_webclient.py
==================
5d8abdde;Eugenio Lacuesta;2019-11-03 01:01:10 -0300;Remove six.text_type from tests

==

tests/test_exporters.py
tests/test_http_response.py
tests/test_loader.py
tests/test_logformatter.py
tests/test_toplevel.py
tests/test_utils_iterators.py
tests/test_utils_python.py
==================
ac625248;Eugenio Lacuesta;2019-11-03 01:00:54 -0300;Remove six.get_method_*

==

scrapy/core/downloader/middleware.py
scrapy/core/spidermw.py
scrapy/utils/reqser.py
==================
54a786b1;Eugenio Lacuesta;2019-11-03 00:58:47 -0300;Remove six imports

==

scrapy/crawler.py
scrapy/exporters.py
scrapy/http/headers.py
scrapy/http/request/__init__.py
scrapy/http/response/text.py
scrapy/linkextractors/htmlparser.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/sgml.py
scrapy/settings/__init__.py
scrapy/spiders/crawl.py
scrapy/spiders/sitemap.py
scrapy/utils/curl.py
scrapy/utils/iterators.py
scrapy/utils/misc.py
tests/test_http_headers.py
tests/test_http_request.py
==================
ce8e515f;Eugenio Lacuesta;2019-11-03 00:36:25 -0300;Remove six type wrappers

==

scrapy/crawler.py
scrapy/exporters.py
scrapy/http/headers.py
scrapy/http/request/__init__.py
scrapy/http/response/text.py
scrapy/linkextractors/htmlparser.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/sgml.py
scrapy/settings/__init__.py
scrapy/spiders/crawl.py
scrapy/spiders/sitemap.py
scrapy/utils/iterators.py
scrapy/utils/misc.py
scrapy/utils/python.py
==================
68bf1921;Eugenio Lacuesta;2019-11-03 00:32:07 -0300;Fix bad import

==

scrapy/exporters.py
==================
1aba5136;Eugenio Lacuesta;2019-11-03 00:26:44 -0300;Remove six.iter* occurrences

==

scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/__init__.py
scrapy/downloadermiddlewares/cookies.py
scrapy/downloadermiddlewares/decompression.py
scrapy/exporters.py
scrapy/extensions/memdebug.py
scrapy/http/request/form.py
scrapy/item.py
scrapy/loader/__init__.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/responsetypes.py
scrapy/settings/__init__.py
scrapy/utils/conf.py
scrapy/utils/datatypes.py
scrapy/utils/python.py
scrapy/utils/spider.py
scrapy/utils/trackref.py
tests/test_settings/__init__.py
tests/test_webclient.py
==================
5ab0f189;Eugenio Lacuesta;2019-11-03 00:01:09 -0300;Remove six.moves occurrences from tests

==

tests/mockserver.py
tests/spiders.py
tests/test_crawl.py
tests/test_engine.py
tests/test_exporters.py
tests/test_feedexport.py
tests/test_http_cookies.py
tests/test_http_request.py
tests/test_pipeline_files.py
tests/test_proxy_connect.py
tests/test_spidermiddleware_offsite.py
tests/test_spidermiddleware_referer.py
tests/test_urlparse_monkeypatches.py
tests/test_utils_datatypes.py
tests/test_utils_defer.py
tests/test_utils_httpobj.py
tests/test_utils_response.py
tests/test_utils_url.py
==================
df00389c;Eugenio Lacuesta;2019-11-02 23:48:11 -0300;Remove six.moves occurrences

==

scrapy/_monkeypatches.py
scrapy/commands/bench.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/s3.py
scrapy/core/downloader/webclient.py
scrapy/downloadermiddlewares/httpproxy.py
scrapy/downloadermiddlewares/redirect.py
scrapy/exporters.py
scrapy/extensions/feedexport.py
scrapy/extensions/httpcache.py
scrapy/extensions/spiderstate.py
scrapy/http/cookies.py
scrapy/http/request/form.py
scrapy/http/request/rpc.py
scrapy/http/response/__init__.py
scrapy/http/response/text.py
scrapy/linkextractors/__init__.py
scrapy/linkextractors/htmlparser.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/regex.py
scrapy/linkextractors/sgml.py
scrapy/mail.py
scrapy/pipelines/files.py
scrapy/robotstxt.py
scrapy/spidermiddlewares/referer.py
scrapy/squeues.py
scrapy/utils/benchserver.py
scrapy/utils/curl.py
scrapy/utils/httpobj.py
scrapy/utils/project.py
scrapy/utils/python.py
scrapy/utils/request.py
scrapy/utils/sitemap.py
scrapy/utils/testsite.py
scrapy/utils/url.py
==================
c0bfaef3;Eugenio Lacuesta;2019-11-02 23:27:04 -0300;Remove __future__ imports from tests

==

tests/mockserver.py
tests/test_downloadermiddleware_httpcache.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_engine.py
tests/test_exporters.py
tests/test_feedexport.py
tests/test_pipeline_media.py
tests/test_utils_deprecate.py
tests/test_utils_log.py
tests/test_utils_request.py
==================
415526d9;Eugenio Lacuesta;2019-11-02 23:25:15 -0300;Remove __future__ imports

==

extras/qps-bench-server.py
scrapy/cmdline.py
scrapy/commands/check.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/parse.py
scrapy/commands/settings.py
scrapy/commands/startproject.py
scrapy/commands/version.py
scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/http.py
scrapy/downloadermiddlewares/ajaxcrawl.py
scrapy/dupefilters.py
scrapy/extensions/httpcache.py
scrapy/pipelines/media.py
scrapy/responsetypes.py
scrapy/shell.py
scrapy/signalmanager.py
scrapy/spiderloader.py
scrapy/utils/boto.py
scrapy/utils/display.py
scrapy/utils/engine.py
scrapy/utils/ossignal.py
scrapy/utils/request.py
scrapy/utils/test.py
scrapy/utils/testproc.py
scrapy/utils/testsite.py
scrapy/utils/trackref.py
==================
48b8ac60;Andrey Rakhmatullin;2019-11-01 20:05:37 +0500;Improve the dbm module ref.
Co-Authored-By: Adrián Chaves <adrian@chaves.io>

==

docs/topics/downloader-middleware.rst
==================
350aa67c;Andrey Rakhmatullin;2019-11-01 19:52:57 +0500;Rename tests/py3-ignores.txt to tests/ignores.txt.

==

conftest.py
tests/ignores.txt
==================
4b0cdf7f;Andrey Rakhmatullin;2019-11-01 19:50:56 +0500;Use self.proc.communicate() after killing mitmdump.

==

tests/test_proxy_connect.py
==================
3c9963ab;Andrey Rakhmatullin;2019-11-01 19:46:38 +0500;Only xfail test_https_connect_tunnel_error on 3.6+.

==

tests/test_proxy_connect.py
==================
e0c5c724;Andrey Rakhmatullin;2019-11-01 19:46:19 +0500;Improve the test_https_tunnel_without_leak_proxy_authorization_header change.

==

tests/test_proxy_connect.py
==================
5eb01b61;Andrey Rakhmatullin;2019-10-31 23:21:30 +0500;Use an older mitmproxy for py3.5.

==

tests/requirements-py3.txt
==================
a5eb59b9;Andrey Rakhmatullin;2019-10-31 23:21:14 +0500;Fix test_proxy_connect.py for py3.5.

==

tests/test_proxy_connect.py
==================
86412313;Andrey Rakhmatullin;2019-10-31 22:55:58 +0500;Fix a duplicate ref name in docs.

==

docs/topics/downloader-middleware.rst
==================
f02c3d1d;Adrián Chaves;2019-10-31 13:31:33 +0100;Use communicate() instead of wait() after killing the mock server (#4095)

==

tests/mockserver.py
==================
7299e91b;Andrey Rakhmatullin;2019-08-28 16:29:53 +0500;Remove Py2-only code that checks sys.version_info.

==

tests/test_utils_reqser.py
==================
397e8835;Andrey Rakhmatullin;2019-08-20 21:35:13 +0500;Replace to_native_str calls with to_unicode.

==

scrapy/core/downloader/handlers/http11.py
scrapy/downloadermiddlewares/cookies.py
scrapy/downloadermiddlewares/robotstxt.py
scrapy/exporters.py
scrapy/http/cookies.py
scrapy/http/response/text.py
scrapy/linkextractors/lxmlhtml.py
scrapy/responsetypes.py
scrapy/robotstxt.py
scrapy/spidermiddlewares/referer.py
scrapy/utils/reqser.py
scrapy/utils/request.py
scrapy/utils/response.py
scrapy/utils/ssl.py
tests/test_command_parse.py
tests/test_commands.py
tests/test_feedexport.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_robotstxt_interface.py
==================
75b1d051;Andrey Rakhmatullin;2019-08-20 21:27:52 +0500;Simplify some more imports.

==

scrapy/downloadermiddlewares/httpproxy.py
scrapy/loader/processors.py
tests/__init__.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_extension_telnet.py
tests/test_feedexport.py
tests/test_http_request.py
tests/test_item.py
tests/test_pipeline_files.py
tests/test_settings/__init__.py
tests/test_spider.py
tests/test_spidermiddleware.py
tests/test_stats.py
tests/test_utils_deprecate.py
tests/test_utils_misc/__init__.py
tests/test_utils_trackref.py
==================
3ac4b430;Andrey Rakhmatullin;2019-10-31 15:20:28 +0500;Remove an unused six import.

==

tests/test_downloader_handlers.py
==================
5b70b051;Andrey Rakhmatullin;2019-08-20 21:13:01 +0500;Some text function messages cleanup, deprecate to_native_str.

==

scrapy/http/response/__init__.py
scrapy/utils/python.py
==================
cea2f5e2;Andrey Rakhmatullin;2019-08-20 21:09:49 +0500;Remove cStringIO imports.

==

scrapy/downloadermiddlewares/decompression.py
scrapy/mail.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/utils/gz.py
scrapy/utils/iterators.py
tests/test_cmdline/__init__.py
tests/test_pipeline_media.py
==================
c2898fdc;Andrey Rakhmatullin;2019-08-20 21:06:52 +0500;Deprecate scrapy.utils.gz.read1.

==

scrapy/utils/gz.py
==================
de7789e5;Andrey Rakhmatullin;2019-08-20 20:56:26 +0500;Remove unneeded and unused code from XmlItemExporter.

==

scrapy/exporters.py
==================
bbd9f4be;Andrey Rakhmatullin;2019-07-22 22:27:29 +0500;Remove six.PY2 and six.PY3 conditionals.

==

docs/topics/downloader-middleware.rst
scrapy/_monkeypatches.py
scrapy/commands/fetch.py
scrapy/crawler.py
scrapy/exporters.py
scrapy/extensions/feedexport.py
scrapy/http/request/form.py
scrapy/http/response/text.py
scrapy/item.py
scrapy/link.py
scrapy/mail.py
scrapy/settings/__init__.py
scrapy/settings/default_settings.py
scrapy/utils/boto.py
scrapy/utils/conf.py
scrapy/utils/datatypes.py
scrapy/utils/gz.py
scrapy/utils/iterators.py
scrapy/utils/python.py
tests/__init__.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_item.py
tests/test_link.py
tests/test_middleware.py
tests/test_request_cb_kwargs.py
tests/test_settings/__init__.py
tests/test_utils_datatypes.py
tests/test_utils_python.py
==================
186f9d88;Andrey Rakhmatullin;2019-09-03 15:24:06 +0500;Fix the skip message for test_download_gzip_response.

==

tests/test_downloader_handlers.py
==================
439e37fc;Andrey Rakhmatullin;2019-09-03 15:23:24 +0500;Mark failing proxy tests.

==

tests/test_proxy_connect.py
==================
b0d6f491;Andrey Rakhmatullin;2019-09-03 15:17:03 +0500;Restore tests/test_proxy_connect.py and update it to modern mitmproxy.

==

tests/requirements-py3.txt
tests/test_proxy_connect.py
==================
b44bd6f8;Andrey Rakhmatullin;2019-07-22 20:51:03 +0500;Remove Python 2-only tests.

==

conftest.py
tests/py3-ignores.txt
tests/test_downloader_handlers.py
tests/test_linkextractors_deprecated.py
tests/test_proxy_connect.py
tests/test_utils_python.py
tests/test_webclient.py
==================
15c55d0c;Adrián Chaves;2019-10-31 10:47:29 +0100;Remove LevelDB support (#4112)

==

scrapy/extensions/httpcache.py
tests/requirements-py3.txt
tests/test_downloadermiddleware_httpcache.py
==================
229e722a;Andrey Rahmatullin;2019-10-31 14:46:02 +0500;Initial Python 2 removal (#4091)

==

.travis.yml
README.rst
docs/faq.rst
docs/intro/install.rst
docs/topics/feed-exports.rst
docs/topics/leaks.rst
docs/topics/media-pipeline.rst
docs/topics/request-response.rst
docs/topics/settings.rst
docs/topics/spiders.rst
requirements-py2.txt
scrapy/__init__.py
setup.py
tests/requirements-py2.txt
tox.ini
==================
6d6da78e;Benjamin Ooghe-Tabanou;2019-10-30 09:13:36 +0100;Add a keep_fragments parameter to the request_fingerprint function (#4104)

==

scrapy/utils/request.py
tests/test_utils_request.py
==================
66cbceeb;Amardeep Bhowmick;2019-10-30 13:39:12 +0530;Fix redirection error when the Location header value starts with 3 slashes (#4042)

==

scrapy/downloadermiddlewares/redirect.py
tests/test_downloadermiddleware_redirect.py
==================
be2e910d;Adrián Chaves;2019-10-29 12:57:02 +0100;Bump version: 1.7.0 → 1.8.0

==

.bumpversion.cfg
scrapy/VERSION
==================
94f060fc;Adrián Chaves;2019-10-29 12:53:46 +0100;Cover Scrapy 1.8.0 in the release notes (#3952)

==

docs/news.rst
docs/topics/logging.rst
scrapy/logformatter.py
==================
18b808b2;Andrey Rahmatullin;2019-10-29 16:30:58 +0500;Merge pull request #4092 from further-reading/master
Add Python 3.8 official support
==
==================
93e3dc1b;Roy;2019-10-28 16:12:03 +0000;[test_downloadermiddleware_httpcache.py] Cleaning text https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
b73d217d;Roy;2019-10-28 12:55:54 +0000;[test_downloadermiddleware_httpcache.py] Fixing pytest mark behaviour https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
74909030;Roy;2019-10-28 12:52:36 +0000;[tox.ini] Removing obsolete py37 extra deps enviornment https://github.com/scrapy/scrapy/issues/4085

==

tox.ini
==================
c51fb959;Roy;2019-10-28 12:36:54 +0000;[test_downloadermiddleware_httpcache] Fixing pytest skip behaviour https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
4432136f;Roy;2019-10-28 12:22:21 +0000;[test_downloadermiddleware_httpcache] Fixing pytest skip behaviour https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
9b47dc6a;Roy;2019-10-28 11:24:52 +0000;[travis, setup] Adding official python 3.8 support https://github.com/scrapy/scrapy/issues/4085

==

.travis.yml
setup.py
==================
16bb3ac2;Roy;2019-10-28 11:24:09 +0000;[test_downloadermiddleware_httpcache] Using skipif approach https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
3af2abb7;Roy Healy;2019-10-28 10:35:04 +0000;Merge pull request #1 from Gallaecio/py38
Mark the LevelDB storage backend as deprecated
==
==================
3d0df419;Adrián Chaves;2019-10-28 11:24:47 +0100;Mark the LevelDB storage backend as deprecated

==

docs/topics/downloader-middleware.rst
scrapy/extensions/httpcache.py
==================
b5a00262;Roy Healy;2019-10-28 09:59:33 +0000;Update .travis.yml
Reverting change to 3.8 extra dependency environment.
==

.travis.yml
==================
7731814c;elacuesta;2019-10-28 06:53:53 -0300;ItemLoader: improve handling of initial item (#4036)

==

docs/topics/loaders.rst
scrapy/loader/__init__.py
tests/test_loader.py
==================
bb91f9c7;Adrián Chaves;2019-10-21 12:08:35 +0200;Cover Scrapy 1.7.4 in the release notes

==

docs/news.rst
==================
20ea9125;Roy;2019-10-27 18:52:01 +0000;[test_downloadermiddleware_httpcache] Making xfails more informative https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
70b28545;Roy;2019-10-27 18:51:26 +0000;[test_downloadermiddleware_httpcache] Making xfails more informative https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
b3df0a84;Roy;2019-10-27 18:28:47 +0000;[test_downloadermiddleware_httpcache] Adding xfails to impacted tests following hack fix https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
11942c43;Roy;2019-10-27 18:02:13 +0000;[test_downloadermiddleware_httpcache] Trying hack to handle systemerror whjen importing leveldb https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
deacd34c;Roy;2019-10-27 17:39:47 +0000;[test_downloadermiddleware_httpcache] Attempting to add xfail for leveldb related tests https://github.com/scrapy/scrapy/issues/4085

==

tests/test_downloadermiddleware_httpcache.py
==================
40687975;Roy Healy;2019-10-27 17:02:17 +0000;Update test_downloadermiddleware_httpcache.py
Adding xfail denoting that leveldb is not supported in 3.8
==

tests/test_downloadermiddleware_httpcache.py
==================
179dc916;Roy Healy;2019-10-27 16:48:20 +0000;Update setup.py
Updating setup.py to remove python 3.8 support for now
==

setup.py
==================
02577f55;Adrián Chaves;2019-10-24 13:25:11 +0200;Have PyLint cover all Python files in the repository

==

pylintrc
tox.ini
==================
84fe4011;Kevin Lloyd Bernal;2019-10-23 20:39:53 +0800;update docs of scrapy.loader.ItemLoader.item

==

docs/topics/loaders.rst
==================
3b6f7ac9;Adrián Chaves;2019-10-22 19:43:02 +0200;Use pylint

==

.travis.yml
docs/utils/linkfix.py
pylintrc
tox.ini
==================
c623a16a;Adrián Chaves;2019-10-22 17:52:34 +0200;Remove unused method from scrapy.pqueues._SlotPriorityQueues

==

scrapy/pqueues.py
==================
bf5c1a3d;Ammar Najjar;2019-10-22 15:56:46 +0200;docs: use "constructor" for "from_crawler"
Issue #4086

==

scrapy/extensions/feedexport.py
==================
7fba8434;Ammar Najjar;2019-10-22 15:55:52 +0200;use instantiation for "Crawler"
Issue #4086

Co-Authored-By: Mikhail Korobov <kmike84@gmail.com>
==

sep/sep-009.rst
==================
f701f5b0;Victor Torres;2019-10-22 10:48:02 -0300;fix #2552 by improving request schema check on its initialization

==

scrapy/http/request/__init__.py
tests/test_http_request.py
==================
7a84a4bd;Ammar Najjar;2019-10-22 15:31:34 +0200;docs: use "constructor" for from_settings() & rom_crawler() factory methods
Issue #4086

==

scrapy/utils/misc.py
tests/test_utils_misc/__init__.py
==================
d96b9f86;Adrián Chaves;2019-10-22 15:24:59 +0200;Use object as type for parameters that allow any value

==

scrapy/settings/__init__.py
==================
5479e7ec;Adrián Chaves;2019-10-22 15:24:44 +0200;Indicate that lists of emails may be provided as a single string or as a list of strings

==

docs/topics/email.rst
==================
1d5c270c;Adrián Chaves;2019-10-22 15:12:52 +0200;Fix dangling file descriptor in FeedExporter when FEED_STORE_EMPTY is False (#4023)

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
d21e1034;Ammar Najjar;2019-10-22 13:24:57 +0200;docs: correct point,comma and plural replacements
Issue #4086

==

docs/topics/exporters.rst
docs/topics/items.rst
docs/topics/loaders.rst
docs/topics/request-response.rst
scrapy/utils/misc.py
==================
4184bac0;purvaudai;2019-10-22 16:57:14 +0530;Added Pathlib.Path test

==

tests/test_feedexport.py
==================
85f56a92;purvaudai;2019-10-22 16:43:17 +0530;Added Pathlib.Path test

==

tests/test_feedexport.py
==================
7031e3a1;purvaudai;2019-10-22 16:31:14 +0530;Added Pathlib.Path test

==

tests/test_feedexport.py
==================
cd096464;purvaudai;2019-10-22 16:19:41 +0530;Added Pathlib.Path test

==

requirements-py2.txt
requirements-py3.txt
==================
5d75ed4c;WinterComes;2019-10-22 13:19:07 +0300;Remove an old note about contracts (#4093)

==

docs/topics/contracts.rst
==================
cd4c211f;purvaudai;2019-10-22 15:38:06 +0530;Added Pathlib.Path test

==

tests/test_feedexport.py
==================
07822935;illgitthat;2019-10-22 06:05:34 -0400;Updating link for miniconda (#4089)

==

docs/intro/install.rst
==================
a7765542;purvaudai;2019-10-22 15:31:55 +0530;Added Pathlib.Path test

==

tests/test_feedexport.py
==================
0b7d8a51;purvaudai;2019-10-22 15:12:53 +0530;Added Pathlib.Path test

==

requirements-py2.txt
requirements-py3.txt
==================
42267914;purvaudai;2019-10-22 15:07:13 +0530;Added Pathlib.Path test

==

requirements-py2.txt
requirements-py3.txt
==================
ad96d6ef;purvaudai;2019-10-22 14:53:59 +0530;Added Pathlib.Path test correctly

==

tests/test_feedexport.py
==================
2ee38e8d;purvaudai;2019-10-22 14:43:47 +0530;Added Pathlib.Path test

==

tests/test_feedexport.py
==================
85ac5c5c;Roy Healy;2019-10-21 19:06:43 +0100;Update .travis.yml
Co-Authored-By: Mikhail Korobov <kmike84@gmail.com>
==

.travis.yml
==================
da8cd944;Ammar Najjar;2019-10-21 19:48:13 +0200;docs: always surround __init__ with `` in docs
Issue #4086

==

docs/topics/exporters.rst
docs/topics/items.rst
docs/topics/loaders.rst
docs/topics/request-response.rst
scrapy/exporters.py
scrapy/extensions/feedexport.py
scrapy/utils/datatypes.py
scrapy/utils/misc.py
scrapy/utils/python.py
sep/sep-009.rst
tests/test_spider.py
==================
c12a0751;Roy;2019-10-21 18:34:15 +0100;[.travis.yml] Added python 3.8 fields https://github.com/scrapy/scrapy/issues/4085

==

.travis.yml
==================
4e939ca7;Roy;2019-10-21 18:33:18 +0100;[setup.py] Added python 3.8 fields https://github.com/scrapy/scrapy/issues/4085

==

setup.py
==================
3d4317bf;Roy;2019-10-21 18:32:30 +0100;[tox.ini] Added python 3.8 fields https://github.com/scrapy/scrapy/issues/4085

==

tox.ini
==================
ad607544;Adrián Chaves;2019-10-21 19:00:03 +0200;Fix references to Python types in parameter type fields

==

docs/topics/contracts.rst
docs/topics/email.rst
docs/topics/exporters.rst
docs/topics/leaks.rst
docs/topics/link-extractors.rst
docs/topics/loaders.rst
docs/topics/request-response.rst
scrapy/crawler.py
scrapy/robotstxt.py
scrapy/settings/__init__.py
scrapy/signalmanager.py
==================
68a7d05e;Ammar Najjar;2019-10-21 15:42:24 +0200;docs: use __init__ method instead of constructor
Issue #4086

==

docs/conf.py
docs/news.rst
docs/topics/email.rst
docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/items.rst
docs/topics/loaders.rst
docs/topics/request-response.rst
scrapy/exporters.py
scrapy/extensions/feedexport.py
scrapy/utils/datatypes.py
scrapy/utils/misc.py
scrapy/utils/python.py
sep/sep-009.rst
tests/test_http_request.py
tests/test_http_response.py
tests/test_loader.py
tests/test_spider.py
tests/test_utils_misc/__init__.py
==================
0fbd1ff4;Adrián Chaves;2019-10-21 14:06:45 +0200;constructor → __init__ method

==

docs/topics/link-extractors.rst
scrapy/linkextractors/lxmlhtml.py
==================
6df6b6dd;Eugenio Lacuesta;2019-10-21 03:56:45 -0300;Initializer -> __init__

==

scrapy/http/response/text.py
==================
8cb53441;Mikhail Korobov;2019-10-19 00:00:02 +0200;Merge pull request #4056 from Gallaecio/documentation-build
Fix internal links in the tutorial and release notes
==
==================
6674f47d;Mikhail Korobov;2019-10-16 22:59:15 +0200;Merge pull request #4069 from seregaxvm/master
update zsh completion
==
==================
865d58fd;José Alberto Orejuela García;2019-10-03 18:06:19 +0200;Make punctuation consistent

==

CODE_OF_CONDUCT.md
README.rst
==================
48944378;Andrey Rahmatullin;2019-10-16 17:03:38 +0500;Merge pull request #4081 from bulatbulat48/documentation-botname
Fixed BOT_NAME documentation
==
==================
84be6a94;Bulat;2019-10-16 14:04:07 +0300;Refactor sentence.

==

docs/topics/settings.rst
==================
c9614a5b;Bulat;2019-10-16 12:07:19 +0300;Fixed BOT_NAME documentation

==

docs/topics/settings.rst
==================
2c6f7fee;Eugenio Lacuesta;2019-10-15 13:48:14 -0300;TextResponse.follow_all: invoke Response.follow_all

==

scrapy/http/response/text.py
==================
2a4d4a46;Eugenio Lacuesta;2019-10-15 11:52:12 -0300;TextResponse.follow_all: Simplify implementation

==

scrapy/http/response/text.py
==================
d72ed46f;Adrián Chaves;2019-10-15 16:03:42 +0200;Improve how extra Item API members are introduced in the documentation

==

docs/topics/items.rst
==================
7b1e69de;Baron Hou;2019-10-15 20:51:15 +0800;reponse → response (#4079)

==

docs/topics/developer-tools.rst
docs/topics/downloader-middleware.rst
==================
9d5398e7;Eugenio Lacuesta;2019-10-14 13:57:46 -0300;TextResponse.follow_all: improve docs

==

scrapy/http/response/text.py
==================
c7c54f54;elacuesta;2019-10-14 13:47:44 -0300;Update scrapy/http/response/text.py
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

scrapy/http/response/text.py
==================
498d33aa;elacuesta;2019-10-14 13:35:54 -0300;Update scrapy/http/response/text.py
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

scrapy/http/response/text.py
==================
ba840c5a;elacuesta;2019-10-14 13:35:24 -0300;Update scrapy/http/response/__init__.py
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

scrapy/http/response/__init__.py
==================
b9708512;elacuesta;2019-10-14 13:35:06 -0300;Update scrapy/http/response/__init__.py
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

scrapy/http/response/__init__.py
==================
12f1e468;Purva Udai;2019-10-13 15:55:27 +0530;Issue #3731

==

scrapy/extensions/feedexport.py
==================
f0db1b4b;Matsievskiy S.V;2019-10-11 00:55:18 +0300;update zsh completion

==

extras/scrapy_zsh_completion
==================
e1fa1fd8;Eugenio Lacuesta;2019-10-10 00:36:38 -0300;TextResponse.follow_all: skip invalid links

==

scrapy/http/response/text.py
tests/sample_data/link_extractor/sgml_linkextractor_no_href.html
tests/test_http_response.py
==================
532770df;akhter wahab;2019-10-09 22:53:14 +0500;instead of .tar.xz adding .xz in others extensions

==

scrapy/linkextractors/__init__.py
==================
a25a2d5e;akhter wahab;2019-10-09 16:05:39 +0500;Add .tar.xz to ignored other extensions

==

scrapy/linkextractors/__init__.py
==================
877ef426;akhter wahab;2019-10-09 16:03:44 +0500;Add .webm to ignored video extensions

==

scrapy/linkextractors/__init__.py
==================
5f168cd4;Eugenio Lacuesta;2019-10-02 14:08:08 -0300;Response.follow_all

==

docs/topics/request-response.rst
scrapy/http/response/__init__.py
scrapy/http/response/text.py
tests/test_http_response.py
==================
fa56460d;Mikhail Korobov;2019-10-07 22:27:42 +0200;Merge pull request #4061 from jbampton/fix-case-of-github
Fix case of GitHub.
==
==================
f5214814;akhter wahab;2019-10-07 23:28:33 +0500;Add dmg, iso & apk to ignored other extensions

==

scrapy/linkextractors/__init__.py
==================
39c9a3cc;John Bampton;2019-10-05 10:09:14 +1000;Fix case of GitHub.

==

.github/ISSUE_TEMPLATE/bug_report.md
.github/ISSUE_TEMPLATE/feature_request.md
docs/news.rst
==================
a4aa5b89;Adrián Chaves;2019-10-02 14:51:06 +0200;Fix internal links in the tutorial and release notes

==

docs/intro/tutorial.rst
docs/news.rst
docs/topics/items.rst
docs/topics/settings.rst
==================
6ad5a89c;elacuesta;2019-10-02 07:18:36 -0300;[Doc] Use autoclass in topics/request-response.rst (#4055)

==

docs/topics/request-response.rst
==================
16508120;Mikhail Korobov;2019-10-02 12:06:22 +0500;Merge pull request #4052 from elacuesta/dummy_stats_collector_fix_elapsed_time
Fix TypeError when using DummyStatsCollector
==
==================
e0fabab5;Eugenio Lacuesta;2019-10-01 11:54:15 -0300;Fix TypeError when using DummyStatsCollector

==

scrapy/extensions/corestats.py
tests/test_stats.py
==================
07a31b13;Eugenio Lacuesta;2019-10-01 17:55:57 -0300;Update LogFormatter tests

==

tests/test_logformatter.py
==================
74b4a5c7;Mikhail Korobov;2019-10-02 00:03:50 +0500;Merge pull request #4006 from whalebot-helmsman/protego-default
Use protego as a default robots.txt parser
==
==================
62995e27;Mikhail Korobov;2019-10-01 23:34:28 +0500;Merge pull request #4050 from KristobalJunta/fix_topics_spiders_typo
fix typo in docs/topics/spiders
==
==================
c232bbdc;Kristobal Junta;2019-10-01 17:41:38 +0300;fix typo in docs/topics/spiders

==

docs/topics/spiders.rst
==================
7632e375;Eugen;2019-10-01 17:29:48 +0300;fix typo in ScrapyCommand.help docstring (#4046)

==

scrapy/commands/__init__.py
==================
175cd2ec;OmarFarrag;2019-10-01 07:27:31 +0200;Update docs/topics/media-pipeline.rst
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

docs/topics/media-pipeline.rst
==================
7f4f98fd;Adrián Chaves;2019-09-30 18:22:28 +0200;Provide complete API documentation coverage of scrapy.linkextractors

==

docs/conf.py
docs/topics/link-extractors.rst
scrapy/linkextractors/__init__.py
scrapy/linkextractors/lxmlhtml.py
tests/test_linkextractors.py
==================
28005b28;OmarFarrag;2019-09-28 06:21:14 +0200;Update media-pipeline.rst

==

docs/topics/media-pipeline.rst
==================
2c14692e;s-sanjay;2019-09-27 00:56:43 -0700;remove .keys() to avoid creating a tmp list/keyview obj (#4031)
Also add --verbose and --nolinks for code coverage

==

scrapy/commands/parse.py
scrapy/commands/runspider.py
tests/test_command_parse.py
==================
31c631f9;Mikhail Korobov;2019-09-25 16:13:13 +0100;Merge pull request #3999 from Gallaecio/documentation-coverage
Provide complete API documentation coverage of scrapy.item
==
==================
1236e9e8;Adrián Chaves;2019-09-03 14:08:08 +0200;Provide complete API documentation coverage of scrapy.item

==

docs/conf.py
docs/topics/items.rst
scrapy/item.py
tests/test_item.py
==================
447b3d9d;Adrián Chaves;2019-09-25 11:13:37 +0200;Fix documentation typo: accesible → accessible (#4033)

==

scrapy/utils/request.py
==================
1364e920;Mikhail Korobov;2019-09-20 15:28:07 +0100;Merge pull request #4015 from elacuesta/remove_deprecated_xlib
Remove deprecated xlib module
==
==================
17c0d72d;Mikhail Korobov;2019-09-20 15:27:17 +0100;Merge pull request #4016 from elacuesta/rule_default_link_extractor
Crawling rules: make link extractors optional
==
==================
874b0057;Mikhail Korobov;2019-09-20 14:51:37 +0100;Merge pull request #4028 from Gallaecio/fix-dont-merge-cookies-docs
Clarify the effects of dont_merge_cookies
==
==================
b14c3cb6;OmarFarrag;2019-09-19 23:33:57 +0200;Add media pipelines FTP documentation

==

docs/topics/media-pipeline.rst
==================
c26a9015;Adrián Chaves;2019-09-19 11:08:06 +0200;Clarify the effects of dont_merge_cookies

==

docs/topics/request-response.rst
==================
9b65f9aa;Adrián Chaves;2019-09-19 09:17:23 +0200;Fix the item exporter example (#4022)

==

docs/topics/exporters.rst
==================
2438ac52;Vostretsov Nikita;2019-09-17 12:27:22 +0500;Update docs/topics/downloader-middleware.rst
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

docs/topics/downloader-middleware.rst
==================
d1d0bf84;Vostretsov Nikita;2019-09-17 12:27:12 +0500;Update docs/topics/downloader-middleware.rst
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

docs/topics/downloader-middleware.rst
==================
57e6f4c7;Vostretsov Nikita;2019-09-17 07:18:37 +0000;add link to performance comparison

==

docs/topics/downloader-middleware.rst
==================
d39ef77e;Vostretsov Nikita;2019-09-17 06:34:33 +0000;add link to google description of lenght-based rule

==

docs/topics/downloader-middleware.rst
==================
b792dba5;Vostretsov Nikita;2019-09-17 06:28:33 +0000;remove periods

==

docs/topics/downloader-middleware.rst
==================
27436cbb;Eugenio Lacuesta;2019-08-29 13:51:42 -0300;[test] LogFormatter.error

==

tests/test_logformatter.py
==================
f6872189;Eugenio Lacuesta;2019-08-29 10:38:49 -0300;Add LogFormatter.error method

==

scrapy/core/scraper.py
scrapy/logformatter.py
==================
50c85e31;Vostretsov Nikita;2019-09-16 14:24:31 +0000;Merge branch 'protego-default' of github.com:whalebot-helmsman/scrapy into protego-default

==
==================
5197b39e;Vostretsov Nikita;2019-09-16 14:24:25 +0000;fix capitalization, remove commas

==

docs/topics/downloader-middleware.rst
==================
0b52fa6c;watsta;2019-09-16 14:12:04 +0200;LogFormatter: Add the ability to skip log messages (#3987)

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/logformatter.py
tests/test_logformatter.py
==================
13735bcf;OmarFarrag;2019-09-16 14:04:06 +0200;Disallow media extensions unregistered with IANA  (#3954)
Co-Authored-By: s-sanjay <sanjay537@gmail.com>

==

scrapy/pipelines/files.py
tests/test_pipeline_files.py
==================
21ad8e20;Eugenio Lacuesta;2019-09-13 16:02:49 -0300;Crawling rules: make link extractors optional

==

docs/topics/spiders.rst
scrapy/spiders/crawl.py
tests/test_spider.py
==================
c5612f38;Eugenio Lacuesta;2019-09-13 14:21:09 -0300;Remove deprecated xlib module

==

.coveragerc
conftest.py
debian/scrapy.lintian-overrides
scrapy/xlib/__init__.py
scrapy/xlib/pydispatch.py
scrapy/xlib/tx.py
tests/test_pydispatch_deprecated.py
==================
66145b4e;Vostretsov Nikita;2019-09-12 18:51:00 +0300;Update docs/topics/downloader-middleware.rst
Co-Authored-By: Mikhail Korobov <kmike84@gmail.com>
==

docs/topics/downloader-middleware.rst
==================
171fa1cd;Vostretsov Nikita;2019-09-10 09:59:36 +0000;documentation rework

==

docs/topics/downloader-middleware.rst
==================
c7f2bdfd;Vostretsov Nikita;2019-09-10 08:58:52 +0000;add protego to install_requires

==

setup.py
==================
6bd88711;Vostretsov Nikita;2019-09-10 08:55:37 +0000;update documentation

==

docs/topics/settings.rst
==================
db202487;Vostretsov Nikita;2019-09-09 14:05:45 +0000;newer version of protego and move up to top

==

requirements-py2.txt
requirements-py3.txt
==================
7b33fa58;Vostretsov Nikita;2019-09-09 17:04:27 +0300;Update requirements-py2.txt
Co-Authored-By: elacuesta <elacuesta@users.noreply.github.com>
==

requirements-py2.txt
==================
38828d3f;Vostretsov Nikita;2019-09-09 17:04:13 +0300;Update docs/topics/downloader-middleware.rst
Co-Authored-By: elacuesta <elacuesta@users.noreply.github.com>
==

docs/topics/downloader-middleware.rst
==================
e418554c;Vostretsov Nikita;2019-09-09 08:12:32 +0000;use proper equal

==

tox.ini
==================
7af8c766;Vostretsov Nikita;2019-09-09 08:10:09 +0000;add pinned versions

==

tox.ini
==================
9578f490;Vostretsov Nikita;2019-09-09 07:36:55 +0000;use protego as a default robots.txt parser

==

docs/topics/downloader-middleware.rst
requirements-py2.txt
requirements-py3.txt
scrapy/settings/default_settings.py
tox.ini
==================
534de739;Mikhail Korobov;2019-09-08 04:23:16 +0500;Merge pull request #3988 from elacuesta/contracts_cb_kwargs
CallbackKeywordArgumentsContract
==
==================
0e8770a2;OmarFarrag;2019-09-06 15:47:57 +0200;test for files pipeline ftp store

==

scrapy/utils/test.py
tests/test_pipeline_files.py
==================
b92b1146;Eugenio Lacuesta;2019-08-31 02:44:09 -0300;[test] cb_kwargs contract

==

tests/test_contracts.py
==================
2061f2a3;Eugenio Lacuesta;2019-08-31 02:10:18 -0300;[doc] cb_kwargs contract

==

docs/topics/contracts.rst
==================
d4b8bf18;Mikhail Korobov;2019-08-30 21:07:22 +0500;Merge pull request #3993 from Gallaecio/documentation-coverage
Provide complete API documentation coverage of scrapy.extensions
==
==================
2828cb76;Adrián Chaves;2019-08-30 14:29:15 +0200;Provide complete API documentation coverage of scrapy.extensions

==

docs/conf.py
docs/topics/downloader-middleware.rst
docs/topics/extensions.rst
==================
ace2df3d;Marc Hernández;2019-08-30 11:03:44 +0200;Fix JSONRequest naming (#3982)

==

docs/news.rst
docs/topics/request-response.rst
scrapy/http/__init__.py
scrapy/http/request/json_request.py
tests/test_http_request.py
==================
eb0bd2da;Eugenio Lacuesta;2019-08-29 14:01:13 -0300;Revert backward-incompatible change (contract priorities)

==

scrapy/settings/default_settings.py
==================
b84f99ff;Júlio César Batista;2019-08-29 11:11:56 -0300;Merge

==
==================
110bc92e;Júlio César Batista;2019-08-29 11:10:00 -0300;Fix default value of FEED_STORAGE_GCS_ACL

==

scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
97a7d775;Eugenio Lacuesta;2019-08-29 10:51:16 -0300;Aplly suggestions by @victor-torres

==

scrapy/contracts/__init__.py
==================
b6b76df0;Eugenio Lacuesta;2019-08-28 18:28:31 -0300;CallbackKeywordArgumentsContract

==

scrapy/contracts/__init__.py
scrapy/contracts/default.py
scrapy/settings/default_settings.py
==================
ede91478;Mikhail Korobov;2019-08-28 22:00:17 +0500;Merge pull request #3966 from anubhavp28/robotstxt_useragent
Adds ROBOTSTXT_USER_AGENT setting
==
==================
93d4b0b0;Mikhail Korobov;2019-08-28 21:59:10 +0500;Merge pull request #3973 from Gallaecio/documentation-coverage
Provide complete API documentation coverage of scrapy.exporters
==
==================
b00f81c5;Mikhail Korobov;2019-08-28 21:58:25 +0500;Merge pull request #3978 from anubhavp28/doc-link-fix
Fixes a link in docs
==
==================
77c8ab2e;Anubhav Patel;2019-08-27 18:44:08 +0530;makes suggested changes

==

docs/topics/downloader-middleware.rst
docs/topics/settings.rst
==================
ad824a26;Anubhav Patel;2019-08-27 18:30:11 +0530;fixes a link in doc

==

docs/topics/settings.rst
==================
3a7b949d;Anubhav Patel;2019-08-27 13:11:31 +0530;Adds integration with Protego robots.txt parser (#3935)

==

docs/topics/downloader-middleware.rst
scrapy/robotstxt.py
tests/test_robotstxt_interface.py
tox.ini
==================
3abe7e6e;elacuesta;2019-08-26 04:35:44 -0300;Add Bug report and Feature request templates (#3471)

==

.github/ISSUE_TEMPLATE/bug_report.md
.github/ISSUE_TEMPLATE/feature_request.md
==================
0fa384e8;Adrián Chaves;2019-08-22 20:10:42 +0200;Provide complete API documentation coverage of scrapy.exporters

==

docs/conf.py
docs/news.rst
docs/topics/exporters.rst
scrapy/exporters.py
==================
97d2f717;OmarFarrag;2019-08-22 16:19:01 +0200;Support extracting ftp settings in `ImagesPipeline`

==

scrapy/pipelines/images.py
==================
2047124b;OmarFarrag;2019-08-22 16:18:14 +0200;Follow PEP8 .. Remove unnecessary comments

==

scrapy/pipelines/files.py
scrapy/utils/ftp.py
==================
bd22b25e;OmarFarrag;2019-08-22 01:30:15 +0200;Make `stat_file` thread safe .. Refactor file storing..  Support act/psv

==

scrapy/extensions/feedexport.py
scrapy/pipelines/files.py
scrapy/utils/ftp.py
==================
8c970c63;OmarFarrag;2019-08-21 18:28:36 +0200;port from str to int
Co-Authored-By: Adrián Chaves <adrian@chaves.io>
==

scrapy/pipelines/files.py
==================
56948c44;Mikhail Korobov;2019-08-19 23:15:09 +0500;Merge pull request #3442 from wRAR/ciphers
Support for overriding OpenSSL ciphers
==
==================
790bf903;OmarFarrag;2019-08-19 19:16:47 +0200;Make FTP persiting files thread safe

==

scrapy/pipelines/files.py
==================
81ac1da3;OmarFarrag;2019-08-19 17:17:21 +0200;Handle leading and trailing slashes

==

scrapy/pipelines/files.py
==================
0a5cb774;OmarFarrag;2019-08-19 17:12:11 +0200;Fix reference mistake

==

scrapy/pipelines/files.py
==================
9b1587ed;OmarFarrag;2019-08-19 16:13:56 +0200;Credentials from settings-Support custom paths-Remove close conenction

==

scrapy/pipelines/files.py
==================
00fe05e5;Anubhav Patel;2019-08-19 09:19:06 +0530;adds ROBOTSTXT_USER_AGENT setting

==

docs/topics/downloader-middleware.rst
docs/topics/settings.rst
scrapy/downloadermiddlewares/robotstxt.py
scrapy/settings/default_settings.py
tests/test_downloadermiddleware_robotstxt.py
==================
c025003d;OmarFarrag;2019-08-18 04:44:09 +0200;Add FTPFileStore

==

scrapy/pipelines/files.py
==================
2b0de060;Tobias Hernstig;2019-08-15 18:54:28 +0200;Fix merge conflicts

==

docs/topics/logging.rst
==================
50c4cafe;Tobias Hernstig;2018-03-11 11:46:07 +0100;Update documentation for logging manually
Usage of basicConfig() together with crawlerRunner is not recommended.
Update documentation to highlight this fact.

Closes #2149, #2352, #3146

==

docs/topics/logging.rst
==================
aaa5229e;Andrey Rakhmatullin;2019-07-15 17:47:06 +0500;Fixes and improvements for DOWNLOADER_CLIENT_TLS_CIPHERS.

==

docs/topics/settings.rst
scrapy/core/downloader/handlers/http11.py
scrapy/utils/ssl.py
tests/mockserver.py
tests/test_downloader_handlers.py
tests/test_webclient.py
==================
9a8edf2b;Andrey Rakhmatullin;2018-09-27 19:52:29 +0500;Tests for setting SSL ciphers.

==

tests/mockserver.py
tests/test_downloader_handlers.py
tests/test_webclient.py
==================
ce281d89;Andrey Rakhmatullin;2018-09-28 20:17:12 +0500;Documentation for DOWNLOADER_CLIENT_TLS_CIPHERS.

==

docs/topics/settings.rst
==================
3384db92;Andrey Rakhmatullin;2018-09-27 19:51:27 +0500;Add support for setting SSL ciphers.

==

scrapy/core/downloader/contextfactory.py
scrapy/settings/default_settings.py
==================
a95de71d;Mikhail Korobov;2019-08-12 22:51:00 +0500;Merge pull request #3950 from elacuesta/version_updates
Remove obsolete version checks
==
==================
2f0c46e7;Mikhail Korobov;2019-08-10 14:25:59 +0500;Merge pull request #3946 from elacuesta/simplify_versions
[MRG+1] Simplify version reporting
==
==================
26fb28b2;Eugenio Lacuesta;2019-08-09 00:49:46 -0300;PEP8-ify HTTP/1.1 downloader handler
Signed-off-by: Eugenio Lacuesta <eugenio.lacuesta@gmail.com>

==

scrapy/core/downloader/handlers/http11.py
==================
d5dcc5ea;Eugenio Lacuesta;2019-08-09 00:30:58 -0300;Import twisted.web.client.URI directly

==

scrapy/core/downloader/handlers/http11.py
==================
d3737d86;Eugenio Lacuesta;2019-08-09 00:21:43 -0300;Remove check for Twisted>=14.0

==

scrapy/core/downloader/handlers/http11.py
==================
e17c9a48;Eugenio Lacuesta;2019-08-08 23:59:17 -0300;Remove check for Twisted>=15.0.0
16.0.0 is currently the minimum supported version

==

scrapy/core/downloader/handlers/http11.py
==================
d92f1b18;Eugenio Lacuesta;2019-08-08 23:53:35 -0300;Simplify import + assignment

==

scrapy/core/downloader/tls.py
==================
b404941e;Eugenio Lacuesta;2019-08-08 23:18:47 -0300;Remove import check for service_identity
service_identity.exceptions.CertificateError is available in the current minimum version (16.0.0)

==

scrapy/core/downloader/tls.py
==================
3164543e;Eugenio Lacuesta;2019-08-08 23:15:03 -0300;Remove fallback ScrapyClientContextFactory class (used in Twisted < 14.0.0)
16.0.0 is currently the minimum supported version

==

scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/tls.py
==================
a940a80f;Eugenio Lacuesta;2019-08-08 23:05:52 -0300;Remove check for pyOpenSSL>=0.16
16.2.0 is currently the minimum supported version

==

scrapy/core/downloader/tls.py
==================
fa9a9033;Eugenio Lacuesta;2019-08-08 22:54:51 -0300;Remove check for Twisted>=14.0.0
16.0.0 is currently the minimum supported version

==

scrapy/core/downloader/tls.py
==================
da385b56;Eugenio Lacuesta;2019-08-08 12:44:23 -0300;Move get_openssl_version function to scrapy.utils.ssl

==

scrapy/utils/ssl.py
scrapy/utils/versions.py
==================
3040f774;Shivam Sandbhor;2019-08-08 17:28:22 +0530;[MRG+1] Update project.py removed one 'hack', seems irrelevant. (#3910)
* Update project.py removed one 'hack', seems irrelevant.

As mentioned by @Gallaecio in issue #3871, the 'hack'  is cleared. I also  double checked whether the environment variable "SCRAPY_PICKLED_SETTINGS_TO_OVERRIDE" was ever set in our codebase and it turns out we didn't set it or used it anywhere else.So I guess the 'hack' was not used in the current version. Also the name of this environment variable rather doesn't suggest it was  a boolean(it is used in  an 'if' condition which has perplexed me )

* Update project.py

* Update project.py

How about this?

* Update project.py

* Update project.py

* Update scrapy/utils/project.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update scrapy/utils/project.py

Co-Authored-By: Adrián Chaves <adrian@chaves.io>

* Update project.py

==

scrapy/utils/project.py
==================
73d1b4b7;Mikhail Korobov;2019-08-08 13:49:09 +0500;Merge pull request #3939 from Gallaecio/improve-scrapes-contract
Report all missing fields when a scrapes contract fails
==
==================
b4556d65;Mikhail Korobov;2019-08-08 13:38:17 +0500;Merge pull request #3941 from starrify/ftp-storage-uri-unquote
[MRG+1] Added: Properly handling quoted passwords in FEED_URI for FTP
==
==================
9119798a;Adrián Chaves;2019-08-05 15:49:07 +0200;Add test coverage for contract failures involving multiple missing fields

==

tests/test_contracts.py
==================
d76b6944;Marc Hernández;2019-08-08 09:43:42 +0200;Create Request from curl command  (#3862)

==

docs/topics/developer-tools.rst
docs/topics/dynamic-content.rst
docs/topics/request-response.rst
scrapy/http/request/__init__.py
scrapy/utils/curl.py
tests/test_http_request.py
tests/test_utils_curl.py
==================
595c995e;Eugenio Lacuesta;2019-08-07 15:38:04 -0300;Simplify version reporting

==

scrapy/utils/versions.py
==================
5dbeece8;elacuesta;2019-08-07 04:36:52 -0300;[MRG+1] Drop py34 support - Update CI envs (#3892)
* Drop py34 support

* Travis experiments

* More Travis experiments

* Bump Twisted version for py35+ (stretch)

* Remove Debian build

* Remove pinned lxml for Py34

* Fix merge error

* Remove unused tox env

* Add environment with pinned versions for py36

* Bump minimum Twisted version in py27; Envs with pinned versions for py27 and py35

* Add botocore as extra dep for py27 tests

* Update requirements-py2.txt

* Add botocore and Pillow as extra dependencies

==

.travis.yml
README.rst
docs/faq.rst
docs/intro/install.rst
requirements-py2.txt
requirements-py3.txt
setup.py
tests/requirements-py2.txt
tests/requirements-py3.txt
tox.ini
==================
7b755a41;Pengyu Chen;2019-08-06 15:18:59 +0100;Added: Properly handling quoted passwords in FEED_URI for FTP

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
bff335cf;Adrián Chaves;2019-08-05 15:47:58 +0200;Improve the error message in contract failures due to multiple missing fields

==

scrapy/contracts/default.py
==================
a8621bbc;tpeng;2014-06-26 11:28:03 +0200;show all the missing field when scrapes contract fails

==

scrapy/contracts/default.py
==================
eef17323;Daniel Graña;2019-08-05 09:39:21 -0300;Merge pull request #3934 from anubhavp28/typo-fix
[MRG+1] Fixes typo
==
==================
18d0affc;Shivam Sandbhor;2019-08-05 16:53:35 +0530;Update reactor.py, updated 'if' sequencing , possibly eliminating a bug if portrange=None
This should be the proper ordering.This is the explanation.
  If 'not portrange' is True ,it is guaranteed that `not hasattr(portrange, '__iter__')`  is also True  the converse of this is not always true.(for example, consider portrange=None, for such case we were executing the logic for `not hasattr(portrange, '__iter__')` . ).Such case is eliminated by this PR.
==

scrapy/utils/reactor.py
==================
9a4cd942;Anubhav Patel;2019-08-03 22:46:06 +0530;fixes typo

==

scrapy/core/downloader/webclient.py
==================
8e813953;Anubhav Patel;2019-08-02 13:13:29 +0530;[MRG+1] [GSoC 2019] Interface for robots.txt parsers (#3796)
Make the robots.txt parser configurable through the new ROBOTSTXT_PARSER setting, support the Reppy and Robotexclusionrulesparser parsers, and allow implementing custom robots.txt parsers.
==

.travis.yml
docs/topics/downloader-middleware.rst
docs/topics/settings.rst
scrapy/downloadermiddlewares/robotstxt.py
scrapy/robotstxt.py
scrapy/settings/default_settings.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_robotstxt_interface.py
tox.ini
==================
a12e8251;Adrián Chaves;2019-08-01 17:06:53 +0200;Cover Scrapy 1.7.3 in the release notes

==

docs/news.rst
==================
783d61d3;sbs2001;2019-08-01 14:11:27 +0530;[MRG+1] Update _monkeypatches.py (#3907)
* Update _monkeypatches.py

The workarounds are not required assuming the bugs regarding urlparse are absent in  Python versions >2.7. We already exit the program if Python  version<2.7 in the __init__.py(line 17).The monkeypatches are deployed after this check at line 27  in  the __init__.py .

* Update _monkeypatches.py

Added the second workaround.

* Update _monkeypatches.py

* Update _monkeypatches.py

==

scrapy/_monkeypatches.py
==================
cdf7889a;Mikhail Korobov;2019-07-31 20:07:44 +0500;Merge pull request #3923 from scrapy/pin-build-environment
Pin Travis-ci build environment to previous default: Trusty
==
==================
a25e09ec;Renne Rocha;2019-07-29 19:07:34 -0300;Added constrain on lxml version based on Python version

==

requirements-py3.txt
setup.py
tests/constraints.txt
==================
7333fc02;Daniel Graña;2019-07-30 23:16:11 -0300;Pin Travis-ci build environment to previous default: Trusty
Travis-ci changed the default build environment to Xenial as explained in https://blog.travis-ci.com/2019-04-15-xenial-default-build-environment
This causes builds meant for Debian Jessie to break as noted by @wRAR in https://github.com/scrapy/scrapy/issues/3917#issuecomment-516426389

This change pins the environment to known working ubuntu trusty distribution prior to dropping Jessie support and upgrade to Xenial as base.

Closes #1369

==

.travis.yml
==================
b01d012b;Daniel Graña;2019-07-30 22:15:26 -0300;Merge pull request #3920 from wRAR/fix-tls-logging
Fix memory handling and error handling in utils.ssl.get_temp_key_info.
==
==================
f21dc24a;Andrey Rakhmatullin;2019-07-30 18:16:12 +0500;Fix memory handling and error handling in utils.ssl.get_temp_key_info.

==

scrapy/utils/ssl.py
==================
06c093f4;Adrián Chaves;2019-07-29 19:02:14 +0200;Merge pull request #3905 from lucywang000/0.001
s3 file store persist_file should accept all supported headers
==
==================
04bca6af;Adrián Chaves;2019-07-29 18:20:55 +0200;Merge pull request #3894 from KristobalJunta/fix_retry_docs
fix default RETRY_HTTP_CODES value in docs
==
==================
7551689c;Lucy Wang;2019-07-26 09:07:29 +0800;s3 file store should accept all supported headers

==

scrapy/pipelines/files.py
==================
9c514b97;Mikhail Korobov;2019-07-24 01:45:40 +0500;Merge pull request #3450 from wRAR/tls-logging
Log cipher, certificate and temp key info on establishing an SSL connection
==
==================
c679aefe;Mikhail Korobov;2019-07-24 01:40:56 +0500;Merge pull request #3660 from anubhavp28/logFormatter-doc-patch
[MRG+1] docs for scrapy.logformatter
==
==================
7843101f;Adrián Chaves;2019-07-23 12:04:26 +0200;Cover Scrapy 1.7.2 in the release notes

==

docs/news.rst
==================
bc8672c3;Adrián Chaves;2019-07-23 11:59:53 +0200;Merge pull request #3896 from elacuesta/fix_configparser_import
Fix ConfigParser import in py2
==
==================
7e622af4;Eugenio Lacuesta;2019-07-22 14:53:17 -0300;Fix ConfigParser import in py2

==

scrapy/utils/conf.py
==================
43d5b5a5;Kristobal Junta;2019-07-22 10:19:08 +0300;fix default RETRY_HTTP_CODES value in docs

==

docs/topics/downloader-middleware.rst
==================
b8a43011;Adrián Chaves;2019-07-18 18:47:29 +0200;Cover Scrapy 1.7.1 in the release notes

==

docs/news.rst
==================
c6453800;Andrey Rakhmatullin;2019-07-18 22:17:39 +0500;Remove an unneeded if.

==

scrapy/core/downloader/contextfactory.py
==================
95dd2df7;Andrey Rakhmatullin;2019-07-18 20:51:26 +0500;Drop an unused import.

==

scrapy/core/downloader/contextfactory.py
==================
42743fd9;Andrey Rakhmatullin;2019-07-18 20:49:25 +0500;Move tls_verbose_logging extraction from __init__ to from_settings.

==

docs/topics/settings.rst
scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/handlers/http11.py
==================
ae4eab98;Adrián Chaves;2019-07-18 17:02:48 +0200;Cover the 1.7.1 PyPI repackaging in the release notes

==

docs/news.rst
==================
4e23d70d;Adrián Chaves;2019-07-18 15:38:25 +0200;Bump version: 1.6.0 → 1.7.0

==

.bumpversion.cfg
scrapy/VERSION
==================
a94b5bef;Adrián Chaves;2019-06-27 15:58:02 +0200;Write the 1.7 release notes and cover dropping Python 2 support in the upcoming 2.0

==

docs/conf.py
docs/contributing.rst
docs/faq.rst
docs/news.rst
docs/topics/contracts.rst
docs/topics/downloader-middleware.rst
docs/topics/feed-exports.rst
docs/topics/items.rst
docs/topics/settings.rst
==================
44eb21aa;Mikhail Korobov;2019-07-18 18:12:57 +0500;Merge pull request #3882 from MagdalenaDeschner/master
add instructions about how to define output file when running scrapy …
==
==================
c44d49b2;Deschner, Magdalena;2019-07-17 13:13:52 +0200;minor PEP8 style changes

==

docs/topics/practices.rst
==================
0d51f9cc;Maram Sumanth;2019-07-17 15:06:49 +0530;[MRG+1] Wrong value of log_count/INFO in stats (#3643)
* Update statscollectors.py

* Update statscollectors.py

* Update statscollectors.py

* Update crawler.py

* Update crawler.py

* corrected tests

* Update test_utils_log.py

* Update crawler.py

* Update crawler.py

* interchanged order

* correced

==

scrapy/crawler.py
==================
b2c013fe;Mikhail Korobov;2019-07-17 14:31:50 +0500;Merge pull request #3878 from elacuesta/mergedict_to_chainmap
Deprecate scrapy.utils.datatypes.MergeDict in favor of collections.ChainMap
==
==================
6660020e;Deschner, Magdalena;2019-07-17 11:30:02 +0200;remove detailed description about individual settings

==

docs/topics/practices.rst
==================
d7074d86;Eugenio Lacuesta;2019-07-16 14:13:45 -0300;Change condition to raise deprecation warning

==

scrapy/utils/datatypes.py
==================
377d8a7b;Mikhail Korobov;2019-07-16 21:58:44 +0500;Merge pull request #3877 from elacuesta/tests_deprecation_warnings
Prevent deprecation warnings
==
==================
e892a484;Deschner, Magdalena;2019-07-16 13:53:56 +0200;add instructions about how to define output file when running scrapy from script instead of cmd

==

docs/topics/practices.rst
==================
7e3a602d;Eugenio Lacuesta;2019-07-15 12:37:09 -0300;Suggested changes

==

scrapy/_monkeypatches.py
scrapy/item.py
scrapy/settings/__init__.py
scrapy/utils/datatypes.py
tests/__init__.py
tests/test_utils_datatypes.py
==================
d5a2a703;Eugenio Lacuesta;2019-07-13 23:47:41 -0300;Fix import

==

tests/test_utils_datatypes.py
==================
ef9a6192;Eugenio Lacuesta;2019-07-13 23:36:39 -0300;More DeprecationWarnings

==

scrapy/settings/__init__.py
tests/test_utils_datatypes.py
==================
62f3e224;Eugenio Lacuesta;2019-07-13 22:44:57 -0300;Deprecate scrapy.utils.datatypes.MergeDict in favor of collections.ChainMap

==

scrapy/loader/processors.py
scrapy/utils/datatypes.py
==================
eced544d;Eugenio Lacuesta;2019-07-13 22:14:47 -0300;Prevent even more DeprecationWarnings

==

scrapy/item.py
scrapy/utils/datatypes.py
tests/test_downloadermiddleware_robotstxt.py
==================
40086dab;Eugenio Lacuesta;2019-07-13 20:57:24 -0300;Prevent more DeprecationWarnings

==

scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http11.py
scrapy/utils/template.py
tests/test_downloadermiddleware_cookies.py
tests/test_engine.py
tests/test_linkextractors.py
tests/test_loader.py
tests/test_utils_url.py
==================
92d624c1;Eugenio Lacuesta;2019-07-13 20:55:45 -0300;[Tests] Prevent more TestCase DeprecationWarnings
* assertRegexpMatches -> assertRegex

==

tests/__init__.py
==================
c24b80e1;Eugenio Lacuesta;2019-07-13 20:34:31 -0300;Prevent DeprecationWarning about logging.warn

==

scrapy/core/downloader/handlers/http11.py
==================
b714a372;Eugenio Lacuesta;2019-07-13 20:23:10 -0300;[Tests] Prevent more DeprecationWarnings
* assertRegexpMatches -> assertRegex
* invalid escape sequence \[

==

tests/test_command_parse.py
==================
27e63e68;Eugenio Lacuesta;2019-07-13 20:10:06 -0300;Monkey patch configparser module to ease the dropping of py2 support

==

scrapy/_monkeypatches.py
scrapy/utils/conf.py
==================
09e27d2d;Eugenio Lacuesta;2019-07-13 18:08:07 -0300;[Tests] Monkey patch unittest.TestCase to prevent DeprecationWarning(s)

==

tests/__init__.py
tests/test_exporters.py
tests/test_http_headers.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_selector.py
tests/test_spider.py
tests/test_spiderloader/__init__.py
==================
a96a07bc;Andrey Rakhmatullin;2019-07-12 18:44:45 +0500;Add a test for DOWNLOADER_CLIENT_TLS_VERBOSE_LOGGING.

==

tests/test_downloader_handlers.py
==================
fa6a0d79;Adrián Chaves;2019-07-12 14:03:11 +0200;Merge pull request #3684 from Gallaecio/remove-ubuntu-topic
Remove docs/topics/ubuntu.rst
==
==================
c4bcfb1a;Adrián Chaves;2019-07-11 11:15:41 +0200;Merge pull request #3866 from Gallaecio/broad-crawl-memory-docs
Extend the topic about broad crawls with information about memory usage
==
==================
ed487b7d;Adrián Chaves;2019-07-11 09:18:00 +0200;broad-crawls.rst: Refactor the memory usage section

==

docs/topics/broad-crawls.rst
==================
98689b27;Andrey Rakhmatullin;2019-07-11 14:02:35 +0500;Improve the DOWNLOADER_CLIENTCONTEXTFACTORY doc.

==

docs/topics/settings.rst
==================
0de6ffc8;Andrey Rakhmatullin;2019-07-11 13:12:56 +0500;Fix super() call.

==

scrapy/core/downloader/tls.py
==================
5cdf2770;Robin;2015-05-29 16:02:02 +0200;Update broad-crawls.rst
Added section on how to treat memory consumption problems of broad crawls.
==

docs/topics/broad-crawls.rst
==================
df68c4b9;Luiz Francisco Rodrigues da Silva;2019-07-10 09:25:52 -0300;Add a setting to use active mode in FTPFeedStorage (#3829)
Add a setting to use active mode in FTPFeedStorage

FTP servers can be configured in active and passive mode, by default
Python and Scrapy use passive mode and there was no way to use active.

This commit adds a setting FEED_STORAGE_FTP_ACTIVE to allow a feed
to be exported to a FTP server configured in active mode.
==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
050a62a9;Mikhail Korobov;2019-07-10 10:18:34 +0500;Merge pull request #3861 from Gallaecio/documentation-coverage
Increase the documentation coverage of exceptions
==
==================
68d898d4;Adrián Chaves;2019-07-10 00:18:51 +0200;Merge pull request #3712 from elacuesta/docs_crawlspider_link_text
[Docs] CrawlSpider: update Rule docs
==
==================
9fb0f845;Eugenio Lacuesta;2019-07-09 15:30:22 -0300;Extend docs about Crawling Rules

==

docs/topics/spiders.rst
==================
d04e84c1;Eugenio Lacuesta;2019-07-09 15:24:31 -0300;Merge remote-tracking branch 'upstream/master' into docs_crawlspider_link_text

==
==================
a0bbbe8f;Adrián Chaves;2019-07-09 12:33:57 +0200;Add the API documentation of ContractFail to the contracts topic

==

docs/topics/contracts.rst
==================
578bccf3;Adrián Chaves;2019-07-09 12:33:07 +0200;Skip scrapy.exceptions.UsageError in the documentation coverage report

==

docs/conf.py
==================
a97a9b57;Mikhail Korobov;2019-07-08 21:26:04 +0500;Merge pull request #3621 from Gallaecio/bfo-for-few-requests
Document that the crawl order is BFO for small numbers of start requests
==
==================
dda12b65;Mikhail Korobov;2019-07-08 20:15:23 +0500;Merge pull request #3672 from Gallaecio/split-items
Add a FAQ entry about splitting items in item pipelines
==
==================
488156b1;Mikhail Korobov;2019-07-08 20:13:55 +0500;Merge pull request #3860 from Gallaecio/documentation-coverage
Skip scrapy.downloadermiddlewares private APIs in the documentation c…
==
==================
a0b09e01;Adrián Chaves;2019-07-08 14:44:46 +0200;Skip scrapy.downloadermiddlewares private APIs in the documentation coverage report

==

docs/conf.py
==================
0b9dce3a;Andrey Rakhmatullin;2019-07-08 17:40:56 +0500;Add DOWNLOADER_CLIENT_TLS_VERBOSE_LOGGING setting.

==

docs/topics/settings.rst
scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/handlers/http10.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/tls.py
scrapy/settings/default_settings.py
==================
783de8a8;Adrián Chaves;2019-02-12 16:36:35 +0100;Document how request concurrency settings impact request order

==

docs/faq.rst
==================
6ea62cac;Adrián Chaves;2019-03-08 16:06:45 +0100;Add a FAQ entry about splitting items in item pipelines

==

docs/faq.rst
docs/topics/spider-middleware.rst
==================
3dff65ac;Mikhail Korobov;2019-07-08 13:54:35 +0500;Merge pull request #3857 from mikolaje/master
PEP8 in cmdline.py
==
==================
9cab3f24;Adrián Chaves;2019-07-08 09:46:48 +0200;Merge pull request #3859 from scrapy/more-deprecations
More deprecations
==
==================
4bef6f43;Mikhail Korobov;2019-07-08 11:32:07 +0500;Merge pull request #3578 from nyov/deprecations
Deprecation removals for Scrapy 1.7
==
==================
cb4477db;Mikhail Korobov;2019-07-08 11:18:40 +0500;deprecate scrapy.utils.markup
it was an import-only shim for w3lib.html

==

scrapy/utils/markup.py
==================
64ff3cd6;Mikhail Korobov;2019-07-08 11:18:15 +0500;deprecate scrapy.utils.multipart
It was a shim for w3lib.form, but w3lib.form is deprecated as well.

==

scrapy/utils/multipart.py
==================
1130711c;Mikhail Korobov;2019-07-08 11:17:30 +0500;deprecate scrapy.utils.http
ChunkedTransferMiddleware is deprecated, so decode_chunked_transfer
can be deprecated as well.

==

scrapy/utils/http.py
==================
67a40009;Andrey Rakhmatullin;2019-07-08 10:31:52 +0500;Work around older pyOpenSSL not having get_cipher_name or get_protocol_version_name.

==

scrapy/core/downloader/tls.py
==================
5442c2d3;nyov;2019-02-23 17:49:58 +0000;Updating S3FeedStorage instancing without AWS key.

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
7a398b70;nyov;2019-01-09 02:36:22 +0000;Deprecation removals for Scrapy 1.7
Removing deprecations of 2015 and prior (pre-1.1)

==

.coveragerc
conftest.py
scrapy/cmdline.py
scrapy/conf.py
scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/http.py
scrapy/crawler.py
scrapy/loader/__init__.py
scrapy/log.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/selector/__init__.py
scrapy/selector/csstranslator.py
scrapy/selector/lxmlsel.py
scrapy/selector/unified.py
scrapy/spiders/__init__.py
scrapy/spiders/crawl.py
scrapy/telnet.py
scrapy/utils/python.py
scrapy/utils/response.py
tests/test_crawler.py
tests/test_downloader_handlers.py
tests/test_pipeline_files.py
tests/test_pipeline_images.py
tests/test_selector.py
tests/test_selector_csstranslator.py
tests/test_spider.py
==================
8f52dada;mikolaje;2019-07-06 19:55:09 +0800;PEP8 in cmdline.py

==

scrapy/cmdline.py
==================
3d8f075b;Daniel Graña;2019-07-05 08:55:43 -0300;Merge pull request #3840 from mabelvj/itemloader-errors
[MRG+1] Itemloader errors #3836
==
==================
4d4bd0e8;Mikhail Korobov;2019-07-04 22:05:46 +0500;Merge pull request #3609 from Gallaecio/2253
Document FilesPipeline.file_path and ImagesPipeline.file_path
==
==================
69b1d5d3;Andrey Rakhmatullin;2018-10-05 18:21:26 +0500;Log cipher, certificate and temp key info on establishing an SSL connection.

==

scrapy/core/downloader/tls.py
scrapy/utils/ssl.py
==================
4c755f1d;Mikhail Korobov;2019-07-02 20:18:14 +0500;Merge pull request #3692 from anubhavp28/doc-patch
[MRG+1] doc for creating custom cache storage backend.
==
==================
9aec7856;Mikhail Korobov;2019-07-02 20:08:14 +0500;Merge pull request #3794 from csalazar/whitelist-form-methods-in-fromresponse
[MRG+1] Fix form methods in FormRequest.from_response (#3777)
==
==================
2e4dc203;Claudio Salazar;2019-06-26 21:36:28 +0200;Add backward compability when method=None in FormRequest

==

scrapy/http/request/form.py
==================
3adf09bc;Daniel Graña;2019-06-26 14:01:29 -0300;Merge pull request #3563 from elacuesta/callback_kwargs
[MRG+1] Callback kwargs
==
==================
312e5738;Eugenio Lacuesta;2019-06-26 12:48:00 -0300;Request.cb_kwargs: update in spider middleware

==

tests/test_request_cb_kwargs.py
==================
d4d68cf3;Eugenio Lacuesta;2019-06-26 12:31:41 -0300;Request.cb_kwargs: update in downloader middleware

==

tests/test_request_cb_kwargs.py
==================
1f9f41b8;Eugenio Lacuesta;2019-06-26 12:31:12 -0300;Move request.cb_kwargs tests to their own test file

==

tests/spiders.py
tests/test_crawl.py
tests/test_request_cb_kwargs.py
==================
428309ba;Eugenio Lacuesta;2019-06-26 11:03:31 -0300;Merge remote-tracking branch 'origin/master' into callback_kwargs

==
==================
268a37cb;Mabel Villalba;2019-06-26 13:23:10 +0200;[itemloader-errors] updated Compose and MapCompose function names
 #3836

==

scrapy/loader/processors.py
==================
c81d120b;Mikhail Korobov;2019-06-25 23:25:58 +0300;Merge pull request #3768 from Gallaecio/meta-ignore-tags
Implement the METAREFRESH_IGNORE_TAGS setting
==
==================
e5f12faf;Mikhail Korobov;2019-06-25 23:11:59 +0300;Merge pull request #3703 from Gallaecio/ajax-docs
Add a topic about reaching data that selectors cannot reach
==
==================
bc137dd2;Mikhail Korobov;2019-06-25 22:28:55 +0300;Merge pull request #3842 from Gallaecio/documentation-coverage
Document scrapy.crawler.Crawler.stop()
==
==================
d7795484;Adrián Chaves;2019-06-25 17:29:49 +0200;Document scrapy.crawler.Crawler.stop()

==

docs/topics/api.rst
scrapy/crawler.py
==================
b1e348b2;Mabel Villalba;2019-06-25 17:00:40 +0200;[itemloader-errors] updated Compose and MapCompose messages and added tests
 #3836

==

scrapy/loader/processors.py
tests/test_loader.py
==================
a753ea7e;Mabel Villalba;2019-06-25 14:35:49 +0200;[itemloader-errors] added test for Compose and MapCompose
 #3836

==

tests/test_loader.py
==================
99eb03a8;Mabel Villalba;2019-06-25 14:17:54 +0200;[itemloader-errors] adapted compose test for the new error being returned by compose
 #3836

==

tests/test_loader.py
==================
ef56e34a;Mabel Villalba;2019-06-25 13:56:53 +0200;[itemloader-errors] fixed typo
 #3836

==

scrapy/loader/__init__.py
==================
ad8c9800;Mabel Villalba;2019-06-25 13:54:47 +0200;[itemloader-errors] undo _proc
 #3836

==

scrapy/loader/__init__.py
==================
f134b1da;Mabel Villalba;2019-06-25 13:45:06 +0200;[itemloader-errors] reordered method
 #3836

==

scrapy/loader/__init__.py
scrapy/loader/processors.py
==================
e5d17b4e;Mabel Villalba;2019-06-25 13:42:40 +0200;[itemloader-errors] reordered method
 #3836

==

scrapy/loader/__init__.py
==================
859008a1;Mabel Villalba;2019-06-20 10:13:59 +0200;[itemloader-errors] added error message to Compose and MapCompose
Fixes issue #3836

==

scrapy/loader/__init__.py
scrapy/loader/processors.py
==================
8a3b15eb;Adrián Chaves;2019-03-27 08:50:33 +0100;Document how to select dynamically-loaded content

==

docs/index.rst
docs/topics/dynamic-content.rst
==================
f4f2b169;Victor Torres;2019-06-24 07:38:05 -0300;Fix a memory leak on the Media Pipeline (Files and Images) (#3813)
We're storing exceptions captured by Twisted on the media pipeline
cache, but we're also using the defer.returnValue method with our
own methods decorated with @defer.inlineCallbacks.

The defer.returnValue method passes returned values forward by
throwing a defer._DefGen_Return exception, which in its turn
extends the BaseException class and is captured by Twisted.

This way, the latest exception stored in the Failure's object may
also have an HtmlResponse object in its __context__ attribute. As
the Response object also keeps track of the Request object that
has originated it, you could figure it out how many RAM we're
wasting here.

This could easily lead to a Memory Leak problem when running
spiders with Media Pipeline enabled and a particular Request set
that tends to raise a significant number of exceptions.

Example triggers:
- media requests with 404 status responses
- user land exceptins coming from custom middlewares
- etc.
==

scrapy/pipelines/media.py
tests/test_pipeline_media.py
==================
663352b2;Mabel Villalba;2019-06-20 10:10:16 +0200;[itemloader-errors] added error message to _process_input_value

==

scrapy/loader/__init__.py
==================
8d1e0e09;Mabel Villalba;2019-06-20 10:06:06 +0200;[itemloader-errors] added error message in get_value

==

scrapy/loader/__init__.py
==================
b53ff59a;Daniel Graña;2019-06-17 12:33:21 -0300;Merge pull request #3790 from andrewbaxter/master
[MRG+1] Account for mangling when serializing requests with private callbacks
==
==================
31cdb940;Daniel Graña;2019-06-17 11:50:49 -0300;Merge pull request #3833 from anubhavp28/remove_unused_var
removes unused var
==
==================
b8900ec6;Anubhav Patel;2019-06-17 00:06:44 +0530;removes unused var

==

tests/test_downloadermiddleware.py
==================
cdfb20ae;Daniel Graña;2019-06-13 19:43:01 -0300;Merge pull request #3739 from Matthijsy/feature/scrapy_check_env
[MRG+1] Add SCRAPY_CHECK environment variable
==
==================
29642966;Daniel Graña;2019-06-13 17:17:08 -0300;Merge pull request #3792 from barraponto/patch-4
[MRG+1] Add 429 to RETRY_HTTP_CODES
==
==================
8a022ac6;Daniel Graña;2019-06-13 17:16:07 -0300;Merge pull request #3810 from Gallaecio/documentation-coverage
Skip scrapy.contracts private APIs in the documentation coverage report
==
==================
c05d24c5;Daniel Graña;2019-06-13 00:06:25 -0300;Merge pull request #3819 from sortafreel/fix_missing_values
[MRG+1] Fix missing values
==
==================
66c40d0e;Daniel Graña;2019-06-12 17:40:26 -0300;Merge pull request #3825 from Gallaecio/fix-py34-setup
Require Twisted<=19.2.0 for Python 3.4
==
==================
1a6ce134;Daniel Graña;2019-06-12 17:40:09 -0300;Merge pull request #3827 from Gallaecio/fix-appveyor-config
Set the cloned directory as PYTHONPATH in appveyor.yml
==
==================
cdeccac6;sortafreel;2019-06-11 17:38:06 +0300;Linting (return previous indentation).

==

tests/test_loader.py
==================
fe0f80f2;Adrián Chaves;2019-06-11 15:50:41 +0200;Set the cloned directory as PYTHONPATH in appveyor.yml

==

appveyor.yml
==================
0da97233;Adrián Chaves;2019-06-11 14:11:38 +0200;Require Twisted<=19.2.0 for Python 3.4

==

setup.py
==================
7dad2f7b;sortafreel;2019-06-11 07:43:03 +0300;Add more tests.

==

tests/test_loader.py
==================
a1bca6a8;sortafreel;2019-06-11 07:36:29 +0300;Add tests.

==

scrapy/loader/__init__.py
tests/test_loader.py
==================
c7ba72b5;Adrián Chaves;2019-06-04 17:10:14 +0200;Skip scrapy.contracts private APIs in the documentation coverage report

==

docs/conf.py
==================
754f52b0;Sortafreel;2019-06-07 03:20:45 +0300;Preprocess values if item built from dict.
https://github.com/scrapy/scrapy/issues/3804

==

scrapy/loader/__init__.py
==================
bd8a1038;Sortafreel;2019-06-07 01:50:03 +0300;Add values (if there're any) when initiating items from dicts
https://github.com/scrapy/scrapy/issues/3804

==

scrapy/loader/__init__.py
==================
0c508795;Claudio Salazar;2019-06-06 22:10:59 +0200;Change behavior to use method GET when there are unknown methods in the form

==

scrapy/http/request/form.py
tests/test_http_request.py
==================
6af1dc89;Andrew Baxter;2019-06-06 04:25:19 +0900;Fix mangling test

==

tests/test_utils_reqser.py
==================
29bbbaa4;Mikhail Korobov;2019-06-05 20:00:26 +0500;Merge pull request #3812 from duketemon/master
[MRG+1] Tutorial: scrapy shell example should say "text" not "title" (#3807)
==
==================
3dd3e8c2;Andrew Baxter;2019-06-05 23:49:54 +0900;Restrict different class mangling tests to Py 3+

==

tests/test_utils_reqser.py
==================
9c81721c;Andrew Baxter;2019-06-05 23:43:56 +0900;Add tests for private method name mangling

==

scrapy/utils/reqser.py
tests/test_utils_reqser.py
==================
c81e15ed;Artem Kuchumov;2019-06-05 13:15:23 +0500;Tutorial: scrapy shell example should say "text" not "title" (#3807)
Tutorial: scrapy shell example should say "text" not "title"
==

docs/intro/tutorial.rst
==================
f755507d;Mikhail Korobov;2019-06-04 18:47:24 +0500;Merge pull request #3567 from Gallaecio/documentation-coverage
Add a Sphinx extension to generate documentation coverage information
==
==================
a3dab41d;Mikhail Korobov;2019-06-04 18:11:08 +0500;Merge pull request #3806 from Gallaecio/statscollectors-currentmodule
Fix a double indexing of the scrapy.statscollectors module in the doc…
==
==================
c7b5ad0e;Adrián Chaves;2019-01-04 18:17:35 +0100;Add a Sphinx extension to generate documentation coverage information

==

docs/Makefile
docs/conf.py
docs/contributing.rst
docs/requirements.txt
tox.ini
==================
ea209a0e;Adrián Chaves;2019-06-03 19:21:40 +0200;Fix module double indexing issues in the documentation

==

docs/topics/stats.rst
docs/topics/telnetconsole.rst
==================
bcad8947;Andrew Baxter;2019-06-03 20:41:02 +0900;Support inherited private method names

==

scrapy/utils/reqser.py
tests/test_utils_reqser.py
==================
890e7fbd;Mikhail Korobov;2019-05-28 19:16:12 +0100;Merge pull request #3791 from barraponto/patch-3
[MRG+1] Fix documentation for spiderloader
==
==================
8d503842;Mikhail Korobov;2019-05-28 19:12:04 +0100;Merge pull request #3797 from mar-heaven/master
[MRG+1] remove a "is"
==
==================
9af91a26;Andrew Baxter;2019-05-28 01:40:26 +0900;Replace regex usage

==

scrapy/utils/reqser.py
tests/test_utils_reqser.py
==================
72b7d3e9;Andrew Baxter;2019-05-27 23:30:23 +0900;Make the regex align to the spec better; add unit tests for name variations

==

scrapy/utils/reqser.py
tests/test_utils_reqser.py
==================
18f01ea6;mar-heaven;2019-05-27 17:15:30 +0800;remove a "is"
When I translated in Chinese, I found a needless "is"
==

docs/topics/spiders.rst
==================
da82ede8;Anubhav Patel;2019-05-25 17:19:10 +0530;describe method as a command

==

docs/topics/downloader-middleware.rst
==================
461682fc;Claudio Salazar;2019-05-25 11:01:19 +0200;Whitelist form methods in FormRequest.from_response method

==

scrapy/http/request/form.py
tests/test_http_request.py
==================
144afcee;Andrew Baxter;2019-05-25 00:52:00 +0900;Use regex to check for private methods

==

scrapy/utils/reqser.py
==================
0ee2284f;Capi Etheriel;2019-05-24 11:11:15 -0300;Add 429 to RETRY_HTTP_CODES

==

scrapy/settings/default_settings.py
==================
7d36fa74;Capi Etheriel;2019-05-24 10:32:55 -0300;Fix documentation for spiderloader

==

docs/topics/api.rst
==================
e667ca76;Andrew Baxter;2019-05-24 21:45:53 +0900;Account for mangling when serializing requests with private callbacks

==

scrapy/utils/reqser.py
tests/test_utils_reqser.py
==================
a3d38041;Mikhail Korobov;2019-05-09 20:59:30 +0500;Merge pull request #3764 from Jeffallan/patch-1
[MRG+1] Update telnetconsole.rst
==
==================
137a3d81;Mikhail Korobov;2019-05-09 20:59:20 +0500;Merge pull request #3762 from Vandenn/update-logging-docs
[MRG+1] doc: update configure_logging docs to discourage use with CrawlerProcess
==
==================
2f0285b6;Mikhail Korobov;2019-05-09 20:58:38 +0500;Merge pull request #3767 from firegolem/patch-1
[MRG+1] Fix a broken github help link
==
==================
611249bb;Adrián Chaves;2019-05-08 12:52:29 +0200;Implement the METAREFRESH_IGNORE_TAGS setting

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/redirect.py
scrapy/settings/default_settings.py
scrapy/utils/response.py
tests/test_downloadermiddleware_redirect.py
==================
3a7850fa;Aditya;2019-05-05 18:45:40 +0530;Update contributing.rst

==

docs/contributing.rst
==================
5814344a;Jeffallan;2019-05-04 14:15:47 -0500;Update telnetconsole.rst
Change spelling of bellow to below.
==

docs/topics/telnetconsole.rst
==================
bc1a9292;Adrián Chaves;2019-05-03 14:42:12 +0200;Improve the documentation about detecting check runs

==

docs/topics/contracts.rst
==================
f6485e66;Matthijs Vos;2019-05-03 13:53:45 +0200;Restore alphabetic order and two lines between import and code

==

scrapy/utils/misc.py
tests/test_utils_misc/__init__.py
==================
8bd207a2;Matthijs Vos;2019-04-28 21:47:47 +0200;Add documentation

==

docs/topics/contracts.rst
==================
122ca621;Vandenn;2019-05-02 23:59:01 +0800;doc: update configure_logging docs to discourage use with CrawlerProcess

==

docs/topics/logging.rst
==================
7809c0b1;Matthijs Vos;2019-04-20 09:25:01 +0200;Revert another non-change comment

==

scrapy/utils/misc.py
==================
935387aa;Matthijs Vos;2019-04-18 22:10:23 +0200;Revert some non-changes

==

scrapy/utils/misc.py
==================
6d527085;Matthijs Vos;2019-04-18 15:19:23 +0200;Add reset case

==

tests/test_utils_misc/__init__.py
==================
29739989;Matthijs Vos;2019-04-18 14:50:02 +0200;Add set_environ test

==

tests/test_utils_misc/__init__.py
==================
6e49c379;Mikhail Korobov;2019-04-17 13:22:11 +0500;Merge pull request #3748 from Gallaecio/docstring-conventions
Cover PEP 257 in the documentation policies
==
==================
5b667b61;Mikhail Korobov;2019-04-17 13:20:37 +0500;Merge pull request #3707 from Gallaecio/pytest-xdist
Use pytest-xdist
==
==================
5a6fb3da;Adrián Chaves;2019-03-29 17:10:16 +0100;Use pytest-xdist

==

docs/contributing.rst
tests/requirements-py2.txt
tests/requirements-py3.txt
==================
fbb42fe1;Adrián Chaves;2019-04-17 08:25:22 +0200;Cover PEP 257 in the documentation policies

==

docs/contributing.rst
==================
4b791274;Mikhail Korobov;2019-04-13 01:52:22 +0500;Merge pull request #3735 from anubhavp28/smallfix
[MRG+1] Changes a parameter name in class `DummyPolicy`
==
==================
71cfe550;Mikhail Korobov;2019-04-13 01:50:19 +0500;Merge pull request #3737 from anubhavp28/anothersmallfix
[MRG+1] Fixes a link in comment
==
==================
92fa657f;Adrián Chaves;2019-04-11 17:34:45 +0200;Merge pull request #3730 from ankostis/doc_logstats_delay
[MRG+1] doc: document LOGSTATS_INTERVAL setting
==
==================
07adca34;Matthijs Vos;2019-04-10 13:01:46 +0200;Fix 'Too many values to unpack'

==

scrapy/utils/misc.py
==================
50730ed2;Matthijs Vos;2019-04-10 13:01:01 +0200;Try it with a string

==

scrapy/commands/check.py
==================
d27c2c68;Matthijs Vos;2019-04-10 12:56:50 +0200;Wrap scrapy check in environment

==

scrapy/commands/check.py
scrapy/utils/misc.py
==================
4cfdc149;Anubhav Patel;2019-04-09 17:52:02 +0530;fixes a link in comment

==

scrapy/extensions/httpcache.py
==================
e6048d55;Anubhav Patel;2019-04-09 17:34:20 +0530;changes parameter name

==

scrapy/extensions/httpcache.py
==================
92801850;Mikhail Korobov;2019-04-07 00:06:08 +0500;Merge pull request #3520 from whalebot-helmsman/round-robin-scheduler-tested
[MRG+1] Downloader-aware Priority Queue for Scrapy
==
==================
aa46e199;Maram Sumanth;2019-04-07 00:33:40 +0530;[MRG+1] Show elapsed time in statscollector (#3638)
* Update corestats.py

* Update corestats.py

* corrected tests

* Update corestats.py

* Update scrapy/extensions/corestats.py


==

scrapy/extensions/corestats.py
tests/test_closespider.py
==================
f816375d;Mikhail Korobov;2019-04-06 23:54:15 +0500;Merge pull request #3726 from ankostis/fixctrlc
[MRG+1] fix: do not catch system exceptions like KeyboardInterrupt
==
==================
a8f83ab9;Kostis Anagnostopoulos;2019-04-06 14:58:32 +0200;doc: document LOGSTATS_INTERVAL setting

==

docs/topics/settings.rst
==================
2079e3c4;Daniel Graña;2019-04-06 06:52:31 -0300;Merge pull request #3728 from victor-torres/process_spider_exception
[MRG+1] fix typo on Spider Middleware template (Response -> Request)
==
==================
35ce92a4;Victor Torres;2019-04-05 11:43:21 -0300;fix typo (Response -> Request)
check docs for more information https://github.com/scrapy/scrapy/blob/b5c552d17ff9e9629434712c3d0595c02853bcfc/docs/topics/spider-middleware.rst

==

scrapy/templates/project/module/middlewares.py.tmpl
==================
3a493b60;Kostis Anagnostopoulos;2019-04-05 11:52:00 +0200;fix: do not catch system exceptions like KeyboardInterrupt

==

scrapy/contracts/__init__.py
scrapy/core/spidermw.py
scrapy/utils/defer.py
scrapy/utils/misc.py
tests/mockserver.py
==================
d39feaba;Mikhail Korobov;2019-04-05 12:31:59 +0500;Merge pull request #3724 from float13/tutorial_grammar
[MRG+1] Docs - Tutorial - Minor grammar edits
==
==================
a101d5fe;float13;2019-04-05 01:12:20 -0400;text edit - delete 2 extra words

==

docs/intro/tutorial.rst
==================
77e36956;float13;2019-04-05 01:04:59 -0400;grammar fix - add apostrophe-s to browser

==

docs/intro/tutorial.rst
==================
d711ecfc;float13;2019-04-05 00:56:51 -0400;grammar fix - delete extra word "shell"

==

docs/intro/tutorial.rst
==================
6336e1d1;float13;2019-04-05 00:54:46 -0400;grammar fix - delete unneeded apostrophe in "lets"

==

docs/intro/tutorial.rst
==================
c2d8f6f4;Mikhail Korobov;2019-04-03 19:01:35 +0500;Merge pull request #3718 from Gallaecio/deprecate-is-gzipped
Deprecate the scrapy.utils.gz.is_gzipped function
==
==================
7acf4eec;Adrián Chaves;2019-04-02 18:36:03 +0200;Deprecate the scrapy.utils.gz.is_gzipped function

==

scrapy/utils/gz.py
==================
7a38623c;Eugenio Lacuesta;2019-04-01 17:09:49 -0300;[Docs] Clarify comment about meta dictionary

==

docs/topics/spiders.rst
==================
8ebbc731;Eugenio Lacuesta;2019-04-01 16:15:03 -0300;[Docs] Rephrase Rule docs

==

docs/topics/spiders.rst
==================
07ff9248;Eugenio Lacuesta;2019-04-01 12:31:26 -0300;[Docs] CrawlSpider: add note about link text

==

docs/topics/spiders.rst
==================
b5c552d1;Konstantin Lopuhin;2019-04-01 10:43:19 +0300;Merge pull request #2061 from elacuesta/process_spider_exception_generator
[MRG+1] process_spider_exception on generators
==
==================
0522fe35;Eugenio Lacuesta;2019-03-29 16:15:34 -0300;parse command: improve option description

==

scrapy/commands/parse.py
==================
294ef51b;Eugenio Lacuesta;2019-03-29 16:12:55 -0300;parse command: update docs about passing callback keyword arguments

==

docs/topics/commands.rst
==================
ccb56a31;Eugenio Lacuesta;2019-03-29 14:12:26 -0300;Update docs about cb_kwargs and meta

==

docs/topics/request-response.rst
==================
f5e0b6b8;Eugenio Lacuesta;2019-03-29 14:03:26 -0300;parse command: rename cb_kwargs option to cbkwargs

==

scrapy/commands/parse.py
tests/test_command_parse.py
==================
1c673345;Vostretsov Nikita;2019-03-29 10:44:55 +0000;added underlines

==

docs/topics/broad-crawls.rst
==================
ef743983;Vostretsov Nikita;2019-03-29 10:38:13 +0000;change wording

==

docs/topics/broad-crawls.rst
==================
f08f841d;Vostretsov Nikita;2019-03-29 10:35:49 +0000;remove small single use method

==

scrapy/core/scheduler.py
==================
539a08cb;Vostretsov Nikita;2019-03-29 10:31:52 +0000;Merge branch 'round-robin-scheduler-tested' of github.com:whalebot-helmsman/scrapy into round-robin-scheduler-tested

==
==================
554d8728;Vostretsov Nikita;2019-03-29 10:31:15 +0000;remove spacing

==

scrapy/core/scheduler.py
==================
2b4bcfaf;Vostretsov Nikita;2019-03-29 10:30:26 +0000;remove comment

==

scrapy/core/scheduler.py
==================
1ee99e1f;Adrián Chaves;2019-03-29 10:29:15 +0000;Update docs/topics/settings.rst
Co-Authored-By: whalebot-helmsman <whalebot.helmsman@gmail.com>
==

docs/topics/settings.rst
==================
bd228f1d;Adrián Chaves;2019-03-29 10:29:04 +0000;Update docs/topics/broad-crawls.rst
Co-Authored-By: whalebot-helmsman <whalebot.helmsman@gmail.com>
==

docs/topics/broad-crawls.rst
==================
e3df6be3;Adrián Chaves;2019-03-29 10:28:52 +0000;Update docs/topics/broad-crawls.rst
Co-Authored-By: whalebot-helmsman <whalebot.helmsman@gmail.com>
==

docs/topics/broad-crawls.rst
==================
46b9ab0c;Adrián Chaves;2019-03-29 10:28:36 +0000;Update docs/topics/broad-crawls.rst
Co-Authored-By: whalebot-helmsman <whalebot.helmsman@gmail.com>
==

docs/topics/broad-crawls.rst
==================
8fb07769;Eugenio Lacuesta;2019-03-28 15:18:00 -0300;Request.cb_kwargs: Update docs

==

docs/topics/debug.rst
docs/topics/jobs.rst
docs/topics/leaks.rst
docs/topics/request-response.rst
==================
e8af6331;Eugenio Lacuesta;2019-03-28 14:56:31 -0300;Add cb_kwargs option to the parse command

==

docs/topics/commands.rst
scrapy/commands/parse.py
tests/test_command_parse.py
==================
3efe3bea;Eugenio Lacuesta;2019-03-28 14:16:03 -0300;Update docs about cb_kwargs and meta

==

docs/topics/request-response.rst
==================
70a4d93a;Eugenio Lacuesta;2019-03-28 10:40:41 -0300;Callback kwargs: more tests

==

tests/spiders.py
tests/test_crawl.py
==================
ec719f55;Mikhail Korobov;2019-03-28 01:39:54 +0500;Merge pull request #3682 from elacuesta/rule_process_request_response_parameter
[MRG+1] Rule.process_request: access Response object
==
==================
c43a2315;Eugenio Lacuesta;2019-03-27 14:42:41 -0300;Merge remote-tracking branch 'upstream/master' into callback_kwargs

==
==================
8528f506;Eugenio Lacuesta;2019-03-27 14:42:26 -0300;[Doc] Update cb_kwargs example

==

docs/topics/request-response.rst
==================
9c9bca4e;Anubhav Patel;2019-03-27 18:29:48 +0530;make suggested changes.

==

docs/topics/downloader-middleware.rst
==================
845bae66;Mikhail Korobov;2019-03-27 08:49:19 +0000;Update docs/topics/broad-crawls.rst
Co-Authored-By: whalebot-helmsman <whalebot.helmsman@gmail.com>
==

docs/topics/broad-crawls.rst
==================
820adb69;Mikhail Korobov;2019-03-27 12:25:38 +0500;Merge pull request #3701 from Gallaecio/documentation-policy-api
Update the documentation policies: Ask to use docstrings to document …
==
==================
ce837b0f;Adrián Chaves;2019-03-25 18:04:04 +0100;Update the documentation policies: Ask to use docstrings to document API members

==

docs/contributing.rst
==================
2fd8b7c2;Maram Sumanth;2019-03-27 00:45:53 +0530;[MRG+1] redirect_reasons in Request.meta (#3687)

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
scrapy/downloadermiddlewares/redirect.py
tests/test_downloadermiddleware_redirect.py
==================
5f2ad537;Maram Sumanth;2019-03-26 16:46:15 +0530;fixed typo

==

tests/test_http_request.py
==================
431f18a9;Adrián Chaves;2019-02-01 13:22:38 +0100;Document FilesPipeline.file_path and ImagesPipeline.file_path

==

docs/topics/media-pipeline.rst
==================
ae856e8b;Maram Sumanth;2019-03-26 16:21:52 +0530;corrected tests

==

tests/test_http_request.py
==================
213b9eb8;Maram Sumanth;2019-03-26 15:59:38 +0530;Update test_http_request.py

==

tests/test_http_request.py
==================
dc8310e2;Maram Sumanth;2019-03-26 15:42:58 +0530;changed tests

==

tests/test_http_request.py
==================
ba13de29;Adrián Chaves;2019-03-26 10:38:38 +0100;Merge branch 'master' into feat-685

==
==================
73e4ff53;Vostretsov Nikita;2019-03-25 13:48:58 +0000;report warnings

==

tests/test_crawler.py
==================
103fdc40;Vostretsov Nikita;2019-03-25 16:16:42 +0300;Merge remote-tracking branch 'upstream/master' into round-robin-scheduler-tested

==
==================
31b8a6b3;Vostretsov Nikita;2019-03-25 08:53:15 +0000;report warnings

==

tests/test_crawler.py
==================
df574de8;Lucy Wang;2019-03-23 00:54:39 +0800;improve tests and fix some lint warnings (#6)
* refactor downloader-aware test cases

* fix lint

* add doctest for _path_safe

* remove unused code

* better doctest

==

scrapy/pqueues.py
tests/test_scheduler.py
==================
8afffb72;Vostretsov Nikita;2019-03-22 09:12:23 +0000;Tests Cleanup add doctest for function no need in this variables move common assertion inside function rename variable rename variables rename function use function this is not a method of public API correct name for test Update docs/topics/settings.rst
Co-Authored-By: whalebot-helmsman <whalebot.helmsman@gmail.com>

==

docs/topics/settings.rst
tests/test_scheduler.py
==================
989bba6c;Vostretsov Nikita;2019-03-07 09:00:14 +0000;Revert "new signal"
This reverts commit 646164fd7d6dd52061804d2df7424cff929bf739.
remove tests
Revert "emit new signal"

This reverts commit fcde0c6880678957a76af6083b6248f430a00fcf.
Revert "documentation for new signal"

This reverts commit 8aeb9f696ece95c16499a96767a7afa3d9c4abf4.

==

docs/topics/signals.rst
scrapy/core/downloader/__init__.py
scrapy/signals.py
tests/test_request_left.py
==================
443fb98a;Vostretsov Nikita;2019-03-05 12:44:07 +0000;Use downloader directly rename variable remove old write function remove unused imports remove old read function remove unused function use mock methods mock downloader close downloader add parse method use new PQ class create mock downloader use downloader directly remove mark/unmark mechanism

==

scrapy/pqueues.py
tests/test_scheduler.py
==================
83eb5376;Mikhail Korobov;2019-01-17 07:38:15 +0500;assorted cleanups: comments, docstrings, etc scheduler cleanup
Scheduler no longer converts requests to dicts; PriorityQueue
instances always work with Request instances; converting Requests
to dicts is now Priority Queue responsibility.
minor cleanup

==

docs/topics/settings.rst
scrapy/core/scheduler.py
scrapy/pqueues.py
scrapy/settings/default_settings.py
scrapy/squeues.py
==================
3b1db71d;Vostretsov Nikita;2019-01-09 12:14:40 +0000;New signal update signature documentation for new signal utilize new signal correct signal handler signature emit new signal test another signal new signal rename test file faster test rename test case tests for signal emitting in bad cases

==

docs/topics/signals.rst
scrapy/core/downloader/__init__.py
scrapy/pqueues.py
scrapy/signals.py
tests/test_request_left.py
tests/test_scheduler.py
==================
757f53a3;Vostretsov Nikita;2019-01-09 10:00:13 +0000;Address Lucy's comments add tests to check correctness of slot setermination unmark requests after downloading shorter better exception message

==

scrapy/pqueues.py
tests/test_scheduler.py
==================
90934959;Mikhail Korobov;2018-12-27 17:12:24 +0500;actually apply __slots__ suggestion [wip] refactoring
* SlotPriorityQueues doesn't care about objects inside, it is now just
  a container for multiple priority queues
* assorted variable renames
* don't inherit DownloaderAwarePriorityQueue from SlotBasedPriorityQueue
* apply @whalebot-helmsman's suggestions for __slots__ and meta issues
more bike-shedding

* remove mutable default arguments
* more verbose variable names
remove unneeded code

* PriorityAsTupleQueue.is_empty does the same as len(self) == 0
* custom PriorityAsTupleQueue.close is not needed after a switch
  to namedtuples
* is_new and is_empty return values are unused
* "url" local variable is unused
PrioritySlot.__str__ shouldn't return unicode in Python 2

also, do some bike-shedding: _pathable -> _path_safe
use namedtuple for PrioritySlot
cleanup: _get_from_request does the same here

Request.meta is always a dict

==

scrapy/pqueues.py
tests/test_scheduler.py
==================
1b4385b7;Eugenio Lacuesta;2019-03-22 19:46:17 -0300;Rule.process_request: move deprecation warnings and compiling code, update tests

==

scrapy/spiders/crawl.py
tests/test_spider.py
==================
174ba3cc;Eugenio Lacuesta;2019-03-22 19:16:18 -0300;Rule.process_request: update docs

==

docs/topics/spiders.rst
==================
56929e77;Eugenio Lacuesta;2019-03-22 18:34:55 -0300;Rule.process_request: deprecate the use of functions taking only one argument

==

scrapy/spiders/crawl.py
==================
bbf24b7a;Eugenio Lacuesta;2019-03-22 18:02:31 -0300;Rule.process_request: use scrapy.utils.python.get_func_args

==

scrapy/spiders/crawl.py
==================
8583c033;Mikhail Korobov;2019-03-23 00:23:06 +0500;Merge pull request #3694 from noviluni/master
[MRG+1] Fix numeration
==
==================
c191a8e7;Adrián Chaves;2019-03-22 19:45:57 +0100;Merge pull request #3698 from noviluni/_fix_gitignore
[MRG+1] remove duplicated entry in gitignore
==
==================
729580da;Mikhail Korobov;2019-03-22 22:56:39 +0500;Merge pull request #3671 from Gallaecio/item-deepcopy
Implement Item.deepcopy()
==
==================
9a0fe8bf;Marc Hernández Cabot;2019-03-20 16:13:31 +0100;remove duplicated entry in gitignore

==

.gitignore
==================
7c148fce;Adrián Chaves;2019-03-08 15:40:16 +0100;Implement Item.deepcopy()

==

docs/topics/items.rst
scrapy/item.py
tests/test_item.py
==================
af2b6665;Konstantin Lopuhin;2019-03-22 18:25:54 +0300;Merge pull request #3505 from kasun/json_request
[MRG+2] Request subclass for json requests #3504
==
==================
4196d486;Mikhail Korobov;2019-03-22 20:05:45 +0500;Merge pull request #3607 from victor-torres/feed-storage-s3-acl
[MRG+1] add FEED_STORAGE_S3_ACL setting
==
==================
72cf1901;Adrián Chaves;2019-03-08 14:46:07 +0100;Add a FAQ entry about name collisions

==

docs/faq.rst
==================
2cb4dc32;Júlio César Batista;2019-03-22 09:50:11 -0300;Mentioning to use JSON API for ACLs

==

docs/topics/settings.rst
==================
338b78d7;Vostretsov Nikita;2018-12-25 09:44:20 +0000;Add documentation add section to broad-crawl topic reword in accord with broad-crawl topic add documentation for new priority queue

==

docs/topics/broad-crawls.rst
docs/topics/settings.rst
==================
8e8ce301;Vostretsov Nikita;2018-12-25 09:14:09 +0000;check CONCURRENT_REQUESTS_PER_IP is not set

==

scrapy/pqueues.py
==================
987c2ae4;Vostretsov Nikita;2018-12-25 09:13:09 +0000;test ip concurrency incompatibility with DAPQ

==

tests/test_scheduler.py
==================
4163a7a1;Vostretsov Nikita;2018-12-21 09:10:32 +0000;no need for this

==

tests/requirements-py2.txt
==================
6ff2574c;Daniel Graña;2018-12-20 19:39:29 -0300;Needs to be installed within tox env

==

.travis.yml
tox.ini
==================
7d3175ac;Daniel Graña;2018-12-20 19:23:23 -0300;Fix boto import error under Jessie testing environment

==

.travis.yml
==================
d970be64;Vostretsov Nikita;2018-12-17 13:52:11 +0000;Integration test integration testing only everything is working, not logic of PQ use method create slot attribute in constructor corect class for test case stop crawler in teardown method use class correct entity naming python 2 adaptation integration test with crawler and spider

==

tests/test_scheduler.py
==================
a23e1894;Vostretsov Nikita;2018-12-14 16:18:34 +0000;Fix boto problem another way to fix boto problem Revert "fix for travis ci based on https://github.com/boto/boto/issues/3717"
This reverts commit 150d2564ff0ea994652da7f5be333d72e0b38d93.
fix for travis ci based on https://github.com/boto/boto/issues/3717

==

tests/requirements-py2.txt
==================
a46613af;Vostretsov Nikita;2018-12-14 14:55:06 +0000;use regular comments

==

scrapy/pqueues.py
==================
6af964cc;Vostretsov Nikita;2018-12-14 14:54:24 +0000;common indentation for comment

==

scrapy/pqueues.py
==================
484927b0;Vostretsov Nikita;2018-12-14 14:38:28 +0000;less complex implementation

==

scrapy/pqueues.py
==================
0e06b9a8;Vostretsov Nikita;2018-12-14 14:35:18 +0000;use urlparse_cached where it is possible

==

scrapy/pqueues.py
==================
7efba101;Lucy Wang;2018-12-10 14:44:15 +0800;remove "sudo: false" now that travis no longer supports it
https://changelog.travis-ci.com/deprecation-container-based-linux-build-environment-82037

==

.travis.yml
==================
f56079f6;Vostretsov Nikita;2018-12-05 10:02:42 +0000;Test cleanups PEP8 fixes no need to close implicitly do not use pytest need to put it into class remove round-robin queue additional check for empty queue use pytest tmpdir fixture

==

scrapy/pqueues.py
tests/test_scheduler.py
==================
9c314800;Adrián Chaves;2018-12-03 17:14:10 +0100;Document the SCRAPY_PROJECT environment variable
Fixes #1109

==

docs/topics/commands.rst
==================
afdb69ea;Adrián Chaves;2018-12-03 16:36:05 +0100;Add a troubleshooting section to the installation instructions
Its initial content covers the workaround for #2473.

==

docs/intro/install.rst
==================
821f5bb2;Vostretsov Nikita;2018-12-03 11:00:03 +0000;First implementation handle exception use O(N) instead of O(NlogN) here we have request as struct additional check for meptiness small performance improvement do not consume another request test number of responses mark requests back to 3 slots test case raise exceptions in case of missed meta add marks to requests and work only with your own requests only disk queue should obtain signals separate functions for slot rasd/write use signlas without variable stop crawler get signals in correct place logic test for download-aware priority queue update comment for structure ensure text type transform slot name to path use implicit structure use unicode type implicitly use real crawler add signals more slot accounting simple implementation of pop small slot accounting code no need for custom len function ability to call super in py27 add slots generic tests for downloader aware queue dummy implementation of crawler aware priority queue move common logic to base class rename class pass crawler to pqclass constructor do not copy quelib.PriorityQueue code add comment about new class remove obsolete function modify behaviour of queuelib.PriorityQueue to dodge very complex priority better way to get name remove obsolete commentary check boundaries function for priority convertion with known limits correct import path move file do not switch on by deffault as ip concurrency not supported set scheduler slot in case of empty slot use constant single place for added urls single place for constants use as default queue correct format for error text test migration from old version with on disk queue in these tests we have only two inflection points - jobdir and priority_queue_cls we do not need separate mock spider, use usual one do not rely on order of dict elements, imply order of list test round robiness of priority queue add comments and requirements for our magick function remove debug logging put queues into slot as we fabricate priorities we do not need special types anymore fabricate priority for priority queue more versatile priorities Scheduler class is not inflection point wrap correct types check for emptinees before initialization tests for new priority queue correct default type for startprios use exact values put common settings to base class test priorities for disk scheduler test dequeue for disk scheduler test length for disk scheduler setUp/tearDown methods for on disk schedulers new methods remove excessive line base class to handle scheduler creation correct method names test priorities deque test close scheduler on test end enqueue some requests test template for scheduler use downloader slot I/O implementation for RoundRobin queue round-robin implementation without I/O and slot detection wrappers for every disk queue class

==

scrapy/core/downloader/__init__.py
scrapy/core/queues.py
scrapy/core/scheduler.py
scrapy/pqueues.py
tests/test_scheduler.py
==================
70aa5b13;Marc Hernández;2019-03-20 15:32:20 +0100;Fix numeration

==

docs/topics/selectors.rst
==================
4c89e53e;Maram Sumanth;2019-03-20 18:46:25 +0530;Update test_http_request.py

==

tests/test_http_request.py
==================
282f24c5;Maram Sumanth;2019-03-20 18:46:22 +0530;Update form.py

==

scrapy/http/request/form.py
==================
04431892;Anubhav Patel;2019-03-17 16:54:28 +0530;doc for creating custom cache storage backend.

==

docs/topics/downloader-middleware.rst
==================
92bbc529;Eugenio Lacuesta;2019-03-16 05:41:40 +0000;Rule.process_request - Renaming

==

scrapy/spiders/crawl.py
==================
6760bca7;Eugenio Lacuesta;2019-03-15 22:32:45 +0000;Rename Request.kwargs to Request.cb_kwargs

==

docs/topics/request-response.rst
scrapy/core/scraper.py
scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/http/response/text.py
scrapy/utils/reqser.py
tests/spiders.py
tests/test_http_request.py
tests/test_utils_reqser.py
==================
645e8d16;Eugenio Lacuesta;2019-03-15 22:20:36 +0000;Count keyword argument checks

==

tests/spiders.py
tests/test_crawl.py
==================
01ed605d;Eugenio Lacuesta;2019-03-15 16:54:14 +0000;PEP8 changes to test_spider.py

==

tests/test_spider.py
==================
fda1d04b;Victor Torres;2019-03-15 13:26:45 -0300;Merge branch 'master' into feed-storage-s3-acl

==
==================
d346b8cb;Adrián Chaves;2019-03-15 08:58:35 +0100;Merge pull request #3626 from Gallaecio/middlewares-from-crawler
[MRG+1] Document that the main entry point of downloader and spider middlewar…
==
==================
70a0f1f2;Adrián Chaves;2019-03-15 08:25:16 +0100;Merge pull request #3610 from Gallaecio/spidercls-check
[MRG+1] Check that spidercls arguments in scrapy.crawler classes are not spid…
==
==================
1f7413dc;Adrián Chaves;2019-03-15 07:58:28 +0100;Merge pull request #3635 from matthieucham/feature-filteringlinkextractor-restrict-text
[MRG+1] Feature filteringlinkextractor restrict text
==
==================
2bd5790d;Adrián Chaves;2019-03-15 07:53:23 +0100;Merge pull request #3629 from johndela1/master
[MRG+1] rel_has_nofollow: remove redundant if statement
==
==================
a2ff647a;Adrián Chaves;2019-03-15 06:36:15 +0100;Remove docs/topics/ubuntu.rst

==

docs/topics/ubuntu.rst
==================
66a502db;Anubhav Patel;2019-03-15 00:28:54 +0530;Merge branch 'master' into logFormatter-doc-patch

==
==================
09e56ae4;Mikhail Korobov;2019-03-14 22:21:34 +0500;Merge pull request #3648 from Gallaecio/backward
backwards → backward (adj.)
==
==================
5dc94db8;Mikhail Korobov;2019-03-14 22:21:09 +0500;Merge branch 'master' into backward

==
==================
54d10603;Mikhail Korobov;2019-03-14 22:18:57 +0500;Merge pull request #3649 from Gallaecio/inline-code-formatting
[MRG+1] Switch from ` to `` where inline code formatting is desired
==
==================
7c54479a;Mikhail Korobov;2019-03-14 22:18:04 +0500;Merge pull request #3662 from anubhavp28/link-patch
Fix a link inside docs
==
==================
c3b67556;Mikhail Korobov;2019-03-14 22:16:28 +0500;Merge pull request #3668 from Gallaecio/retry-complete-docs
Remove the unexisting retry_complete signal from the documentation
==
==================
f4395538;Mikhail Korobov;2019-03-14 22:10:42 +0500;Merge pull request #3670 from Gallaecio/depth-first-doc
Clarify the documentation of DEPTH_PRIORITY further
==
==================
9c2c3124;Mikhail Korobov;2019-03-14 21:53:44 +0500;Merge pull request #3673 from Gallaecio/friendlier-documentation-1
Use the description from README.rst on index.rst
==
==================
39a17aff;Mikhail Korobov;2019-03-14 21:52:37 +0500;Merge pull request #3676 from Gallaecio/patch-1
Update developer-tools.rst
==
==================
83ec947f;Eugenio Lacuesta;2019-03-13 11:23:51 +0000;Rule.process_request defaults to None in the docs

==

scrapy/spiders/crawl.py
==================
b30ca379;Eugenio Lacuesta;2019-03-13 11:02:51 +0000;Rule.process_request: docs

==

docs/topics/spiders.rst
==================
22fda61d;Eugenio Lacuesta;2019-03-13 10:54:38 +0000;Rule.process_request: tests

==

tests/test_spider.py
==================
43fd6229;Eugenio Lacuesta;2019-03-13 10:21:50 +0000;Rule.process_request: optionally take a Response object

==

scrapy/spiders/crawl.py
==================
35f7595d;Maram Sumanth;2019-03-11 23:58:37 +0530;changed variable names

==

scrapy/http/request/form.py
==================
e9cd4ee0;Anubhav Patel;2019-03-10 20:37:56 +0530;fix list alignment and line width

==

scrapy/logformatter.py
==================
82049e9c;Anubhav Patel;2019-03-10 20:14:55 +0530;make suggested changes.

==

docs/topics/logging.rst
docs/topics/settings.rst
scrapy/logformatter.py
==================
91aec8b3;Adrián Chaves;2019-03-08 18:19:30 +0100;Update developer-tools.rst
Fixes #3674
==

docs/topics/developer-tools.rst
==================
b1063d9b;Adrián Chaves;2019-03-08 17:22:49 +0100;Use the description from README.rst on index.rst

==

docs/index.rst
==================
e108e3ad;Adrián Chaves;2019-03-08 15:13:11 +0100;Clarify the documentation of DEPTH_PRIORITY further

==

docs/topics/settings.rst
==================
4ef38d92;Adrián Chaves;2019-03-08 14:21:00 +0100;Remove the unexisting retry_complete signal from the documentation

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/retry.py
==================
120007c0;Adrián Chaves;2019-03-08 13:53:47 +0100;Add a FAQ entry on how to deal with long lists of allowed domains

==

docs/faq.rst
docs/topics/spider-middleware.rst
==================
924b6743;Anubhav Patel;2019-03-07 16:40:59 +0530;move api docs to source code

==

docs/topics/logging.rst
docs/topics/settings.rst
scrapy/logformatter.py
==================
184def10;Anubhav Patel;2019-03-07 00:09:10 +0530;fix a link inside docs

==

docs/topics/architecture.rst
==================
f7bf3abb;Maram Sumanth;2019-03-06 14:10:03 +0530;Modified code

==

scrapy/http/request/form.py
==================
82d239f3;Anubhav Patel;2019-03-06 12:08:09 +0530;docs for scrapy.logformatter

==

docs/topics/logging.rst
==================
7da460b7;Maram Sumanth;2019-03-04 17:25:15 +0530;Update form.py

==

scrapy/http/request/form.py
==================
8831fafa;Maram Sumanth;2019-03-04 15:42:48 +0530;Update test_http_request.py

==

tests/test_http_request.py
==================
fdf03a6d;Maram Sumanth;2019-03-04 15:12:44 +0530;correcting tests

==

tests/test_http_request.py
==================
d75b61b9;Maram Sumanth;2019-03-04 15:07:12 +0530;Update test_http_request.py

==

tests/test_http_request.py
==================
6eca6f92;Maram Sumanth;2019-03-04 14:59:34 +0530;Update form.py

==

scrapy/http/request/form.py
==================
75d6f56c;Adrián Chaves;2019-03-01 16:56:58 +0100;Switch from ` to `` where inline code formatting is desired

==

docs/contributing.rst
docs/news.rst
docs/topics/api.rst
docs/topics/downloader-middleware.rst
docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/jobs.rst
docs/topics/loaders.rst
docs/topics/logging.rst
docs/topics/media-pipeline.rst
docs/topics/practices.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
docs/topics/ubuntu.rst
scrapy/crawler.py
scrapy/logformatter.py
scrapy/pipelines/files.py
scrapy/utils/ftp.py
scrapy/utils/log.py
scrapy/utils/python.py
scrapy/utils/url.py
sep/sep-006.rst
tests/mocks/dummydbm.py
tests/test_command_shell.py
==================
858f5be7;Adrián Chaves;2019-03-01 16:10:23 +0100;backwards → backward (adj.)

==

docs/news.rst
docs/topics/request-response.rst
docs/topics/spiders.rst
docs/versioning.rst
scrapy/cmdline.py
scrapy/conf.py
scrapy/core/downloader/handlers/http.py
scrapy/extensions/feedexport.py
scrapy/log.py
scrapy/signals.py
scrapy/utils/conf.py
sep/sep-018.rst
tests/test_downloader_handlers.py
tests/test_feedexport.py
tests/test_utils_conf.py
==================
e3b15252;Matthieu Grandrie;2019-02-21 17:19:58 +0100;New constructor arg *restrict_text* for FilteringLinkExtractor.
Same as allow and deny args, it holds a string, a regex or an iterable of. Links whose text don't match one of the regex are filtered out.
DOC restrict_text in LxmlLinkExtractor

==

docs/topics/link-extractors.rst
scrapy/linkextractors/__init__.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/sgml.py
tests/test_linkextractors.py
==================
0bb3d8ca;Júlio César Batista;2019-02-27 18:41:01 -0300;Updating Google Cloud Storage scheme to gs instead of gcs

==

docs/topics/feed-exports.rst
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
c72ab1d4;Daniel Graña;2019-02-20 11:39:21 -0300;Merge pull request #3625 from Ordepsousa/master
[MRG+1] A different S3 Endpoint URL is now possible when uploading images
==
==================
b02d26fa;John de la Garza;2019-02-15 16:54:19 -0800;rel_has_nofollow: remove redundant if statement

==

scrapy/utils/misc.py
==================
9fed6fcb;Victor Torres;2019-02-14 16:59:51 -0200;trigger tests

==
==================
9b8ba4c3;Victor Torres;2019-02-14 16:20:56 -0200;try to import botocore before runing some tests

==

tests/test_feedexport.py
==================
ea8be627;Victor Torres;2019-02-13 19:53:10 -0200;botocore is not supported on debian jessie

==

tests/test_feedexport.py
tox.ini
==================
dc0b6438;Victor Torres;2019-02-13 19:44:50 -0200;refactoring tests to avoid mocking private method

==

tests/test_feedexport.py
==================
b4d132b9;Victor Torres;2019-02-13 19:21:14 -0200;setting botocore version as described in debian jessie website
https://packages.debian.org/en/jessie/python-botocore

==

tox.ini
==================
430e9392;Pedro Sousa;2019-02-13 19:59:40 +0000;Added missing AWS Settings for ImagesPipeline

==

scrapy/pipelines/images.py
==================
50bf4c60;Adrián Chaves;2019-02-13 17:39:20 +0100;Document that the main entry point of downloader and spider middlewares is from_crawler()

==

docs/topics/downloader-middleware.rst
docs/topics/spider-middleware.rst
==================
04ccf79e;Pedro Sousa;2019-02-13 15:39:45 +0000;A different S3 Endpoint URL is now possible when uploading images

==

scrapy/pipelines/images.py
==================
984e706f;Victor Torres;2019-02-12 12:26:57 -0200;using blank string instead of None as default value as proposed by @kmike

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
==================
c2dede27;Victor Torres;2019-02-12 12:22:05 -0200;reduce code with simple ternary operator

==

scrapy/extensions/feedexport.py
==================
7c9f0bd8;Victor Torres;2019-02-12 12:19:30 -0200;using named params with optional amazon s3 params

==

scrapy/extensions/feedexport.py
==================
03e61b99;Adrián Chaves;2019-02-01 13:50:01 +0100;Check that spidercls arguments in scrapy.crawler classes are not spider objects

==

scrapy/crawler.py
tests/test_crawler.py
tests/test_downloadermiddleware_httpproxy.py
==================
1eac2a16;Victor Torres;2019-02-08 16:50:39 -0200;simplifying how we deal with threads.deferToThread calls

==

tests/test_feedexport.py
==================
f824f5b2;Victor Torres;2019-02-08 15:19:57 -0200;testing public method store instead of private method _store_in_thread
need to mock deferToThread function

==

tests/test_feedexport.py
==================
cfd183a9;Victor Torres;2019-02-08 14:49:26 -0200;no need to use get here since we're defining a default value in default_settings.py

==

scrapy/extensions/feedexport.py
==================
ceae356e;Victor Torres;2019-02-08 11:47:35 -0200;add FEED_STORAGE_S3_ACL to default_settings.py file

==

scrapy/settings/default_settings.py
==================
079af889;Victor Torres;2019-02-07 10:42:59 -0200;also testing without botocore

==

tests/test_feedexport.py
==================
dbeb088e;Victor Torres;2019-02-07 09:29:16 -0200;trying to fix jessie testenv by adding botocore to requirements and fixing its version

==

tox.ini
==================
e25b9a23;Victor Torres;2019-02-06 18:52:39 -0200;calling it feeds instead of objects

==

docs/topics/feed-exports.rst
==================
7b83ed7c;Victor Torres;2019-02-06 18:52:24 -0200;remove typo

==

docs/topics/feed-exports.rst
==================
e0f34be3;Victor Torres;2019-02-06 18:50:19 -0200;update docs

==

docs/topics/feed-exports.rst
==================
126207fb;Victor Torres;2019-02-06 18:38:17 -0200;PEP8: use short name for mock method

==

tests/test_feedexport.py
==================
ad83ffdf;Victor Torres;2019-02-06 18:32:46 -0200;refactoring

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
01356809;Victor Torres;2019-01-29 11:10:06 -0300;add FEED_STORAGE_S3_ACL setting

==

scrapy/extensions/feedexport.py
==================
cb5f800b;Júlio César Batista;2019-02-08 11:26:33 -0200;Adding documentation about Google Cloud Storage Feed Export

==

docs/topics/feed-exports.rst
docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
2bbbd02b;Júlio César Batista;2019-02-08 09:45:10 -0200;Adding an option to set ACL while uploading the blob to GCS

==

scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
4a53de16;Júlio César Batista;2019-02-08 09:09:56 -0200;Sorted schemas alphabetically

==

scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
==================
fc6809b0;Júlio César Batista;2019-02-08 09:08:54 -0200;Add gcs schema to FEED_STORAGES_BASE

==

scrapy/settings/default_settings.py
==================
1bb6c415;Júlio César Batista;2019-02-08 09:04:01 -0200;Turning into instance attributes

==

scrapy/extensions/feedexport.py
==================
b364bfb6;Raul Gallegos;2019-02-06 23:11:51 -0500;Merge pull request #3615 from Gallaecio/form-request-example
Indicate that users must implement their own authentication result check
==
==================
38af090f;Adrián Chaves;2019-02-04 11:17:58 +0100;Indicate that users must implement their own authentication result check
The example of form-based login could lead some users to think its authentication result
check was final. See https://stackoverflow.com/a/54410966/939364

This change should make it more obvious that users are expected to implement their
own logic to check whether authentication worked or not.

==

docs/topics/request-response.rst
==================
a4059851;Júlio César Batista;2019-01-31 18:29:15 -0200;Refactoring tests

==

scrapy/utils/test.py
tests/test_feedexport.py
==================
5a55c426;Júlio César Batista;2019-01-31 17:20:29 -0200;Adding GCSFeedStorage

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
65d63132;Daniel Graña;2019-01-31 01:28:53 -0300;Be consistent with domain used for links to documentation website

==

CONTRIBUTING.md
INSTALL
README.rst
docs/contributing.rst
docs/topics/selectors.rst
scrapy/extensions/telnet.py
scrapy/templates/project/module/items.py.tmpl
scrapy/templates/project/module/middlewares.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/templates/project/module/settings.py.tmpl
sep/sep-001.rst
sep/sep-006.rst
tests/__init__.py
==================
88326cd8;Daniel Graña;2019-01-31 01:16:28 -0300;Set release date to 1.6.0

==

docs/news.rst
==================
b8594353;Daniel Graña;2019-01-30 18:00:40 -0300;Bump version: 1.5.0 → 1.6.0

==

.bumpversion.cfg
scrapy/VERSION
==================
13121746;Daniel Graña;2019-01-30 15:03:49 -0300;Merge pull request #3549 from scrapy/release-notes-1.6
1.6 release notes
==
==================
91791cd3;Mikhail Korobov;2019-01-30 17:53:58 +0500;DOC final changelog cleanups

==

docs/news.rst
==================
2c8c8b2d;Mikhail Korobov;2019-01-30 17:30:13 +0500;DOC fix after bad merge - remove duplicate entries in changelog

==

docs/news.rst
==================
0fc9d705;Mikhail Korobov;2019-01-30 03:28:19 +0500;DOC mention that telnet security improvements happened in 1.5.2

==

docs/news.rst
==================
4cf4dd1d;Mikhail Korobov;2019-01-30 03:08:17 +0500;DOC add recent changes to changelog

==

docs/news.rst
==================
638469f9;Mikhail Korobov;2018-12-28 01:13:01 +0500;DOC extract_first/extract matches get/getall better
Thanks @Gallaecio!

==

docs/news.rst
==================
e479f5aa;Mikhail Korobov;2018-12-27 00:48:10 +0500;DOC update changelog
* changes from recently merged pull requests
* more highlights
* re-organized headers
* Selector API changes

==

docs/news.rst
==================
70691079;Mikhail Korobov;2018-12-26 18:28:24 +0500;[wip] draft 1.6 release notes

==

docs/news.rst
==================
e3e804cf;Eugenio Lacuesta;2019-01-28 15:10:34 -0300;Styling nitpick :-)

==

scrapy/core/downloader/middleware.py
==================
b5026b84;Daniel Graña;2019-01-28 10:44:19 -0300;Merge pull request #3544 from joaquingx/fix-item-pipeline-x
Fix item-pipeline example
==
==================
c4f57608;Daniel Graña;2019-01-28 10:22:48 -0300;Merge pull request #3588 from ejulio/dupefilter-debug
[MRG+1] Adding requests referer to RFPDupeFilter log messages
==
==================
8fca9861;Harry Moreno;2019-01-26 16:47:10 -0500;fix grammar

==

docs/topics/media-pipeline.rst
==================
0e5b6755;Daniel Graña;2019-01-28 10:18:45 -0300;Merge pull request #3605 from morenoh149/patch-2
fix grammar
==
==================
b828b5f8;Harry Moreno;2019-01-26 18:39:05 -0500;fix grammar

==

docs/topics/jobs.rst
==================
d9aa5391;kasun Herath;2019-01-25 21:26:28 +0530;enabled sort keys only if not provided

==

scrapy/http/request/json_request.py
==================
71743a65;Daniel Graña;2019-01-19 18:43:58 +0000;Add release notes for v1.5.2

==

docs/news.rst
==================
722a30ac;Maram Sumanth;2019-01-19 13:20:05 +0530;Update test_http_request.py

==

tests/test_http_request.py
==================
7dee841b;Maram Sumanth;2019-01-19 13:20:01 +0530;Update form.py

==

scrapy/http/request/form.py
==================
8eade7d8;Júlio César Batista;2019-01-18 11:39:35 -0200;Testing stats and log messages from RFPDupeFilter

==

tests/test_dupefilters.py
==================
bdf12f77;Júlio César Batista;2019-01-18 11:38:59 -0200;Logging the request referer when DUPEFILTER_DEBUG is active

==

scrapy/dupefilters.py
==================
a9f68acb;Maram Sumanth;2019-01-17 23:51:09 +0530;modified code

==

scrapy/http/request/form.py
==================
6be73f06;Maram Sumanth;2019-01-17 23:50:58 +0530;Updated tests

==

tests/test_http_request.py
==================
6f86c93f;Maram Sumanth;2019-01-16 23:54:35 +0530;Increased test cases

==

tests/test_http_request.py
==================
3e67fa8f;Maram Sumanth;2019-01-16 23:01:38 +0530;Improved for better user readability

==

scrapy/http/request/form.py
==================
9f1f4df9;Maram Sumanth;2019-01-16 22:59:41 +0530;Update test_http_request.py

==

tests/test_http_request.py
==================
bddfeaba;Eugenio Lacuesta;2019-01-15 15:35:46 -0300;Add Request.kwargs docs

==

docs/topics/request-response.rst
==================
f3813e37;kasun Herath;2019-01-14 23:03:21 +0530;Merge remote-tracking branch 'origin/master' into json_request

==
==================
3f914f6d;kasun Herath;2019-01-14 23:03:14 +0530;made jsonrequest dump into private method

==

scrapy/http/request/json_request.py
tests/test_http_request.py
==================
023290da;Maram Sumanth;2019-01-13 23:50:31 +0530;Update test_http_request.py

==

tests/test_http_request.py
==================
4abcdcb3;Maram Sumanth;2019-01-13 23:22:53 +0530;Update test_http_request.py

==

tests/test_http_request.py
==================
9a4bbd6d;Maram Sumanth;2019-01-13 23:05:58 +0530;Update form.py

==

scrapy/http/request/form.py
==================
1bea5d30;Maram Sumanth;2019-01-13 22:35:16 +0530;Fixed error

==

scrapy/http/request/form.py
==================
b5e45480;Maram Sumanth;2019-01-13 20:12:31 +0530;Included test

==

tests/test_http_request.py
==================
ac111088;Maram Sumanth;2019-01-13 20:12:29 +0530;duplicate keys handled

==

scrapy/http/request/form.py
==================
57e7c769;Eugenio Lacuesta;2019-01-09 10:40:44 -0300;Test callback kwargs

==

tests/spiders.py
tests/test_crawl.py
==================
770a501f;Eugenio Lacuesta;2019-01-09 10:40:03 -0300;Test request kwargs (copy, serialization)

==

scrapy/http/request/__init__.py
tests/test_http_request.py
tests/test_utils_reqser.py
==================
a67f1ce5;Eugenio Lacuesta;2019-01-03 17:49:41 -0300;Serialize Request kwargs

==

scrapy/utils/reqser.py
==================
69a1ee79;Eugenio Lacuesta;2019-01-03 17:38:29 -0300;Copy request.kwargs

==

scrapy/http/request/__init__.py
==================
a2b509a4;Eugenio Lacuesta;2019-01-03 17:38:06 -0300;Pass callback kwargs with response.follow

==

scrapy/http/response/__init__.py
scrapy/http/response/text.py
==================
50a0d87d;Eugenio Lacuesta;2019-01-03 17:20:08 -0300;Passing keyword arguments to callbacks

==

scrapy/core/scraper.py
scrapy/http/request/__init__.py
==================
6c78b3d5;Eugenio Lacuesta;2019-01-03 13:15:58 -0300;Deques can't be sliced, use itertools.islice instead

==

scrapy/core/spidermw.py
==================
9759112a;Eugenio Lacuesta;2019-01-03 11:34:07 -0300;Merge branch 'master' into process_spider_exception_generator

==
==================
e1f8b55b;Joaquin Garmendia Cabrera;2018-12-28 16:53:12 -0500;Improve syntax for readability

==

docs/topics/item-pipeline.rst
==================
094dde6f;Mikhail Korobov;2018-12-28 20:11:46 +0500;Merge pull request #3512 from victor-torres/sitemap_filter
[MRG+1] Add sitemap_filter function to SitemapSpider class
==
==================
5a824c90;Victor Torres;2018-12-27 18:34:41 -0300;using shorter import version and moving datetime import to the beginning of the code snippet

==

docs/topics/spiders.rst
==================
bfbcf52e;Victor Torres;2018-12-27 18:12:31 -0300;fix SitemapSpider import

==

docs/topics/spiders.rst
==================
b6830877;Victor Torres;2018-12-27 17:37:59 -0300;improving docs

==

docs/topics/spiders.rst
==================
e1597f7c;Victor Torres;2018-12-26 15:05:21 -0300;improve readability

==

docs/topics/spiders.rst
==================
fe283bcd;Victor Torres;2018-12-26 12:32:22 -0300;add test case for sitemap filter with alternate links

==

tests/test_spider.py
==================
10f46bca;Victor Torres;2018-12-26 11:20:18 -0300;documenting sitemap entries as suggested by @kmike

==

docs/topics/spiders.rst
==================
5e7ecf9d;Victor Torres;2018-12-21 17:31:52 -0300;add tests for sitemapindex

==

tests/test_spider.py
==================
657f0663;Victor Torres;2018-12-20 13:35:52 -0300;rename param from urls to entries

==

docs/topics/spiders.rst
scrapy/spiders/sitemap.py
tests/test_spider.py
==================
d7d5917f;Victor Torres;2018-11-30 11:20:12 -0300;add tests for the sitemap_filter method in the SitemapSpider class

==

tests/test_spider.py
==================
672385a3;Victor Torres;2018-11-29 18:33:20 -0300;using a method definition instead of a None attribute

==

docs/topics/spiders.rst
scrapy/spiders/sitemap.py
==================
a5e1b7bb;Victor Torres;2018-11-29 18:19:14 -0300;add sitemap_filter attribute to SitemapSpider class
it makes it possible to filter sitemap urls by any available attribute

for example, you can filter urls with lastmod greater than a given datetime

it can be helpful when the url loc itself does not aggregate that information

==

docs/topics/spiders.rst
scrapy/spiders/sitemap.py
==================
93cf3835;Daniel Graña;2018-12-26 11:16:19 -0300;Merge pull request #3394 from hcoura/dh-lazyloading-optional
Make lazy loading Download Handlers optional
==
==================
f6ce7163;Daniel Graña;2018-12-26 11:13:52 -0300;Merge pull request #3476 from elacuesta/deque_appendleft
[MRG+1] Use collections.deque instead of list to store MiddlewareManager's methods
==
==================
76433feb;Daniel Graña;2018-12-26 11:10:57 -0300;Merge pull request #3548 from scrapy/fix-aws-settings-docs
fix docs for AWS_... settings. A follow-up to GH-2609.
==
==================
5cf26c99;Daniel Graña;2018-12-26 11:09:07 -0300;Merge pull request #3547 from scrapy/setup.py-3.7
declare Python 3.7 support in setup.py
==
==================
d473be20;Daniel Graña;2018-12-26 11:08:49 -0300;Merge pull request #3519 from fpghost/master
[MRG+1] the strip() isnt needed after base64 encoding user pass
==
==================
5d02aab9;Daniel Graña;2018-12-26 11:04:30 -0300;Merge pull request #3496 from frederik-elwert/patch-1
[MRG+1] Add documentation to `scrapy shell` command.
==
==================
6a0ea0cf;Daniel Graña;2018-12-26 10:58:44 -0300;Merge pull request #3415 from scrapy/telnet-auth
[MRG+1] Telnet console authentication
==
==================
71e47629;Mikhail Korobov;2018-12-26 16:35:05 +0500;DOC fix docs for AWS_... settings. A follow-up to GH-2609.

==

docs/topics/settings.rst
==================
4306886a;Mikhail Korobov;2018-12-26 14:45:06 +0500;Merge pull request #3527 from hsiaoyi0504/patch-1
unify the quote style
==
==================
cdd04dfb;Mikhail Korobov;2018-12-26 13:13:49 +0500;declare Python 3.7 support in setup.py

==

setup.py
==================
7c267010;Mikhail Korobov;2018-12-26 01:33:58 +0500;DOC warn about telnet console being insecure

==

docs/topics/telnetconsole.rst
==================
dbfabf02;Mikhail Korobov;2018-12-26 01:04:34 +0500;Merge branch 'master' into telnet-auth

==
==================
f85c9158;Joaquin Garmendia Cabrera;2018-12-23 00:26:58 -0500;Update item-pipeline example

==

docs/topics/item-pipeline.rst
==================
23bffff5;Daniel Graña;2018-12-20 19:54:34 -0300;Merge pull request #3526 from lucywang000/update-travis
remove "sudo: false" now that travis no longer supports it
==
==================
d4fd1236;Daniel Graña;2018-12-20 19:49:55 -0300;Merge pull request #3538 from scrapy/boto-import-error-under-jessie
Fix boto import error under Jessie testing environment
==
==================
8ed6beb7;Daniel Graña;2018-12-20 19:39:29 -0300;Needs to be installed within tox env

==

.travis.yml
tox.ini
==================
f6dfc5f3;Daniel Graña;2018-12-20 19:23:23 -0300;Fix boto import error under Jessie testing environment

==

.travis.yml
==================
24acc50d;kasun Herath;2018-12-18 23:16:14 +0530;dumps_kwargs parameter in docs

==

docs/topics/request-response.rst
==================
12ad06b7;kasun Herath;2018-12-17 23:17:13 +0530;docs change

==

docs/topics/request-response.rst
==================
8f1507a4;kasun Herath;2018-12-17 23:14:06 +0530;dumps_kwargs

==

docs/topics/request-response.rst
scrapy/http/request/json_request.py
tests/test_http_request.py
==================
665c04b0;Daniel Graña;2018-12-12 11:56:47 -0300;Merge pull request #3518 from Gallaecio/scrapy-project-doc
Document the SCRAPY_PROJECT environment variable
==
==================
71ef321b;kasun Herath;2018-12-12 11:12:48 +0530;sort_keys while serializing to json

==

scrapy/http/request/json_request.py
==================
cd9d8e28;hsiao yi;2018-12-11 19:21:07 +0800;unify the quote style

==

docs/intro/overview.rst
==================
ecda6913;kasun Herath;2018-12-10 22:34:49 +0530;allow to send empty data values and docs changes

==

docs/topics/request-response.rst
scrapy/http/request/json_request.py
tests/test_http_request.py
==================
4d487599;Lucy Wang;2018-12-10 14:44:15 +0800;remove "sudo: false" now that travis no longer supports it
https://changelog.travis-ci.com/deprecation-container-based-linux-build-environment-82037

==

.travis.yml
==================
3c981bf2;kasun Herath;2018-12-09 12:56:12 +0530;add documentation

==

docs/topics/request-response.rst
==================
c347acbf;kasun Herath;2018-12-09 11:27:09 +0530;warning if body and data are provided

==

scrapy/http/request/json_request.py
tests/test_http_request.py
==================
cd619c1d;kasun Herath;2018-12-08 22:10:45 +0530;removed overriden replace method

==

scrapy/http/request/json_request.py
tests/test_http_request.py
==================
e766bde3;Mikhail Korobov;2018-12-06 18:07:43 +0500;Merge pull request #3517 from Gallaecio/install-troubleshooting
[MRG+1] Add a troubleshooting section to the installation instructions
==
==================
d7c8eee2;fpghost;2018-12-04 10:57:51 +0100;the strip() isnt needed

==

scrapy/downloadermiddlewares/httpproxy.py
==================
62f3349c;Adrián Chaves;2018-12-03 17:14:10 +0100;Document the SCRAPY_PROJECT environment variable
Fixes #1109

==

docs/topics/commands.rst
==================
274b65df;Adrián Chaves;2018-12-03 16:36:05 +0100;Add a troubleshooting section to the installation instructions
Its initial content covers the workaround for #2473.

==

docs/intro/install.rst
==================
1b2b8b4b;kasun Herath;2018-11-27 08:57:44 +0530;fix tests under py3

==

tests/test_http_request.py
==================
1ce6662a;kasun Herath;2018-11-24 20:02:00 +0530;Implement Request subclass for json requests

==

scrapy/http/__init__.py
scrapy/http/request/json_request.py
tests/test_http_request.py
==================
a25cf5c8;Vostretsov Nikita;2018-11-20 16:13:09 +0000;function to get unique file queues for any type of base queue

==

scrapy/core/queues.py
==================
886513c3;Konstantin Lopuhin;2018-11-20 11:10:32 +0300;Merge pull request #3495 from toddrme2178/patch-1
[MRG+1] Include additional files in sdists
==
==================
127bf499;Frederik Elwert;2018-11-16 22:15:03 +0100;Add documentation to `scrapy shell` command.
The special syntax required for local files (`./file.html`) is not documented as part of the `scrapy shell --help` output. This patch adds that.
==

scrapy/commands/shell.py
==================
491929c2;Todd;2018-11-16 13:38:19 -0500;Include additional files in sdists
In particular this includes files needed for running the tests, as well as the changelog.
==

MANIFEST.in
==================
dc65e752;Mikhail Korobov;2018-11-06 03:33:09 +0500;Merge pull request #3468 from ilhaoni/feature/update-docs-intro-tutorial
[MRG+1] Update Scrapy Tutorial docs 
==
==================
6c98010f;Immanuella Lim;2018-11-04 16:04:45 +0800;Remove 'Dive into Python3' reference

==

docs/intro/tutorial.rst
==================
f97e3e90;Eugenio Lacuesta;2018-10-29 12:40:20 -0300;Use collections.deque instead of list to store methods

==

scrapy/core/downloader/middleware.py
scrapy/core/spidermw.py
scrapy/middleware.py
tests/test_middleware.py
==================
c9b5bd6a;Immanuella Lim;2018-10-18 02:22:32 +0800;Remove ad link Dive Into Python3 from tutorial docs

==

docs/intro/tutorial.rst
==================
44f8e28b;Daniel Graña;2018-10-16 19:53:20 -0300;Fix headings' underlines

==

docs/topics/telnetconsole.rst
==================
06f2db7f;Daniel Graña;2018-10-16 19:51:32 -0300;Merge pull request #3445 from jfflisikowski/3097-item-urls-not-defined-in-example
[MRG+1] Updating debug example file (#3097)  
==
==================
553b3a1c;Daniel Graña;2018-10-16 15:08:34 -0300;Merge pull request #3465 from hcoura/telnet-auth
Add Telnet console authentication docs
==
==================
92b7955d;Henrique Coura;2018-10-16 14:50:00 -0300;Add Telnet console authentication docs

==

docs/topics/telnetconsole.rst
==================
c602e697;Eugenio Lacuesta;2018-10-11 13:33:41 -0300;Force Travis build

==
==================
e0360e52;Eugenio Lacuesta;2018-10-11 11:55:13 -0300;Add tests for MutableChain

==

tests/test_utils_python.py
==================
15f0a890;Eugenio Lacuesta;2018-10-11 11:34:59 -0300;Assign processing methods to a variable before iterating

==

scrapy/core/spidermw.py
==================
a05eaeed;Eugenio Lacuesta;2018-10-11 11:31:51 -0300;Simplify MutableChain

==

scrapy/utils/python.py
==================
58f55653;Eugenio Lacuesta;2018-10-11 11:23:12 -0300;Move MutableChain to scrapy.utils.python

==

scrapy/core/spidermw.py
scrapy/utils/python.py
==================
2396356a;Eugenio Lacuesta;2018-10-10 11:37:43 -0300;Merge branch 'master' into process_spider_exception_generator

==
==================
edaf74bf;jfflisikowski;2018-10-02 19:48:48 +0200;Correct the unclear comments by adding <# < processing code not shown >

==

docs/topics/debug.rst
==================
d80f9ed7;Daniel Graña;2018-09-26 14:00:46 -0300;Merge pull request #3429 from hcoura/telnet-auth
Randomly generate telnet credentials by default
==
==================
441e1e75;Henrique Coura;2018-09-26 13:28:34 -0300;Style changes

==

scrapy/extensions/telnet.py
tests/test_extension_telnet.py
==================
5f9931d2;Henrique Coura;2018-09-26 13:07:04 -0300;do not log username

==

scrapy/extensions/telnet.py
==================
e57a629e;Henrique Coura;2018-09-26 11:54:57 -0300;Generate only password, encode username/password only on login

==

scrapy/extensions/telnet.py
scrapy/settings/default_settings.py
tests/test_extension_telnet.py
==================
37cfb498;Henrique Coura;2018-09-24 16:42:49 -0300;Randomly generate telnet credentials by default

==

scrapy/extensions/telnet.py
scrapy/settings/default_settings.py
tests/test_extension_telnet.py
==================
bafd174a;Daniel Graña;2018-09-18 13:07:41 -0300;Merge pull request #3390 from scrapy/parsel-1.5
[MRG+1] update Scrapy to use parsel 1.5
==
==================
ffbd33ed;Mikhail Korobov;2018-09-18 05:03:35 +0500;DOC mention gotcha with `foo::text` selector and empty `foo` elements
also, move "Selecting attributes" reference closer to `a::atr(href)` example

==

docs/topics/selectors.rst
==================
2c3b2158;Mikhail Korobov;2018-09-18 05:02:17 +0500;DOC address @stummjr's review comments
* fixed several small issues
* re-written "Creating Selectors" section
* fixed remaining .extract usage in tests

==

docs/intro/tutorial.rst
docs/topics/selectors.rst
tests/test_utils_iterators.py
==================
9db21e55;Mikhail Korobov;2018-09-15 02:43:37 +0500;DOC fix remove_namespaces example
See https://github.com/scrapy/parsel/pull/119

==

docs/topics/selectors.rst
==================
dc95ecbe;Mikhail Korobov;2018-09-12 18:36:25 +0500;DOC use autodocs for selectors; document more methods and attributes; suggest get/getall

==

docs/topics/selectors.rst
scrapy/selector/unified.py
==================
7fdfdb7f;Mikhail Korobov;2018-08-22 17:34:44 +0500;DOC reorganize selectors tutorial, port more topics from parsel docs, adjust wording in the introduction

==

docs/topics/selectors.rst
==================
bdcc045f;Mikhail Korobov;2018-08-22 04:27:21 +0500;DOC switch from .extract to get/getall API in docs
Also, response.urljoin is added in a few places, for robustness.

==

docs/intro/tutorial.rst
docs/topics/shell.rst
docs/topics/spiders.rst
==================
afce9716;Mikhail Korobov;2018-08-22 04:25:43 +0500;DOC mention .attrib in the tutorial

==

docs/intro/tutorial.rst
==================
12e42bbe;Mikhail Korobov;2018-08-22 04:20:55 +0500;switch SgmlLinkExtractor to .getall

==

scrapy/linkextractors/sgml.py
==================
460f0f04;Mikhail Korobov;2018-08-22 04:20:32 +0500;[backwards incompatible] switch ItemLoader from .extract to .getall.
This change is backwards incompatible if ItemLoader is used with a custom Selector
subclass which overrides .extract without overriding .getall.

==

scrapy/loader/__init__.py
==================
8c29be60;Mikhail Korobov;2018-08-22 04:18:29 +0500;update spider templates to use .get

==

scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
==================
53da56c8;Mikhail Korobov;2018-08-22 04:17:55 +0500;TST update tests to use get/getall/attrib instead of extract

==

tests/test_command_shell.py
tests/test_http_response.py
tests/test_loader.py
tests/test_pipeline_crawl.py
tests/test_selector.py
tests/test_spider.py
tests/test_utils_iterators.py
==================
2c48d156;Mikhail Korobov;2018-08-22 04:01:17 +0500;DOC cleanup references in tutorials:
* remove unused link
* fix ReST syntax
* fix a link to regular expression docs

==

docs/intro/tutorial.rst
docs/topics/selectors.rst
==================
09fd6c2a;Mikhail Korobov;2018-08-22 03:59:58 +0500;DOC unlink Firefox & Firebug sections from the tutorial for now.
See https://github.com/scrapy/scrapy/issues/3373 and https://github.com/scrapy/scrapy/issues/3372 for motivation.

==

docs/intro/tutorial.rst
==================
d32c4dea;Mikhail Korobov;2018-08-15 16:23:31 +0500;DOC update Scrapy selectors tutorial to match parsel's tutorial better

==

docs/topics/selectors.rst
==================
ca27010d;Mikhail Korobov;2018-08-15 16:22:56 +0500;DOC .extract_first() -> .get()

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/shell.rst
docs/topics/spiders.rst
==================
395d9d03;Mikhail Korobov;2018-08-15 16:16:57 +0500;add pytest temp files to gitignore

==

.gitignore
==================
0ccead66;Mikhail Korobov;2018-08-15 16:16:36 +0500;DOC more Python 3 in examples

==

docs/topics/commands.rst
docs/topics/items.rst
docs/topics/jobs.rst
docs/topics/loaders.rst
docs/topics/selectors.rst
docs/topics/settings.rst
==================
25ac4691;Mikhail Korobov;2018-08-09 03:32:46 +0500;require parsel 1.5+

==

requirements-py2.txt
requirements-py3.txt
setup.py
==================
72239785;Daniel Graña;2018-09-06 11:41:02 -0300;Merge pull request #3381 from StasDeep/fix/issue-3380
[MRG+1] Use dont_filter=True for contracts requests
==
==================
2aae514f;Daniel Graña;2018-09-05 12:25:07 -0300;Merge branch 'master' into fix/issue-3380

==
==================
51767655;Daniel Graña;2018-09-05 12:24:50 -0300;Merge pull request #3377 from StasDeep/feature/issue-3364
Add handling of errors in contract methods
==
==================
d7b98a37;Daniel Graña;2018-09-05 11:26:59 -0300;Merge branch 'master' into feature/issue-3364

==
==================
ae8a0dc7;Daniel Graña;2018-09-05 11:21:26 -0300;Merge pull request #3383 from StasDeep/feature/issue-3382
[MRG+1] Add ability to use FormRequest in contracts
==
==================
4da0b59c;Daniel Graña;2018-09-05 11:17:13 -0300;Merge pull request #3393 from whalebot-helmsman/singal-request-added-to-downloader-slot
[MRG+1] New signal for reqeuests reached downloader
==
==================
eb64214c;Daniel Graña;2018-09-05 10:54:40 -0300;Move telnetconsole settings defaults to scrapy defaults

==

scrapy/extensions/telnet.py
scrapy/settings/default_settings.py
==================
e65f7e0c;Daniel Graña;2018-09-05 10:49:46 -0300;Working POC for authenticating telnet console

==

scrapy/extensions/telnet.py
==================
8dbbbd13;Stas Glubokiy;2018-09-03 20:07:37 +0300;Use request_cls attribute in contract definition

==

docs/topics/contracts.rst
scrapy/contracts/__init__.py
tests/test_contracts.py
==================
c02cfa57;Vostretsov Nikita;2018-08-29 11:21:55 +0000;remove comma

==

docs/topics/signals.rst
==================
0007cd03;Daniel Graña;2018-08-28 14:51:39 -0300;Merge pull request #3405 from stav/offsite-pep8
[MRG+1] PEP8 ofsite middleware
==
==================
6e9fa3a4;Steven Almeroth;2018-08-24 15:18:16 -0400;PEP8 ofsite middleware

==

scrapy/spidermiddlewares/offsite.py
==================
e45ef7dc;Mikhail Korobov;2018-08-23 19:44:14 +0500;Merge pull request #3400 from testingcan/docs-developer-tools
[MRG+1] Added general guide for developer tools

Fixes #3373 and #3372.
==
==================
79de3d56;Raphael Wuillemier;2018-08-23 16:19:13 +0200;Removed obsolete firebug-images

==

docs/topics/_images/firebug1.png
docs/topics/_images/firebug2.png
docs/topics/_images/firebug3.png
==================
e98e7f85;testingcan;2018-08-23 14:50:49 +0200;Added missing curly brace

==

docs/topics/developer-tools.rst
==================
4d3aaabb;Raphael Wuillemier;2018-08-23 12:40:31 +0200;Updated code, added code snippets and improved readability

==

docs/topics/developer-tools.rst
==================
3a71e7db;testingcan;2018-08-22 16:57:51 +0200;Increased length of "="

==

docs/topics/developer-tools.rst
==================
af555cab;Raphael Wuillemier;2018-08-22 14:15:53 +0200;Added general guide for developer tools instead of Firefox and Firebug-sections

==

docs/index.rst
docs/intro/tutorial.rst
docs/topics/_images/inspector_01.png
docs/topics/_images/network_01.png
docs/topics/_images/network_02.png
docs/topics/_images/network_03.png
docs/topics/developer-tools.rst
docs/topics/firebug.rst
docs/topics/firefox.rst
==================
167211ff;Henrique Coura;2018-08-20 15:54:04 -0300;Default is lazy, load_object exception handling, code improvements

==

scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/datauri.py
scrapy/core/downloader/handlers/file.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http10.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
9ab85fe7;Stas Glubokiy;2018-08-19 17:21:28 +0300;Merge branch 'master' of github.com:StasDeep/scrapy into feature/issue-3382

==
==================
57824600;Stas Glubokiy;2018-08-19 16:56:41 +0300;Use six.get_unbound_function in test_same_url

==

tests/test_contracts.py
==================
0467737c;Stas Glubokiy;2018-08-18 15:42:21 +0300;Fix mockserver usage

==

tests/test_contracts.py
==================
1311f6b5;Stas Glubokiy;2018-08-18 15:42:10 +0300;Merge branch 'master' of github.com:StasDeep/scrapy into fix/issue-3380

==
==================
e2de0a72;Stas Glubokiy;2018-08-18 15:24:30 +0300;Use except Exception

==

scrapy/contracts/__init__.py
==================
11576f5c;Stas Glubokiy;2018-08-18 15:24:07 +0300;Merge branch 'master' of github.com:StasDeep/scrapy into feature/issue-3364

==
==================
5bac4367;Henrique Coura;2018-08-17 15:07:37 -0300;Make lazy loading Download Handlers optional

==

scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
561ad3b6;Vostretsov Nikita;2018-08-17 14:40:24 +0000;emit new signal

==

scrapy/core/downloader/__init__.py
==================
afb1458b;Vostretsov Nikita;2018-08-17 14:39:54 +0000;tests for new signal

==

tests/test_engine.py
==================
597b8a97;Vostretsov Nikita;2018-08-17 14:39:42 +0000;documentation for new signal

==

docs/topics/signals.rst
==================
d95762db;Vostretsov Nikita;2018-08-17 14:39:24 +0000;new signal

==

scrapy/signals.py
==================
2b212d42;Vostretsov Nikita;2018-08-17 14:39:06 +0000;ignore cache for pytests

==

.gitignore
==================
c7654f7c;Mikhail Korobov;2018-08-17 19:25:41 +0500;Merge pull request #3379 from StasDeep/fix/issue-3378
Use inspect.getmembers in tested_methods_from_spidercls
==
==================
ddd69f4c;Stas Glubokiy;2018-08-15 20:39:43 +0300;Use MockServer in test_same_url

==

tests/test_contracts.py
==================
2cb4decb;Stas Glubokiy;2018-08-15 20:36:10 +0300;Move TestSameUrlSpider to test method

==

tests/test_contracts.py
==================
4de493ef;Stas Glubokiy;2018-08-15 20:24:00 +0300;Add test_same_url

==

tests/test_contracts.py
==================
91f986ec;Mikhail Korobov;2018-08-15 21:18:37 +0500;Merge pull request #3315 from scrapy/test-on-windows
Enable AppVeyor CI for running test suite on Windows env
==
==================
38608bc2;Daniel Graña;2018-08-15 11:59:09 -0300;Use ignore_errors option from rmtree

==

tests/test_feedexport.py
==================
4eaf8690;Daniel Graña;2018-08-15 08:54:18 -0300;Twisted's unittest.Testcase assertRaiess can't be used as context manager

==

tests/test_crawler.py
==================
a304d6b6;Daniel Grana;2018-08-15 02:02:20 -0700;Workaround to pass tests/test_feedexporter.py under windows

==

tests/test_feedexport.py
==================
e7fe243c;Daniel Grana;2018-08-15 01:09:23 -0700;Fix test_crawler under windows

==

tests/test_crawler.py
==================
96517cb7;Daniel Grana;2018-08-15 01:08:40 -0700;Fix test_command_parse under windows

==

tests/test_command_parse.py
==================
d93d9603;Daniel Graña;2018-08-15 01:53:20 -0300;Fix test_utils_project under Windows

==

tests/test_utils_project.py
==================
cb281757;Jakob de Maeyer;2016-02-03 18:35:35 +0000;Fix csviter tests by explicitly using newline only

==

tests/test_utils_iterators.py
==================
ca53a869;Daniel Graña;2018-07-07 11:07:05 -0300;Fix presentation of template directory in startproject command

==

scrapy/commands/startproject.py
tests/test_commands.py
==================
0e532e3d;Daniel Graña;2018-07-07 10:46:15 -0300;Creating a connection to 0.0.0.0 fails on windows but not on linux nor mac

==

tests/mockserver.py
==================
ed068e59;Daniel Graña;2018-07-07 10:28:07 -0300;Cache pip cache and do not rebuild tags on appveyor and travis

==

appveyor.yml
==================
a21abac7;Daniel Graña;2018-07-07 10:15:20 -0300;fix ftp tests on windows

==

tests/test_downloader_handlers.py
==================
fb09148c;Daniel Graña;2018-07-06 18:10:56 -0300;Fix bad merge on ParseCommandTest

==

tests/test_commands.py
==================
22505a34;Jakob de Maeyer;2016-02-03 18:42:51 +0000;Fix cmdline profiling test on Windows by using proper path composing

==

tests/test_cmdline/__init__.py
==================
03415296;Jakob de Maeyer;2016-02-03 18:12:08 +0000;Fix Feedexport test in Windows by using proper file URI

==

tests/test_feedexport.py
==================
ed8255bd;Daniel Graña;2018-07-06 17:53:56 -0300;Fix merge issues with stderr/out fixes for windows buffering

==

tests/test_commands.py
==================
57a1d66c;Jakob de Maeyer;2016-02-03 16:56:43 +0000;Fix test issues caused by Windows pipe buffer filling up

==

tests/test_commands.py
==================
152fde70;Jakob de Maeyer;2016-02-02 18:23:23 +0000;Fix FTPTestCase by using Windows-friendly temporary file name

==

tests/test_downloader_handlers.py
==================
19ad9410;Daniel Graña;2018-07-03 17:15:48 -0300;pywin32 is required to run tests under windows

==

tests/requirements-py3.txt
==================
dd75297e;Daniel Graña;2018-07-03 16:58:02 -0300;Run Appveyor CI for master and release branches only, but also PRs

==

appveyor.yml
==================
4c53957f;Daniel Graña;2018-07-03 16:56:05 -0300;Skip leveldb tests on windows

==

tests/requirements-py3.txt
==================
1d25c98e;Daniel Graña;2018-07-03 16:41:53 -0300;Add appveyor.yml

==

appveyor.yml
==================
b4b1e483;Stas Glubokiy;2018-08-11 22:18:43 +0300;Add ability to use FormRequest in contracts

==

docs/topics/contracts.rst
scrapy/contracts/__init__.py
tests/test_contracts.py
==================
8fc017d3;Stas Glubokiy;2018-08-11 19:25:33 +0300;Add dont_filter to ContractsManager requests

==

scrapy/contracts/__init__.py
==================
76220e87;Stas Glubokiy;2018-08-11 18:49:12 +0300;Use inspect.getmembers in tested_methods_from_spidercls

==

scrapy/contracts/__init__.py
tests/test_contracts.py
==================
8bc536d8;Stas Glubokiy;2018-08-11 18:34:37 +0300;Merge branch 'master' of github.com:StasDeep/scrapy into feature/issue-3364

==
==================
ebbde57e;Stas Glubokiy;2018-08-11 17:50:56 +0300;Add custom contracts tests

==

tests/test_contracts.py
==================
fb7d4cbc;Stas Glubokiy;2018-08-11 16:08:26 +0300;Add error handling in contracts

==

scrapy/contracts/__init__.py
==================
8a4e51a1;Konstantin Lopuhin;2018-08-10 17:27:45 +0300;Merge pull request #3371 from StasDeep/fix/issue-3370
[MRG+1] Fix contract errback (#3370)
==
==================
16dad817;Stas Glubokiy;2018-08-09 21:07:25 +0300;Fix contract errback

==

scrapy/contracts/__init__.py
tests/test_contracts.py
==================
c8f3d07e;Konstantin Lopuhin;2018-08-07 10:05:44 +0300;Merge pull request #3367 from testingcan/doc-tutorial-update
[MRG+1] Updated tutorial.rst to include more and up-to-date beginner resources
==
==================
d3aa1e86;Raphael Wuillemier;2018-08-06 17:40:31 +0200;Updated tutorial.rst to include more and up-to-date beginner resources

==

docs/intro/tutorial.rst
==================
dc37ec99;Eugenio Lacuesta;2018-08-03 23:18:54 -0300;Force Travis build

==
==================
40449fa0;Eugenio Lacuesta;2018-08-03 18:20:25 -0300;Update docs, add tests, remove FIXME comment

==

docs/topics/spider-middleware.rst
scrapy/core/scraper.py
tests/test_spidermiddleware.py
tests/test_spidermiddleware_output_chain.py
==================
8c55f5eb;Eugenio Lacuesta;2018-08-03 15:16:26 -0300;Simplify check for re-raised exception. Add tests.

==

scrapy/core/spidermw.py
tests/test_spidermiddleware.py
==================
eb007baf;Konstantin Lopuhin;2018-08-02 22:22:40 +0300;Merge pull request #3359 from scrapy/unused-imports
remove unused imports from scrapy/settings/__init__.py
==
==================
d90bdd5d;Konstantin Lopuhin;2018-08-02 22:21:23 +0300;Merge pull request #3358 from BurnzZ/fix-error-msg-feedexport-when-using-s3
[MRG+1] provide better error message when disabling s3 exporter
==
==================
db714f5a;Daniel Graña;2018-08-02 14:49:14 -0300;Merge pull request #3283 from CCInCharge/issue3247
Fix #3247: Allow scrapy.FormRequest.from_response method to handle duplicate keys
==
==================
c87a4f5c;Mikhail Korobov;2018-08-01 01:45:16 +0500;remove unused imports from scrapy/settings/__init__.py
This is a follow-up to https://github.com/scrapy/scrapy/pull/3327

==

scrapy/settings/__init__.py
==================
980be4cb;Kevin Lloyd Bernal;2018-07-31 19:05:04 +0800;provide better error message when disabling s3 exporter

==

scrapy/extensions/feedexport.py
==================
801d3c07;Eugenio Lacuesta;2018-07-27 15:06:25 -0300;Fix bad exception handling, add tests

==

scrapy/core/spidermw.py
tests/test_spidermiddleware_invalid_values.py
==================
d6d3e87e;Eugenio Lacuesta;2018-07-27 14:47:52 -0300;Rename test file

==

tests/test_spidermiddleware_output_chain.py
==================
93afe185;Daniel Graña;2018-07-26 17:02:31 -0300;Merge pull request #2956 from elacuesta/dupefilter_from_crawler
Add from_crawler support to dupefilters
==
==================
999341b6;Eugenio Lacuesta;2018-07-20 22:17:55 -0300;Simplify dupefilter creation

==

scrapy/core/scheduler.py
==================
9e14f8c7;Eugenio Lacuesta;2018-03-23 21:19:57 -0300;Fix test for dupefilter

==

tests/test_dupefilters.py
==================
0089a4ab;Eugenio Lacuesta;2018-03-23 13:19:31 -0300;Add test for direct creation of dupefilter (no from_crawler/from_settings)

==

tests/test_dupefilters.py
==================
d306fe30;Eugenio Lacuesta;2017-12-30 22:49:22 -0300;Test dupefilter creation by the Scheduler

==

tests/test_dupefilters.py
==================
701cd2ff;Eugenio Lacuesta;2017-10-09 09:42:34 -0300;Add from_crawler support to dupefilters

==

scrapy/core/scheduler.py
tests/test_dupefilters.py
==================
782f8665;CCInCharge;2018-06-07 16:39:48 -0700;Fix #3247: Allow scrapy.FormRequest.from_response method to handle duplicate keys

==

scrapy/http/request/form.py
tests/test_http_request.py
==================
895df937;Mikhail Korobov;2018-07-25 23:50:06 +0300;Merge pull request #3350 from granadoho/master
make amendments to grammer
==
==================
733ac632;Mikhail Korobov;2018-07-25 23:49:08 +0300;Merge pull request #3347 from korigod/doc_copyright-notice
Doc: update copyright notice
==
==================
b6abd459;Daniel Graña;2018-07-25 11:58:25 -0300;Merge pull request #3342 from elacuesta/copy-request-flags
[MRG+1] Include flags when copying requests
==
==================
732d7e1c;Daniel Graña;2018-07-25 11:55:16 -0300;Merge pull request #3348 from elacuesta/enhancement/alternate-feedexport-constructors
[MRG+1] Add from_crawler constructor for feed exporters and storages
==
==================
48866457;Malcolm Granado Ho Yong Liang;2018-07-25 14:38:37 +0800;make amendments to grammer

==

docs/contributing.rst
==================
784eed11;Eugenio Lacuesta;2018-07-20 19:08:46 -0300;Improve test coverage (downloader middleware)

==

scrapy/core/downloader/middleware.py
tests/test_downloadermiddleware.py
==================
917c1fde;Eugenio Lacuesta;2018-07-20 12:09:50 -0300;Merge branch 'master' into enhancement/alternate-feedexport-constructors

==
==================
98d74d10;Eugenio Lacuesta;2018-07-20 12:08:49 -0300;Requested changes

==

scrapy/extensions/feedexport.py
scrapy/utils/misc.py
tests/test_feedexport.py
==================
7020c3e4;Andrei Korigodski;2018-07-20 14:46:57 +0300;Doc: update copyright notice
The years are updated. The hyphen is replaced with an en dash.
==

docs/conf.py
==================
6a38fc39;Eugenio Lacuesta;2018-07-19 11:56:23 -0300;Include flags when copying requests

==

scrapy/http/request/__init__.py
tests/test_http_request.py
==================
20defa2e;Eugenio Lacuesta;2018-07-19 10:31:06 -0300;Better handling of method indexes

==

scrapy/core/spidermw.py
==================
71a1406c;Eugenio Lacuesta;2018-07-18 17:40:30 -0300;Logging changes

==

tests/test_spidermiddleware.py
==================
6329441c;Eugenio Lacuesta;2018-07-18 16:59:24 -0300;ModuleNotFoundError was added in py3.6

==

tests/test_spidermiddleware.py
==================
c493721b;Eugenio Lacuesta;2018-07-18 15:18:42 -0300;Merge branch 'master' into process_spider_exception_generator

==
==================
fa784b1b;Eugenio Lacuesta;2018-07-18 15:17:43 -0300;Merge branch 'process_spider_exception_generator_experiment' into process_spider_exception_generator

==
==================
a3af0bfd;Eugenio Lacuesta;2018-07-18 15:15:55 -0300;More tests

==

scrapy/core/spidermw.py
tests/test_spidermiddleware.py
==================
258121db;Mikhail Korobov;2018-07-18 19:33:50 +0500;Merge pull request #3335 from scrapy/docs-retry-codes
update default RETRY_HTTP_CODES on docs
==
==================
610f5896;Eugenio Lacuesta;2018-07-17 19:13:03 -0300;Add callback and errback in the same step

==

scrapy/core/spidermw.py
==================
56e92d90;Eugenio Lacuesta;2018-07-17 15:15:38 -0300;Update tests

==

tests/test_spidermiddleware.py
==================
e96b7782;Eugenio Lacuesta;2018-07-15 18:17:37 -0300;Merge branch 'master' into process_spider_exception_generator_experiment

==
==================
b8e8922d;Eugenio Lacuesta;2018-07-15 17:50:55 -0300;Simplify stuff. Add more tests.

==

scrapy/core/spidermw.py
tests/test_spidermiddleware.py
==================
60c2ef86;Eugenio Lacuesta;2018-07-15 16:47:55 -0300;Revert "Default values for OffsiteMiddleware"
This reverts commit ba294351381c0dd81476603246d2cea6c31486be.

==

scrapy/spidermiddlewares/offsite.py
==================
cff9e876;Eugenio Lacuesta;2018-07-15 16:21:08 -0300;Fix tests

==

tests/test_spidermiddleware.py
==================
c5fa0ae6;Eugenio Lacuesta;2018-07-14 19:58:42 -0300;Untested experiment

==

scrapy/core/spidermw.py
==================
0c579b52;Eugenio Lacuesta;2018-07-14 19:58:42 -0300;Untested experiment

==

scrapy/core/spidermw.py
==================
e7e18db1;Eugenio Lacuesta;2018-07-11 14:04:35 -0300;Fix tests

==

tests/test_spidermiddleware.py
==================
c61e8a61;Valdir Stumm Junior;2018-07-13 11:55:16 -0700;[doc] update default RETRY_HTTP_CODES

==

docs/topics/downloader-middleware.rst
==================
c8621331;Mikhail Korobov;2018-07-12 02:10:24 +0500;1.5.1 release notes

==

docs/news.rst
==================
01e317e7;Daniel Graña;2018-07-11 12:01:49 -0300;Merge pull request #3327 from nyov/deprecations
[MRG+1] Remove deprecated CrawlerSettings class and Settings attributes
==
==================
f8f5f463;Daniel Graña;2018-07-11 12:00:08 -0300;Merge pull request #3253 from rpkilby/depth-stats
[MRG+1] Update depth middleware stats (fixes #3245)
==
==================
9c6d2652;Daniel Graña;2018-07-11 11:50:02 -0300;Merge pull request #3152 from nctl144/ftp_linkextractors
[MRG+1] add ftp to the scheme list
==
==================
8d5320dc;Mikhail Korobov;2018-07-11 17:36:55 +0500;Merge pull request #3326 from lopuhin/patiences-master
Python 3.7 support
==
==================
9428a4a3;Konstantin Lopuhin;2018-07-09 21:03:26 +0300;More visible telnet conch message
Capture traceback when trying to import required twisted modules,
print it in case telnet is enabled, and mention settings variable
that can be used to supress the message.
Thanks @kmike!

==

scrapy/extensions/telnet.py
==================
4f6778aa;nyov;2018-07-09 17:16:31 +0000;Remove deprecated CrawlerSettings class and Settings attributes

==

docs/news.rst
scrapy/settings/__init__.py
tests/test_settings/__init__.py
==================
92b504ea;Konstantin Lopuhin;2018-07-09 13:43:36 +0300;Fix telnet warnings in tests
Disable telnet console if it's not available, else we'll get an extra
warning about failure to enable it, and tests will fail.

==

tests/test_crawler.py
tests/test_utils_log.py
==================
b3cd12dc;Konstantin Lopuhin;2018-07-09 12:53:40 +0300;Try to get python3.7 by using xenial base and sudo
See https://github.com/travis-ci/travis-ci/issues/9815#issuecomment-401756442
and https://github.com/travis-ci/travis-ci/issues/9815#issuecomment-402045581

==

.travis.yml
==================
f4f39057;Konstantin Lopuhin;2018-07-09 12:46:45 +0300;Make csviter work on python 3.7
PEP 479 does not allow for StopIteration in generators.  Instead,
handle it explicitly, also use a for loop which looks simpler.

==

scrapy/utils/iterators.py
==================
2773fe09;Konstantin Lopuhin;2018-07-09 12:36:58 +0300;Make "docs" the last build, even though it still uses python3.6 for now

==

.travis.yml
==================
cf9399ac;Konstantin Lopuhin;2018-07-09 12:26:56 +0300;Use python 3.7 on travis

==

.travis.yml
==================
17e9914b;Konstantin Lopuhin;2018-07-09 12:26:09 +0300;Catch SyntaxError as well when importing manhole
Also give a more detailed reason why telnet is not enabled (for the
future).

==

requirements-py3.txt
scrapy/extensions/telnet.py
==================
722e1afc;Konstantin Lopuhin;2018-07-09 12:21:19 +0300;Update ancient pytest on python 3
2.9 gives collection errors on python 3.7 due to PEP 479.

==

tests/requirements-py3.txt
==================
1d2e2735;Konstantin Lopuhin;2018-07-09 11:59:22 +0300;Merge branch 'master' of https://github.com/patiences/scrapy into patiences-master

==
==================
666e2371;Daniel Graña;2018-07-06 13:49:59 -0300;Merge pull request #3318 from scrapy/delete-relocation-shims
[MRG+1] Delete relocation shims
==
==================
f531b668;Mikhail Korobov;2018-07-06 03:28:01 +0500;SpiderManager shim is removed

==

scrapy/interfaces.py
scrapy/spidermanager.py
scrapy/utils/deprecate.py
==================
36453348;Mikhail Korobov;2018-07-06 03:23:37 +0500;remove ancient modules kept only for error messages

==

.coveragerc
conftest.py
scrapy/project.py
scrapy/stats.py
==================
d4c7cc84;Mikhail Korobov;2018-07-06 03:19:43 +0500;remove backwards compatibility shims for relocated modules

==

.coveragerc
conftest.py
scrapy/command.py
scrapy/contrib/__init__.py
scrapy/contrib/closespider.py
scrapy/contrib/corestats.py
scrapy/contrib/debug.py
scrapy/contrib/downloadermiddleware/__init__.py
scrapy/contrib/downloadermiddleware/ajaxcrawl.py
scrapy/contrib/downloadermiddleware/chunked.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/decompression.py
scrapy/contrib/downloadermiddleware/defaultheaders.py
scrapy/contrib/downloadermiddleware/downloadtimeout.py
scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/contrib/downloadermiddleware/httpproxy.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/downloadermiddleware/stats.py
scrapy/contrib/downloadermiddleware/useragent.py
scrapy/contrib/exporter/__init__.py
scrapy/contrib/feedexport.py
scrapy/contrib/httpcache.py
scrapy/contrib/linkextractors/__init__.py
scrapy/contrib/linkextractors/htmlparser.py
scrapy/contrib/linkextractors/lxmlhtml.py
scrapy/contrib/linkextractors/regex.py
scrapy/contrib/linkextractors/sgml.py
scrapy/contrib/loader/__init__.py
scrapy/contrib/loader/common.py
scrapy/contrib/loader/processor.py
scrapy/contrib/logstats.py
scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/__init__.py
scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/spidermiddleware/__init__.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/httperror.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/referer.py
scrapy/contrib/spidermiddleware/urllength.py
scrapy/contrib/spiders/__init__.py
scrapy/contrib/spiders/crawl.py
scrapy/contrib/spiders/feed.py
scrapy/contrib/spiders/init.py
scrapy/contrib/spiders/sitemap.py
scrapy/contrib/spiderstate.py
scrapy/contrib/statsmailer.py
scrapy/contrib/throttle.py
scrapy/contrib_exp/__init__.py
scrapy/contrib_exp/downloadermiddleware/__init__.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/contrib_exp/iterators.py
scrapy/dupefilter.py
scrapy/linkextractor.py
scrapy/spider.py
scrapy/squeue.py
scrapy/statscol.py
scrapy/utils/decorator.py
scrapy/utils/deprecate.py
==================
0a0e6227;Eugenio Lacuesta;2018-07-04 16:19:19 -0300;New tests

==

tests/test_spider_mw.py
tests/test_spidermiddleware.py
==================
0b287063;Eugenio Lacuesta;2018-07-04 16:14:51 -0300;Do not inherit from object

==

tests/test_spider_mw.py
==================
6f5c39d6;Oz T;2018-07-04 00:22:24 +0300;Fix for CSV export unnecessary blank lines problem on Windows (#3039)

==

scrapy/exporters.py
==================
74ce1561;chainly;2018-07-04 03:00:59 +0800;add item_error to be catchable (#3256)

==

docs/topics/signals.rst
scrapy/core/scraper.py
scrapy/signals.py
tests/pipelines.py
tests/test_engine.py
==================
d05c8677;Grammy Jiang;2018-07-04 02:58:43 +0800;[MRG+1] change the bad smell code (#3304)
Change the bad smell code
==

scrapy/downloadermiddlewares/httpproxy.py
==================
8d93691a;Daniel Graña;2018-07-03 10:33:26 -0300;Merge pull request #3311 from scrapy/rename-requirements
[MRG+1] TST make it clear which requirements are Python 2-only
==
==================
985ab636;Eugenio Lacuesta;2018-07-01 17:49:30 -0300;Store output methods on the 'methods' dict

==

scrapy/core/spidermw.py
==================
4fca9aba;Eugenio Lacuesta;2018-07-01 13:18:29 -0300;Recover from a callback exception

==

tests/test_spider_mw.py
==================
6ed9440e;Eugenio Lacuesta;2018-06-30 21:27:10 -0300;Tests for exceptions on spider callbacks

==

tests/test_spider_mw.py
==================
735de816;Eugenio Lacuesta;2018-06-30 20:55:17 -0300;Test for exceptions on process_spider_input

==

tests/test_spider_mw.py
==================
df75a094;Eugenio Lacuesta;2018-07-01 13:30:50 -0300;Update docs

==

docs/topics/spider-middleware.rst
==================
f11d65f7;Mikhail Korobov;2018-06-29 18:34:11 +0500;TST make it clear which requirements are Python 2-only
* rename requirements.txt to requirements-py2.txt, to make it clear they are Python 2-only
* make requirements-py3.txt consistent with requirements-py2.txt

==

requirements-py2.txt
requirements-py3.txt
tests/requirements-py2.txt
tox.ini
==================
64f48efa;Daniel Graña;2018-06-27 23:42:32 -0300;Merge pull request #3308 from scrapy/fix-build
TST exclude lxml==4.2.2 from tests
==
==================
8782901f;Mikhail Korobov;2018-06-28 01:11:15 +0500;[MRG+1] TST test agains latest pypy (#3309)
pypy3 is not upgraded, as tests segfault with pypy3 6.0 for some reason
==

.travis.yml
==================
45f67eb6;Mikhail Korobov;2018-06-27 14:51:01 +0500;TST exclude lxml==4.2.2 from tests, as it doesn't play well with Pillow

==

tests/constraints.txt
tox.ini
==================
fac1b2f3;Mikhail Korobov;2018-06-27 03:23:47 +0500;TST remove workaround for old Pillow versions which don't support BytesIO

==

tests/test_pipeline_images.py
==================
bc4dbd27;Daniel Graña;2018-06-27 11:19:32 -0300;Merge pull request #3305 from grammy-jiang/patch-1
Make the version of ipython less than 6.0 in python 2.7
==
==================
594a441e;Daniel Graña;2018-06-27 11:16:07 -0300;Merge pull request #3294 from rennerocha/feed-exporter-docs
[MRG+1] Improve docs of S3 Storage to make Python version more explicit
==
==================
ba294351;Eugenio Lacuesta;2018-06-25 15:01:12 -0300;Default values for OffsiteMiddleware
For some reason test_crawl.py seems to be skipping the spider_opened
method, which initializes the host_regex instance variable

==

scrapy/spidermiddlewares/offsite.py
==================
4740dca8;Eugenio Lacuesta;2018-06-24 20:59:18 -0300;Deferred-like process_output/process_exception chain

==

scrapy/core/spidermw.py
==================
ab48837f;Eugenio Lacuesta;2018-06-24 20:21:14 -0300;Merge branch 'master'

==
==================
9ad3af9d;Grammy Jiang;2018-06-23 17:31:54 +0800;Update requirements.txt
make the version of ipython less than 6.0 in python 2.7
==

tests/requirements.txt
==================
1fd1702a;Mikhail Korobov;2018-06-22 04:17:18 +0500;Merge pull request #3299 from grammy-jiang/dev
[MRG+1] fix the test case name of HttpProxyMiddleware
==
==================
88bd0679;Grammy Jiang;2018-06-20 16:56:46 +0800;fix the test case name of HttpProxyMiddleware

==

tests/test_downloadermiddleware_httpproxy.py
==================
991e9b88;Konstantin Lopuhin;2018-06-19 18:10:14 +0300;Merge pull request #3298 from leo8a/master
fix typo in news.rst: extractred --> extracted
==
==================
7a601d76;Leo;2018-06-19 10:51:55 +0200;fix typo
extractred --> extracted
==

docs/news.rst
==================
72d0899b;Vostretsov Nikita;2018-06-14 17:58:48 +0300;Return non-zero exit code from scrapy commands in case of spider bootstrap errors
* method to detect spider creation in crawler

* correct method name

* method to know if crawlers has spiders

* we do not need to issue requests

* set exit code accordingly to spiders in crawlers

* more portable way to check ofr exceptions

* more clear way

* test cases for several spiders per crawler

* grammatically correct name for method

* method is private

* grammatically correct name for method

* method is private

* remove unused import

* correct order of imports

* changes mechanism of obtaining spider status from method to object member

* rename tests

==

scrapy/commands/crawl.py
scrapy/commands/runspider.py
scrapy/crawler.py
tests/test_commands.py
tests/test_crawler.py
==================
667eb715;Mikhail Korobov;2018-06-14 19:56:52 +0500;Merge pull request #3284 from mugayoshi/issue3282
[MRG+1] Update debugging memory leaks section in the docs
==
==================
e2bb218e;Renne Rocha;2018-06-13 18:11:43 -0300;Include Python version indication to each required library used in S3 storage

==

docs/topics/feed-exports.rst
==================
d4511667;mugayoshi;2018-06-09 18:17:11 +0900;Update debugging memory leaks section in the docs
Add Python3 tools description.

==

docs/topics/leaks.rst
==================
c6030ce8;Daniel Graña;2018-06-01 21:52:32 -0300;Merge pull request #3231 from starrify/updating-argument-of-cookiejar-clear
[MRG+2] Added: Allowing optional arguments for `scrapy.http.cookies.CookieJar.clear`
==
==================
596f3960;Colton Herinckx;2018-05-19 16:32:55 -0700;reversed earlier change that seemed to cause Travis CI build failure

==

requirements-py3.txt
==================
12d10eec;Colton Herinckx;2018-05-14 13:53:53 -0700;changed Twisted >= 17.9.0 to Twisted>=17.9.0

==

requirements-py3.txt
==================
9bd5444a;Colton Herinckx;2018-05-14 13:48:28 -0700;added oxford commas to LICENSE

==

LICENSE
==================
98d9093d;Colton Herinckx;2018-05-14 13:37:16 -0700;minor grammatical fixes in CODE_OF_CONDUCT.md

==

CODE_OF_CONDUCT.md
==================
3cf871c6;Mikhail Korobov;2018-06-02 04:13:26 +0500;Merge pull request #3281 from fbergen/gunzipperf
[MRG+2] Improve gunzip performance for big files on Python 3
==
==================
847b50ce;Mikhail Korobov;2018-06-02 01:09:59 +0500;Merge pull request #3201 from grammy-jiang/master
[MRG+1] fix a mistake in topic spider-middleware.rst
==
==================
6a2d2c3b;Fredrik Bergenlid;2018-06-01 21:38:07 +0200;Improve gunzip performance for big files

==

scrapy/utils/gz.py
==================
13b15dc9;Mikhail Korobov;2018-06-01 22:20:41 +0500;Merge pull request #3279 from lewoudar/patch-1
Update spiders.rst
==
==================
f1d87ee0;Mikhail Korobov;2018-06-01 20:54:39 +0500;Merge pull request #3280 from cms-/patch-1
Minor edits to contributing.rst
==
==================
ecdd888f;Chris Slothouber;2018-06-01 09:25:34 -0400;Minor edits to contributing.rst
Corrected minor grammatical issues and increased clarity of instructions.
==

docs/contributing.rst
==================
ffa7bede;Kevin Tewouda;2018-05-30 06:33:18 +0200;Update spiders.rst
I changed URLs to :class:`~scrapy.http.Request` in start_urls explanation of the default spider
==

docs/topics/spiders.rst
==================
b364d272;Vostretsov Nikita;2018-05-23 21:25:50 +0300;[MRG+1] Automatic port selection for servicies in unit tests (#3210)
* ability to pass port as a parameter

* try to find free ports

* use environment variables to pass mock server address

* get mock server address from environment variables

* ability to select ports for proxy in runtime

* use common method for URLs from mock server

* https support

* get mock server address

* get mock address

* replace hand-written mechanism by kernel-based one

* use ephemeral ports in mockserver

* strip EOL from addresses

* use ephemeral port in proxy

* no need to restore environment as it is restored in tearDown

* decode bytes

* use mockserver address as a variable

* ability to pass address as variable

* per test-case mockserver

* use base class

* remove obsolete environment manipulation

* return usage of proxy for http cases

* common method for broking proxy auth credentials

* python version-independent url methods

==

tests/mockserver.py
tests/spiders.py
tests/test_closespider.py
tests/test_crawl.py
tests/test_downloader_handlers.py
tests/test_feedexport.py
tests/test_pipeline_crawl.py
tests/test_proxy_connect.py
tests/test_spidermiddleware_httperror.py
==================
6a182c95;Ryan P Kilby;2018-05-09 12:00:18 -0400;Depth stats are not optional

==

scrapy/spidermiddlewares/depth.py
==================
2dfc5d12;Ryan P Kilby;2018-05-09 11:59:38 -0400;Update DEPTH_STATS refs to DEPTH_STATS_VERBOSE

==

docs/topics/settings.rst
docs/topics/spider-middleware.rst
scrapy/settings/default_settings.py
==================
bac1e2d4;Konstantin Lopuhin;2018-05-17 13:21:42 +0300;Merge pull request #3263 from whalebot-helmsman/no_twisted_18_4_0
[MRG+1] Blacklist twisted version with regression
==
==================
c5ddfddb;Vostretsov Nikita;2018-05-17 08:53:42 +0000;blacklist twisted version with regression in constraints file

==

requirements.txt
tests/constraints.txt
tox.ini
==================
0d015e5c;Vostretsov Nikita;2018-05-16 09:36:07 +0000;blacklist twisted version with regression

==

requirements.txt
==================
c4f096d3;Konstantin Lopuhin;2018-04-26 09:36:39 +0300;Merge pull request #3224 from lucywang000/better-processors-doc
[MRG+1] Improve document about functions as processors
==
==================
f36e1b53;Konstantin Lopuhin;2018-04-25 19:42:19 +0300;Merge pull request #3199 from rhoboro/gcs_acl
[MRG+1] FilesPipeline supports ACL for Google Cloud Storage
==
==================
e75f721c;Pengyu Chen;2018-04-23 22:08:28 +0800;Added: Allowing optional arguments for `scrapy.http.cookies.CookieJar.clear`

==

scrapy/http/cookies.py
==================
57b0e6b6;Lucy Wang;2018-04-19 13:35:46 +0800;improve document about functions as processors

==

docs/topics/loaders.rst
==================
6ef6585b;rhoboro;2018-04-13 19:06:29 +0900;update docs

==

docs/topics/media-pipeline.rst
==================
560ee623;rhoboro;2018-04-13 19:00:27 +0900;set defalut value "" to FILES_STORE_GCS_ACL

==

scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/settings/default_settings.py
==================
46497348;rhoboro;2018-04-13 12:06:39 +0900;Using bucket's default object ACL

==

docs/topics/media-pipeline.rst
scrapy/pipelines/files.py
scrapy/settings/default_settings.py
==================
da1256a9;Konstantin Lopuhin;2018-04-05 11:42:49 +0300;Merge pull request #3189 from stav/master
[MRG+1] Doc: update wording for COOKIES_ENABLED
==
==================
cb76b883;grammy-jiang;2018-04-04 05:56:05 -0400;fix a mistake in topic spider-middleware.rst

==

docs/topics/spider-middleware.rst
==================
74a9c652;rhoboro;2018-04-03 18:20:37 +0900;update docs for support gcs acl

==

docs/topics/media-pipeline.rst
==================
5254ac39;rhoboro;2018-04-03 18:00:08 +0900;added test for gcs policy

==

scrapy/utils/test.py
tests/test_pipeline_files.py
==================
8e8994c6;rhoboro;2018-04-02 15:36:47 +0900;add acl support for gcs

==

scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/settings/default_settings.py
==================
c6d20bdd;Steven Almeroth;2018-03-27 16:21:07 -0400;Doc: update wording for COOKIES_ENABLED

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
==================
6c3970e6;Daniel Graña;2018-03-21 16:32:12 -0300;Merge pull request #3153 from virmht/new_bug
[MRG+1] Fixed bug FormRequest.from_response() clickdata ignores input[type=image]
==
==================
dd064413;Viral Mehta;2018-03-19 19:28:41 +0530;corrected syntax error in XPath

==

scrapy/http/request/form.py
==================
a5acc937;Viral Mehta;2018-03-19 18:19:39 +0530;Resolving Comments

==

scrapy/http/request/form.py
==================
e25e2afe;Viral Mehta;2018-03-17 18:20:14 +0530;Removed unnecessary print statements

==

scrapy/http/request/form.py
==================
ff5f717f;Viral Mehta;2018-03-17 18:17:48 +0530;Fixed formatting issues

==

scrapy/http/request/form.py
==================
6cc6bbb5;Daniel Graña;2018-03-14 11:47:58 -0300;Merge pull request #3166 from lucywang000/catch-tls-certificate-error
catch CertificateError in tls verification
==
==================
2c58da19;Lucy Wang;2018-03-14 09:27:59 +0800;update docstring of ScrapyClientTLSOptions

==

scrapy/core/downloader/tls.py
==================
1a2f0193;Lucy Wang;2018-03-13 19:14:52 +0800;fix tests on jessie

==

scrapy/core/downloader/tls.py
tests/test_downloader_handlers.py
==================
6a7cdf9a;siulkilulki;2018-03-13 08:35:27 +0100;[MRG+1] Add 'flv' to ignored video extensions. (#3165)

==

scrapy/linkextractors/__init__.py
==================
d9e6c73f;Lucy Wang;2018-03-13 13:05:37 +0800;revert wrong changes

==

tests/keys/localhost.crt
tests/keys/localhost.key
==================
e4871009;Lucy Wang;2018-03-13 08:59:03 +0800;add a test case

==

tests/keys/localhost-ip.gen.README
tests/keys/localhost.crt
tests/keys/localhost.ip.crt
tests/keys/localhost.ip.key
tests/keys/localhost.key
tests/test_downloader_handlers.py
==================
13a74d77;Lucy Wang;2018-03-12 22:25:19 +0800;catch CertificateError in tls verification

==

scrapy/core/downloader/tls.py
==================
412f8526;Arvind Prasanna;2018-03-06 23:58:27 -0500;A few typo fixes and some grammatical enhancements

==

docs/news.rst
==================
f10a43d5;Patience Shyu;2018-03-05 11:43:39 +0100;[WIP] Install Twisted from branch for py3.7

==

requirements-py3.txt
requirements.txt
==================
5d1f5245;Patience Shyu;2018-03-05 11:14:50 +0100;[WIP] Install Twisted from branch to bypass syntax issue

==

requirements.txt
==================
ca7d79c2;Patience Shyu;2018-03-05 10:46:51 +0100;Install Twisted from branch to bypass syntax issue

==

requirements.txt
==================
65744c21;Viral Mehta;2018-03-03 20:07:50 +0530;Corrected Test

==

tests/test_http_request.py
==================
d5b7ebcf;Viral Mehta;2018-03-03 18:17:49 +0530;Fixed bug FormRequest.from_response() clickdata ignores input[type=image]

==

scrapy/http/request/form.py
tests/test_http_request.py
==================
4c054414;nctl144;2018-03-03 00:00:03 -0500;add ftp to the scheme list

==

scrapy/linkextractors/__init__.py
tests/test_linkextractors.py
==================
fab68ff6;Patience Shyu;2018-03-02 17:05:14 +0100;Use 3.7-dev version for travis

==

.travis.yml
==================
aca2655c;Patience Shyu;2018-03-02 14:57:39 +0100;[WIP] Run tests for Python 3.7

==

.travis.yml
tox.ini
==================
acd2b8d4;NewUserHa;2018-02-22 06:37:26 +0800;[MRG+1] Fix part of issue #3128 - None should not be a valid type for 'url' in Response.follow (#3131)
* fix one issue of issue#3128

because @kmike posted: 'If url is '', Scrapy should follow the same page, this is an intended behavior.'

*  fix one issue of issue#3128

because @kmike posted: 'If url is '', Scrapy should follow the same page, this is an intended behavior.'

==

scrapy/http/response/__init__.py
tests/test_http_response.py
==================
426da0ed;Cathal Garvey;2018-02-16 18:09:48 +0000;Merge pull request #3127 from Anjalizi/patch-2
Updated contributing.rst
==
==================
bbc2a356;Anjali Jain;2018-02-16 23:33:10 +0530;further edited

==

docs/contributing.rst
==================
6954da13;Anjali Jain;2018-02-15 23:27:40 +0530;Updated contributing.rst
Rectified grammatical errors
==

docs/contributing.rst
==================
f8c688e6;Konstantin Lopuhin;2018-02-14 18:50:26 +0300;Merge pull request #3123 from scrapy/fix-docs-build
fix docs building on CI
==
==================
dc0304fd;Mikhail Korobov;2018-02-13 19:47:41 +0500;fix docs building with recent sphinx: don't use deprecated sphinx options and imports

==

docs/_ext/scrapydocs.py
docs/conf.py
docs/requirements.txt
==================
c56f7b3c;Daniel Graña;2018-02-08 18:22:56 -0300;Merge pull request #3113 from WenbinZhang/master
[MRG+1] Update robotstxt.py
==
==================
68e45d32;Daniel Graña;2018-02-08 18:22:36 -0300;Merge pull request #3115 from scrapy/telnet-log-level
[MRG+1] use INFO log level to show telnet host/port
==
==================
936dbc7b;Konstantin Lopuhin;2018-02-08 23:43:29 +0300;Merge branch 'master' into master

==
==================
8d2240d0;Konstantin Lopuhin;2018-02-08 23:39:37 +0300;Merge pull request #3082 from elacuesta/pickle-requests
[MRG+1] Do not serialize unpickable objects (py3)
==
==================
6edd4114;Eugenio Lacuesta;2018-02-08 15:47:20 -0300;Clarify comment about Pyhton versions

==

scrapy/squeues.py
==================
0d87e77a;Eugenio Lacuesta;2018-02-08 14:49:26 -0300;Bump parsel dependency

==

requirements.txt
setup.py
==================
e4558cb2;Eugenio Lacuesta;2018-01-19 10:51:30 -0300;Update test for unpickable objects

==

tests/test_squeues.py
==================
a5654087;Eugenio Lacuesta;2018-01-16 16:14:35 -0300;Do not serialize unpickable objects (py3)

==

scrapy/squeues.py
tests/test_squeues.py
==================
eff46924;Konstantin Lopuhin;2018-02-08 12:01:36 +0300;Merge pull request #3100 from scrapy/robots-stats
[MRG+1] more stats for RobotsTxtMiddleware
==
==================
0c374c00;Mikhail Korobov;2018-02-08 05:09:02 +0500;use INFO log level to show telnet host/port

==

scrapy/extensions/telnet.py
==================
4d5e5378;Wenbin Zhang;2018-02-07 10:59:32 -0500;Update robotstxt.py
Add message to IgnoreRequest exception so that it can be detectedin the errbak method of a spider
==

scrapy/downloadermiddlewares/robotstxt.py
==================
fd02fa80;Konstantin Lopuhin;2018-02-06 16:21:59 +0300;Merge pull request #3096 from jesuslosada/fix-signal-names
[MRG+1] Fix OS signal names
==
==================
6f264ab1;Mikhail Korobov;2018-01-30 05:47:28 +0500;more stats for RobotsTxtMiddleware

==

scrapy/downloadermiddlewares/robotstxt.py
==================
c1916626;Jesús Losada;2018-01-27 21:24:15 +0000;Fix OS signal names

==

scrapy/utils/ossignal.py
==================
8be28fe4;Daniel Graña;2018-01-26 13:52:21 -0300;Merge pull request #3092 from scrapy/fix-tests-for-w3lib-1.19
Fix tests to account for changes in w3lib 1.19
==
==================
ba15b63e;Mikhail Korobov;2018-01-26 02:11:49 +0500;TST fix tests to account for changes in w3lib 1.19

==

tests/test_http_response.py
==================
1d158126;Yash Sharma;2018-01-26 01:42:17 +0530;Changed some documentations (#3089)
DOC typo fix in defer_fail docstring
==

scrapy/utils/defer.py
==================
7c9e3221;Mikhail Korobov;2018-01-11 01:34:11 +0500;Merge pull request #3059 from jesuslosada/fix-typo
Fix typo in comment
==
==================
786144e0;Mikhail Korobov;2018-01-11 01:33:38 +0500;Merge pull request #3058 from jesuslosada/fix-link
Fix link in news.rst
==
==================
b170e9fb;Daniel Graña;2018-01-07 19:16:11 -0500;Merge pull request #2609 from otobrglez/extending-s3-files-store
S3FilesStore support for other S3 providers (botocore options)
==
==================
61c0b147;Jesús Losada;2018-01-01 16:03:55 +0000;Fix typo in comment

==

scrapy/core/downloader/handlers/http11.py
==================
a0836b8f;Jesús Losada;2018-01-01 15:59:38 +0000;Fix link in news.rst

==

docs/news.rst
==================
2dee1913;Daniel Graña;2017-12-31 16:44:38 -0300;Merge branch 'master' into extending-s3-files-store

==
==================
aa83e159;Mikhail Korobov;2017-12-30 02:09:52 +0500;Bump version: 1.4.0 → 1.5.0

==

.bumpversion.cfg
scrapy/VERSION
==================
d07fe119;Mikhail Korobov;2017-12-30 02:09:41 +0500;set release date

==

docs/news.rst
==================
9b4d6a40;Daniel Graña;2017-12-29 11:57:04 -0300;Merge pull request #3053 from scrapy/release-notes-1.5
Release notes for the upcoming 1.5.0 version 
==
==================
c107059e;Mikhail Korobov;2017-12-29 07:07:43 +0500;DOC fix rst syntax

==

docs/news.rst
==================
d4e5671d;Mikhail Korobov;2017-12-29 07:06:00 +0500;make release docs more readable, add highlights

==

docs/news.rst
==================
45b0e1a0;Mikhail Korobov;2017-12-28 07:33:43 +0500;DOC draft 1.5 release notes

==

docs/news.rst
==================
461f9daf;Paul Tremberth;2017-07-27 19:56:17 +0200;Update release notes for upcoming 1.4.1 version

==

docs/news.rst
==================
a1cc5a63;Raphael;2017-12-27 18:54:17 -0200;Add mention to dont_merge_cookies in CookiesMiddlewares docs (#2999) (#3030)
Add mention to dont_merge_cookies in CookiesMiddlewares docs (#2999)

==

docs/topics/downloader-middleware.rst
==================
57d04aa9;Daniel Graña;2017-12-26 14:12:47 -0300;Merge pull request #2767 from redapple/http-proxy-endpoint-key
[MRG+1] Use HTTP pool and proper endpoint key for ProxyAgent
==
==================
930f6ed8;Mikhail Korobov;2017-12-25 18:50:58 +0500;Merge pull request #3050 from lopuhin/pypy3
Add PyPy3 support
==
==================
bb1f3118;Konstantin Lopuhin;2017-12-25 15:46:05 +0300;Add PyPy3 support to faq and install doc

==

docs/faq.rst
docs/intro/install.rst
==================
041308af;Konstantin Lopuhin;2017-12-25 14:27:20 +0300;Fix get_func_args test for pypy3
These built-in functions are exposed as methods in PyPy3.
For scrapy this does not matter as:
1) they do not work for CPython at all
2) get_func_args is checked for presense of an argument in scrapy,
   extra "self" does not matter.
But it still makes sense to leave these tests so that we know we
shouldn't use get_func_args for built-in functions/methods.

==

tests/test_utils_python.py
==================
f71df6f9;Konstantin Lopuhin;2017-12-25 13:46:22 +0300;Run tests for PyPy3

==

.travis.yml
tox.ini
==================
632f1cc0;Mikhail Korobov;2017-12-25 15:59:56 +0500;Merge pull request #3049 from scrapy/trove-classifiers
[MRG+1] setup.py: mention that we support PyPy. See GH-2213.
==
==================
9f9edead;Mikhail Korobov;2017-12-25 15:32:50 +0500;Merge pull request #3048 from lopuhin/pypy-install-docs
[MRG+1] Mention PyPy support, add PyPy to install docs
==
==================
1058169f;Mikhail Korobov;2017-12-25 15:31:07 +0500;setup.py: mention that we support PyPy. See GH-2213.

==

setup.py
==================
ea41114c;Konstantin Lopuhin;2017-12-25 12:29:02 +0300;Mention PyPy support, add PyPy to install docs

==

docs/faq.rst
docs/intro/install.rst
==================
bdc12f39;Mikhail Korobov;2017-12-20 21:08:13 +0500;Merge pull request #3045 from hugovk/rm-3.3
[MRG+1] Drop support for EOL Python 3.3
==
==================
cbcf80b9;Hugo;2017-12-20 17:34:13 +0200;Fix typo
[CI skip]
==

docs/intro/install.rst
==================
f11c21c6;Hugo;2017-12-20 17:05:56 +0200;Test on Python 3.4

==

.travis.yml
==================
44623687;Hugo;2017-12-19 17:59:05 +0200;Drop support for EOL Python 3.3

==

.travis.yml
README.rst
docs/faq.rst
docs/intro/install.rst
setup.py
tox.ini
==================
86c322c3;Daniel Graña;2017-12-13 13:17:28 -0300;Merge pull request #3038 from scrapy/update-contributing-docs
DOC update "Contributing" docs
==
==================
9aa9dd8d;Mikhail Korobov;2017-12-12 19:17:00 +0500;DOC mention an easier way to track pull requests locally. Thanks @eliasdorneles!

==

docs/contributing.rst
==================
f716843a;Mikhail Korobov;2017-12-12 16:19:43 +0500;DOC update "Contributing" docs:
* suggest Stack Overflow for Scrapy usage questions;
* encourage users to submit test-only pull requests with reproducable examples;
* encourage users to pick up stalled pull requests;
* we don't use AUTHORS file as a main acknowledgement source;
* suggest using Sphinx autodocs extension

==

docs/contributing.rst
==================
a21b8004;Konstantin Lopuhin;2017-12-08 15:45:16 +0300;Merge pull request #3011 from Jane222/master
[MRG+1] Issues a warning when user puts a URL into allowed_domains (#2250)
==
==================
22c68baf;Jana Cavojska;2017-12-07 18:38:29 +0100;url_pattern is now being compiled before entering the loop

==

scrapy/spidermiddlewares/offsite.py
==================
3cf0332e;Daniel Graña;2017-11-29 16:26:48 -0300;Merge pull request #2957 from ScrapingLab/add_meta_json_to_parse_command
[MRG+1] Scrapy Command: add --meta/-m to the "parse" command to pass additional meta data into the request
==
==================
454d5e57;Jana Cavojska;2017-11-26 20:07:04 +0100;checking for subclass of URLWarning instead of checking error message text when URL in allowed_domains

==

scrapy/spidermiddlewares/offsite.py
tests/test_spidermiddleware_offsite.py
==================
8ec3b476;Jana Cavojska;2017-11-26 16:36:15 +0100;triggering a warning when user puts URL in allowed_domains now covered by test

==

scrapy/spidermiddlewares/offsite.py
tests/test_spidermiddleware_offsite.py
==================
6af323d7;IAlwaysBeCoding;2017-11-26 00:24:52 +0100;Fix spelling mistake on scrapy parse command docs
Fixed spelling mistake from "will be pass" to "will be passed"
==

docs/topics/commands.rst
==================
97dc5271;Konstantin Lopuhin;2017-11-24 17:56:57 +0300;Merge pull request #3020 from Jesse-Bakker/add-fromcrawler-middleware-docs
[MRG+1] Added from_crawler to middleware docs
==
==================
bd16951a;Mikhail Korobov;2017-11-24 16:49:56 +0500;Merge pull request #3013 from KosayJabre/patch-1
Separated import statements
==
==================
0b14cb44;Jesse Bakker;2017-11-23 15:25:43 +0100;Added from_crawler to middleware docs

==

docs/topics/downloader-middleware.rst
docs/topics/spider-middleware.rst
==================
91ff194d;Jana Cavojska;2017-11-20 21:23:31 +0100;looping over allowed_domains directly instead of via index

==

scrapy/spidermiddlewares/offsite.py
==================
5441cc18;KosayJabre;2017-11-19 18:09:38 -0400;Separated import statements
Just separated the import statements. Tiny change - testing GitHub!
==

scrapy/commands/edit.py
==================
62a62610;Jana Cavojska;2017-11-18 20:03:59 +0100;Issues a warning when user puts a URL into allowed_domains (#2250)

==

scrapy/spidermiddlewares/offsite.py
==================
846fd835;IAlwaysBeCoding;2017-11-11 18:30:01 -0500;removed commented out code, wrapped line to pep-8 and removed backlashes

==

docs/topics/commands.rst
scrapy/commands/parse.py
tests/test_command_parse.py
==================
b8870ee8;Daniel Graña;2017-11-03 13:15:31 -0200;Merge pull request #2989 from colinmorris/ItemExporterDocsExample
[MRG+1] Revise/modernize item exporter example in docs
==
==================
fd733451;Konstantin Lopuhin;2017-11-02 19:23:46 +0300;Merge pull request #2983 from codeaditya/https-links
[MRG+1] Use https link in default user agent
==
==================
b7a88fad;Mikhail Korobov;2017-11-02 18:59:20 +0500;Merge pull request #2991 from lopuhin/pypy-build-2
Fix PyPy build
==
==================
abb6d0a1;Konstantin Lopuhin;2017-11-01 17:26:59 +0300;Use portable pypy directly
They are provided by https://github.com/squeaky-pl/portable-pypy

==

.travis.yml
==================
23e571e8;colinmorris;2017-10-31 18:08:47 -0400;fix issues identified in review

==

docs/topics/exporters.rst
==================
8a755237;colinmorris;2017-10-31 17:14:53 -0400;revise/modernize item exporter example in docs

==

docs/topics/exporters.rst
==================
df7e0a43;Aditya;2017-10-28 23:37:44 +0530;Use https link in default user agent

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
108f8c4f;Mikhail Korobov;2017-10-28 21:45:05 +0500;Merge pull request #2982 from codeaditya/https-links
Fix broken links and use https links wherever possible
==
==================
dae7b1cd;Aditya;2017-10-28 16:53:32 +0530;Migrate all subdomains on readthedocs.org to readthedocs.io

==

scrapy/templates/project/scrapy.cfg
==================
97d047a0;Aditya;2017-10-28 16:48:41 +0530;Fix link for Tox

==

tox.ini
==================
23c7437e;Aditya;2017-10-28 16:34:49 +0530;Fix link for 'XPath and XSLT with lxml'

==

sep/sep-006.rst
==================
9d9d83a8;Aditya;2017-10-28 16:24:40 +0530;Use https links wherever possible

==

CONTRIBUTING.md
INSTALL
README.rst
debian/control
debian/copyright
docs/contributing.rst
docs/intro/overview.rst
docs/topics/practices.rst
docs/topics/selectors.rst
docs/topics/shell.rst
scrapy/_monkeypatches.py
scrapy/core/downloader/contextfactory.py
scrapy/crawler.py
scrapy/downloadermiddlewares/chunked.py
scrapy/downloadermiddlewares/httpcache.py
scrapy/exporters.py
scrapy/extensions/httpcache.py
scrapy/extensions/telnet.py
scrapy/pipelines/files.py
scrapy/signalmanager.py
scrapy/templates/project/module/items.py.tmpl
scrapy/templates/project/module/middlewares.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/templates/project/module/settings.py.tmpl
scrapy/utils/defer.py
scrapy/utils/deprecate.py
scrapy/utils/http.py
scrapy/utils/log.py
scrapy/utils/url.py
sep/sep-001.rst
sep/sep-006.rst
sep/sep-013.rst
sep/sep-017.rst
sep/sep-020.rst
setup.py
tests/__init__.py
tests/keys/example-com.conf
==================
79df51aa;Mikhail Korobov;2017-10-27 14:14:37 +0500;Merge pull request #2978 from codeaditya/https-links
Use https for external links wherever possible in docs
==
==================
1d9c8f52;Daniel Graña;2017-10-26 15:04:18 -0300;Merge pull request #2921 from revolter/hotfix/disable-logging
[MRG+1] Add option to disable automatic log handler install
==
==================
9dd680d5;Aditya;2017-10-26 23:32:20 +0530;Use https for external links wherever possible in docs

==

README.rst
artwork/README.rst
docs/contributing.rst
docs/faq.rst
docs/intro/install.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/debug.rst
docs/topics/deploy.rst
docs/topics/firebug.rst
docs/topics/firefox.rst
docs/topics/jobs.rst
docs/topics/loaders.rst
docs/topics/media-pipeline.rst
docs/topics/practices.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/shell.rst
docs/topics/spiders.rst
extras/coverage-report.sh
==================
dc4b36a8;Daniel Graña;2017-10-26 11:38:43 -0300;Merge pull request #2952 from NoExitTV/Unhelpful-log-message-from-core.downloader.handlers.http11
[MRG+1] Changed unhelpful log message from core.downloader.handlers.http11
==
==================
4f8b45ec;Daniel Graña;2017-10-26 11:35:32 -0300;Merge pull request #2929 from djunzu/add_m4v_to_ignored_extensions
[MRG+1] Add m4v extension to IGNORED_EXTENSIONS in LinkExtractor.
==
==================
9be8f02d;Daniel Graña;2017-10-26 09:58:56 -0300;Merge pull request #2942 from rodrigc/twisted-17.9.0
[MRG+1] Bump Twisted requirement on Python 3 to 17.9.0 to catch many Python 3 fixes.
==
==================
98fb03e8;Mikhail Korobov;2017-10-26 17:01:47 +0500;Merge pull request #2958 from codeaditya/update-links
Link "Debugging in Python" article to its new location
==
==================
496fc60b;Mikhail Korobov;2017-10-26 16:15:36 +0500;Merge pull request #2963 from djunzu/mention_request_meta_depth_on_depthmiddleware_doc
Add note about request.meta['depth'] in DepthMiddleware
==
==================
73c40eb3;Mikhail Korobov;2017-10-26 16:05:31 +0500;Merge pull request #2964 from weldon0405/patch-1
Update tutorial.rst startproject files
==
==================
124d577d;Mikhail Korobov;2017-10-26 16:04:59 +0500;Merge pull request #2976 from weldon0405/patch-2
updated file structure to include middlewares.py
==
==================
95815d27;Weldon Malbrough;2017-10-25 23:16:30 -0400;updated file structure to include middlewares.py

==

docs/topics/commands.rst
==================
169dc286;Weldon Malbrough;2017-10-16 22:46:32 -0400;Update tutorial.rst startproject files
Added middlewares.py to accurately reflect the file structure created by "scrapy startproject tutorial"
==

docs/intro/tutorial.rst
==================
8288f78a;djunzu;2017-10-16 21:34:37 -0200;Add note about request.meta['depth'] in DepthMiddleware

==

docs/topics/spider-middleware.rst
==================
9cdf34b7;Aditya;2017-10-10 22:49:22 +0530;Link "Debugging in Python" article to its new location
Reference: https://web.archive.org/web/20170203104051/http://www.ferg.org/papers/debugging_in_python.html

==

docs/topics/extensions.rst
==================
b802c212;Eugenio Lacuesta;2017-10-09 13:04:34 -0300;Merge pull request #1 from kmike/e-process_spider_exception_generator
TST cleanup spider middleware tests
==
==================
9b850301;NoExitTV;2017-10-06 13:45:35 +0200;Changed log message to include information about request as user djunzu commented

==

scrapy/core/downloader/handlers/http11.py
==================
345d948f;NoExitTV;2017-10-05 15:37:05 +0200;Changed the log message to make it more clear. As requested in issue #2927

==

scrapy/core/downloader/handlers/http11.py
==================
938bc184;NoExitTV;2017-10-05 15:31:00 +0200;Changed the log message to make it more clear. As requested in issue #2927

==

scrapy/core/downloader/handlers/http11.py
==================
e914556a;NoExitTV;2017-10-05 15:12:01 +0200;Changed the log message to make it more clear. As requested in issue #2927

==

scrapy/core/downloader/handlers/http11.py
==================
f729d748;Paul Tremberth;2017-08-28 11:21:11 +0200;Use a helper for to_bytes() and None input

==

scrapy/mail.py
==================
9cd348d9;Paul Tremberth;2017-08-22 12:29:47 +0200;Handle None values for smtp user and password

==

scrapy/mail.py
==================
0d8a33fd;Paul Tremberth;2017-08-08 17:42:56 +0200;Update docs

==

docs/topics/email.rst
==================
80bb4fcf;Paul Tremberth;2017-08-08 17:40:36 +0200;Convert SMTP credentials to bytes if needed

==

scrapy/mail.py
==================
12c7628f;Paul Tremberth;2017-08-08 17:13:45 +0200;Encode message using supplied charset

==

scrapy/mail.py
==================
fc406801;Craig Rodrigues;2017-03-21 00:21:41 -0700;ESMTPSenderFactory takes a message of bytes

==

scrapy/mail.py
==================
5fac2d7b;Daniel Graña;2017-10-02 13:52:20 -0300;Merge pull request #2923 from rhoboro/fixes-685
[MRG+2] Fixes #685 FilesPipeline support for Google Cloud Storage.
==
==================
92fa74fb;Mikhail Korobov;2017-10-02 10:26:54 +0200;Merge pull request #2922 from stav/doc.response-body
[Doc] Update Response.body type
==
==================
3431870b;Mikhail Korobov;2017-10-02 10:25:40 +0200;Merge pull request #2924 from superyyrrzz/patch-1
minor fix typo
==
==================
2e4ddc69;Mikhail Korobov;2017-10-02 10:24:27 +0200;Merge pull request #2947 from lagenar/fix-tests-typo
Fix typos in tests
==
==================
59c3f6f0;Lucas Moauro;2017-10-01 12:24:56 -0300;Fix typos in tests

==

tests/test_downloadermiddleware_httpproxy.py
==================
d4555b2b;rhoboro;2017-09-29 12:07:29 +0900;update docs for supporting google cloud storage

==

docs/topics/media-pipeline.rst
==================
346310cd;Mikhail Korobov;2017-09-28 13:04:56 +0200;Merge pull request #2915 from redapple/versions-with-cryptography
Print cryptography package version
==
==================
e733f51d;Paul Tremberth;2017-09-25 12:49:27 +0200;Fix test

==

tests/test_command_version.py
==================
00c81a32;Craig Rodrigues;2017-09-23 11:01:34 -0700;Bump Twisted requirement to 17.9.0 to catch many Python 3 fixes.

==

requirements-py3.txt
==================
5d17f38a;Mikhail Korobov;2017-09-20 17:59:46 +0500;Merge pull request #2935 from lopuhin/pypy2.7-build
Update pypy version regexp to get last release
==
==================
84111969;Konstantin Lopuhin;2017-09-20 13:35:48 +0200;Update pypy version regexp to get last release
PyPy changed naming conention since 5.8 release, not it's called
pypy2.7-x.x.x

==

.travis.yml
==================
dcb279bd;djunzu;2017-09-17 16:09:22 -0300;Add m4v extension to IGNORED_EXTENSIONS in LinkExtractor.
	modified:   scrapy/linkextractors/__init__.py

==

scrapy/linkextractors/__init__.py
==================
088b80d4;Renze Yu;2017-09-13 23:29:22 +0800;minor fix typo

==

docs/intro/tutorial.rst
==================
ee166ec4;rhoboro;2017-09-13 17:35:46 +0900;Support for ImagesPipeline

==

scrapy/pipelines/files.py
scrapy/pipelines/images.py
==================
e5d4364b;rhoboro;2017-09-13 16:24:04 +0900;Add tests for GCS Storage

==

scrapy/utils/test.py
tests/test_pipeline_files.py
tox.ini
==================
d71a0634;rhoboro;2017-09-12 18:30:15 +0900;Support for Google Cloud Storage

==

scrapy/pipelines/files.py
==================
3637b75a;Steven Almeroth;2017-09-12 15:54:09 -0400;[Doc] Update Response.body type

==

docs/topics/request-response.rst
==================
aab98080;Iulian Onofrei;2017-09-11 00:40:55 +0300;Add option to disable automatic log handler install

==

scrapy/crawler.py
==================
abaf466b;Paul Tremberth;2017-09-07 11:37:40 +0200;Print cryptography package version

==

scrapy/commands/version.py
scrapy/utils/versions.py
==================
b8fabeed;cclauss;2017-09-01 13:55:05 +0200;ur'string' not needed in Py 2, syntax error in Py3
This instance was missed in #2909 --> ur'Scrapy developers' --> u'Scrapy developers'
==

docs/conf.py
==================
6213fa51;Mikhail Korobov;2017-09-01 15:42:02 +0500;Merge pull request #2909 from cclauss/patch-2
ur'string' not needed in Py 2, syntax error in Py3
==
==================
b7022360;cclauss;2017-09-01 11:56:09 +0200;ur'string' not needed in Py 2, syntax error in Py3
Convert `u'(.*)\:\d+\:\s\[(.*)\]\s(?:(.*)\sto\s(.*)|(.*))'`--> `u'(.*)\:\d+\:\s\[(.*)\]\s(?:(.*)\sto\s(.*)|(.*))'`to be compatible with both Python 2 and Python 3.  See #2891
==

docs/utils/linkfix.py
==================
9f16f040;cclauss;2017-09-01 11:53:59 +0200;ur'string' not needed in Py 2, syntax error in Py3
Convert `ur'Scrapy Documentation'`--> `u'Scrapy Documentation'`to be compatible with both Python 2 and Python 3.  See #2891
==

docs/conf.py
==================
65ac0b06;Mikhail Korobov;2017-08-29 19:20:46 +0500;Merge pull request #2894 from redapple/log-custom-overriden-settings
Move logging of overriden settings to Crawler init
==
==================
a429d780;Pablo Hoffman;2017-08-24 16:03:36 -0300;update scrapinghub.com urls to use https

==

docs/intro/install.rst
docs/topics/deploy.rst
docs/topics/logging.rst
docs/topics/practices.rst
docs/topics/ubuntu.rst
==================
7a35a1ad;Paul Tremberth;2017-08-23 17:08:21 +0200;Remove trailing bracket from components versions log

==

scrapy/utils/log.py
==================
1968a8ec;Paul Tremberth;2017-08-23 15:08:10 +0200;Move logging of overriden settings to Crawler init

==

scrapy/crawler.py
scrapy/utils/log.py
==================
1ba77f08;Mikhail Korobov;2017-08-21 19:15:30 +0500;Merge pull request #2869 from cclauss/patch-3
# noqa to close #2836
==
==================
885289f4;Mikhail Korobov;2017-08-21 19:15:03 +0500;Merge pull request #2854 from jenya/2853-sitemap-follow-alternate-fix
[MRG+1] Follow alternate link for all types of sitemaps #2853
==
==================
984c0c19;Mikhail Korobov;2017-08-16 16:36:00 +0500;Merge pull request #2884 from iamminji/patch-1
fix typo
==
==================
1dcea6a9;kim minji;2017-08-16 18:07:52 +0900;fix typo

==

scrapy/crawler.py
==================
d5f3543d;Daniel Graña;2017-08-09 07:56:57 -0300;Merge pull request #2865 from kirankoduru/2831-explicit-msg-for-scrapy-parse-callback
[MRG+1] Explicit message for scrapy parse callback
==
==================
fd27cde2;Chomba Ng'ang'a;2017-08-08 19:08:53 +0300;Update asserts to use more generic ones

==

tests/test_http_cookies.py
tests/test_http_request.py
tests/test_loader.py
tests/test_utils_python.py
tests/test_utils_signal.py
tests/test_webclient.py
==================
4ca61a20;Chomba Ng'ang'a;2017-08-07 18:29:36 +0300;Update deprecated test aliases
- change ``failIf`` to ``assertFalse``
- change ``asertEquals`` to ``assertEqual``
- change ``assert_`` to ``assertTrue``

https://docs.python.org/2/library/unittest.html#deprecated-aliases

==

tests/test_cmdline/__init__.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_cookies.py
tests/test_downloadermiddleware_defaultheaders.py
tests/test_downloadermiddleware_downloadtimeout.py
tests/test_downloadermiddleware_httpauth.py
tests/test_downloadermiddleware_httpcompression.py
tests/test_downloadermiddleware_httpproxy.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_useragent.py
tests/test_http_cookies.py
tests/test_http_request.py
tests/test_loader.py
tests/test_pipeline_images.py
tests/test_selector.py
tests/test_spider.py
tests/test_spidermiddleware_depth.py
tests/test_spidermiddleware_httperror.py
tests/test_spidermiddleware_offsite.py
tests/test_spidermiddleware_referer.py
tests/test_spidermiddleware_urllength.py
tests/test_urlparse_monkeypatches.py
tests/test_utils_datatypes.py
tests/test_utils_defer.py
tests/test_utils_iterators.py
tests/test_utils_misc/__init__.py
tests/test_utils_project.py
tests/test_utils_python.py
tests/test_utils_signal.py
tests/test_webclient.py
==================
2960c9b5;Kiran Koduru;2017-08-05 16:29:41 -0400;Use self.__class__.__name__ instead of showing generic Spider class name

==

scrapy/spiders/__init__.py
==================
12409a0c;Kiran Koduru;2017-08-02 08:32:38 -0400;Fix broken encoding on text for py 3

==

tests/test_spider.py
==================
7adab61a;kirankoduru;2017-08-01 22:42:26 -0400;Added test for NotImplemented Spider.parse method

==

tests/test_spider.py
==================
be71f98e;kirankoduru;2017-07-29 20:51:54 -0400;Explicit message for scrapy parse callback
The scrapy parse method raises a NotImplementedError when not defined,
but for new comers it can be hard to debug what might be going wrong.

Adding an explicit message for NotImplementedError will help new users.

==

scrapy/spiders/__init__.py
==================
a68a8f8f;Paul Tremberth;2017-08-05 11:45:50 +0200;Merge remote-tracking branch 'origin/1.4'

==
==================
0a69a32b;cclauss;2017-08-04 14:35:43 +0200;Force Travis CI to test again

==

tests/test_item.py
==================
c016a430;cclauss;2017-08-04 01:44:23 +0200;# noqa to close #2836
Marks #2836 as will not fix.
==

tests/test_item.py
==================
0cb3085f;Paul Tremberth;2017-08-03 16:35:47 +0200;Add test for alternate links

==

tests/test_spider.py
==================
01ac8838;Eugene Vorobev;2017-07-26 19:51:27 +0300;Follow alternate link for all types of sitemaps

==

scrapy/spiders/sitemap.py
==================
71d5b7d7;david watson;2017-08-01 13:49:22 -0400;fix typo (#2867)

==

docs/topics/broad-crawls.rst
==================
6e6b5cc2;Andrei Petre;2017-08-01 17:14:43 +0300;Use getfullargspec under the scenes for py3 to stop DeprecationWarning (#2864)
Use getfullargspec under the scenes for py3 to stop DeprecationWarning. 

Closes #2862


==

scrapy/utils/python.py
==================
19382c56;Daniel Graña;2017-07-31 11:37:26 -0300;Merge pull request #2755 from redapple/downloader-mdw-template
[MRG+1] Add template for a downloader middleware
==
==================
a65fec05;simik-ru;2017-07-30 17:04:02 +0300;Small fix in description of startproject arguments

==

docs/topics/commands.rst
==================
aaaa4da7;Paul Tremberth;2017-05-24 12:42:54 +0200;Add template for a downloader middleware

==

scrapy/templates/project/module/middlewares.py.tmpl
scrapy/templates/project/module/settings.py.tmpl
==================
9d34b2fe;Mikhail Korobov;2017-07-28 00:02:06 +0500;Merge pull request #2857 from redapple/scrapy-components-logs-startup
Log versions information at startup
==
==================
bf7ef3e4;Paul Tremberth;2017-07-27 20:07:14 +0200;Move methods to a new scrapy.utils.versions

==

scrapy/commands/version.py
scrapy/utils/log.py
scrapy/utils/versions.py
==================
219c8aa0;Paul Tremberth;2017-07-27 17:30:30 +0200;Log versions information at startup

==

scrapy/commands/version.py
scrapy/utils/log.py
==================
5d9bac78;Daniel Graña;2017-07-26 15:59:37 -0300;Merge pull request #2849 from cclauss/patch-2
[MRG+1] xrange() --> range() for Python 3
==
==================
bbc56e69;Daniel Graña;2017-07-26 15:46:35 -0300;Merge pull request #2852 from starrify/new-http-codes-to-retry-2851
Added: HTTP status code 522/524 to retry.
==
==================
881a5e3a;Daniel Graña;2017-07-26 15:29:23 -0300;Merge pull request #2847 from redapple/redirect-308
Handle HTTP 308 Permanent Redirect
==
==================
15a5c533;Paul Tremberth;2017-07-26 19:07:57 +0200;Add tests for HTTP 307 permanent redirects

==

tests/test_downloadermiddleware_redirect.py
==================
1fdc1068;Paul Tremberth;2017-07-24 18:25:11 +0200;HTTP Cache: treat 308 as 301

==

tests/test_downloadermiddleware_httpcache.py
==================
5dc9a88c;Paul Tremberth;2017-07-24 18:10:58 +0200;Handle HTTP 308 Permanent Redirect

==

scrapy/downloadermiddlewares/redirect.py
tests/test_downloadermiddleware_redirect.py
==================
11a1f970;Pengyu Chen;2017-07-26 16:11:13 +0800;Added: HTTP status code 522/524 to retry.

==

scrapy/settings/default_settings.py
==================
4d77c308;Jakob de Maeyer;2015-11-23 12:24:05 +0100;Add from_crawler constructor to S3FeedStorage

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
815d6160;Jakob de Maeyer;2015-11-16 18:28:49 +0100;Add from_crawler constructor for feed exporters and storages

==

scrapy/extensions/feedexport.py
scrapy/middleware.py
scrapy/utils/misc.py
tests/test_feedexport.py
tests/test_utils_misc/__init__.py
==================
33dfac50;cclauss;2017-07-24 22:06:17 +0200;xrange() --> range() for Python 3
Either this PR or #2845.
==

extras/qpsclient.py
==================
17bbd714;Mikhail Korobov;2017-07-25 00:28:14 +0500;Merge pull request #2812 from elacuesta/inspect_response_populate_spider
Populate spider variable when using shell.inspect_response
==
==================
b6d036ed;Daniel Graña;2017-07-24 15:55:30 -0300;Merge pull request #2837 from dguo/patch-2
Fix a typo in the Items documentation
==
==================
6de106e7;Daniel Graña;2017-07-24 15:48:03 -0300;Merge pull request #2763 from scrapy/dataloss-typo
DOC fixed rst syntax in DOWNLOAD_FAIL_ON_DATALOSS docs
==
==================
12971a7b;Daniel Graña;2017-07-24 15:47:39 -0300;Merge pull request #2764 from scrapy/readme-cleanup
DOC change "releases" section content
==
==================
c01c1ef2;Daniel Graña;2017-07-24 15:42:00 -0300;Merge pull request #2655 from Granitosaurus/ptpython_support
[MRG+1] add support for embeded ptpython shell
==
==================
2371a2a0;Daniel Graña;2017-07-24 15:41:30 -0300;Merge pull request #2789 from starrify/add-response-follow-tag-link
[MRG+1] Added: Now supporting <link> tags in Response.follow
==
==================
d1e948ce;Daniel Graña;2017-07-24 15:29:38 -0300;Merge pull request #2791 from starrify/doc-DontCloseSpider
[MRG+1] Added doc for `scrapy.exceptions.DontCloseSpider`. Also fixes inaccurate doc for `scrapy.signals.spider_idle`.
==
==================
8e0b640d;Daniel Graña;2017-07-24 15:28:15 -0300;Merge pull request #2826 from dguo/patch-1
[MRG+1] Tweak the CSVFeedSpider documentation
==
==================
45b81693;Daniel Graña;2017-07-24 15:14:33 -0300;Merge pull request #2769 from stummjr/issue-2766
[MRG+1] Add verification to check if Request callback is callable
==
==================
50b2567d;Daniel Graña;2017-07-24 14:44:41 -0300;Merge pull request #2848 from redapple/tox-jessie-ssl
[WIP] Jessie toxenv: Add cryptography as per https://packages.debian.org/jessie/python-cryptography
==
==================
1a18587d;Paul Tremberth;2017-07-24 19:30:08 +0200;Jessi toxenv: Add cryptography as per https://packages.debian.org/jessie/python-cryptography

==

tox.ini
==================
bb0bd691;Valdir Stumm Junior;2017-07-24 11:12:09 -0300;Improve error message when callback is not callable

==

scrapy/http/request/__init__.py
==================
26c48897;Danny Guo;2017-07-18 19:56:51 -0500;Fix a typo in the Items documentation

==

docs/topics/items.rst
==================
17fe6d25;Mikhail Korobov;2017-07-15 12:09:45 +0200;Merge pull request #2828 from cconrad/patch-1
Spelling mistake
==
==================
18b96dd8;Claus Conrad;2017-07-15 11:31:09 +0200;Spelling mistake

==

docs/topics/broad-crawls.rst
==================
dedc4a8b;Danny Guo;2017-07-13 22:58:10 -0500;Tweak the CSVFeedSpider documentation

==

docs/topics/spiders.rst
==================
15abc0b9;Mikhail Korobov;2017-07-06 15:53:33 +0500;Merge pull request #2816 from redapple/dns-cache-disabled
Fix DNS resolver when DNSCACHE_ENABLED=False
==
==================
f0ded6b7;Paul Tremberth;2017-07-04 23:18:15 +0200;Do not cache DNS responses when cache size is 0

==

scrapy/resolver.py
==================
1f08d9a6;Paul Tremberth;2017-07-04 23:10:19 +0200;Add test for DNS cache disabling

==

tests/test_commands.py
==================
793b2376;Eugenio Lacuesta;2017-07-03 11:28:04 -0300;Populate spider variable when using shell.inspect_response

==

scrapy/shell.py
==================
dd5ab6c5;Mikhail Korobov;2017-07-03 18:36:54 +0500;Merge pull request #2793 from lopuhin/pypy2
Fix PyPy test failures
==
==================
b0a92363;Konstantin Lopuhin;2017-06-19 19:16:50 +0300;Use environment markers for custom PyPy requirements

==

setup.py
tox.ini
==================
5ba8e5ad;Konstantin Lopuhin;2017-06-19 17:45:28 +0300;Remove duplicate PyPy toxenv from Travis config
Thanks for the catch @redapple

==

.travis.yml
==================
271b3a48;Konstantin Lopuhin;2017-06-19 16:46:16 +0300;Require pypy build to pass

==

.travis.yml
==================
ea08b952;Konstantin Lopuhin;2017-06-19 16:45:29 +0300;Remove Jython gc branch: it's not supported

==

scrapy/utils/python.py
==================
a8df0900;Konstantin Lopuhin;2017-06-15 14:29:28 +0300;Fix httpcache leveldb tests: gc.collect after del
LevelDB does not have "official" close method, so we have
to rely on garbage collection to close it.

==

scrapy/extensions/httpcache.py
==================
b4eb60e5;Konstantin Lopuhin;2017-06-15 13:24:06 +0300;Install PyPyDispatcher for PyPy tests
Using https://github.com/lopuhin/pydispatcher, pypy branch.
This is executed as a separate step to avoid changing
default requirements.txt and setup.py. If just added to "deps"
in tox, this install command will be executed as one command
and PyPyDispatcher will not override PyDispatcher.

==

tox.ini
==================
19ca986a;Konstantin Lopuhin;2016-09-02 00:32:33 +0300;Move garbage_collect to scrapy.utils.python

==

scrapy/cmdline.py
scrapy/utils/python.py
==================
7c67047e;Konstantin Lopuhin;2016-09-01 18:35:57 +0300;Fix get_func_args tests under PyPy
On CPython get_func_args does not work correctly for built-in
methods.

==

tests/test_utils_python.py
==================
5abb70c8;Konstantin Lopuhin;2016-09-01 15:43:57 +0300;Fix test_weakkeycache on PyPy: run gc.collect()
One gc.collect() seems to be enough, but it's more reliable
to run it several times (at most 100), until all objects are collected.

==

tests/test_utils_python.py
==================
c3d17659;Konstantin Lopuhin;2016-09-01 15:39:16 +0300;Fix queue serialization test on PyPy
It is not affected by Twisted bug #7989 and is more permissive
with pickling (especially with protocol=2).

==

tests/test_squeues.py
==================
6014856d;Konstantin Lopuhin;2016-09-01 18:39:25 +0300;Fix test_output_processor_error undere PyPy
For float(u'$10') PyPy includes "u'" in the error message,
and it's more fair to check error message on input we are really
passing.

==

tests/test_loader.py
==================
5a08cf3b;Konstantin Lopuhin;2016-09-02 00:22:22 +0300;Fix test_start_requests_errors for PyPy
Twisted prints errors in DebugInfo.__del__, but PyPy does not run
gc.collect() on exit:
http://doc.pypy.org/en/latest/cpython_differences.html?highlight=gc.collect#differences-related-to-garbage-collection-strategies

==

scrapy/cmdline.py
==================
f712513e;Pengyu CHEN;2017-06-15 10:41:02 +0800;Added doc for `scrapy.exceptions.DontCloseSpider`. Also fixes inaccurate doc for `scrapy.signals.spider_idle`.

==

docs/topics/exceptions.rst
docs/topics/signals.rst
==================
b33e0d5a;Pengyu CHEN;2017-06-14 12:17:20 +0800;Added: Now supporting <link> tags in Response.follow

==

scrapy/http/response/text.py
tests/test_http_response.py
==================
5aebdac4;Mikhail Korobov;2017-06-14 03:29:45 +0500;Merge pull request #2781 from crasker/patch-1
use suggest method instead of DEPRECATED one
==
==================
4e84424f;Mikhail Korobov;2017-06-14 03:28:31 +0500;Merge pull request #2777 from chuanjin/patch-1
Update extensions.rst
==
==================
ae679f64;Casker;2017-06-09 16:12:20 +0800;Create item-pipeline.rst

==

docs/topics/item-pipeline.rst
==================
39ad0d0b;Paul Tremberth;2017-06-06 10:48:30 +0200;Fix setting name reference

==

docs/topics/extensions.rst
==================
e7061f7a;Paul Tremberth;2017-06-06 10:47:43 +0200;Reformat a bit

==

docs/topics/extensions.rst
==================
3f8542eb;Chuan Jin;2017-06-05 23:31:37 +0200;Update extensions.rst
#2759
==

docs/topics/extensions.rst
==================
4b6f68b9;Valdir Stumm Junior;2017-06-05 17:26:52 -0300;make reqser tests create Request with proper callback/errback

==

tests/test_utils_reqser.py
==================
0f6f4867;Valdir Stumm Junior;2017-06-05 16:19:00 -0300;fix parse command issue with callback as a string

==

scrapy/commands/parse.py
==================
fad6b70d;Paul Tremberth;2017-06-01 16:37:28 +0200;Use https:// for readthedocs links

==

docs/intro/install.rst
docs/news.rst
docs/topics/commands.rst
docs/topics/deploy.rst
docs/topics/item-pipeline.rst
docs/topics/scrapyd.rst
docs/topics/spiders.rst
==================
6b092c66;Paul Tremberth;2017-06-01 12:29:01 +0200;Handle Twisted versions before 15.0

==

scrapy/core/downloader/handlers/http11.py
==================
e162c1ff;Paul Tremberth;2017-06-01 11:58:17 +0200;Pass proxy URI to ProxyAgent as bytes

==

scrapy/core/downloader/handlers/http11.py
==================
60727ded;Valdir Stumm Junior;2017-05-31 15:00:38 -0300;verify if Request callback is callable

==

scrapy/http/request/__init__.py
tests/test_http_request.py
==================
c8dc1586;Paul Tremberth;2017-05-30 17:22:23 +0200;Use HTTP pool and proper endpoint key for ProxyAgent

==

scrapy/core/downloader/handlers/http11.py
==================
5e1f7a9e;Mikhail Korobov;2017-05-30 00:50:32 +0500;DOC change "releases" section content

==

README.rst
==================
08388088;Mikhail Korobov;2017-05-30 00:44:11 +0500;DOC fixed rst syntax in DOWNLOAD_FAIL_ON_DATALOSS docs

==

docs/topics/settings.rst
==================
d847e65a;Paul Tremberth;2017-05-29 20:35:40 +0200;Merge pull request #2762 from stummjr/add-subreddit-to-docs
Include references to Scrapy subreddit in the docs
==
==================
80b160d0;Valdir Stumm Junior;2017-05-29 14:56:49 -0300;include references to scrapy subreddit in the docs

==

docs/contributing.rst
docs/index.rst
==================
af2963d0;Kurt Peek;2017-05-24 15:50:47 +0200;Update autothrottle.rst
Added missing bullet point for the AUTOTHROTTLE_TARGET_CONCURRENCY setting.
==

docs/topics/autothrottle.rst
==================
5f69ec98;Paul Tremberth;2017-05-18 23:01:05 +0200;Bump version: 1.3.2 → 1.4.0

==

.bumpversion.cfg
scrapy/VERSION
==================
fc2846d6;Paul Tremberth;2017-05-18 22:59:46 +0200;Set release date for v1.4.0

==

docs/news.rst
==================
79b0d860;Paul Tremberth;2017-05-18 22:57:51 +0200;Merge pull request #2630 from scrapy/release-notes-1.4.0
Release notes for 1.4.0
==
==================
76e5b0f6;Mikhail Korobov;2017-05-19 01:13:32 +0500;DOC 1.4 deprecations and backwards incompatible changes, add recent commits to news.

==

docs/news.rst
==================
edcde7a2;Mikhail Korobov;2017-05-18 23:11:34 +0500;DOC tweak release notes: promote response.follow, mention logging/stats changes

==

docs/news.rst
==================
a3d3cd4c;Paul Tremberth;2017-05-17 19:52:18 +0200;Update with latest merges

==

docs/news.rst
==================
432668ac;Paul Tremberth;2017-05-16 16:00:26 +0200;Mention implementation of #667

==

docs/news.rst
==================
896c30a8;Paul Tremberth;2017-05-12 19:39:31 +0200;Reference items pretty-printing issue number

==

docs/news.rst
==================
55d10823;Paul Tremberth;2017-05-11 14:25:11 +0200;Reference recent fixes and commits

==

docs/news.rst
==================
7d723947;Paul Tremberth;2017-05-10 18:55:09 +0200;Reword mention of new response.follow() shortcut

==

docs/news.rst
==================
c6464cc4;Paul Tremberth;2017-05-09 20:16:41 +0200;Add verbose introduction to new features

==

docs/news.rst
==================
e139d990;Paul Tremberth;2017-04-21 16:53:20 +0200;Fix sphinx-build warning on deprecated latex_paper_size

==

docs/Makefile
==================
cba55cd1;Paul Tremberth;2017-04-21 16:52:32 +0200;Rephrase other sections

==

docs/news.rst
==================
8729a91f;Paul Tremberth;2017-04-19 17:22:37 +0200;Rephrase "New features" section

==

docs/news.rst
docs/topics/media-pipeline.rst
docs/topics/request-response.rst
==================
851adced;Paul Tremberth;2017-03-06 23:36:21 +0100;List merged pull requests since 1.3.3

==

docs/news.rst
==================
0c237c6c;Paul Tremberth;2017-05-18 21:38:54 +0200;Merge pull request #2750 from scrapy/codecov
tweak coverage reports
==
==================
25f609e2;Daniel Graña;2017-05-18 16:34:02 -0300;Merge pull request #2675 from simongartz/png-p-to-jpg-conversion-fix
[MRG+1] Fixes conversion of transparent PNG with palette images to jpg #2452
==
==================
8aa2e4f9;Paul Tremberth;2017-05-18 21:32:51 +0200;Merge pull request #1829 from nyov/nyov/editor
[MRG+1] Remove dependency on os.environ from default settings
==
==================
b9d3b447;Daniel Graña;2017-05-18 16:31:01 -0300;Merge pull request #2670 from qhuang872/master
[MRG+1] Update spiders.rst
==
==================
14381041;Paul Tremberth;2017-05-18 21:30:19 +0200;Merge pull request #2740 from luzfcb/luzfcb-run-scrapy-from-module
[MRG+1] Add support for executing scrapy using -m option of python
==
==================
9ce03d09;Mikhail Korobov;2017-05-19 00:01:27 +0500;codecov config: disable project check, tweak PR comments

==

codecov.yml
==================
1a452c03;Bernardas;2017-05-18 16:57:13 +0000;increase ptpython priority since it can use other shells as backend

==

scrapy/utils/console.py
==================
532400f9;Mikhail Korobov;2017-05-17 15:46:33 +0500;Merge pull request #2643 from harshasrinivas/set-retry-times-per-request
[MRG+1] Add feature to set RETRY_TIMES per request (#2642)
==
==================
1acacab9;Mikhail Korobov;2017-05-17 13:48:00 +0500;Merge pull request #2741 from eliat123/2576_cleanup_MEMUSAGE_REPORT
[FIX #2576] cleanup: removed unused MEMUSAGE_REPORT
==
==================
73668ce4;Daniel Graña;2017-05-16 09:47:45 -0300;Merge pull request #2721 from HarrisonGregg/feature-drop-from-response-field
[MRG+1] Allow dropping field in from_response formdata
==
==================
b74b98fa;Eli Atzaba;2017-05-16 13:59:58 +0300;cleanup: removed unused MEMUSAGE_REPORT
Signed-off-by: Eli Atzaba <eliat123@gmail.com>

==

docs/topics/extensions.rst
docs/topics/settings.rst
scrapy/extensions/memusage.py
scrapy/settings/default_settings.py
==================
df7a5c4a;Fábio C. Barrionuevo da Luz;2017-05-15 22:52:23 -0300;Add support for executing scrapy using -m option of python
python -m scrapy
==

scrapy/__main__.py
==================
ffef828a;Harrison Gregg;2017-04-30 19:33:51 -0400;Add test for dropping fields in from_response request body

==

tests/test_http_request.py
==================
45a32302;Harrison Gregg;2017-04-30 19:14:47 -0400;Add documentation for dropping fields in from_response request body

==

docs/topics/request-response.rst
==================
26f723e4;Harrison Gregg;2017-04-30 19:07:29 -0400;Allow formdata value to be None to drop field generated from response

==

scrapy/http/request/form.py
==================
dfe6d3d5;Paul Tremberth;2017-05-12 18:12:48 +0200;Merge pull request #2456 from elacuesta/feed_export_beautify
[MRG+1] Feed exports: beautify JSON and XML
==
==================
3a0a86ed;Paul Tremberth;2017-05-12 17:26:17 +0200;Clarify FEED_EXPORT_INDENT section

==

docs/topics/feed-exports.rst
==================
25535dba;Eugenio Lacuesta;2017-05-10 16:45:15 -0300;Feed exports: edit note, fix typos

==

docs/topics/exporters.rst
docs/topics/feed-exports.rst
==================
548a4329;Kurt Peek;2017-05-05 13:03:56 +0200;Minor grammatical changes

==

docs/topics/logging.rst
==================
63b8caf5;Eugenio Lacuesta;2017-05-09 11:58:53 -0300;Feed exports: rewrite indentation test without .strip()

==

tests/test_feedexport.py
==================
f0122e2c;Mikhail Korobov;2017-05-08 16:24:18 +0500;Merge pull request #2729 from yandongxu/master
Fix doc: open file with "wb" mode will get an error in python 3
==
==================
4966dd7a;yandongxu;2017-05-08 18:50:30 +0800;Fix doc: open file with "wb" mode will get an error in python 3

==

docs/topics/item-pipeline.rst
==================
6c1cacb5;Liu Siyuan;2017-05-06 05:47:06 +0800;[MRG+1] doc: fix documentation error in link-extractor.rst (#2676)
* fix doc error in link-extractor.rst

* remove the import clause

* update based on suggestion

==

docs/topics/link-extractors.rst
==================
362d6f2d;Daniel Graña;2017-05-04 11:44:51 -0300;Merge pull request #2622 from rolando-contrib/download-maxsize-abort
[MRG+1] Abort connection earlier and avoid to buffer data when max size limit is reached
==
==================
7fc11c13;Mikhail Korobov;2017-04-28 02:58:46 +0500;Merge pull request #2720 from redapple/update-test-server-cert
Change "localhost" test server certificate
==
==================
6d14e392;Paul Tremberth;2017-04-27 23:35:01 +0200;Remove old test certificate+key

==

tests/keys/cert.pem
tests/mockserver.py
==================
e6ab8bc9;Paul Tremberth;2017-04-27 23:10:52 +0200;Change "localhost" test server certificate

==

tests/keys/localhost.crt
tests/keys/localhost.gen.README
tests/keys/localhost.key
tests/test_downloader_handlers.py
==================
2b34c6ed;Rolando Espinoza;2017-03-04 21:29:24 -0300;Abort connection earlier and avoid to buffer data
A symptom of this issue was having the log message "Received (X) bytes
larger than download max size (Y)" several times printed, with increased
X values.

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
==================
2d66c58e;Daniel Graña;2017-04-26 16:10:21 -0300;Merge pull request #2678 from redapple/double-content-length-0-post
Set bodyproducer with empty content for POST
==
==================
4bc0c6b0;Martín Gaitán;2017-04-25 22:33:22 -0300;Update practices.rst
fix a typo

==

docs/topics/practices.rst
==================
c3d0f9b6;Paul Tremberth;2017-04-25 17:03:41 +0200;Add test for non-duplicated `Content-Length: 0` for bodyless POST

==

tests/test_downloader_handlers.py
==================
a63d9f50;Paul Tremberth;2017-04-25 17:03:03 +0200;Restore comments on why POST needs `Content-Length: 0`

==

scrapy/core/downloader/handlers/http11.py
==================
b1a0a6e2;Paul Tremberth;2017-04-25 17:01:54 +0200;Make mockserver runnable outside of tox
Add POST support for Echo resource

==

tests/mockserver.py
==================
97fc68fa;Paul Tremberth;2017-04-24 22:08:39 +0200;Refactor conditions on body producer

==

scrapy/core/downloader/handlers/http11.py
==================
aa59cf42;Paul Tremberth;2017-04-24 12:35:40 +0200;Merge pull request #2668 from harshasrinivas/docs-sphinx-rtd-theme
[MRG+1] Add sphinx_rtd_theme to docs setup readme
==
==================
1e12187e;Paul Tremberth;2017-04-24 12:28:50 +0200;Merge pull request #2714 from tbcardoso/docs_disable_dupefilter
[MRG+1] Mention how to disable request filtering in documentation of DUPEFILTER_CLASS setting
==
==================
00ee9eae;Tiago Cardoso;2017-04-22 14:36:44 +0100;Mention how to disable request filtering in documentation of DUPEFILTER_CLASS setting

==

docs/topics/settings.rst
==================
3dee913d;Paul Tremberth;2017-04-22 01:00:51 +0200;Merge pull request #2713 from JulienPalard/master
[PEDANTIC] FIX trailing whitespaces in LICENSE.
==
==================
30eec559;Julien Palard;2017-04-22 00:24:18 +0200;[PEDANTIC] FIX trailing whitespaces in LICENSE.

==

LICENSE
==================
2d7f11ec;Paul Tremberth;2017-04-18 16:21:56 +0200;Merge pull request #2710 from redapple/travis-pypy-portable
Travis CI: use portable pypy for Linux
==
==================
9731077a;Mikhail Korobov;2017-04-12 21:25:00 +0500;Merge pull request #2683 from harshasrinivas/docs-SelectorList
[MRG+1] Remove __nonzero__ from SelectorList docs
==
==================
9e04e775;Mikhail Korobov;2017-04-12 21:24:25 +0500;Merge pull request #2705 from redapple/docs-selectors-sections
DOC Rearrange selector sections
==
==================
f3f7a418;Paul Tremberth;2017-04-12 16:32:21 +0200;Travis CI: use portable pypy for Linux

==

.travis.yml
==================
422b38f6;Paul Tremberth;2017-04-11 16:55:43 +0200;DOC Rearrange selector sections

==

docs/topics/selectors.rst
==================
25281915;Paul Tremberth;2017-04-05 16:21:57 +0200;Merge pull request #2695 from LMKight/command-list-fix
[MRG+1] command-list-fix
==
==================
05ce1296;LMKight;2017-04-03 19:47:01 +0200;changed code according to request

==

scrapy/cmdline.py
==================
6352c2e9;LMKight;2017-04-02 15:11:13 +0200;fixed command list

==

scrapy/cmdline.py
==================
8753b458;Mikhail Korobov;2017-03-29 15:43:48 +0500;Merge pull request #2690 from redapple/faq-py3-windows
FAQ Rewrite note on Python 3 support on Windows
==
==================
163618c9;Paul Tremberth;2017-03-29 12:02:44 +0200;FAQ Rewrite note on Python 3 support on Windows

==

docs/faq.rst
docs/intro/install.rst
==================
2ff6b057;harshasrinivas;2017-03-24 20:43:28 +0530;Remove __nonzero__ from SelectorList docs

==

docs/topics/selectors.rst
==================
34f4434b;Mikhail Korobov;2017-03-24 19:31:52 +0500;Merge pull request #2682 from harshasrinivas/compile-docs-open-webbrowser
[MRG+1] Update Makefile to open webbrowser in MacOS (#2661)
==
==================
0298bcbe;harshasrinivas;2017-03-24 18:13:08 +0530;Update Makefile to open webbrowser in MacOS (#2661)

==

docs/Makefile
==================
38e6857c;harshasrinivas;2017-03-23 19:45:04 +0530;Improvise the clarity of test cases

==

tests/test_downloadermiddleware_retry.py
==================
99e3c0d6;Paul Tremberth;2017-03-23 11:52:01 +0100;Set bodyproducer with empty content for POST

==

scrapy/core/downloader/handlers/http11.py
==================
21d794d3;Simon Diviani Gartz;2017-03-21 17:04:30 +0100;Fixes conversion of transparent PNG with palette images to jpg #2452

==

scrapy/pipelines/images.py
tests/test_pipeline_images.py
==================
b040df5a;Mikhail Korobov;2017-03-21 15:56:18 +0500;TST cleanup spider middleware tests

==

tests/test_spidermiddleware.py
==================
776129a9;Paul Tremberth;2017-03-21 10:51:31 +0100;Merge pull request #2649 from pawelmhm/logformatter-2647
[MRG+2] [logformatter] 'flags' format spec backward compatibility
==
==================
8ecc307e;Qiwei Huang;2017-03-20 19:37:07 -0700;Update spiders.rst
Added note to allowed_domain attribute with an example explaining what goes in the list
==

docs/topics/spiders.rst
==================
c5f74f7d;Qiwei Huang;2017-03-20 18:52:33 -0700;Update spiders.rst
Added a note to allowed_domains attribute, reminding users not to add urls into the list.
==

docs/topics/spiders.rst
==================
83aa0c5e;harshasrinivas;2017-03-20 22:36:09 +0530;Clarify docs readme

==

docs/README.rst
docs/requirements.txt
==================
4ec07ae7;harshasrinivas;2017-03-20 22:21:08 +0530;Create docs/requirements.txt

==

docs/README.rst
docs/requirements.txt
tox.ini
==================
a57e49d5;harshasrinivas;2017-03-20 19:49:31 +0530;Add sphinx_rtd_theme to docs setup readme

==

docs/README.rst
==================
11cf6ad4;Oto Brglez;2017-03-19 12:48:06 +0100;Comments for AWS_ENDPOINT_URL setting.

==

docs/topics/settings.rst
==================
60569179;Oto Brglez;2017-03-19 12:35:39 +0100;Updating media-pipeline docs for S3-like storage.

==

docs/topics/media-pipeline.rst
==================
10741aca;harshasrinivas;2017-03-19 06:17:28 +0530;Update docs - improve clarity

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
==================
0d9ebd6e;harshasrinivas;2017-03-19 06:15:46 +0530;Update tests for max_retry_times

==

tests/test_downloadermiddleware_retry.py
==================
49c5afc5;harshasrinivas;2017-03-19 06:08:35 +0530;Fix bug involving OR condition

==

scrapy/downloadermiddlewares/retry.py
==================
4345eaf1;Pawel Miech;2017-03-17 08:11:20 +0100;[logformatter] backward compat comments

==

scrapy/logformatter.py
tests/test_logformatter.py
==================
ec55799d;Mikhail Korobov;2017-03-16 15:31:28 +0500;Merge pull request #2616 from redapple/mediapipeline-redirect-fix-continued
[MRG] Allow redirections in media files downloads
==
==================
1c0da174;Paul Tremberth;2017-03-15 13:11:58 +0100;Merge pull request #2646 from woxcab/master
[MRG+1] Allowed passing objects of Mapping class or its subclass to the CaselessDict initializer
==
==================
a84652e7;woxcab;2017-03-15 12:39:48 +0300;Init tests are split by initializer' input

==

tests/test_utils_datatypes.py
==================
7ba4b0a2;Bernardas;2017-03-15 07:50:31 +0000;add support for embeded ptpython shell

==

scrapy/utils/console.py
==================
9d97d788;harshasrinivas;2017-03-15 04:13:47 +0530;Update docs for meta key

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
==================
e321ac99;harshasrinivas;2017-03-15 04:12:32 +0530;Update unittests for max_retry_times

==

tests/test_downloadermiddleware_retry.py
==================
966bd49c;harshasrinivas;2017-03-14 16:23:47 +0530;Update unittest for meta['max_retry_times']

==

tests/test_downloadermiddleware_retry.py
==================
694c6d3d;harshasrinivas;2017-03-14 16:14:40 +0530;Simplify retry_times assignment statement

==

scrapy/downloadermiddlewares/retry.py
==================
4e4395f1;Mikhail Korobov;2017-03-14 15:11:28 +0500;Merge pull request #2644 from delftswa2017/fsfilestore_fixme_fix
[MRG+1] Fixed the FIXME in FSFilesStore
==
==================
0f2a5cdb;Pawel Miech;2017-03-13 15:13:24 +0100;[logformatter] 'flags' format spec backward compatibility
pass 'flags' kwarg to logger so that it is compatible with old
format of CRAWLEDMSG.

==

scrapy/logformatter.py
tests/test_logformatter.py
==================
fbb411a8;woxcab;2017-03-13 14:16:39 +0300;Allowed passing objects of Mapping class or its subclass to the CaselessDict initializer

==

scrapy/utils/datatypes.py
tests/test_utils_datatypes.py
==================
3cd9185a;jorenham;2017-03-08 20:44:39 +0100;Fixed the FIXME; more specific exception catching

==

scrapy/pipelines/files.py
==================
0d57b5cd;harshasrinivas;2017-03-13 02:10:23 +0530;Prevent max_retry_times override

==

scrapy/downloadermiddlewares/retry.py
==================
871134ee;Paul Tremberth;2017-03-12 17:30:24 +0100;Refactor to also test FilesPipeline

==

tests/test_pipeline_crawl.py
==================
810658bc;harshasrinivas;2017-03-12 05:06:12 +0530;Add feature to set RETRY_TIMES per request (#2642)

==

scrapy/downloadermiddlewares/retry.py
==================
708f1b00;Paul Tremberth;2017-03-10 21:36:33 +0100;Add integration tests for MEDIA_ALLOW_REDIRECTS

==

tests/test_pipeline_crawl.py
==================
7dcc86e6;Paul Tremberth;2017-03-10 21:35:25 +0100;Add file listing resource + redirecting resource to MockServer

==

tests/mockserver.py
tests/sample_data/test_site/files/images/python-logo-master-v3-TM-flattened.png
tests/sample_data/test_site/files/images/python-powered-h-50x65.png
tests/sample_data/test_site/files/images/scrapy.png
==================
4cfbe820;Eugenio Lacuesta;2017-03-10 15:47:47 -0300;Downloader middleware: raise _InvalidOutput
Instead of AssertionError, to make it consistent with spider middleware

==

scrapy/core/downloader/middleware.py
==================
9c256cf6;Eugenio Lacuesta;2017-03-10 15:41:57 -0300;Undocument _InvalidOutput exception

==

docs/topics/exceptions.rst
scrapy/core/spidermw.py
scrapy/exceptions.py
tests/test_spidermiddleware.py
==================
cfb56400;Paul Tremberth;2017-03-10 17:15:26 +0100;Merge pull request #2641 from redapple/release-notes-1.3.3-master
Update release notes and versionadded for SPIDER_LOADER_WARN_ONLY
==
==================
a7f5207e;Paul Tremberth;2017-03-10 12:25:58 +0100;Update version added for SPIDER_LOADER_WARN_ONLY

==

docs/topics/settings.rst
==================
b2c505d8;Paul Tremberth;2017-03-10 16:29:44 +0100;Set release date in changelog for v1.3.3

==

docs/news.rst
==================
d8865b33;Paul Tremberth;2017-03-10 14:02:00 +0100;Update changelog for upcoming 1.3.3

==

docs/news.rst
==================
9c69e900;Mikhail Korobov;2017-03-09 23:01:27 +0500;Merge pull request #2632 from redapple/spider-loader-warn-or-fail
[MRG] Add SPIDER_LOADER_WARN_ONLY to toggle between spiderloader failure or warning
==
==================
9628a739;Paul Tremberth;2017-03-09 17:40:34 +0100;Update settings docs for new SPIDER_LOADER_WARN_ONLY

==

docs/topics/settings.rst
==================
f2ac24eb;Paul Tremberth;2017-03-09 17:38:15 +0100;Do not only warn on wrong spider modules for "scrapy list"

==

scrapy/commands/list.py
==================
36160f1b;Paul Tremberth;2017-03-09 12:56:50 +0100;Merge pull request #2477 from scrapy/recommend-anaconda-for-win
[MRG+2] docs: installation instructions, mention conda in the beginning (closes #2475)
==
==================
c0cbaccb;Paul Tremberth;2017-03-09 12:47:20 +0100;Merge pull request #2581 from lopuhin/respect-custom-log-level
[MRG+1] Respect custom log level: fixes GH-1612
==
==================
db13ab5e;Paul Tremberth;2017-03-09 12:44:10 +0100;Merge pull request #2611 from delftswa2017/httpcachemiddleware_log
[MRG+1] [logging] HttpCacheMiddleware: log cache directory at instantiation
==
==================
c5e193d0;Paul Tremberth;2017-03-09 12:42:59 +0100;Merge pull request #2636 from delftswa2017/contrib_docs_fix
[MRG+1] Removed contrib section in contribution documentation
==
==================
9cfe9ae0;Paul Tremberth;2017-03-09 12:21:03 +0100;Do not use self.assertRaises() as context manager

==

tests/test_spiderloader/__init__.py
==================
ac63d3a3;jorenham;2017-03-09 10:56:23 +0100;Removed contrib section; contrib is deprecated

==

docs/contributing.rst
==================
4090cc39;Eugenio Lacuesta;2017-03-08 18:11:20 -0300;Spider middleware: use Mockserver to test process_spider_exception

==

tests/test_spidermiddleware.py
==================
7be773e1;Paul Tremberth;2017-03-07 17:40:40 +0100;Add SPIDER_LOADER_WARN_ONLY to toggle between spiderloader failure and warning

==

scrapy/commands/list.py
scrapy/commands/runspider.py
scrapy/commands/settings.py
scrapy/commands/startproject.py
scrapy/commands/version.py
scrapy/settings/default_settings.py
scrapy/spiderloader.py
tests/test_spiderloader/__init__.py
==================
d3f8f3d3;Mikhail Korobov;2017-03-07 20:08:42 +0500;Merge pull request #2612 from redapple/dupe-spider-name-tests
[WIP] Add warning on duplicate spider name
==
==================
c7bb2fa8;Eugenio Lacuesta;2017-03-07 11:55:26 -0300;Feed exports: consistent and backwards compatible behaviour on indent

==

docs/topics/exporters.rst
docs/topics/feed-exports.rst
scrapy/exporters.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
766b2c84;Eugenio Lacuesta;2017-02-23 10:21:33 -0300;Feed exports: enforce difference between None and 0 on indent
Also rename params and settings from "indent_width" to just "indent"

==

docs/topics/exporters.rst
docs/topics/feed-exports.rst
scrapy/exporters.py
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
7e9153b3;Eugenio Lacuesta;2016-12-19 10:43:04 -0300;Feed exports: beautify JSON and XML

==

docs/topics/exporters.rst
docs/topics/feed-exports.rst
scrapy/exporters.py
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
0b9a18e1;Paul Tremberth;2017-03-07 15:41:17 +0100;Warn only once for all spiders

==

scrapy/spiderloader.py
tests/test_spiderloader/__init__.py
==================
978306a2;Paul Tremberth;2017-03-07 14:48:16 +0100;Fix dupe spider name warning string tests

==

tests/test_spiderloader/__init__.py
==================
a017f7b9;Paul Tremberth;2017-03-07 14:44:27 +0100;Warn about modules where duplicate spider names were found

==

scrapy/spiderloader.py
==================
802ed30e;Mikhail Korobov;2017-03-07 16:56:54 +0500;Merge pull request #2391 from redapple/always-gunzip-content-enc-gzip
[MRG] Always decompress Content-Encoding: gzip at HttpCompression stage
==
==================
b6378c7e;Paul Tremberth;2017-03-07 12:28:24 +0100;Revert to using self.assert methods

==

tests/test_downloadermiddleware_httpcompression.py
==================
6f55ca46;Konstantin Lopuhin;2017-03-07 14:20:52 +0300;Revert unneeded test_crawl changes

==

tests/test_crawl.py
==================
4caceccd;Paul Tremberth;2017-03-07 10:51:34 +0100;Use 3-bytes for gzip archive type sniffing

==

scrapy/utils/gz.py
==================
b174744b;Paul Tremberth;2016-11-10 10:50:34 +0100;Do not silently fail on gzip unzipping

==

scrapy/downloadermiddlewares/httpcompression.py
scrapy/spiders/sitemap.py
==================
11cdf58a;Paul Tremberth;2016-11-09 23:08:23 +0100;Always decompress Content-Encoding: gzip at HttpCompression stage
Let SitemapSpider handle decoding of .xml.gz files if necessary

==

scrapy/downloadermiddlewares/httpcompression.py
scrapy/spiders/sitemap.py
scrapy/utils/gz.py
tests/test_downloadermiddleware_httpcompression.py
tests/test_spider.py
==================
6320b743;Mikhail Korobov;2017-03-07 13:23:35 +0500;Merge pull request #2393 from redapple/response-replace-encoding
[MRG] Use body to choose response type after decompression content
==
==================
e42b846a;Paul Tremberth;2016-11-10 16:26:55 +0100;Use body to chose response type after decompression content

==

scrapy/downloadermiddlewares/httpcompression.py
tests/test_downloadermiddleware_httpcompression.py
==================
451f1474;Mikhail Korobov;2017-03-06 22:16:21 +0500;Merge pull request #2628 from redapple/brotli-docs
DOC Mention brotli support in HttpCompressionMiddleware section
==
==================
20c4f9f4;Mikhail Korobov;2017-03-06 21:44:08 +0500;Merge pull request #2627 from redapple/referrer-empty-string-header
Fix referrer policy from response headers and support explicit empty string
==
==================
2a7d391e;Paul Tremberth;2017-03-06 17:30:32 +0100;DOC Mention brotli support in HttpCompressionMiddleware section

==

docs/topics/downloader-middleware.rst
==================
768f3155;Paul Tremberth;2017-03-06 16:20:37 +0100;Fix referrer policy from response headers and support explicit empty string

==

scrapy/spidermiddlewares/referer.py
tests/test_spidermiddleware_referer.py
==================
d7b26edf;Paul Tremberth;2017-03-06 14:47:01 +0100;Merge pull request #2625 from redapple/release-notes-packaging-fix
Update release notes for 1.0.7, 1.1.4 and 1.2.3
==
==================
a8b47d6c;Paul Tremberth;2017-03-06 14:25:52 +0100;Update release notes for 1.0.7, 1.1.4 and 1.2.3

==

docs/news.rst
==================
0a17f9b5;Paul Tremberth;2017-03-06 13:50:46 +0100;Merge pull request #2334 from ArturGaspar/data_uri
[MRG+1] data URI download handler.
==
==================
2c5fa0c1;Mikhail Korobov;2017-03-03 21:44:07 +0500;Merge pull request #2617 from redapple/engine-dupe-statement
Remove redundant slot.add_request() call in ExecutionEngine
==
==================
30d812ee;Paul Tremberth;2017-03-03 17:15:37 +0100;Remove redundant slot.add_request() call in ExecutionEngine

==

scrapy/core/engine.py
==================
c68f99ee;Paul Tremberth;2017-03-03 17:03:25 +0100;Refactor settings tests

==

tests/test_pipeline_media.py
==================
c3b6feca;Paul Tremberth;2017-03-03 16:29:07 +0100;Fix setting lookup for MEDIA_ALLOWED_REDIRECTS

==

scrapy/pipelines/media.py
==================
ef04cfd2;Konstantin Lopuhin;2017-02-21 19:55:52 +0300;Respect log settings in custom_settings: fixes GH-1612
A new root logger is installed when a crawler is created
if one was already installed before.
This allows to respect custom settings related to logging,
such as LOG_LEVEL, LOG_FILE, etc.

==

scrapy/crawler.py
scrapy/utils/log.py
tests/test_crawl.py
tests/test_crawler.py
==================
f7e11b19;Paul Tremberth;2017-03-03 16:00:59 +0100;Cleanup

==

scrapy/pipelines/media.py
tests/test_pipeline_media.py
==================
ecde166e;Paul Tremberth;2017-03-03 15:50:34 +0100;Refactor without MEDIA_HTTPSTATUS_LIST setting

==

docs/topics/media-pipeline.rst
scrapy/pipelines/media.py
tests/test_pipeline_media.py
==================
72fbb687;Paul Tremberth;2017-03-03 12:31:05 +0100;Revert "expose allowed_status tuple for media pipeline"
This reverts commit 052809c73ed20b9a728a8fd7df3de5f45f2dad8d.

==

scrapy/downloadermiddlewares/redirect.py
==================
c64ebee0;Paul Tremberth;2017-03-02 22:40:10 +0100;Refactor (WIP)

==

scrapy/pipelines/media.py
==================
11b31c9f;Bernardas;2016-08-24 08:44:56 +0000;fix redirect change

==

tests/test_pipeline_media.py
==================
3cef1cd4;Bernardas;2016-08-24 08:40:46 +0000;adjust variable wording and redirect logic

==

scrapy/pipelines/media.py
tests/test_pipeline_media.py
==================
f0b4077f;Bernardas;2016-08-24 08:39:30 +0000;expose allowed_status tuple for media pipeline

==

scrapy/downloadermiddlewares/redirect.py
==================
2e052c86;Bernardas;2016-08-23 17:13:09 +0000;fix error when settings are not provided

==

scrapy/pipelines/media.py
==================
85427808;Bernardas;2016-08-23 17:09:43 +0000;typo and clarify handling

==

docs/topics/media-pipeline.rst
==================
6a422147;Bernardas;2016-08-23 16:56:31 +0000;add tests for media pipeline MEDIA_ALLOW_REDIRECTS and MEDIA_HTTPSTATUS_LIST settings

==

tests/test_pipeline_media.py
==================
25ed4912;Bernardas;2016-08-23 16:55:34 +0000;add description for media pipeline MEDIA_ALLOW_REDIRECTS and MEDIA_HTTPSTATUS_LIST settings

==

docs/topics/media-pipeline.rst
==================
5d005849;Bernardas;2016-08-23 16:54:10 +0000;add media pipeline settings to enable redirection and handling of certain http statuses

==

scrapy/pipelines/files.py
scrapy/pipelines/media.py
==================
5e89db54;jorenham;2017-03-03 15:32:20 +0100;Moved cache dir logging to `open_spider` in FilesystemCacheStorage for consistency

==

scrapy/extensions/httpcache.py
==================
42b429dc;jorenham;2017-03-03 15:15:59 +0100;Log full cache file path instead of cache directory for the storages that cache to single files.

==

scrapy/extensions/httpcache.py
==================
7e8453cf;Mikhail Korobov;2017-03-03 04:05:13 +0500;Merge pull request #2306 from redapple/referrer-policy
[MRG] Referrer policies in RefererMiddleware
==
==================
fad499ab;Paul Tremberth;2017-03-02 23:06:04 +0100;Rename arguments (bis)

==

scrapy/spidermiddlewares/referer.py
==================
db176f87;Paul Tremberth;2017-03-02 22:56:23 +0100;Remove Legacy Policy which is equivalent to UnsafeUrl Policy

==

scrapy/spidermiddlewares/referer.py
==================
93024c24;Mikhail Korobov;2017-03-03 02:53:36 +0500;Merge pull request #2537 from scrapy/no-canonicalize
[MRG+1] Set canonicalize=False for LinkExtractor
==
==================
c2c50319;Paul Tremberth;2017-03-02 22:53:27 +0100;Rename arguments

==

scrapy/spidermiddlewares/referer.py
==================
b50d0370;Artur Gaspar;2017-03-02 14:46:33 -0300;Test response attributes in data URI download handler.

==

tests/test_downloader_handlers.py
==================
f96490df;jorenham;2017-03-02 16:17:51 +0100;Move cache storage logging to the individual storage classes

==

scrapy/downloadermiddlewares/httpcache.py
scrapy/extensions/httpcache.py
==================
12a8ddec;Paul Tremberth;2017-03-02 13:03:18 +0100;Fix tests

==

tests/test_spiderloader/__init__.py
==================
e71803c8;Paul Tremberth;2016-11-23 11:52:02 +0100;Add tests for duplicate spider name warnings

==

tests/test_spiderloader/__init__.py
==================
5be5ef57;Paul Tremberth;2016-11-23 11:01:31 +0100;Remove extra blank line

==

scrapy/spiderloader.py
==================
6abd9ba8;Erick;2016-10-21 18:24:59 -0300;Fix warning to duplicated spider. Issue 2181

==

scrapy/spiderloader.py
==================
f3b75c94;MrMenezes;2016-10-21 18:02:16 -0300;Fix warning to duplicated spider. Issue 2181

==

scrapy/spiderloader.py
==================
97d84d92;jorenham;2017-03-02 11:04:16 +0100;Logging the cache directory at HttpCacheMiddleware instantiation #2604

==

scrapy/downloadermiddlewares/httpcache.py
==================
a70ec30e;Oto Brglez;2017-03-01 23:02:42 +0100;Adding new options.

==

scrapy/pipelines/files.py
==================
2d55d838;Paul Tremberth;2017-03-01 20:59:52 +0100;Fix strip_url() tests

==

tests/test_utils_url.py
==================
efa50039;Paul Tremberth;2017-03-01 17:43:47 +0100;Add tests for policy fallback on unknown policies from meta and headers

==

tests/test_spidermiddleware_referer.py
==================
6916dd62;Paul Tremberth;2017-03-01 17:42:46 +0100;Warn or fail with exception on unknown policies

==

scrapy/spidermiddlewares/referer.py
==================
8226e770;Paul Tremberth;2017-03-01 12:41:33 +0100;Add test for Referer header on HTTP redirections

==

scrapy/spidermiddlewares/referer.py
tests/test_spidermiddleware_referer.py
==================
d2aa51c0;Paul Tremberth;2017-02-27 16:05:22 +0100;Update tests

==

tests/test_spidermiddleware_referer.py
==================
04e4d086;Paul Tremberth;2017-02-27 16:04:37 +0100;Pass URLs around instead of Request/Responses

==

scrapy/spidermiddlewares/referer.py
scrapy/utils/url.py
==================
bc200d11;Paul Tremberth;2017-02-21 17:08:39 +0100;Rename setting to REFERRER_POLICY (with 2 Rs)

==

docs/topics/spider-middleware.rst
scrapy/settings/default_settings.py
scrapy/spidermiddlewares/referer.py
tests/test_spidermiddleware_referer.py
==================
537683f9;Paul Tremberth;2017-02-21 16:47:57 +0100;Add autoclass directives to document built-in policies

==

docs/topics/spider-middleware.rst
scrapy/spidermiddlewares/referer.py
==================
3dc09eec;Paul Tremberth;2017-01-30 15:25:49 +0100;Use table for referrer policy options

==

docs/topics/spider-middleware.rst
==================
605935f0;Paul Tremberth;2017-01-26 12:09:34 +0100;Edit text

==

docs/topics/spider-middleware.rst
==================
eb07285a;Paul Tremberth;2017-01-18 17:20:35 +0100;Reword warning on no-referrer-when-downgrade policy

==

docs/topics/spider-middleware.rst
==================
03ff19d1;Paul Tremberth;2017-01-18 16:29:20 +0100;Update docs for new "referrer_policy" Request.meta key

==

docs/topics/request-response.rst
docs/topics/spider-middleware.rst
==================
e249abc3;Paul Tremberth;2017-01-18 15:48:28 +0100;Update docs

==

docs/topics/spider-middleware.rst
==================
c86f568b;Paul Tremberth;2017-01-17 22:31:29 +0100;Update docs with "strict-..." policies

==

docs/topics/spider-middleware.rst
==================
b6c761d2;Paul Tremberth;2017-01-17 17:57:17 +0100;Fix tests

==

scrapy/spidermiddlewares/referer.py
tests/test_spidermiddleware_referer.py
==================
ebcacd3f;Paul Tremberth;2017-01-17 17:18:00 +0100;Update StrictOriginPolicy

==

scrapy/spidermiddlewares/referer.py
==================
deb85671;Paul Tremberth;2017-01-17 16:22:49 +0100;Update NoReferrerWhenDowngradePolicy

==

scrapy/spidermiddlewares/referer.py
==================
77aec5a7;Paul Tremberth;2017-01-17 14:19:19 +0100;Fix implementation

==

scrapy/spidermiddlewares/referer.py
==================
5cef67ae;Paul Tremberth;2017-01-17 14:18:33 +0100;Update Referrer tests for "strict-" policies

==

tests/test_spidermiddleware_referer.py
==================
c808a97c;Paul Tremberth;2017-01-12 18:22:18 +0100;Add new "strict-" policies

==

scrapy/spidermiddlewares/referer.py
==================
0a0b60a5;Paul Tremberth;2016-10-26 12:41:00 +0200;Add tests for stripping userinfo with percent-encoded delimiters

==

tests/test_utils_url.py
==================
8864d0e8;Paul Tremberth;2016-10-24 18:21:49 +0200;Rename helper function to strip_url() + add more tests

==

scrapy/spidermiddlewares/referer.py
scrapy/utils/url.py
tests/test_utils_url.py
==================
5dd7311c;Paul Tremberth;2016-10-19 14:45:33 +0200;Move URL credentials stripping to a helper function

==

scrapy/spidermiddlewares/referer.py
scrapy/utils/url.py
tests/test_utils_url.py
==================
c9c59db4;Paul Tremberth;2016-10-12 18:29:47 +0200;Update documentation about REFERER_POLICY setting

==

docs/topics/spider-middleware.rst
==================
285d5bc0;Paul Tremberth;2016-10-12 17:34:12 +0200;Patch "Referer" header on HTTP redirects if necessary

==

scrapy/spidermiddlewares/referer.py
==================
d3d4d66c;Paul Tremberth;2016-10-12 16:30:25 +0200;Add tests for referrer-policy set in response HTTP headers

==

tests/test_spidermiddleware_referer.py
==================
e50e670e;Paul Tremberth;2016-10-12 16:16:53 +0200;Add test for custom referrer policy via settings

==

scrapy/spidermiddlewares/referer.py
tests/test_spidermiddleware_referer.py
==================
ec8b4c1a;Paul Tremberth;2016-10-11 20:00:34 +0200;Change __init__ default "settings" arg handling

==

scrapy/spidermiddlewares/referer.py
==================
0344f57f;Paul Tremberth;2016-10-11 19:53:15 +0200;Support case-insensitive policy names in settings

==

scrapy/spidermiddlewares/referer.py
tests/test_spidermiddleware_referer.py
==================
e72b6e33;Paul Tremberth;2016-10-11 18:27:56 +0200;Add tests for referrer policy via settings and via Request meta

==

tests/test_spidermiddleware_referer.py
==================
842ce131;Paul Tremberth;2016-10-11 18:27:31 +0200;Make default referrer policy customizable via settings

==

scrapy/settings/default_settings.py
scrapy/spidermiddlewares/referer.py
==================
f6205778;Paul Tremberth;2016-10-05 19:06:26 +0200;Refactor ReferrerPolicy methods

==

scrapy/spidermiddlewares/referer.py
==================
f6a800fd;Paul Tremberth;2016-10-05 18:55:35 +0200;Remove all non-cached urlparsing references

==

scrapy/spidermiddlewares/referer.py
==================
59cb884a;Paul Tremberth;2016-10-05 18:44:46 +0200;Use urlparse_cached() for OriginWhenCrossOriginPolicy

==

scrapy/spidermiddlewares/referer.py
==================
f2ee6be3;Paul Tremberth;2016-10-05 18:33:31 +0200;Use urlparse_cached() for OriginPolicy

==

scrapy/spidermiddlewares/referer.py
==================
3af88a28;Paul Tremberth;2016-10-05 18:27:18 +0200;Use urlparse_cached() on request and responses

==

scrapy/spidermiddlewares/referer.py
==================
7ec1b5f6;Paul Tremberth;2016-10-05 17:12:44 +0200;Add tests for the different referrer policies

==

scrapy/spidermiddlewares/referer.py
tests/test_spidermiddleware_referer.py
==================
baed7c43;Paul Tremberth;2016-10-05 11:18:26 +0200;WIP Add Referrer policies

==

scrapy/spidermiddlewares/referer.py
tests/test_spidermiddleware_referer.py
==================
7b49b9c0;Mikhail Korobov;2017-03-01 20:23:19 +0500;Merge pull request #2590 from rolando-contrib/handle-data-loss-gracefully
[MRG+2] Handle data loss gracefully.
==
==================
706ed0e0;Eugenio Lacuesta;2016-06-14 12:34:07 -0300;Spider middleware: process_spider_exception on generators

==

docs/topics/exceptions.rst
docs/topics/spider-middleware.rst
scrapy/core/spidermw.py
scrapy/exceptions.py
tests/test_spidermiddleware.py
==================
f01ae6ff;Rolando Espinoza;2017-02-23 11:42:34 -0400;Handle data loss gracefully.
Websites that return a wrong ``Content-Length`` header may cause a data
loss error. Also when a chunked response is not finished properly.

This change adds a new setting ``DOWNLOAD_FAIL_ON_DATALOSS`` (default:
``True``) and request.meta key ``download_fail_on_dataloss``.

==

docs/topics/request-response.rst
docs/topics/settings.rst
scrapy/core/downloader/handlers/http11.py
scrapy/settings/default_settings.py
tests/test_downloader_handlers.py
==================
2f28cb3b;Paul Tremberth;2017-03-01 12:51:12 +0100;Merge pull request #2587 from MikeinRealLife/documentation_update
[MRG+1] Document ftp_user and ftp_password meta keys
==
==================
0e5ed213;Mikhail Korobov;2017-02-28 15:39:42 +0500;Merge pull request #2599 from redapple/py3-ignores-cleanup-ftp
Fix FTP downloader and re-enable FTP tests on Python 3
==
==================
0b90c3b4;Paul Tremberth;2017-02-27 17:42:00 +0100;Re-enable FTP tests on Python 3

==

scrapy/core/downloader/handlers/ftp.py
tests/py3-ignores.txt
tests/test_downloader_handlers.py
==================
c72ba073;Mikhail Korobov;2017-02-27 21:03:35 +0500;Merge pull request #2543 from scrapy/retry-stats
[MRG+1] Retry stats
==
==================
9a5479cb;Konstantin Lopuhin;2017-02-26 14:15:05 +0400;Merge pull request #2596 from arvindch/patch-1
Use single quotes uniformly
==
==================
e85f0db1;Arvind Chembarpu;2017-02-25 16:48:17 +0530;Use single quotes uniformly
The default spider template mixes single and double quotes.
==

scrapy/templates/spiders/basic.tmpl
==================
d6a8288a;Mikhail Korobov;2017-02-25 13:12:21 +0500;Merge pull request #2595 from Lodour/master
Add omitted "self" arguments
==
==================
4274f0d4;mangogao;2017-02-25 15:44:20 +0800;Add omitted "self" arguments
“self” argument is omitted in some methods.

==

scrapy/templates/project/module/middlewares.py.tmpl
==================
441f2550;MikeinRealLife;2017-02-22 21:23:27 -0800;fixed typo
removed duplicate line

==

docs/topics/request-response.rst
==================
96a570a9;MikeinRealLife;2017-02-22 21:17:34 -0800;fixed ticket #2574

==

docs/topics/request-response.rst
==================
3139f4a5;Artur Gaspar;2017-02-12 11:23:56 -0200;Add data URI download handler to settings.

==

scrapy/settings/default_settings.py
==================
121a668a;Artur Gaspar;2017-02-12 11:23:21 -0200;Rename data URI downloader module.

==

scrapy/core/downloader/handlers/datauri.py
tests/test_downloader_handlers.py
==================
c847e7d4;Artur Gaspar;2017-02-08 12:38:49 -0200;Use w3lib data URI parser.

==

scrapy/core/downloader/handlers/data.py
==================
3397d275;Artur Gaspar;2017-02-08 12:32:00 -0200;Test for binary body content from data URI downloader.

==

tests/test_downloader_handlers.py
==================
7e9f2c31;Artur Gaspar;2016-08-12 02:09:35 -0300;Ensure bytes objects when needed in data URI downloader.

==

scrapy/core/downloader/handlers/data.py
==================
d60642e1;Artur Gaspar;2016-08-12 00:45:42 -0300;data URI download handler.

==

scrapy/core/downloader/handlers/data.py
tests/test_downloader_handlers.py
==================
ce8a9aad;Mikhail Korobov;2017-02-22 18:55:42 +0500;Merge pull request #2566 from scrapy/httperror-stats
[MRG+1] HttpErrorMiddleware stats
==
==================
26c1256f;Mikhail Korobov;2017-02-16 03:11:28 +0500;HttpErrorMiddleware stats

==

scrapy/spidermiddlewares/httperror.py
tests/test_spidermiddleware_httperror.py
==================
cac51190;Mikhail Korobov;2017-02-21 13:51:36 +0500;Merge pull request #2577 from redapple/cleanup-ctxfactory
Set context factory implementation based on Twisted version
==
==================
565d1ca7;Mikhail Korobov;2017-02-21 02:44:36 +0600;Merge pull request #2495 from redapple/proxy-connect-headers-buffer
[MRG] Buffer CONNECT response bytes from proxy until all HTTP headers are received
==
==================
2b4d4631;Mikhail Korobov;2017-02-21 00:05:40 +0500;TST fixed compatibility with new link extractor whitespace handling

==

tests/test_http_response.py
tests/test_linkextractors.py
tests/test_linkextractors_deprecated.py
==================
df446d16;Mikhail Korobov;2017-02-07 03:11:59 +0500;fix deprecated link extractors

==

scrapy/linkextractors/sgml.py
tests/test_linkextractors_deprecated.py
==================
47f7da87;Mikhail Korobov;2017-02-07 02:03:26 +0500;canonicalize=False by default for LinkExtractor. Fixes GH-1941.

==

docs/topics/link-extractors.rst
scrapy/linkextractors/lxmlhtml.py
tests/sample_data/link_extractor/sgml_linkextractor.html
tests/test_linkextractors.py
==================
bb7d99ed;Mikhail Korobov;2017-02-07 01:30:45 +0500;drop unneeded urlparse call

==

scrapy/linkextractors/__init__.py
==================
93e449f1;Mikhail Korobov;2017-02-20 23:19:54 +0600;Merge pull request #2343 from redapple/anonymous-ftp
[MRG+1] Support Anonymous FTP
==
==================
f3a75674;Paul Tremberth;2017-02-20 17:15:05 +0100;Add note on FTP_PASSWORD default value

==

docs/topics/settings.rst
==================
301847d8;Paul Tremberth;2017-02-20 16:40:37 +0100;Set context factory implementation based on Twisted version

==

scrapy/core/downloader/contextfactory.py
==================
adb180fb;Paul Tremberth;2017-02-20 16:25:12 +0100;Use bytearray for the CONNECT message bytes buffer

==

scrapy/core/downloader/handlers/http11.py
==================
1d80efde;Paul Tremberth;2017-02-20 16:15:05 +0100;Merge pull request #2159 from scrapy/remove-prerelease-configuration
[MRG+1] Remove bumpversion prerelease configuration
==
==================
ff3e299e;Omer Schleifer;2017-02-20 16:42:29 +0200;[MRG+2] add flags to request (#2082)
* add flags to request

* fxi test - add flags to request

* fix test(2) - add flags to request

* fix test(2) - add flags to request

* Updated test to reqser with flags field of request

* Updated documntation with flags field of request

* fix test identation

* fix test failed

* make the change backward comptaible

* remove  unrequired  spaces, fix documentation request flags

* remove  unrequired  space

* fx assert equal

* flags default is empty list

* Add flags to request

* add flags to request

* fxi test - add flags to request

* fix test(2) - add flags to request

* fix test(2) - add flags to request

* Updated test to reqser with flags field of request

* Updated documntation with flags field of request

* fix test identation

* fix test failed

* make the change backward comptaible

* remove  unrequired  spaces, fix documentation request flags

* remove  unrequired  space

* fx assert equal

* flags default is empty list

* add flags to request squashed commits

==

docs/topics/request-response.rst
scrapy/http/request/__init__.py
scrapy/logformatter.py
scrapy/utils/reqser.py
tests/test_logformatter.py
tests/test_utils_reqser.py
==================
b0388e49;Daniel Graña;2017-02-20 11:23:49 -0300;Merge pull request #1728 from scrapy/deprecate-make-requests-from-url
deprecate Spider.make_requests_from_url. 
==
==================
c68140e6;Daniel Graña;2017-02-20 11:21:21 -0300;Merge pull request #2540 from scrapy/response-follow
response.follow
==
==================
377db31a;Daniel Graña;2017-02-20 11:18:48 -0300;Merge pull request #2557 from scrapy/gitignore
add a couple more lines to gitignore
==
==================
e578be73;Daniel Graña;2017-02-20 11:18:04 -0300;Merge pull request #2539 from scrapy/enable-memusage
Enable memusage extension by default.
==
==================
4a1b88fe;Paul Tremberth;2017-02-20 15:16:40 +0100;Merge pull request #2567 from scrapy/no-py3-badge
remove “Python 3 progress” badge
==
==================
b15b4541;Daniel Graña;2017-02-20 11:15:21 -0300;Merge pull request #2569 from scrapy/fix-project-util-test-osx
TST fixed ProjectUtilsTest on OS X
==
==================
fab168bb;Daniel Graña;2017-02-20 11:14:28 -0300;Merge pull request #2572 from advarisk/warning-formrequest-from-response
[MRG+1] document issue with FormRequest.from_response due to bug in lxml
==
==================
85ef6a62;Daniel Graña;2017-02-20 11:12:48 -0300;Merge pull request #2564 from elacuesta/docs_exporters
[MRG+1] Doc: binary mode is required for exporters
==
==================
b2d66dc1;Daniel Graña;2017-02-20 11:12:10 -0300;Merge pull request #2562 from terut/feature/build_request
[MRG+1] Separate building request from _requests_to_follow in CrawlSpider
==
==================
322fd68e;Daniel Graña;2017-02-20 11:09:50 -0300;Merge pull request #2548 from scrapy/formrequest-whitespaces
[MRG+1] FormRequest: handle whitespaces in action attribute properly
==
==================
4a93be4a;Daniel Graña;2017-02-20 11:08:32 -0300;Merge pull request #2547 from scrapy/linkextractor-strip-whitespaces
[MRG+1] LinkExtractors: strip whitespaces
==
==================
58a18e30;Daniel Graña;2017-02-20 11:04:55 -0300;Merge pull request #2535 from pawelmhm/brotli
[MRG+1] [httpcompression] add support for br - brotli content encoding
==
==================
7ad51562;Mikhail Korobov;2017-02-20 20:00:32 +0600;Merge pull request #2570 from scrapy/tests-cleanup-resources
[MRG+1] TST remove temp files and folders
==
==================
f2e20012;Paul Tremberth;2017-02-20 14:50:05 +0100;Explicitly remove test directories in FTP tests

==

tests/test_downloader_handlers.py
==================
d35a01a1;Paul Tremberth;2017-02-20 14:23:23 +0100;Update default password

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
b80e1bb6;Paul Tremberth;2016-10-24 15:08:24 +0200;Document new FTP_* settings

==

docs/topics/settings.rst
==================
565baae1;Paul Tremberth;2016-10-24 15:07:55 +0200;Change FTP_* settings names

==

scrapy/core/downloader/handlers/ftp.py
scrapy/settings/default_settings.py
==================
26b7c039;Paul Tremberth;2016-10-20 18:06:59 +0200;Remove debug print statement

==

tests/test_downloader_handlers.py
==================
3ffa2c57;Paul Tremberth;2016-10-20 18:01:50 +0200;Support Anonymous FTP
Fixes GH-2342

==

scrapy/core/downloader/handlers/ftp.py
scrapy/settings/default_settings.py
tests/test_downloader_handlers.py
==================
165e2cb8;Ashish Kulkarni;2017-02-17 14:54:22 +0530;document issue with FormRequest.from_response due to bug in lxml
This can make the spider fail due to incorrect values being posted
server-side, which is extremely hard to debug because it is easy
to miss leading/trailing whitespace, even with a logging proxy.

The fix was merged for lxml 3.8 in lxml/lxml#228 so document that
as well.

==

docs/topics/request-response.rst
==================
5adacc4d;Mikhail Korobov;2017-02-17 02:35:02 +0500;fixed method override check in Python 2

==

scrapy/spiders/__init__.py
scrapy/utils/deprecate.py
==================
a1e8a852;Mikhail Korobov;2017-02-17 00:18:29 +0500;fix make_requests_from_url deprcation implementation, add tests

==

scrapy/spiders/__init__.py
tests/test_spider.py
==================
78cb46a0;Mikhail Korobov;2017-02-16 18:22:04 +0500;TST fix a weird OS X testing issue
pytest intercepts temp file creation to provide readable file/folder
names; path is built from method name; in case of conflicts
pytests uses increasing numbers, but it seems it doesn’t account
for case-insensitive (but case preserving) OS X filesystem. There
are methods named test_encoding, pytest thinks test_Encoding is
different and fails to create a test folder

==

tests/test_webclient.py
==================
b9928558;Mikhail Korobov;2017-02-16 17:50:38 +0500;TST remove temporary files and folders

==

tests/test_downloader_handlers.py
tests/test_feedexport.py
tests/test_spiderstate.py
tests/test_webclient.py
==================
f0c4e5df;Mikhail Korobov;2017-02-16 16:32:23 +0500;TST fixed ProjectUtilsTest on OS X
Temp folder can be a symlink on OS X.

==

tests/test_utils_project.py
==================
71dda270;Mikhail Korobov;2017-02-16 04:22:19 +0500;DOC remove “Python 3 progress” badge
Badge doesn’t work, and Scrapy already works fine in Python 3
for practical purposes.

==

README.rst
==================
692975ac;Mikhail Korobov;2016-01-27 00:32:15 +0500;deprecate Spider.make_requests_from_url. Fixes #1495.

==

docs/topics/spiders.rst
scrapy/spiders/__init__.py
tests/spiders.py
tests/test_engine.py
==================
d09eed76;Mikhail Korobov;2017-02-08 23:44:55 +0500;use w3lib.html.strip_html5_whitespace function; expand docs; strip consistently before calling process_value

==

docs/topics/link-extractors.rst
scrapy/linkextractors/htmlparser.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/sgml.py
scrapy/utils/url.py
==================
d079e15f;Mikhail Korobov;2017-02-08 17:03:11 +0500;Strip leading/trailing whitespaces in link extractors. Fixes GH-838.

==

docs/topics/link-extractors.rst
scrapy/linkextractors/htmlparser.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/sgml.py
scrapy/utils/url.py
tests/sample_data/link_extractor/sgml_linkextractor.html
tests/test_linkextractors.py
tests/test_linkextractors_deprecated.py
==================
ad36a4a6;Mikhail Korobov;2017-02-08 16:58:38 +0500;RegexLinkExtractor: add \x0c to whitespace characters, as per html5 standard

==

scrapy/linkextractors/regex.py
==================
074caf43;Mikhail Korobov;2017-02-09 00:17:56 +0500;FormRequest: handle whitespaces in action attribute properly

==

scrapy/http/request/form.py
tests/test_http_request.py
==================
fade5763;Mikhail Korobov;2017-02-16 02:02:50 +0500;TST more response.follow tests

==

tests/test_http_response.py
==================
5b79c6a6;Mikhail Korobov;2017-02-16 00:06:52 +0500;DOC document response.follow methods; expand the tutorial

==

docs/intro/tutorial.rst
docs/topics/request-response.rst
scrapy/http/response/__init__.py
scrapy/http/response/text.py
==================
160da6ab;Mikhail Korobov;2017-02-15 04:41:53 +0500;fixed tests in Python 2

==

tests/test_http_response.py
==================
2674f317;Mikhail Korobov;2017-02-15 04:39:47 +0500;Response.follow

==

scrapy/http/response/__init__.py
scrapy/http/response/text.py
tests/test_http_response.py
==================
608c3f0c;Mikhail Korobov;2017-02-15 04:17:41 +0500;handle whitespace in response.follow; add tests

==

scrapy/http/response/text.py
tests/__init__.py
tests/test_http_response.py
==================
71dd5d0b;Mikhail Korobov;2017-02-07 06:11:08 +0500;strip URL extracted from selectors (as per html5 standard)

==

scrapy/http/response/text.py
==================
877057fa;Mikhail Korobov;2017-02-07 06:00:09 +0500;initial response.follow implementation

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/request-response.rst
scrapy/http/response/text.py
==================
e1ceaf3b;Mikhail Korobov;2017-02-13 21:06:05 +0500;require w3lib 1.17+

==

requirements-py3.txt
requirements.txt
setup.py
==================
39df675f;Mikhail Korobov;2017-02-14 23:28:50 +0500;make retry middleware changes backwards compatible

==

scrapy/downloadermiddlewares/retry.py
==================
922d3fec;Eugenio Lacuesta;2017-02-14 12:11:06 -0300;Doc: binary mode is required for exporters

==

docs/topics/exporters.rst
==================
e285b1d6;Mikhail Korobov;2017-02-07 18:17:07 +0500;retry stats

==

scrapy/downloadermiddlewares/retry.py
scrapy/downloadermiddlewares/stats.py
scrapy/utils/misc.py
scrapy/utils/python.py
scrapy/utils/response.py
tests/test_downloadermiddleware_retry.py
tests/test_proxy_connect.py
==================
afac3fd2;Mikhail Korobov;2017-02-14 20:58:39 +0600;Merge pull request #2530 from elacuesta/proxy_credentials
[MRG+1] Use credentials from request.meta['proxy']
==
==================
ae0ea31a;Eugenio Lacuesta;2017-02-08 13:21:10 -0300;Add HTTPPROXY_ENABLED setting (default True)

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/httpproxy.py
scrapy/settings/default_settings.py
tests/test_downloadermiddleware_httpproxy.py
==================
5b31dfe3;terut;2017-02-13 23:51:43 -0800;Separate building request from _requests_to_follow in CrawlSpider
You just overwrite buiding request if you can use another request class
because of something like splash-plugin.

==

scrapy/spiders/crawl.py
==================
7dd7646e;Daniel Graña;2017-02-13 14:57:55 -0300;Bump version: 1.3.1 → 1.3.2

==

.bumpversion.cfg
scrapy/VERSION
==================
9315e944;Daniel Graña;2017-02-13 14:56:29 -0300;Release notes for 1.3.2

==

docs/news.rst
==================
45f19021;Daniel Graña;2017-02-13 14:48:12 -0300;Merge pull request #2558 from scrapy/twisted-17-fix
Fixed compatibility with twisted 17+
==
==================
1bc4d8b6;Mikhail Korobov;2017-02-13 20:03:53 +0500;fixed tls in Twisted 17+

==

scrapy/core/downloader/tls.py
==================
de65ad3f;Mikhail Korobov;2017-02-13 18:44:39 +0500;TST replace Ubuntu 12.04 tox environment with 14.04

==

tox.ini
==================
9956f198;Mikhail Korobov;2017-02-13 18:40:53 +0500;add a couple more lines to gitignore

==

.gitignore
==================
5ee595d6;Mikhail Korobov;2017-02-09 18:16:49 +0500;Merge pull request #2551 from redapple/tutorial-author-selector
Use consistent selectors for author field in tutorial
==
==================
29e60213;Paul Tremberth;2017-02-09 10:41:21 +0100;Use consistent selectors for author field in tutorial

==

docs/intro/tutorial.rst
==================
f32a229e;Paul Tremberth;2017-02-08 18:30:07 +0100;Merge pull request #2510 from elacuesta/reqser_request_class
[MRG+1] Preserve request class when converting to/from dicts (utils.reqser)
==
==================
9c0aae72;Eugenio Lacuesta;2017-02-03 10:32:36 -0300;Use credentials from request.meta['proxy'] if present

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/httpproxy.py
tests/test_downloadermiddleware_httpproxy.py
==================
af55a871;Paul Tremberth;2017-02-08 17:08:19 +0100;Bump version: 1.3.0 → 1.3.1

==

.bumpversion.cfg
scrapy/VERSION
==================
ff8a564b;Paul Tremberth;2017-02-08 17:05:06 +0100;Set date for 1.3.1 release

==

docs/news.rst
==================
094937bc;Mikhail Korobov;2017-02-08 20:47:10 +0500;Merge pull request #2536 from scrapy/release-notes-1.3.1
[MRG] Update changelog for upcoming 1.3.1 release
==
==================
48c8c679;Paul Tremberth;2017-02-06 18:03:48 +0100;Update changelog for upcoming 1.3.1 release

==

docs/news.rst
==================
d205206a;Paul Tremberth;2017-02-08 13:21:15 +0100;Merge pull request #2345 from gustavodeandrade/master
[MRG+1] Fix documentation about HTML entities decoding with selector extraction
==
==================
7d0b8904;Paul Tremberth;2017-02-08 13:02:50 +0100;Merge pull request #2533 from djrobust/patch-1
[MRG+1] Use yield with nested parsing of responses
==
==================
a8893190;Paul Tremberth;2017-02-08 13:01:02 +0100;Merge pull request #2464 from elacuesta/component_order_integer
[MRG+2] Validate numeric values (components order)
==
==================
3becb861;Paul Tremberth;2017-02-08 12:59:45 +0100;Merge pull request #2544 from scrapy/twisted-version-cleanup
[MRG+1] Remove code required to support ancient twisted versions.
==
==================
e87f1844;Paul Tremberth;2017-02-08 12:58:41 +0100;Merge pull request #2538 from scrapy/linkextractor-fail-fast
LinkExtractor: don’t check all regexes if one of them matches
==
==================
5ad64204;Paul Tremberth;2017-02-08 12:15:15 +0100;Merge pull request #2509 from rolando-contrib/py36-classcell-compat
[MRG+1] BUG: Fix __classcell__ propagation required in Python 3.6.
==
==================
4e765aca;Rolando Espinoza;2017-01-24 10:30:47 -0400;BUG: Fix __classcell__ propagation.
Python 3.6 added simpler customization of class creation but this
requires to propagate correctly the __classcell__ attribute in custom
__new__ methods.

See https://docs.python.org/3.6/whatsnew/3.6.html#pep-487-simpler-
customization-of-class-creation

==

scrapy/item.py
tests/test_item.py
==================
f2f9350c;Mikhail Korobov;2017-02-08 00:57:21 +0500;Merge pull request #2542 from scrapy/redirect-cleanup
[MRG+1] Cleanup MetaRefreshMiddleware: remove redundant check
==
==================
04b2f79e;Mikhail Korobov;2017-02-07 22:30:58 +0500;Remove code required to support ancient twisted versions. See GH-1887.

==

scrapy/core/downloader/handlers/http.py
tests/mockserver.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_retry.py
==================
eaf62ab6;Mikhail Korobov;2017-02-07 17:56:43 +0500;cleanup MetaRefreshMiddleware: remove redundant check

==

scrapy/downloadermiddlewares/redirect.py
==================
24e82bfe;Eugenio Lacuesta;2016-12-23 12:58:29 -0300;Validate values for components order

==

scrapy/utils/conf.py
tests/test_utils_conf.py
==================
fb4ef21a;Pawel Miech;2017-02-07 10:22:42 +0100;[httpcompression] minor style edits

==

scrapy/downloadermiddlewares/httpcompression.py
tests/requirements-py3.txt
tests/requirements.txt
==================
85a12497;Mikhail Korobov;2017-02-07 03:32:54 +0500;Enable memusage extension by default. Fixes GH-2187.

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
f73eb715;Mikhail Korobov;2017-02-07 02:16:06 +0500;LinkExtractor: don’t check all regexes if one of them matches

==

scrapy/linkextractors/__init__.py
==================
af802bad;Pawel Miech;2017-02-06 15:45:21 +0100;[httpcompression] add brotlipy for python 3

==

tests/requirements-py3.txt
==================
3daf4736;Pawel Miech;2017-02-06 12:29:33 +0100;[httpcompression] skip test if no brotli

==

scrapy/downloadermiddlewares/httpcompression.py
tests/requirements.txt
tests/test_downloadermiddleware_httpcompression.py
==================
f8f8bbe0;Pawel Miech;2017-02-06 12:17:45 +0100;[httpcompression] import brotli when available

==

requirements.txt
scrapy/downloadermiddlewares/httpcompression.py
tests/test_downloadermiddleware_httpcompression.py
==================
16c4b4e1;Pawel Miech;2017-02-06 11:41:08 +0100;[httpcompression] add support for br - brotli content encoding

==

requirements.txt
scrapy/downloadermiddlewares/httpcompression.py
tests/sample_data/compressed/html-br.bin
tests/test_downloadermiddleware_httpcompression.py
==================
3b8e6d4d;Mikhail Korobov;2017-02-06 13:09:35 +0500;Merge pull request #2531 from Lukas0907/patch-1
Fix typo in downloader-middleware.rst.
==
==================
2743786d;Mikhail Korobov;2017-02-06 13:05:46 +0500;Merge pull request #2534 from shio-phys/fix/typo_of_doc
fix typo
==
==================
fcb3daf4;Takehiro Shiozaki;2017-02-06 14:03:41 +0900;fix typo

==

docs/topics/spider-middleware.rst
==================
3021084f;djrobust;2017-02-04 20:07:05 -0800;Use 'yield' when parsing multiple responses
Use 'yield' consistently across examples of parse functions.
==

docs/topics/request-response.rst
==================
09643796;Lukas Anzinger;2017-02-03 20:05:17 +0100;Fix typo in downloader-middleware.rst.

==

docs/topics/downloader-middleware.rst
==================
814ce37d;Mikhail Korobov;2017-02-03 02:43:46 +0500;Merge pull request #2528 from redapple/dns-retry-test
Make DNS retry test compatible with Twisted 17+
==
==================
7b8bbc92;Mikhail Korobov;2017-02-03 02:38:49 +0500;Merge pull request #2215 from redapple/travis-pypy
Enable PyPy tests on Travis (allowed to fail)
==
==================
02e1d2b1;Paul Tremberth;2017-02-02 22:28:37 +0100;Add trailing dot

==

tests/test_crawl.py
==================
e604c0f3;Paul Tremberth;2017-02-02 18:26:41 +0100;Remove unused imports

==

tests/test_crawl.py
==================
ae2a5292;Mikhail Korobov;2017-02-02 22:17:26 +0500;Merge pull request #2457 from redapple/parsel-selector-kwargs
[MRG] Support kwargs for response.xpath()
==
==================
3358254c;Paul Tremberth;2017-02-02 17:53:28 +0100;Make DNS retry test compatible with Twisted 17+

==

tests/test_crawl.py
==================
1295c17a;Paul Tremberth;2017-02-02 17:47:22 +0100;Bump parsel requirement to at least parsel v1.1

==

requirements.txt
setup.py
==================
1c0b8053;Paul Tremberth;2017-01-11 19:44:21 +0100;DOC Mention XPath variables in Selectors section

==

docs/topics/selectors.rst
==================
803d8c4b;Paul Tremberth;2016-12-20 11:26:42 +0100;Add tests for passing kwargs on response .xpath() shortcut

==

tests/test_http_response.py
==================
0cf6344c;Paul Tremberth;2016-12-09 17:58:38 +0100;Support kwargs for response.xpath()

==

scrapy/http/response/text.py
==================
c305c462;Mikhail Korobov;2017-02-02 21:24:56 +0500;Merge pull request #2503 from redapple/view-no-redirect
[MRG] Fix view command against new --no-redirect option
==
==================
d4a8f438;Mikhail Korobov;2017-02-02 21:15:24 +0500;Merge pull request #2519 from redapple/settings-getbool-new
[MRG+1] Support 'True' and 'False' strings as boolean settings values
==
==================
245287fd;Mikhail Korobov;2017-02-02 21:13:59 +0500;Merge pull request #2496 from redapple/dns-resolver-timeout
[MRG] Enforce DNS resolution timeout
==
==================
73f985cb;Paul Tremberth;2017-02-02 13:22:23 +0100;Merge pull request #2525 from scrapy/cache-docs
DOC mention LevelDB cache storage backend
==
==================
9c754031;Mikhail Korobov;2017-02-02 17:16:57 +0500;Merge pull request #2466 from eLRuLL/settings-pipeline-template
[MRG+1] settings: fixing name of the pipeline template
==
==================
55742c03;Mikhail Korobov;2017-02-01 22:43:28 +0500;DOC mention LevelDB cache storage backend

==

docs/topics/downloader-middleware.rst
==================
70f260d3;Paul Tremberth;2017-02-01 15:14:32 +0100;Don't run coverage stats when on PyPy

==

tox.ini
==================
8c4f614d;Paul Tremberth;2016-09-01 15:25:38 +0200;Enable PyPy tests on Travis

==

.travis.yml
==================
a5862437;Paul Tremberth;2017-01-13 15:51:44 +0100;Buffer CONNECT response bytes from proxy until all HTTP headers are received

==

scrapy/core/downloader/handlers/http11.py
==================
d2e9ea0c;Paul Tremberth;2017-01-13 16:17:51 +0100;Enforce DNS resolution timeout

==

scrapy/resolver.py
==================
ae6d8d72;Paul Tremberth;2017-01-30 16:33:08 +0100;Support 'True' and 'False' strings as boolean settings values

==

scrapy/settings/__init__.py
tests/test_settings/__init__.py
==================
4156a861;Paul Tremberth;2017-01-30 15:57:37 +0100;Update docs on view command

==

docs/topics/commands.rst
==================
fc077116;Paul Tremberth;2017-01-30 15:54:28 +0100;Remove unused --headers option for view command

==

scrapy/commands/view.py
==================
4ca191ea;Paul Tremberth;2017-01-25 14:40:46 +0100;Merge pull request #2512 from fladi/fix_manpage_spelling
Fix spelling error in scrapy.1 manpage.
==
==================
87472346;Paul Tremberth;2017-01-25 11:28:20 +0100;Update scrapy.1

==

extras/scrapy.1
==================
bae12870;Michael Fladischer;2017-01-24 22:20:37 +0100;Fix spelling error in scrapy.1 manpage.
The word "intepreted" should be "interpreted".

==

extras/scrapy.1
==================
53757e51;Eugenio Lacuesta;2017-01-24 11:29:11 -0300;Preserve request class when converting to/from dicts (utils.reqser)

==

scrapy/utils/reqser.py
tests/test_utils_reqser.py
==================
4620d2f4;Paul Tremberth;2017-01-24 10:33:22 +0100;Merge pull request #2470 from chekunkov/patch-1
[MRG+1] .devN release suffix must be preceded with a dot
==
==================
efbb1557;Mikhail Korobov;2017-01-23 17:03:58 +0500;Merge pull request #2507 from eLRuLL/non-doc-readmes
[MRG+1] Changing README to README.rst
==
==================
a347c75b;Paul Tremberth;2017-01-23 11:40:38 +0100;Merge branch 'master' into patch-1

==
==================
29954441;Raul Gallegos;2017-01-22 19:23:44 -0500;changing README to README.rst

==

artwork/README.rst
docs/README.rst
sep/README.rst
==================
c275ceb1;Mikhail Korobov;2017-01-20 03:36:37 +0500;Merge pull request #2485 from redapple/tox-py36
Add Python 3.6 tox env + Travis CI build for it
==
==================
f7abef4b;Mikhail Korobov;2017-01-20 03:35:37 +0500;Merge pull request #2497 from eLRuLL/formid-docs
[MRG+1] Adding formid to FormRequest documentation
==
==================
b279bc85;Paul Tremberth;2017-01-19 16:28:52 +0100;Fix view command against new --no-redirect option

==

scrapy/commands/view.py
==================
df1a4241;Raul Gallegos;2017-01-14 20:45:20 -0500;adding formid to FormRequest documentation

==

docs/topics/request-response.rst
==================
5586fc7e;Paulius Aleksiūnas;2017-01-10 11:12:42 +0200;Update architecture.rst
In the data flow image arrows are red.
==

docs/topics/architecture.rst
==================
4636bef4;Paul Tremberth;2017-01-10 10:28:38 +0100;Merge pull request #2483 from Digenis/doc_spider_args2attrs
[MRG+1] Document copying of spider arguments to attributes
==
==================
bf2277a0;Paul Tremberth;2017-01-10 10:27:38 +0100;Update spiders.rst

==

docs/topics/spiders.rst
==================
900b6710;Νικόλαος-Διγενής Καραγιάννης;2017-01-05 12:53:00 +0200;Document copying of spider arguments to attributes

==

docs/topics/spiders.rst
==================
b3406677;Paul Tremberth;2017-01-09 14:40:02 +0100;Update classifiers in setup.py

==

setup.py
==================
e7d0dae7;Mikhail Korobov;2017-01-09 01:42:44 +0500;Merge pull request #2469 from scrapy/update-readme
[MRG+1] Upgrade CoC and mention it after main contributing docs
==
==================
6b838b02;Paul Tremberth;2017-01-06 16:10:14 +0100;Use matrix build config

==

.travis.yml
==================
53769245;Paul Tremberth;2017-01-06 16:02:14 +0100;Use python 3.6 directly

==

.travis.yml
==================
40851a3d;Paul Tremberth;2017-01-06 15:44:32 +0100;Use Python 3.6-dev on Travis

==

.travis.yml
==================
a2147314;Paul Tremberth;2017-01-06 15:38:35 +0100;Add Python 3.6 tox env + Travis CI build for it

==

.travis.yml
tox.ini
==================
b6ab1ae9;Elias Dorneles;2017-01-03 15:14:59 -0200;docs: installation instructions, mention conda in the beginning (closes #2475)

==

docs/intro/install.rst
==================
e7dede66;Paul Tremberth;2017-01-03 14:01:34 +0100;Merge pull request #2458 from rolando-contrib/http11-maxsize-logging-tweak
[MRG+1] ENH Pass arguments to logger rather than formatted message.
==
==================
8a865743;Alex;2016-12-28 14:10:50 +0000;.devN release suffix must be preceded with a dot
https://packaging.python.org/distributing/#standards-compliance-for-interoperability

==

.travis.yml
==================
b7dd089b;Elias Dorneles;2016-12-27 11:33:23 -0200;show CoC in its own section

==

README.rst
==================
dabcb17d;Elias Dorneles;2016-12-27 11:32:15 -0200;update code of conduct http://contributor-covenant.org/version/1/4

==

CODE_OF_CONDUCT.md
==================
9922ec15;Elias Dorneles;2016-12-27 09:52:35 -0200;mention contributing document before CoC in the README

==

README.rst
==================
2240f00a;nyov;2016-03-01 07:12:19 +0000;Remove dependency on os.environ from default settings
Avoid loading settings from environment in scrapy core.
Instead it's better to populate them from the starting
shell or an embedding script.

==

docs/topics/commands.rst
docs/topics/settings.rst
scrapy/cmdline.py
scrapy/commands/edit.py
scrapy/settings/default_settings.py
==================
e7c7e055;Raul Gallegos;2016-12-24 11:55:04 -0500;settings: fixing name of the pipeline template

==

scrapy/templates/project/module/settings.py.tmpl
==================
cc06b6b1;Mikhail Korobov;2016-12-21 23:23:50 +0500;Merge pull request #2460 from redapple/filepipe-random-test-fail
TST: Randomize FILES_EXPIRES above 90 days
==
==================
07f9985a;Paul Tremberth;2016-12-21 17:03:11 +0100;TST: Randomize FILES_EXPIRES above 90 days

==

tests/test_pipeline_files.py
==================
ac74d5a4;Paul Tremberth;2016-12-21 16:28:44 +0100;Bump version: 1.2.2 → 1.3.0

==

.bumpversion.cfg
scrapy/VERSION
==================
f8793e24;Paul Tremberth;2016-12-21 16:27:01 +0100;Set release date for 1.3.0

==

docs/news.rst
==================
0c27d252;Paul Tremberth;2016-12-21 16:25:13 +0100;Merge pull request #2437 from scrapy/release-notes-1.3.0
Update changelog for upcoming 1.3.0 release
==
==================
b9e7ca04;Paul Tremberth;2016-12-21 16:11:19 +0100;Reword things a tiny bit

==

docs/news.rst
==================
d60a6899;Paul Tremberth;2016-12-21 16:01:36 +0100;Merge logging changes into "New features" section

==

docs/news.rst
==================
4eeec3e4;Paul Tremberth;2016-12-21 15:59:18 +0100;Add preamble on why 1.3.0 comes so soon after 1.2.2

==

docs/news.rst
==================
49a84c2d;Paul Tremberth;2016-12-21 14:32:21 +0100;Add note on HTTP redirects with shell and fetch

==

docs/news.rst
==================
90980018;Paul Tremberth;2016-12-19 17:09:47 +0100;Add note on LOG_SHORT_NAMES

==

docs/news.rst
==================
9d5afd8c;Paul Tremberth;2016-12-16 18:46:49 +0100;Add note on HttpErrorMiddleware new logging level

==

docs/news.rst
==================
e9b3cf01;Paul Tremberth;2016-12-09 17:23:59 +0100;Update changelog for upcoming 1.3.0 release

==

docs/news.rst
==================
d09ec3db;Elias Dorneles;2016-12-21 09:49:15 -0200;Merge pull request #2410 from redapple/fetch-transparent-redirect
[MRG+1] Transparently handle redirections in fetch and shell
==
==================
6dec4a3c;Rolando Espinoza;2016-12-20 20:02:31 -0400;ENH Pass arguments to logger rather than formatted message.
This not only use the standard form but helps error aggregation
libraries (i.e.: Sentry) to avoid duplicating the message.

==

scrapy/core/downloader/handlers/http11.py
==================
140a57d7;Paul Tremberth;2016-12-19 17:51:30 +0100;Amend note on --no-redirect option for shell tool

==

docs/topics/commands.rst
==================
d19c4c1f;Mikhail Korobov;2016-12-19 21:46:56 +0500;Merge pull request #2433 from redapple/wrong-spidermodules-warning
[MRG+1] Warn user instead of failing for wrong SPIDER_MODULES setting
==
==================
78d34cc4;Paul Tremberth;2016-12-19 17:11:17 +0100;Merge pull request #2454 from crasker/fix/low_parsel_version_number
[MRG+1] Fix/low parsel version number
==
==================
ed1e4d8d;Paul Tremberth;2016-12-19 16:02:55 +0100;Merge pull request #1731 from scrapy/disable-toplevel-2
[MRG+1] LOG_SHORT_NAMES option to disable TopLevelFormatter
==
==================
2b3abdb7;zhouyc;2016-12-19 11:27:57 +0800;update parsel version which will cause attribute error

==

setup.py
==================
da19f0b7;Mikhail Korobov;2016-12-16 22:14:54 +0500;DOC how to override log level for a specific Scrapy component

==

docs/topics/logging.rst
==================
0fc73a9d;Mikhail Korobov;2016-12-16 21:47:58 +0500;DOC update examples with long longger names

==

docs/intro/tutorial.rst
docs/topics/benchmarking.rst
docs/topics/downloader-middleware.rst
docs/topics/settings.rst
docs/topics/shell.rst
==================
97e82107;Elias Dorneles;2016-12-14 12:18:04 -0200;Merge pull request #2270 from redapple/httperror-log-info
[MRG+1] Raise log level for HttpErrorMiddleware to INFO (from DEBUG)
==
==================
70a69d21;Paul Tremberth;2016-12-12 22:40:48 +0100;Use built-in range()

==

scrapy/commands/fetch.py
scrapy/shell.py
==================
f7e40814;Paul Tremberth;2016-12-12 22:37:53 +0100;Add tests for SequenceExclude container

==

tests/test_utils_datatypes.py
==================
f457379a;Paul Tremberth;2016-12-09 16:56:26 +0100;Add stacktrace in warning message

==

scrapy/spiderloader.py
==================
05b4555f;Mikhail Korobov;2016-12-09 02:19:51 +0500;TST tests for LOG_SHORT_NAMES

==

tests/test_commands.py
==================
e46572d6;Mikhail Korobov;2016-12-09 02:19:33 +0500;TST end-to-end test for LOG_LEVEL option
there were no end-to-end tests for this option

==

tests/test_commands.py
==================
6eab59cb;Mikhail Korobov;2016-12-09 02:14:12 +0500;TST cleanup runspider tests

==

tests/test_commands.py
==================
05cec0f2;Mikhail Korobov;2016-01-27 15:21:05 +0500;fixed ReST syntax

==

docs/topics/settings.rst
==================
a75ad2bb;Akhil Lb;2015-11-04 01:59:57 +0530;LOG_SHORT_NAMES option

==

docs/topics/logging.rst
docs/topics/settings.rst
scrapy/settings/default_settings.py
scrapy/utils/log.py
==================
7d178360;Paul Tremberth;2016-12-08 17:27:25 +0100;Update documentation about --no-redirect option

==

docs/topics/commands.rst
docs/topics/shell.rst
scrapy/shell.py
==================
948e3cd0;Paul Tremberth;2016-12-08 12:50:26 +0100;Warn user instead of failing for wrong SPIDER_MODULES setting

==

scrapy/spiderloader.py
tests/test_spiderloader/__init__.py
==================
2cd579a7;Paul Tremberth;2016-12-07 19:07:32 +0100;Add test for fetch(url) within shell with and without redirect

==

tests/test_command_shell.py
==================
7e54de24;Paul Tremberth;2016-12-07 18:41:24 +0100;Add tests for shell command with and without --no-redirect

==

tests/test_command_shell.py
==================
bd8c293a;Mikhail Korobov;2016-12-07 22:05:15 +0500;Merge pull request #2411 from redapple/remove-chunked-transfer-mw
[MRG+1] Remove ChunkedTransferMiddleware from default settings
==
==================
cce631ab;Elias Dorneles;2016-12-07 15:00:01 -0200;Merge pull request #1887 from nyov/twisted11
[MRG+2] Bump Twisted dependency to 13.1.0
==
==================
778bed07;Paul Tremberth;2016-12-07 17:56:13 +0100;Let framework handle only HTTP redirects by default for fetch and shell commands

==

scrapy/commands/fetch.py
scrapy/commands/shell.py
scrapy/shell.py
scrapy/utils/datatypes.py
tests/test_command_fetch.py
==================
ff3aec66;Mikhail Korobov;2016-12-07 20:08:18 +0500;Merge pull request #2331 from moisesguimaraes/fixes-2272
[MRG+1] Fixes issue #2272 using arg_to_iter() to wrap single values and list() to…
==
==================
a9c69458;Elias Dorneles;2016-12-07 11:21:15 -0200;Merge pull request #2422 from rolando-contrib/nested-spiders-modules
[MRG+1] DOC State explicitly that spiders are loaded recursively.	
==
==================
86281465;Mikhail Korobov;2016-12-06 23:03:09 +0500;Merge pull request #2427 from redapple/pipe-test-fail
TST: Randomize IMAGES_EXPIRES above 90 days
==
==================
5efd6525;Paul Tremberth;2016-12-06 18:49:53 +0100;TST: Randomize IMAGES_EXPIRES above 90 days

==

tests/test_pipeline_images.py
==================
f3d59953;Paul Tremberth;2016-12-06 15:21:00 +0100;Bump version: 1.2.1 → 1.2.2

==

.bumpversion.cfg
scrapy/VERSION
==================
ea968c6c;Paul Tremberth;2016-12-06 15:18:31 +0100;Merge pull request #2423 from redapple/release-notes-1.2.2
Update changelog for upcoming 1.2.2 release
==
==================
09e310d0;Paul Tremberth;2016-12-06 15:03:38 +0100;Set release date for 1.2.2

==

docs/news.rst
==================
aa2e1b03;Paul Tremberth;2016-12-06 14:44:19 +0100;Add reference to fixed scheduler settings documentation

==

docs/news.rst
==================
89d5f5ac;Paul Tremberth;2016-12-01 22:42:16 +0100;Update changelog for upcoming 1.2.2 release

==

docs/news.rst
==================
97df1391;Mikhail Korobov;2016-12-06 18:42:07 +0500;Merge pull request #2417 from pawelmhm/scheduler-docs
[MRG+1] Add docs for some scheduler settings
==
==================
c08d278c;Moisés Guimarães;2016-12-05 16:47:24 -0300;removes note from docs.

==

docs/topics/email.rst
==================
a4178f99;Moisés Guimarães;2016-12-05 15:24:26 -0300;fixes params types in docs.

==

docs/topics/email.rst
==================
c58ea021;Moisés Guimarães;2016-12-04 11:56:14 -0300;fixes docs

==

docs/topics/email.rst
==================
67bc2e0b;nyov;2016-12-02 21:00:39 +0000;Wipe scrapy.xlib.tx

==

scrapy/xlib/tx.py
scrapy/xlib/tx/LICENSE
scrapy/xlib/tx/README
scrapy/xlib/tx/_newclient.py
scrapy/xlib/tx/client.py
scrapy/xlib/tx/endpoints.py
scrapy/xlib/tx/interfaces.py
scrapy/xlib/tx/iweb.py
==================
67cf64ed;nyov;2016-12-02 20:53:06 +0000;Deprecate scrapy.xlib.tx

==

scrapy/xlib/tx/__init__.py
==================
534772f6;nyov;2016-12-02 01:15:37 +0000;Import xlib.tx code from twisted proper

==

scrapy/core/downloader/handlers/http11.py
scrapy/downloadermiddlewares/httpcache.py
scrapy/downloadermiddlewares/retry.py
tests/test_downloadermiddleware_retry.py
==================
985755d1;nyov;2016-12-01 23:44:15 +0000;Remove obsolete xlib code for Twisted 13.1.0

==

scrapy/xlib/tx/_newclient.py
scrapy/xlib/tx/client.py
scrapy/xlib/tx/endpoints.py
scrapy/xlib/tx/interfaces.py
scrapy/xlib/tx/iweb.py
==================
c8cf1a30;nyov;2016-12-01 22:02:11 +0000;Bump Twisted dependency to 13.1.0 (released June 2013)

==

requirements.txt
scrapy/xlib/tx/_newclient.py
scrapy/xlib/tx/client.py
scrapy/xlib/tx/endpoints.py
scrapy/xlib/tx/interfaces.py
scrapy/xlib/tx/iweb.py
setup.py
==================
e1ea0c43;nyov;2016-12-01 22:02:10 +0000;Strip xlib.tx code of Twisted 10

==

scrapy/xlib/tx/__init__.py
scrapy/xlib/tx/_newclient.py
scrapy/xlib/tx/client.py
scrapy/xlib/tx/endpoints.py
scrapy/xlib/tx/interfaces.py
scrapy/xlib/tx/iweb.py
==================
c4e67c06;Elias Dorneles;2016-12-01 18:43:48 -0200;Merge pull request #2421 from rolando-contrib/tests-bug
[MRG+1] TST: Fix duplicated test name.
==
==================
f3a44207;Elias Dorneles;2016-12-01 18:43:23 -0200;Merge pull request #2388 from redapple/robotparser-native-str
[MRG+1] Parse robots.txt content as native str
==
==================
826b7e92;Mikhail Korobov;2016-12-02 00:20:27 +0500;Merge pull request #2386 from rolando-contrib/manifest-tweak
[MRG+1] Ignore explicitly compiled python files.
==
==================
923b974f;Rolando Espinoza;2016-12-01 12:52:52 -0300;TST Include nested a nested spider in spider loader test.

==

tests/test_spiderloader/__init__.py
tests/test_spiderloader/test_spiders/nested/__init__.py
tests/test_spiderloader/test_spiders/nested/spider4.py
==================
6431e7a1;Rolando Espinoza;2016-12-01 13:24:12 -0300;DOC State explicitly that spiders are loaded recursively.

==

docs/topics/api.rst
==================
d9f43e21;Rolando Espinoza;2016-12-01 11:56:33 -0300;TST: Fix duplicated test name.

==

tests/test_spiderloader/__init__.py
==================
5f0af906;Elias Dorneles;2016-12-01 11:24:54 -0200;Merge pull request #2395 from elacuesta/robots_txt_relative_sitemap_url
[MRG+1] Handle relative sitemap URLs in robots.txt
==
==================
5ff64ad0;Eugenio Lacuesta;2016-11-15 11:47:25 -0300;handle relative sitemap urls in robots.txt

==

scrapy/spiders/sitemap.py
scrapy/utils/sitemap.py
tests/test_spider.py
tests/test_utils_sitemap.py
==================
2086ff40;Elias Dorneles;2016-11-30 10:49:41 -0200;Merge pull request #2418 from ahlinc/fix_retriggered_issue_396
[MRG+1] Fix #396 re-triggered issue
==
==================
bba4645f;Mikhail Korobov;2016-11-30 17:01:37 +0500;Merge pull request #2404 from redapple/scrapy-version
[MRG+1] Print more dependencies versions in "scrapy version" verbose output
==
==================
27606aad;Andrew Hlynskyi;2016-11-30 09:47:02 +0200;Fix #396 re-triggered issue
The InteractiveShellEmbed class is a singleton
and we need to drop the instance with its clear_instance() method
to rebuild the instance from scratch with fresh environment
for each subsequent Scrapy's shell drop in.

==

scrapy/utils/console.py
==================
624284e8;Paul Tremberth;2016-11-29 18:18:59 +0100;Fix indent

==

docs/topics/settings.rst
==================
f98ffb53;Pawel Miech;2016-11-29 16:52:54 +0100;add docs for some scheduler settings

==

docs/faq.rst
docs/topics/settings.rst
==================
059085b5;Paul Tremberth;2016-11-24 18:23:34 +0100;Remove docs for deprecated ChunkedTransfer middleware

==

docs/topics/downloader-middleware.rst
==================
8cffb4bb;Paul Tremberth;2016-11-24 17:50:21 +0100;Update warning wording

==

scrapy/downloadermiddlewares/chunked.py
==================
e6f174b0;Paul Tremberth;2016-11-24 17:33:27 +0100;Add deprecation warning for ChunkedTransfer middleware

==

scrapy/downloadermiddlewares/chunked.py
==================
03cf5f1b;Paul Tremberth;2016-11-24 17:18:57 +0100;Remove ChunkedTransferMiddleware from default settings

==

docs/topics/downloader-middleware.rst
docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
9aefc0a8;Paul Tremberth;2016-11-24 13:41:51 +0100;Add test for fetch command with redirections disabled

==

scrapy/utils/testsite.py
tests/test_command_fetch.py
==================
35b655d2;Paul Tremberth;2016-11-24 12:23:22 +0100;Handle redirects transparently by default in shell and fetch
Adds --no-status-aware command line option to have previous behaviour

==

scrapy/commands/fetch.py
scrapy/commands/shell.py
scrapy/shell.py
==================
01142e2a;Paul Tremberth;2016-11-22 14:48:33 +0100;Print more dependencies versions in "scrapy version" verbose output

==

scrapy/commands/version.py
tests/test_command_version.py
==================
a07400ce;Mikhail Korobov;2016-11-22 18:21:38 +0500;Merge pull request #2396 from redapple/ubuntu-packages-toc
[MRG] DOC Remove "Ubuntu" section from sidebar/ToC
==
==================
d62776a8;Pablo Hoffman;2016-11-16 12:19:32 -0300;mention scrapoxy in best practices doc

==

docs/topics/practices.rst
==================
8db85453;Paul Tremberth;2016-11-16 13:56:58 +0100;Add "orphan" metadata for Ubuntu packages page
As described in http://www.sphinx-doc.org/en/latest/markup/misc.html#metadata

==

docs/topics/ubuntu.rst
==================
11fe3751;Paul Tremberth;2016-11-16 11:55:09 +0100;DOC Remove "Ubuntu" section from sidebar/ToC

==

docs/index.rst
==================
6cd35c77;Paul Tremberth;2016-11-15 17:38:32 +0100;Pass user-agent as native str when checking URLs against robots.txt

==

scrapy/downloadermiddlewares/robotstxt.py
tests/test_downloadermiddleware_robotstxt.py
==================
1cbc57fa;Elias Dorneles;2016-11-15 12:58:40 -0200;Merge pull request #2337 from muriloviana/add-middleware-template
[MRG+1] Add middleware to template project (closes #2335)
==
==================
570e12b5;Mikhail Korobov;2016-11-14 21:24:14 +0500;Merge pull request #2328 from scrapy/download-latency-meta-docs
[MRG+1] Document `download_latency` meta key
==
==================
7025d665;Valdir Stumm Junior;2016-10-18 11:51:13 -0200;document download_latency meta key

==

docs/topics/request-response.rst
==================
201a16f6;Paul Tremberth;2016-11-14 12:10:14 +0100;Merge pull request #2394 from nyov/fix-le
[MRG+1] LinkExtractor PY3 'unicode' type fix
==
==================
e8205f67;nyov;2015-07-29 15:34:27 +0000;LinkExtractor PY3 'unicode' type fix

==

scrapy/linkextractors/htmlparser.py
scrapy/linkextractors/sgml.py
==================
de89b1b5;Paul Tremberth;2016-11-10 11:38:22 +0100;Merge pull request #2275 from scrapy/response-css-xpath-message
[MRG+1] Add better messages for when response content isn't text (closes #2264)
==
==================
6d6dc713;Mikhail Korobov;2016-11-10 00:35:43 +0600;Merge pull request #2387 from rolando-contribute/conda-forge-updates
[MRG+1] Update conda channel to conda-forge and show conda version badge.
==
==================
28155dfc;Paul Tremberth;2016-11-09 12:20:06 +0100;Parse robots.txt content as native str
Fixes #2373

==

scrapy/downloadermiddlewares/robotstxt.py
tests/test_downloadermiddleware_robotstxt.py
==================
76459e19;Rolando Espinoza;2016-11-08 21:30:27 -0300;Update conda channel to conda-forge and show conda version badge.

==

README.rst
docs/intro/install.rst
==================
3cd56da0;Rolando Espinoza;2016-11-08 20:52:32 -0300;Ignore explicitly compiled python files.
This avoids to include compiled files in the templates directory.

==

MANIFEST.in
==================
ea83e677;Mikhail Korobov;2016-11-08 18:32:07 +0600;Merge pull request #2382 from redapple/slot-heartbeat-state-test
Test Slot's heartbeat state before stopping it
==
==================
af2280e6;Paul Tremberth;2016-11-08 13:30:51 +0100;Update docstring

==

tests/pipelines.py
==================
27456996;Paul Tremberth;2016-11-08 11:46:16 +0100;Add assertion on crawler not running

==

tests/test_crawl.py
==================
61efacdd;Paul Tremberth;2016-11-08 11:35:42 +0100;Add testcase for catching exception from open_spider() from pipeline

==

tests/pipelines.py
tests/test_crawl.py
==================
7727d87f;Paul Tremberth;2016-11-07 16:44:57 +0100;Test Slot's heartbeat state before stopping it
Also add a test on state of looping task in LogStats extension

Fixes #2011 and #2362

==

scrapy/core/engine.py
scrapy/extensions/logstats.py
==================
0f5eb4cf;Mikhail Korobov;2016-11-07 19:02:53 +0600;Merge pull request #2380 from rahulkant13may/master
Document update in "Using Firefox for scraping"
==
==================
f56aef99;Rahul Kant;2016-11-07 17:49:22 +0530;Add closing tag in <tbody>

==

docs/topics/firefox.rst
==================
f2e49bc2;Gustavo de Andrade;2016-11-01 21:32:17 -0200;Update selectors.rst
Decode instead escape, exceptions &lt; and &amp; (kmike)
Second sentence droped (Digenis)
==

docs/topics/selectors.rst
==================
9755ef93;Mikhail Korobov;2016-10-29 12:46:48 +0600;Merge pull request #2369 from jc0n/media-pipeline-docs-typo
Fix typo in media pipeline docs
==
==================
d85da273;John O'Connor;2016-10-28 19:44:46 -0700;Fix typo in media pipeline docs

==

docs/topics/media-pipeline.rst
==================
a9c74dbe;Elias Dorneles;2016-10-25 09:53:24 -0200;Merge pull request #2339 from visued/master
[MRG+1] Update documentation to explain the use of double quotes on Windows (fixes #2325)
==
==================
bd4f156d;Paul Tremberth;2016-10-24 12:42:59 +0200;Merge pull request #2354 from stav/doc-spider-arguments
[MRG+1] doc: wording
==
==================
99daea49;Steven Almeroth;2016-10-21 16:14:57 -0700;Doc: wording

==

docs/topics/spiders.rst
==================
a958e549;Steven Almeroth;2016-10-21 16:13:40 -0700;Doc: remove trailing spaces

==

docs/topics/spiders.rst
==================
1be2447a;Mikhail Korobov;2016-10-21 11:08:17 +0200;Merge pull request #2346 from redapple/master-pr2313
Fix tutorial AuthorSpider
==
==================
c7d245b9;Randy Pen;2016-10-07 22:52:58 +0800;update
Thx for your advice.
==

docs/intro/tutorial.rst
==================
eacc5937;Randy Pen;2016-10-07 16:48:57 +0800;fix example code
In the AuthorSpider, original css selector failed to get links of author pages
==

docs/intro/tutorial.rst
==================
6df48d57;Paul Tremberth;2016-10-21 10:37:45 +0200;Bump version: 1.2.0 → 1.2.1

==

.bumpversion.cfg
scrapy/VERSION
==================
f0e93573;Paul Tremberth;2016-10-21 10:34:47 +0200;Merge pull request #2341 from redapple/release-notes-1.2.1
Update release notes for upcoming 1.2.1
==
==================
c559a64c;Paul Tremberth;2016-10-21 10:17:46 +0200;Set date for 1.2.1 release

==

docs/news.rst
==================
22772a61;Paul Tremberth;2016-10-20 13:12:27 +0200;Update release notes for upcoming 1.2.1

==

docs/news.rst
==================
c7dfb5eb;gustavodeandrade;2016-10-21 00:08:08 -0200;Fix issue 1704

==

docs/topics/selectors.rst
==================
eb5d3965;Paul Tremberth;2016-10-20 22:24:14 +0200;Merge pull request #2344 from jaympatel/master
Typo (through was misspelled)
==
==================
f357ccd0;Jay Patel;2016-10-20 15:52:28 -0400;Typo (through was misspelled)

==

scrapy/core/scraper.py
==================
871eec98;Mikhail Korobov;2016-10-20 09:05:14 +0200;Merge pull request #2327 from bopace/http-header-docs
[MRG+1] Added documentation about accessing header values
==
==================
71c8278f;Mikhail Korobov;2016-10-20 09:04:19 +0200;Merge pull request #2329 from josericardo/scrapy-2262
[MRG+1] Better explain middleware orders and processing directions
==
==================
db408528;Paul Tremberth;2016-10-20 04:26:12 +0200;Do not interpret non-ASCII bytes in "Location" and percent-encode them (#2322)
* Do not interpret non-ASCII bytes in "Location" and percent-encode them

Fixes GH-2321

The idea is to not guess the encoding of "Location" header value
and simply percent-encode non-ASCII bytes,
which should then be re-interpreted correctly by the remote website
in whatever encoding was used originally.

See https://tools.ietf.org/html/rfc3987#section-3.2

This is similar to the changes to safe_url_string in
https://github.com/scrapy/w3lib/pull/45

* Remove unused import

==

scrapy/downloadermiddlewares/redirect.py
tests/test_downloadermiddleware_redirect.py
==================
09c401bf;muriloviana;2016-10-19 14:09:01 -0200;use crawler only to register signals in from_crawler()

==

scrapy/templates/project/module/middlewares.py.tmpl
==================
32fd6928;muriloviana;2016-10-19 13:50:09 -0200;define method spider_opened and update class instructions

==

scrapy/templates/project/module/middlewares.py.tmpl
==================
38e292a1;muriloviana;2016-10-19 12:47:23 -0200;add from_crawler method to template and turn the returns methods explicit

==

scrapy/templates/project/module/middlewares.py.tmpl
==================
34f2014c;muriloviana;2016-10-19 00:37:31 -0200;change settings middleware name and updating middleware template

==

scrapy/commands/startproject.py
scrapy/templates/project/module/middleware.py.tmpl
scrapy/templates/project/module/middlewares.py.tmpl
scrapy/templates/project/module/settings.py.tmpl
==================
d5bd44a5;muriloviana;2016-10-18 17:29:16 -0200;add middleware to template project

==

scrapy/commands/startproject.py
scrapy/templates/project/module/middleware.py.tmpl
==================
f74051e6;Victor Sued;2016-10-18 16:36:43 -0200;update documentation to explain the use of double quotes on Windows.

==

docs/intro/tutorial.rst
==================
fd016ee7;bopace;2016-10-18 09:37:45 -0600;Fixed wording of documentation

==

docs/topics/request-response.rst
==================
3fb6e524;Moisés Guimarães;2016-10-18 12:24:11 -0300;fixes import for py35 env.

==

scrapy/mail.py
==================
6cc83c04;Paul Tremberth;2016-10-18 16:35:19 +0200;Merge pull request #2330 from lfmattossch/note-python2-name
[MRG+1] Added a note about invalid spider names in python 2 (fixes #2251)
==
==================
e12e364a;Jose Ricardo;2016-10-18 12:29:30 -0200;Add details to the spider middlewares docs
Document the effects of the middleware order in a more detailed way.

==

docs/topics/spider-middleware.rst
==================
a5f44503;Mikhail Korobov;2016-10-18 16:20:59 +0200;Merge pull request #2302 from Granitosaurus/pipeline_doc_fix
[MRG+1] Fix JsonWriterPipeline example in docs
==
==================
45e95b79;Moisés Guimarães;2016-10-18 11:06:55 -0300;(fixes #2272) using arg_to_iter() to wrap single values and list() to avoid consuming from generators.

==

scrapy/mail.py
tests/test_mail.py
==================
7c33e0cb;Luiz Fernando Mattos Schlindwein;2016-10-18 11:55:51 -0200;added a note about invalid spider names in python 2

==

docs/topics/spiders.rst
==================
ea7bd395;Jose Ricardo;2016-10-18 11:48:58 -0200;Make architecture overview references a little more clear on the docs
Expliciting what actually happens by adding links to the respective methods
that are invoked in each processing phase.

==

docs/topics/architecture.rst
==================
bebcd508;Jose Ricardo;2016-10-18 11:22:55 -0200;Add downloader middleware ordering details to the docs
Add more details, making it easier to understand what are the effects of
setting a downloader middleware order.

==

docs/topics/downloader-middleware.rst
==================
bfe28ae7;Bo Pace;2016-10-17 14:10:05 -0600;Added documentation about accessing header values

==

docs/topics/request-response.rst
==================
7e20725e;Mikhail Korobov;2016-10-17 11:44:28 +0200;Merge pull request #2314 from redapple/tls-ciphers
[MRG+1] Use OpenSSL default ciphers
==
==================
dc1f9ad2;Paul Tremberth;2016-10-12 15:32:18 +0200;Merge pull request #2307 from eLRuLL/genspider-no-www-fix
genspider: removing www. from starturl templates
==
==================
118b42ab;Raul Gallegos;2016-10-11 22:08:05 -0500;making start_urls a list in basic genspider template

==

scrapy/templates/spiders/basic.tmpl
==================
c3411373;Paul Tremberth;2016-10-07 12:28:16 +0200;Use OpenSSL default ciphers
Twisted default TLS options restricts the ciphers list a bit -- "a secure default"
https://github.com/twisted/twisted/blob/e38cc25a67747899c6984d6ebaa8d3d134799415/src/twisted/internet/_sslverify.py#L1861

We want to be a bit more permissive with Scrapy
(at least as permissive as Scrapy 1.0 was, and which used a default OpenSSL Context)

See https://www.openssl.org/docs/manmaster/apps/ciphers.html#CIPHER_STRINGS

OpenSSL's 'DEFAULT' seems to be reasonable enough.

Fixes #2311

==

scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/tls.py
==================
dd778892;Raul Gallegos;2016-10-05 12:16:45 -0500;genspider: removing www. from starturl templates

==

scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
==================
dfba151f;Bernardas;2016-10-05 16:35:23 +0000;Remove unnecessary note for the JsonWriterPipeline example

==

docs/topics/item-pipeline.rst
==================
eb91cb8e;Bernardas;2016-10-03 20:31:41 +0000;fix JsonWriterPipeline example

==

docs/topics/item-pipeline.rst
==================
3235bfeb;Paul Tremberth;2016-10-03 13:04:11 +0200;Bump version: 1.2.0dev2 → 1.2.0

==

.bumpversion.cfg
scrapy/VERSION
==================
95c6b9df;Paul Tremberth;2016-10-03 13:00:14 +0200;Merge pull request #2280 from scrapy/release-notes-1.2
Update release notes for upcoming 1.2.0
==
==================
e2137d77;Paul Tremberth;2016-10-03 12:41:18 +0200;Add release date for scrapy 1.2

==

docs/news.rst
==================
a4331263;Paul Tremberth;2016-10-03 12:38:44 +0200;Merge pull request #2294 from redapple/release-headers
Change release section titles to have correct links in ToC
==
==================
32c46453;Paul Tremberth;2016-10-03 12:34:28 +0200;Merge pull request #2300 from mineo/patch-3
Remove duplicate colons from the feed export settings docs
==
==================
e8edc6c2;Wieland Hoffmann;2016-10-02 16:08:10 +0200;Remove duplicate colons from the feed export settings docs

==

docs/topics/feed-exports.rst
==================
5d38a8e2;Daniel Graña;2016-09-30 15:23:55 -0300;Merge pull request #2298 from scrapy/update-1.2-relnotes-data-dir-util
Update 1.2 release notes with data_path changes from #1581
==
==================
bca374d6;Daniel Graña;2016-09-30 15:23:34 -0300;Merge pull request #1581 from scrapy/fix-util-function-to-work-outside-project-dir
[MRG+1] Make data_path work when outside project (used by HttpCacheMiddleware and Deltafetch plugin)
==
==================
2d932c17;Elias Dorneles;2016-09-30 15:07:58 -0300;test abs path outside project as well

==

tests/test_utils_project.py
==================
fed53c1e;Paul Tremberth;2016-09-30 17:35:29 +0200;Merge pull request #2267 from scrapy/deprecate-ubuntu-packages
[MRG+1] Deprecate official Ubuntu packages and update installation instructions
==
==================
559b4eda;Elias Dorneles;2016-09-30 11:42:50 -0300;update release notes with changes from #1581

==

docs/news.rst
==================
ab3f27b5;Paul Tremberth;2016-09-30 16:30:37 +0200;Merge pull request #2296 from scrapy/architecture-overview-once-more-with-feeling
[MRG+1] architecture docs: restore explanation loop to step 1 (see comment in 3ac3ac4)
==
==================
8bafcf33;Elias Dorneles;2016-09-30 11:20:30 -0300;improve description of engine

==

docs/topics/architecture.rst
==================
9c90d951;Elias Dorneles;2016-09-29 19:11:17 -0300;update data_path dosctring

==

scrapy/utils/project.py
==================
e1072120;Elias Dorneles;2016-09-29 19:02:43 -0300;restore explanation loop to step 1 (see comment in 3ac3ac4)

==

docs/topics/architecture.rst
==================
25bd3b3f;Elias Dorneles;2016-09-29 18:30:42 -0300;add .scrapy when outside spider too, add tests

==

scrapy/utils/project.py
tests/test_utils_project.py
==================
8e4947ef;Elias Dorneles;2015-11-03 15:46:05 -0200;make utils.project.data_path return path unmodified when outside project

==

scrapy/utils/project.py
==================
fd0b6fae;Paul Tremberth;2016-09-29 14:36:13 +0200;Change release section titles to have correct links in ToC

==

docs/news.rst
==================
47ef202a;Paul Tremberth;2016-09-29 14:25:53 +0200;Merge pull request #2285 from redapple/relnotes-debian-jessie-baseline
Mention new Debian Jessie baseline
==
==================
c670e3cd;Paul Tremberth;2016-09-29 14:22:08 +0200;Move mention

==

docs/news.rst
==================
86eb8655;Elias Dorneles;2016-09-29 09:15:09 -0300;Merge pull request #2287 from pawelmhm/docs-2230
[MRG+1][docs/item_pipeline] process_item returning Deferred docs
==
==================
60559369;Elias Dorneles;2016-09-29 09:11:45 -0300;Merge pull request #2292 from stummjr/fix-example-section
[MRG+1] Update examples section in documentation with quotes.toscrape spiders
==
==================
7ba16b73;Paul Tremberth;2016-09-29 10:27:36 +0200;Merge pull request #2293 from scrapy/architecture-overview-fix-reqs-vs-urls
docs: update data flow description and image (fixes: #2278)
==
==================
33d04684;Paul Tremberth;2016-09-29 10:25:21 +0200;Fix typo

==

docs/intro/install.rst
==================
3ac3ac4d;Elias Dorneles;2016-09-28 16:38:45 -0300;docs: update data flow description and image (fixes: #2278) This fixes the explanation to use Requests instead of URLs, which is what actually happens, and is also consistent with the new tutorial, which already explains how URLs become Request objects.
I've also changed the "loop", jumping from 9 to step 2.

==

docs/topics/_images/scrapy_architecture_02.png
docs/topics/architecture.rst
==================
5680c610;Valdir Stumm Junior;2016-09-28 15:45:01 -0300;Doc: update examples section with quotes.toscrape.com spiders

==

docs/intro/examples.rst
==================
23abf2d3;Paul Tremberth;2016-09-28 18:31:27 +0200;Fix title underline

==

docs/intro/install.rst
==================
8d130b29;Paul Tremberth;2016-09-28 17:09:17 +0200;Update installation guide

==

docs/intro/install.rst
==================
c707c313;Paul Tremberth;2016-09-26 17:20:13 +0200;Fix Debian number

==

docs/news.rst
==================
39dbd890;pawelmhm;2016-09-24 08:36:09 +0200;[docs/item_pipeline] process_item returning Deferred docs
* quote url
* use hash of url as filename

==

docs/topics/item-pipeline.rst
==================
bba31b54;Paul Tremberth;2016-09-23 17:23:37 +0200;Mention new Debian Jessie baseline

==

docs/news.rst
==================
7eeee6f6;Paul Tremberth;2016-09-23 16:39:09 +0200;Mention \uXXXX escapes in regards to FEED_EXPORT_ENCODING

==

docs/news.rst
==================
d52fbf20;Paul Tremberth;2016-09-23 16:34:06 +0200;Merge remote-tracking branch 'origin/master' into release-notes-1.2

==
==================
d8672689;Paul Tremberth;2016-09-23 16:25:52 +0200;Merge pull request #2284 from redapple/release-notes-1.1.3-master
Update release notes with 1.1.3 changes
==
==================
80c1e5dc;Paul Tremberth;2016-09-22 21:33:05 +0200;Set release date, fix typo and add tutorial improvement issue number

==

docs/news.rst
==================
a0f87d2f;Paul Tremberth;2016-09-22 17:21:26 +0200;Update release notes for upcoming 1.1.3 bugfix release

==

docs/news.rst
==================
c2493c94;Elias Dorneles;2016-09-23 09:05:34 -0300;Merge pull request #2282 from pawelmhm/docs-2230
[docs] document that process_item can return Deferred
==
==================
b2bfd1e5;Pawel Miech;2016-09-23 10:36:03 +0200;[docs] document that process_item can return Deferred

==

docs/topics/item-pipeline.rst
==================
a975a505;Paul Tremberth;2016-09-22 16:39:21 +0200;Merge pull request #2252 from eliasdorneles/tutorial-upgrades
[MRG+2] Tutorial: rewrite tutorial seeking to improve learning path
==
==================
24bb9152;Elias Dorneles;2016-09-22 11:15:30 -0300;Merge pull request #2229 from ahlinc/fix_shell_completion
[MRG+1] Fix completion in `scrapy shell` for new imports
==
==================
f4a22089;Elias Dorneles;2016-09-22 11:04:45 -0300;addressing review comments and other minor editing

==

docs/intro/tutorial.rst
==================
2e08a9b4;Paul Tremberth;2016-09-22 12:00:14 +0200;Merge pull request #2271 from redapple/mailsender-lists
[MRG+1] Add note on "to" and "cc" as lists for sending emails
==
==================
d636e5ba;Elias Dorneles;2016-09-21 18:54:12 -0300;better description for start_requests expected return value

==

docs/intro/tutorial.rst
==================
32017a76;Elias Dorneles;2016-09-21 11:06:36 -0300;recommend learn python the hard way for beginners

==

docs/intro/tutorial.rst
==================
38266cc9;Elias Dorneles;2016-09-21 11:02:24 -0300;recommend Dive into Python and Python tutorial instead of LPTHW for non-beginners

==

docs/intro/tutorial.rst
==================
9c9690c7;Elias Dorneles;2016-09-21 10:30:08 -0300;add better messages for when response content isn't text (closes #2264)

==

scrapy/http/response/__init__.py
tests/test_http_response.py
==================
c126c593;Elias Dorneles;2016-09-20 18:19:25 -0300;address more review comments

==

docs/intro/tutorial.rst
==================
a876ea5b;Elias Dorneles;2016-09-20 15:10:49 -0300;minor grammar fix

==

docs/intro/tutorial.rst
==================
bc41fdf2;Elias Dorneles;2016-09-20 15:04:08 -0300;address review comments, add debug log to initial spider

==

docs/intro/tutorial.rst
==================
a19af5b1;Elias Dorneles;2016-09-20 14:15:52 -0300;Merge pull request #2273 from redapple/version-stability
[MRG+1] Remove mention of odd-numbered versions for development releases
==
==================
40293551;Paul Tremberth;2016-09-20 18:14:43 +0200;Remove mention of odd-numbered versions for development releases
Fixes GH-1317

==

docs/versioning.rst
==================
125b6911;Elias Dorneles;2016-09-20 12:47:03 -0300;more reviewing and editing, minor restructure, syntax fixes

==

docs/intro/tutorial.rst
==================
e59d79bf;Paul Tremberth;2016-09-20 17:17:22 +0200;Add note on "to" and "cc" as lists for sending emails
Fixes GH-2244

==

docs/topics/email.rst
==================
8975371a;Elias Dorneles;2016-09-20 09:45:05 -0300;Merge branch 'master' into tutorial-upgrades

==
==================
f4f93c5c;Elias Dorneles;2016-09-20 09:19:48 -0300;fix tox docs build, adjust title

==

docs/intro/tutorial.rst
==================
3fd947b3;Elias Dorneles;2016-09-20 09:00:58 -0300;Merge pull request #2269 from redapple/unserializable-warning
Log warning when request cannot be serialized (instead of error)
==
==================
81a0e3cd;Paul Tremberth;2016-09-20 13:42:28 +0200;Raise log level for HttpErrorMiddleware to INFO (from DEBUG)
Fixes GH-910

==

scrapy/spidermiddlewares/httperror.py
tests/test_spidermiddleware_httperror.py
==================
a135dbaf;Paul Tremberth;2016-09-20 12:47:33 +0200;Log warning when request cannot be serialized (instead of error)
Fixes GH-2035

==

scrapy/core/scheduler.py
==================
8893527a;Ashish Kulkarni;2016-08-05 12:54:18 +0530;temporarily deprecate official Ubuntu packages
They are not currently updated and fail to install on
Ubuntu 16.04. Also update the instructions to refer to
the earliest supported LTS (Ubuntu 12.04).

fixes #2137 and closes #2076

==

docs/intro/install.rst
docs/topics/ubuntu.rst
==================
fee07835;Valdir Stumm Junior;2016-09-19 19:19:31 -0300;Completing the data extraction section

==

docs/intro/tutorial.rst
==================
2a409d1d;Elias Dorneles;2016-09-19 17:13:04 -0300;[wip] changing introduction to scraping with selectors

==

docs/intro/tutorial.rst
==================
eb49b459;Daniel Graña;2016-09-19 15:17:45 -0300;Merge pull request #2212 from redapple/debian-jessie-baseline
Add Debian Jessie test env
==
==================
41cd9f40;Paul Tremberth;2016-09-19 18:43:52 +0200;Merge pull request #2243 from pawelmhm/image-pipeline-2198
[MRG+1] [image & file pipeline] loading setting for user classes
==
==================
06331525;Elias Dorneles;2016-09-19 08:11:18 -0300;Merge pull request #2202 from scrapy/doc-arch-overview2
[MRG+1] DOC move Data Flow below the picture; add links to components
==
==================
bb8740a5;Paul Tremberth;2016-09-19 12:26:36 +0200;Update 1.2 release notes with latest changes

==

docs/news.rst
==================
490f6e08;Mikhail Korobov;2016-09-19 14:44:45 +0600;Merge pull request #2239 from redapple/streamlogger-flush
[MRG+1] Add flush() method to StreamLogger
==
==================
5657f6b8;Mikhail Korobov;2016-09-19 14:40:30 +0600;Merge pull request #2258 from redapple/feed-export-started
[MRG+1] Feed exporter: start exporting only on first item
==
==================
55236872;Mikhail Korobov;2016-09-19 14:39:09 +0600;Merge pull request #2225 from Tethik/parse_command_rules_fix
[MRG+1] Two small fixes for when using the parse command and the '-r' flag (rules).
==
==================
8c38dde4;Joakim Uddholm;2016-09-19 05:33:05 +0200;Moved parse command tests to its own file. Added some checks to check for logged errors.

==

tests/test_command_parse.py
tests/test_commands.py
==================
88cf86f5;Joakim Uddholm;2016-09-19 00:51:36 +0200;Merge pull request #1 from redapple/tethik_parse_command_rules_fix
Add tests for crawl command non-default cases
==
==================
48f6a065;Paul Tremberth;2016-09-17 15:25:45 +0200;Flush StreamLogger handlers

==

scrapy/utils/log.py
==================
27f88ad9;Paul Tremberth;2016-09-17 14:19:21 +0200;Merge pull request #2260 from waynelovely/tutorial-fix-20160917-1
Fix a dict key in the tutorial
==
==================
cc8497ab;Wayne Lovely;2016-09-17 11:09:28 +0000;Fix a dict key in the tutorial

==

docs/intro/tutorial.rst
==================
992b2517;Mikhail Korobov;2016-09-17 06:10:06 +0600;Merge pull request #2248 from redapple/scrapy-shell-import-scrapy
[MRG+1] Make scrapy available in shell without explicit import statement
==
==================
91fcafde;Mikhail Korobov;2016-09-17 06:06:53 +0600;Merge pull request #2257 from scrapy/mention-stackoverflow
Mentions stackoverflow as support channel (fixes #2255)
==
==================
03ab0772;Paul Tremberth;2016-09-17 01:36:56 +0200;Feed exporter: start exporting only on first item
Fixes GH-872

==

scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
233b98d6;Valdir Stumm Junior;2016-09-16 18:08:10 -0300;include section describing spider arguments

==

docs/intro/tutorial.rst
==================
31545a9f;Elias Dorneles;2016-09-16 17:13:24 -0300;tutorial: updating extracting data section to introduce CSS and XPath equally

==

docs/intro/tutorial.rst
==================
147e7560;Elias Dorneles;2016-09-16 16:47:24 -0300;update after review comments (thanks @stummjr)

==

docs/intro/tutorial.rst
==================
31260cf0;Elias Dorneles;2016-09-16 16:05:36 -0300;mentions stackoverflow as help channel (fixes #2255)

==

docs/index.rst
==================
de1a6ac6;Elias Dorneles;2016-09-16 16:00:23 -0300;Merge pull request #2249 from scrapy/fix-overview-spider
[MRG+1] docs: update overview spider code to use toscrape.com and minor changes
==
==================
21de617c;Elias Dorneles;2016-09-16 15:55:14 -0300;mention that spiders need to subclass scrapy.Spider

==

docs/intro/tutorial.rst
==================
b2a5cddb;Elias Dorneles;2016-09-16 15:44:39 -0300;tutorial: update section about following links, expand examples adding an AuthorSpider to demonstrate further a different crawling arrangement.

==

docs/intro/tutorial.rst
==================
0cd9dfcc;Valdir Stumm Junior;2016-09-16 15:21:49 -0300;small fixes on tutorial

==

docs/intro/tutorial.rst
==================
0da497cf;Valdir Stumm Junior;2016-09-16 11:55:23 -0300;updates on the first section (our first spider)

==

docs/intro/tutorial.rst
==================
c508f406;Elias Dorneles;2016-09-15 18:05:09 -0300;use harcoded URLs, remove item reference on second spider

==

docs/intro/tutorial.rst
==================
24277912;Elias Dorneles;2016-09-15 17:46:31 -0300;tutorial: remove item class definition and present start_requests first This changes the tutorial, removing the step of creating an item class and also starts by presenting the start_requests method instead of start_urls.

==

docs/intro/tutorial.rst
==================
75531e40;Elias Dorneles;2016-09-15 16:56:13 -0300;use better condition in example spider

==

docs/intro/overview.rst
==================
effaab86;Paul Tremberth;2016-09-15 21:37:15 +0200;Update shell help with availability of scrapy module

==

scrapy/shell.py
==================
1d159ae6;Elias Dorneles;2016-09-15 15:37:03 -0300;minor grammar fix

==

docs/intro/overview.rst
==================
18bd0b08;Elias Dorneles;2016-09-15 15:16:30 -0300;docs: update overview spider code to use toscrape.com and minor changes So, this will replace the spider example code from the overview that scrapes questions from StackOverflow by a spider scraping quotes (much like the one in the tutorial), and upates the text around it to be consistent.
There are also minor wording changes plus a small Sphinx/reST syntax fix
on the features list at the bottom (it was creating a definition list,
causing one line to be bold).

==

docs/intro/overview.rst
==================
105163fe;Paul Tremberth;2016-09-15 19:26:53 +0200;Make scrapy available in shell without explicit import statement

==

scrapy/shell.py
==================
b828facf;Paul Tremberth;2016-09-15 19:25:20 +0200;Add shell test for using scrapy.Request() directly without importing scrapy

==

tests/test_command_shell.py
==================
2f60f2a5;Paul Tremberth;2016-09-15 12:05:03 +0200;Merge pull request #2236 from stummjr/new-tutorial-toscrape
[MRG+1] Update broken Scrapy tutorial to use quotes.toscrape.com
==
==================
7d882095;pawelmhm;2016-09-15 09:30:09 +0200;[image & file pipeline] loading setting for user classes
if user has some custom subclass of Image pipeline and no setting for
this pipeline, he should get default settings defined for Image Pipeline.

Fixes #2198

==

scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/pipelines/media.py
tests/test_pipeline_files.py
tests/test_pipeline_images.py
==================
a9a96bed;Elias Dorneles;2016-09-14 18:09:39 -0300;updated tutorial as per review comments

==

docs/intro/tutorial.rst
==================
bc67cd9e;Valdir Stumm Junior;2016-09-14 12:39:29 -0300;fix indentation issue

==

docs/intro/tutorial.rst
==================
498a3725;Paul Tremberth;2016-09-14 12:19:50 +0200;Add flush() method to StreamLogger
Fixes GH-2125

==

scrapy/utils/log.py
==================
10f8c52f;Valdir Stumm Junior;2016-09-09 10:35:28 -0300;changed tutorial examples from dmoz to quotes.toscrape.com

==

docs/intro/tutorial.rst
==================
129421c7;Elias Dorneles;2016-09-12 13:21:16 -0300;Merge pull request #1503 from demelziraptor/amazon-json-response
[MRG+1] interpreting json-amazonui-streaming as TextResponse
==
==================
fbb55592;Paul Tremberth;2016-09-12 13:35:14 +0200;Add tests for crawl command non-default cases

==

tests/test_commands.py
==================
80260824;Andrew Hlynskyi;2016-09-12 00:43:58 +0300;Fix completion in `scrapy shell` for new imports

==

scrapy/utils/console.py
==================
114437c1;Pengyu CHEN;2015-11-04 02:29:28 +0800;added: Doc for `scrapy.http.TextResponse.urljoin`

==

docs/topics/request-response.rst
==================
743a0aa4;Joakim Uddholm;2016-09-08 21:52:14 +0200;Two fixes for when using the parse command and the '-r' flag (rules). 1. Use default "parse" as callback when the matching rule has no callback. 2. Log error and return when no rule matches the parsed url.

==

scrapy/commands/parse.py
==================
0ef570f6;Matti Remes;2016-09-03 17:36:47 +0300;Update exceptions.rst
Added the missing dot. (+1 squashed commit)
Squashed commits:
[2198972] Update exceptions.rst

There are namely no constructors in classes in Python but an ``__init__`` method instead.

==

docs/topics/exceptions.rst
==================
ec4ab126;Paul Tremberth;2016-09-07 10:15:12 +0200;Merge pull request #2220 from scrapy/comment-typo-fix
typo fix in HttpProxyMiddleware
==
==================
960b1bc8;Mikhail Korobov;2016-09-07 04:54:32 +0500;typo fix in HttpProxyMiddleware

==

scrapy/downloadermiddlewares/httpproxy.py
==================
9e6a72cc;Paul Tremberth;2016-09-05 15:59:58 +0200;Merge pull request #2217 from stummjr/add-analytics-to-docs
[MRG+1] Add Segment Analytics to Documentation
==
==================
9cea6f07;Valdir Stumm Junior;2016-09-02 14:51:07 -0300;Add Segment Analytics to Documentation

==

docs/_templates/layout.html
==================
b188f61b;Paul Tremberth;2016-09-01 17:38:38 +0200;Update release notes for upcoming 1.2.0 version

==

docs/news.rst
==================
58cd7bf8;Paul Tremberth;2016-09-01 11:17:53 +0200;Remove "precise" test env from Travis-CI config

==

.travis.yml
==================
2b2bfcea;Paul Tremberth;2016-09-01 10:20:49 +0200;Add "jessie" build to Travis-CI config

==

.travis.yml
==================
22e870e9;Paul Tremberth;2016-09-01 10:19:49 +0200;Add Debian Jessie test env

==

tox.ini
==================
eedb6ce7;Paul Tremberth;2016-08-31 11:51:47 +0200;Merge pull request #2190 from stummjr/fix-docs
[MRG+1] Fix RANDOMIZE_DOWNLOAD_DELAY description in the docs
==
==================
1e95bf59;Elias Dorneles;2016-08-29 11:08:30 -0300;Merge pull request #2197 from thomdixon/improve-response-documentation
[MRG+1] Correct documentation about Response parameters
==
==================
495d3226;Mikhail Korobov;2016-08-26 20:16:22 +0500;DOC move Data Flow below the picture; add links to components

==

docs/topics/architecture.rst
==================
f68dc302;Thom Dixon;2016-08-24 09:11:27 -0700;Fix indentation

==

docs/topics/request-response.rst
==================
633abfbe;Thom Dixon;2016-08-24 08:47:52 -0700;Correct documentation about Response parameters
This fixes issue #2196

==

docs/topics/request-response.rst
==================
d61650d8;Valdir Stumm Junior;2016-08-19 18:24:32 -0300;fix RANDOMIZE_DOWNLOAD_DELAY description in the docs

==

docs/topics/settings.rst
==================
cacd038b;Paul Tremberth;2016-08-19 17:04:28 +0200;Merge pull request #2188 from scrapy/release-notes-1.1.2-master
Add release notes for 1.1.2 version
==
==================
f18c3e5c;Paul Tremberth;2016-08-18 16:18:08 +0200;Add release notes for 1.1.2 version

==

docs/news.rst
==================
9de6f1ca;Paul Tremberth;2016-08-17 14:51:30 +0200;Merge pull request #1905 from rootAvish/duplication-fix
[MRG+1] Modified read failure recovery in utils/gz.py to read only the last f.extrasize bytes of f.extrabuf[ ]
==
==================
241bd00e;Mikhail Korobov;2016-08-16 20:59:17 +0600;Merge pull request #2168 from advarisk/w3lib-canonicalize-url
[MRG+1] Use w3lib.url.canonicalize_url() from w3lib 1.15.0
==
==================
bb3b8064;Ashish Kulkarni;2016-08-08 16:54:03 +0530;Use w3lib.url.canonicalize_url() from w3lib 1.15.0
Also remove code/imports which are now unused due to this change.

fixes #2157

==

docs/topics/link-extractors.rst
requirements.txt
scrapy/linkextractors/__init__.py
scrapy/utils/request.py
scrapy/utils/url.py
setup.py
tests/test_utils_url.py
==================
9a734e67;Paul Tremberth;2016-08-12 18:28:34 +0200;Merge pull request #2058 from dalleng/serialize_set
[MRG+1] Add set serialization to ScrapyJSONEncoder
==
==================
d9437fd3;rootavish;2016-04-06 08:47:06 +0530;Modifying existing gzip read failure recovery mechanism to patch read for broken archives

==

scrapy/utils/gz.py
tests/sample_data/compressed/unexpected-eof-output.txt
tests/sample_data/compressed/unexpected-eof.gz
tests/test_utils_gz.py
==================
1ec21006;Paul Tremberth;2016-08-11 11:52:59 +0200;Merge pull request #2169 from Tethik/parse_command_callback_typo
[MRG+1] Typo fix for error in parse command 
==
==================
625c69fd;Joakim Uddholm;2016-08-08 14:32:53 +0200;Fixed typo in error message when selecting a callback method for the parse command.

==

scrapy/commands/parse.py
==================
414857a5;Mikhail Korobov;2016-08-05 21:52:27 -0400;Merge pull request #2140 from jesuslosada/images-expires
[MRG+1] Fix IMAGES_EXPIRES default value
==
==================
fa78849e;Mikhail Korobov;2016-08-05 21:46:28 -0400;Merge pull request #2165 from loreguerra/master
[MRG+1] Updated architecture graph for organization/clarity
==
==================
7d432872;Lorena;2016-08-04 11:01:14 -0700;text updates to match graphic

==

docs/topics/_images/scrapy_architecture_02.png
docs/topics/architecture.rst
==================
04f93e09;Lorena;2016-08-04 10:04:47 -0700;updated graph for organization/clarity

==

docs/topics/_images/scrapy_architecture_02.png
docs/topics/architecture.rst
==================
27d4cea6;Paul Tremberth;2016-08-01 20:50:14 +0200;Merge pull request #2161 from redapple/release-notes-1.1.1-master
Release notes for 1.1.1
==
==================
5b1d98b8;Paul Tremberth;2016-07-13 17:59:11 +0200;Update 1.1.1 release date

==

docs/news.rst
==================
928e93f8;Paul Tremberth;2016-07-13 17:36:13 +0200;Update notes with latest 1.1 commits

==

docs/news.rst
==================
e1d118d5;Paul Tremberth;2016-07-11 16:26:42 +0200;Update release notes for upcoming 1.1.1 release

==

docs/news.rst
==================
2a0a96ae;Paul Tremberth;2016-08-01 17:57:57 +0200;Merge pull request #2160 from stummjr/patch-1
[MRG+1] Remove README download count badge
==
==================
63876fc6;Valdir Stumm Jr;2016-08-01 12:16:50 -0300;Remove download stats badge

==

README.rst
==================
4eec0535;Elias Dorneles;2016-08-01 11:37:51 -0300;remove bumpversion prerelease configuration I propose to remove the prerelease configuration from bumpversion, because I think its behavior is just too confusing.
The rational for this is that making the release procedure predictable
is more important than facilitating making pre-releases, which are sort
of the exception in the workflow.

The current configuration makes most common cases confusing:

* bug fix releases require you have to remember to use `--serialize "{major}.{minor}.{patch}"`
* to start a pre-release cycle, you actually use `minor` or `patch`
* to do the actual minor or patch release, you use `prerel`

Also, `prerel` breaks if you run it on a branch with a final release,
because it can't parse the prerelease information.

Therefore, I propose keeping the bumpversion defaults, and do the
prereleases (dev1, dev2, rc1, etc) manually (with `--new-version`),
which makes for a more predictable and intuitive behavior.

* `bumpversion minor` and `bumpversion patch` will work as expected
* pre-releases will be manually handled, but this seems a small overhead
  than remembering the details I mention above.

If you're happy with this, I'll also update [the wiki][1] with new
instructions.

[1]: https://github.com/scrapy/scrapy/wiki/Scrapy-release-procedure

==

.bumpversion.cfg
==================
2c9a38d1;Mikhail Korobov;2016-07-31 21:28:38 -0400;Merge pull request #2153 from Digenis/Selector_bad_args
[MRG+1] Selector should not receive both response and text
==
==================
643dbeff;Νικόλαος-Διγενής Καραγιάννης;2016-07-29 17:13:59 +0300;Selector should not receive both response and text

==

scrapy/selector/unified.py
tests/test_selector.py
==================
34e7dadf;Elias Dorneles;2016-07-29 10:12:52 -0300;Merge pull request #1610 from darshanime/scheduler_debug
[MGR+1] Change, document `LOG_UNSERIALIZABLE_REQUESTS`
==
==================
d8e62e66;darshanime;2016-07-26 20:46:12 +0530;update log demo print

==

docs/topics/jobs.rst
docs/topics/settings.rst
==================
fe68a45c;Paul Tremberth;2016-07-26 12:50:25 +0200;Merge pull request #2138 from jesuslosada/master
[MRG+1] Apply the FILES_STORE_S3_ACL setting in ImagesPipeline
==
==================
b6375d37;Elias Dorneles;2016-07-25 10:49:29 -0300;Merge pull request #1566 from darshanime/signal-example
[MRG+1] Include example for signal docs
==
==================
a2e64525;Darshan Chaudhary;2015-10-29 15:40:07 +0530;Include signal example

==

docs/topics/media-pipeline.rst
docs/topics/signals.rst
scrapy/utils/misc.py
==================
0c77b6d0;darshanime;2016-07-25 17:55:05 +0530;update docs for settings

==

docs/topics/jobs.rst
docs/topics/settings.rst
scrapy/core/scheduler.py
==================
2d9e5937;Darshan Chaudhary;2015-11-25 12:34:11 +0530;Include deprecated warning

==

scrapy/core/scheduler.py
scrapy/settings/deprecated.py
==================
472a8a47;Darshan Chaudhary;2015-11-21 00:40:01 +0530;Change name, log once

==

docs/topics/jobs.rst
docs/topics/settings.rst
scrapy/core/scheduler.py
scrapy/settings/default_settings.py
==================
82215560;Jesús Losada;2016-07-22 23:22:18 +0200;Add documentation on Amazon S3 ACLs

==

docs/topics/media-pipeline.rst
==================
e17fdd72;Diego Allen;2016-06-16 21:56:24 -0400;Add set serialization to ScrapyJSONEncoder

==

scrapy/utils/serialize.py
tests/test_utils_serialize.py
==================
7c3e3b48;Jesús Losada;2016-07-22 20:03:49 +0200;Fix ImagesPipeline test settings

==

tests/test_pipeline_images.py
==================
f193c52a;Jesús Losada;2016-07-22 19:47:29 +0200;Fix IMAGES_EXPIRES default value
The default value should be 90.

==

scrapy/pipelines/images.py
==================
c6a2ca4e;Jesús Losada;2016-07-22 19:32:29 +0200;Document S3 capabilities in FilesPipeline and ImagesPipeline

==

docs/topics/media-pipeline.rst
docs/topics/settings.rst
==================
f72991a9;Jesús Losada;2016-07-21 21:18:22 +0200;Add the IMAGES_STORE_S3_ACL setting

==

scrapy/pipelines/images.py
scrapy/settings/default_settings.py
==================
ec1c6150;Paul Tremberth;2016-07-19 12:31:06 +0200;Merge pull request #2005 from feliperuhland/master
[MRG+1] Included new optional parameter in startproject command line
==
==================
fe088925;Felipe Ruhland;2016-07-19 00:12:39 -0300;Included implementation notes in docstring
Signed-off-by: Felipe Ruhland <felipe.ruhland@gmail.com>

==

scrapy/commands/startproject.py
==================
de64a1f6;Felipe Ruhland;2016-07-19 00:04:45 -0300;Fix scrapy.cfg validation
Signed-off-by: Felipe Ruhland <felipe.ruhland@gmail.com>

==

scrapy/commands/startproject.py
==================
a86562b7;Elias Dorneles;2016-07-18 09:24:03 -0300;Merge pull request #2128 from kas/patch-1
(docs) Minor grammar fix in logging.rst
==
==================
5fabed51;Kenneth Schnall;2016-07-15 23:14:11 -0400;Update logging.rst

==

docs/topics/logging.rst
==================
79639d0f;Mikhail Korobov;2016-07-13 14:44:00 +0000;Merge pull request #1989 from pawelmhm/fix-images-pipeline-uppercase-other
[MRG+1] [image_pipeline] bring back uppercase class attributes
==
==================
ceecf3b2;Pawel Miech;2016-07-13 16:17:34 +0200;[image_pipeline] minor style tweaks

==

scrapy/pipelines/images.py
==================
2dd1a9e3;Mikhail Korobov;2016-07-13 10:48:08 +0000;Merge pull request #2094 from redapple/dns-invalid-id
Catch and ignore certification verification exception for IP-address hosts
==
==================
005cf949;Paul Tremberth;2016-07-13 11:01:30 +0200;Change wording of warning + docstring for ScrapyClientTLSOptions

==

scrapy/core/downloader/tls.py
==================
3b591556;Elias Dorneles;2016-07-12 17:05:39 -0300;Merge pull request #2120 from kas/kas-patch-1
(docs) Fix small grammar issue in practices.rst (Supersedes #2119)
==
==================
2489f84d;Kenneth Schnall;2016-07-12 15:34:50 -0400;Update practices.rst

==

docs/topics/practices.rst
==================
859bcf48;Paul Tremberth;2016-07-12 17:53:19 +0200;Rephrase warning

==

scrapy/core/downloader/tls.py
==================
c3109daa;Paul Tremberth;2016-07-12 17:01:09 +0200;Merge pull request #2034 from dracony/master
[MRG+1] Added option to turn off ensure_ascii for JSON exporters
==
==================
33a39b36;Dracony;2016-06-08 17:24:08 +0200;added FEED_EXPORT_ENCODING setting to allow encoding specification

==

docs/topics/feed-exports.rst
scrapy/exporters.py
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
9818c97f;Pawel Miech;2016-07-12 14:15:41 +0200;[image_pipeline] dont use assert in doctest

==

scrapy/pipelines/media.py
==================
c22cc109;Pawel Miech;2016-07-12 13:58:36 +0200;[image_pipeline] style edits
* 80 characters line limit
* shortening some code
* removed dead code
* add doctest for _key_for_pipe function

==

docs/topics/media-pipeline.rst
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/pipelines/media.py
==================
8a22a74e;Paul Tremberth;2016-07-11 12:15:38 +0200;Merge pull request #2065 from redapple/octet-stream-no-decompress
[MRG+2] [HttpCompressionMW] Do not decompress gzip binary/octet-stream responses
==
==================
962eb11c;Paul Tremberth;2016-07-11 11:30:05 +0200;Simplify regex conditions

==

scrapy/utils/gz.py
==================
778f1cf8;Paul Tremberth;2016-07-08 18:13:20 +0200;Merge remote-tracking branch 'origin/master' into octet-stream-no-decompress

==
==================
d43a3573;Elias Dorneles;2016-07-08 08:47:56 -0300;Merge pull request #2050 from Tethik/is_gzipped_fix
[MRG+1] Is_gzipped for application/x-gzip;charset=utf-8
==
==================
b7553d92;Mikhail Korobov;2016-07-08 10:47:54 +0600;Merge pull request #2038 from redapple/canonicalize-idna-failures
[MRG] Do not fail on canonicalizing URLs with wrong netlocs
==
==================
5f261cf2;Mikhail Korobov;2016-07-08 10:45:22 +0600;Merge pull request #2026 from Digenis/contributing-full_subjects
[MRG+1] Encourage complete titles in pull requests
==
==================
52a52e23;Mikhail Korobov;2016-07-08 10:44:24 +0600;Merge pull request #2001 from matveinazaruk/issue-2000
[MRG+1] Fixed choosing of response class.
==
==================
0ab7c1fb;Elias Dorneles;2016-07-06 18:01:30 -0300;Merge pull request #2052 from stummjr/genspider-standalone
[MRG+1] Enable genspider command outside project folder
==
==================
081595a2;Valdir Stumm Junior;2016-07-05 22:48:18 -0300;document new genspider behavior

==

docs/topics/commands.rst
==================
8987b177;Valdir Stumm Junior;2016-07-04 18:59:53 -0300;remove references to Item classes in templates

==

scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
==================
1779f5fe;Valdir Stumm Junior;2016-06-11 20:44:08 -0300;enable genspider command outside projects

==

scrapy/commands/genspider.py
tests/test_commands.py
==================
759a555d;Mikhail Korobov;2016-07-06 21:43:41 +0600;Merge pull request #2069 from redapple/https-connect-host
[MRG] Add "Host" header in CONNECT requests to HTTPS proxies
==
==================
1737c158;Paul Tremberth;2016-07-06 17:29:39 +0200;Merge pull request #2091 from eLRuLL/default_headers_priority
[MRG+1] prioritize default headers over user agent middlewares
==
==================
15d0c891;Paul Tremberth;2016-07-06 17:15:21 +0200;Cleanup unused argument

==

scrapy/core/downloader/handlers/http11.py
==================
8ec6c22d;Mikhail Korobov;2016-07-06 20:07:19 +0600;Merge pull request #2095 from scrapy/testing-deps
[MRG+1] TST pin pytest-cov to 2.2.1; upgrade pytest
==
==================
42737347;Mikhail Korobov;2016-07-06 18:29:49 +0500;TST pin pytest-cov to 2.2.1; upgrade pytest

==

tests/requirements-py3.txt
tests/requirements.txt
==================
37efdde3;Paul Tremberth;2016-07-06 14:18:59 +0200;Catch and ignore TLS verification exception for IP-address hosts
Fixes GH-2092

==

scrapy/core/downloader/tls.py
tests/test_downloader_handlers.py
==================
49ac7de2;Raul Gallegos;2016-07-05 15:38:17 -0500;prioritize default headers over user agent

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
441df4c8;Elias Dorneles;2016-07-05 10:26:33 -0300;Merge pull request #2060 from pawelmhm/windows-python3
[MRG+1] [docs] add note about windows + python3
==
==================
2a92ffb4;Νικόλαος-Διγενής Καραγιάννης;2016-06-04 10:32:29 +0300;Encourage descriptive PR titles

==

docs/contributing.rst
==================
b67440de;Pawel Miech;2016-07-04 16:35:59 +0200;docs on Scrapy on Windows + Python 3

==

docs/faq.rst
docs/intro/install.rst
==================
6539277f;Paul Tremberth;2016-06-21 17:14:41 +0200;Fix CONNECT request timeout (with an ugly hack)

==

tests/test_downloader_handlers.py
==================
d9343463;Paul Tremberth;2016-06-21 13:26:32 +0200;Add "Host" header in CONNECT requests to HTTPS proxies

==

scrapy/core/downloader/handlers/http11.py
==================
10a2c46e;Paul Tremberth;2016-06-20 13:39:37 +0200;[HttpCompressionMiddleware] Do not decompress binary/octet-stream responses

==

scrapy/utils/gz.py
tests/test_downloadermiddleware_httpcompression.py
==================
fa4d0cdf;Pawel Miech;2016-06-20 12:39:09 +0200;[FilesPipeline, ImagesPipeline] fix for cls attrs with DEFAULT prefix
some class attributes for ImagePipeline and FilesPipeline had DEFAULT prefix. These
attributes should be preserved as well, if users subclasses define values for
DEFAULT_<CLS_ATTRIBUTE_NAME> attribute this value should be preserved.

==

scrapy/pipelines/files.py
scrapy/pipelines/images.py
tests/test_pipeline_files.py
tests/test_pipeline_images.py
==================
07d16055;Pawel Miech;2016-06-17 13:28:51 +0200;[docs] warnings about windows + python 3 in faq and install

==

docs/faq.rst
docs/intro/install.rst
==================
73cc066c;Pawel Miech;2016-06-17 09:21:58 +0200;[docs] add note about windows + python3

==

docs/news.rst
==================
10b79c9b;Pawel Miech;2016-06-15 15:49:11 +0200;[files-pipeline] update docs with note about settings
for subclasses.

==

docs/topics/media-pipeline.rst
==================
539d34bc;Pawel Miech;2016-06-15 15:39:11 +0200;[media-pipeline, file-pipeline] allow setting custom settings for subclasses
* move key_for_pipe function to media pipeline so that file pipeline can use it
* use key_for_pipe in file pipeline so that users can define custom settings for subclasses easily
* add tests for file pipelines attributes and settings

==

scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/pipelines/media.py
tests/test_pipeline_files.py
==================
acbfdc61;Pawel Miech;2016-06-15 15:12:18 +0200;[files_pipeline] ensure class attributes are preserved
dont override class attributes with default settings (same as in image pipeline).

==

scrapy/settings/default_settings.py
tests/test_pipeline_files.py
==================
c6d1686d;Pawel Miech;2016-06-15 14:48:25 +0200;[files_pipeline] unify tests for files pipeline
if test tests same thing but for different field it can be unified into one.

==

tests/test_pipeline_files.py
==================
72e4d5f3;Pawel Miech;2016-06-15 14:07:17 +0200;[image_pipeline] another test for subclass inheritance
test case when subclass inherits from base class and has no attributes nor
settings defined.

==

tests/test_pipeline_images.py
==================
ee39d11e;Pawel Miech;2016-06-15 11:25:38 +0200;[image_pipeline] refactor and simplify tests for image settings
unify tests that test same thing for different attribute values into one. Add
better docstrings for tests.

==

scrapy/pipelines/images.py
tests/test_pipeline_images.py
==================
23f99e98;Joakim Uddholm;2016-06-14 21:33:51 +0200;is_gzipped: Separated tests again.

==

tests/test_utils_gz.py
==================
80c296e0;Mikhail Korobov;2016-06-14 23:45:04 +0600;Merge pull request #2048 from redapple/bs4-faq
[MRG] Add FAQ entry on using BeautifulSoup in spider callbacks
==
==================
1ff9a482;Paul Tremberth;2016-06-14 19:33:56 +0200;Do not commit on any HTML parsing speed assumption with BS4+lxml

==

docs/faq.rst
==================
d7151725;Pawel Miech;2016-06-14 19:09:56 +0200;[image_pipeline] unify and simplify tests for setting loading
there was identical test for different setting keys. I unified it into
one unit test.

Fixes comments for tests, adds comments about intention of uppercase attrs.

Adds another test for user defined setting keys and uppercase attrs.

==

scrapy/pipelines/images.py
tests/test_pipeline_images.py
==================
36928d89;Joakim Uddholm;2016-06-14 15:40:20 +0200;is_gzipped: improved readability

==

scrapy/utils/gz.py
==================
6cbd92fa;Paul Tremberth;2016-06-14 15:33:34 +0200;Add note on how to choose parser with BeautifulSoup

==

docs/faq.rst
==================
259426ec;Joakim Uddholm;2016-06-14 14:39:16 +0200;is_gzipped: Changed to regex to check the content-type header. Also suggested by @redapple.

==

scrapy/utils/gz.py
==================
124e218a;Joakim Uddholm;2016-06-14 14:22:18 +0200;Added new testcases suggested by @redapple.

==

tests/test_utils_gz.py
==================
edca2832;Elias Dorneles;2016-06-13 17:35:34 -0300;Merge pull request #2054 from matt-oconnell/tutorial-typos
Typo fixes
==
==================
b76b3746;Matvei Nazaruk;2016-06-13 22:36:13 +0300;Added test for http11 choosing response type without content-type header.

==

tests/test_downloader_handlers.py
==================
0bb12889;Matt O'Connell;2016-06-13 16:21:02 -0400;Typo fixes

==

docs/intro/tutorial.rst
==================
2c98a88a;Joakim Uddholm;2016-06-12 10:49:34 +0200;Separated tests based on case

==

tests/test_utils_gz.py
==================
db729f5b;Joakim Uddholm;2016-06-12 02:26:16 +0200;Suggested fix for is_gzipped

==

scrapy/utils/gz.py
==================
989f6b88;Joakim Uddholm;2016-06-12 01:38:01 +0200;Test to show bug with is_gzipped and Content-Type: application/gzip;charset.

==

tests/test_utils_gz.py
==================
7978237e;Paul Tremberth;2016-06-10 17:42:18 +0200;Add FAQ entry on using BeautifulSoup in spider callbacks

==

docs/faq.rst
==================
a62d4b08;Pawel Miech;2016-06-10 12:48:02 +0200;[image-pipeline] image settings with class name
allow to have image settings with class name, so that settings for user defined ImagePipeline
subclasses can be defined easily.

==

docs/topics/media-pipeline.rst
scrapy/pipelines/images.py
tests/test_pipeline_images.py
==================
1aec5200;Paul Tremberth;2016-06-08 16:49:33 +0200;Do not fail on canonicalizing URLs with wrong netlocs
Fixes #2010

==

scrapy/utils/url.py
tests/test_utils_url.py
==================
b7925e42;Paul Tremberth;2016-06-06 16:14:27 +0200;Merge pull request #2008 from foromer4/master
[MRG+1] Fix issue HttpCompressionMiddleware tries to decode HEAD responses #1899
==
==================
6ff605b4;Mikhail Korobov;2016-06-06 20:13:24 +0600;Merge pull request #1974 from starrify/more-errors-to-retry
[MRG+1] Added: Retrying scrapy.core.downloader.handlers.http11.TunnelError
==
==================
f929853c;Paul Tremberth;2016-06-06 16:11:29 +0200;Merge pull request #2015 from lopuhin/patch-1
[MRG+1] Use "url" variable in the example
==
==================
da8d0ead;Konstantin Lopuhin;2016-05-27 10:47:57 +0300;Use "url" variable in the example
Instead of hardcoded http://www.example.com: without it url variable is unused and only one request will make it past dupefilter.
==

docs/topics/downloader-middleware.rst
==================
c8ec79d9;omer;2016-05-25 06:56:06 +0300;fix issue with '' in python 3

==

tests/test_downloadermiddleware_httpcompression.py
==================
9ad54b38;Felipe Ruhland;2016-05-24 13:03:33 -0300;Fix template description after create project

==

scrapy/commands/startproject.py
tests/test_commands.py
==================
85c4ecb9;Felipe Ruhland;2016-05-24 13:00:41 -0300;Removed validation of project_name dir exists

==

scrapy/commands/startproject.py
==================
b8a09d7a;Felipe Ruhland;2016-05-24 11:58:52 -0300;Added tests for more or less parameters

==

tests/test_commands.py
==================
fc9a45ee;Felipe Ruhland;2016-05-24 11:57:56 -0300;Simplified copytree function

==

scrapy/commands/startproject.py
==================
24a45cc6;Felipe Ruhland;2016-05-24 10:58:50 -0300;Fix py35 compatibility tests

==

scrapy/commands/startproject.py
==================
ffa77e1a;omer;2016-05-24 14:24:29 +0300;Do not decode of head response (2)

==

scrapy/downloadermiddlewares/httpcompression.py
==================
089483ae;Felipe Ruhland;2016-05-23 23:16:15 -0300;Updated docs for new option in command line

==

docs/topics/commands.rst
==================
2521f031;Felipe Ruhland;2016-05-23 23:15:53 -0300;Created new tests for implementation

==

tests/test_commands.py
==================
6beb4f01;Felipe Ruhland;2016-05-23 23:14:33 -0300;Created project_dir optional parameter in startproject command line

==

scrapy/commands/startproject.py
==================
ce48bae5;omer;2016-05-23 19:52:38 +0300;Do not decode of head response

==

tests/test_downloadermiddleware_httpcompression.py
==================
1bc9d35a;Matvei Nazaruk;2016-05-19 22:24:37 +0300;Fixed choosing of response class based on body.

==

scrapy/core/downloader/handlers/http11.py
==================
d3ced85e;Elias Dorneles;2016-05-18 13:18:47 -0300;Merge pull request #1995 from scrapy/docs-errback
DOC Add info and example on errbacks
==
==================
b3367c7a;Paul Tremberth;2016-05-18 18:00:09 +0200;DOC Add info and example on errbacks

==

docs/topics/request-response.rst
==================
c2c8036a;Paul Tremberth;2016-05-18 16:52:09 +0200;DOC Update copyright notice

==

docs/conf.py
==================
6c67db39;Pawel Miech;2016-05-18 12:04:52 +0200;[image_pipeline] tests for class attrs backward compatibility
and docs about image pipeline settings.

==

docs/topics/media-pipeline.rst
tests/test_pipeline_images.py
==================
ed4b9afb;Elias Dorneles;2016-05-17 13:41:53 -0300;Merge pull request #1994 from scrapy/overview-code
[DOC][Overview] Use idiomatic .extract_first()
==
==================
149c4cd4;Paul Tremberth;2016-05-17 17:53:40 +0200;[DOC][Overview] Use idiomatic .extract_first()

==

docs/intro/overview.rst
==================
9b3c72cb;Paul Tremberth;2016-05-17 16:24:05 +0200;DOC Place FEED_TEMPDIR setting at lexicographical position

==

docs/topics/settings.rst
==================
4cef1a1d;Pawel Miech;2016-05-13 12:35:35 +0200;[image_pipeline] bring back uppercase pipeline attributes
allow users to have class attributes on image pipelines. This assumes
that class attributes are useful if users want to have different pipeline
classes inhriting from ImagePipeline.

==

scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/settings/default_settings.py
tests/test_pipeline_images.py
==================
0700e437;Paul Tremberth;2016-05-11 17:31:50 +0200;Update release notes and date for 1.1.0

==

docs/news.rst
==================
aecc23d2;mgachhui;2016-05-08 18:39:56 +0530;Added Python 3.3+ to readme

==

README.rst
==================
0e2b49c8;Elias Dorneles;2016-05-11 10:51:45 -0300;[MRG+1] Prevent empty warnings in case of certificate verification failures
[MRG+1] Prevent empty warnings in case of certificate verification failures
==
==================
bd3e71a1;Paul Tremberth;2016-05-11 14:50:08 +0200;Merge pull request #1980 from redapple/release-notes-1.0.6-merge
Merge 1.0.6 release notes
==
==================
d62654df;Paul Tremberth;2016-05-11 14:39:55 +0200;Merge 1.0.6 release notes

==

docs/news.rst
==================
137197b9;Paul Tremberth;2016-05-11 13:12:35 +0200;Prevent empty warnings in case of certificate verification failures
Fixes #1976

==

scrapy/core/downloader/tls.py
==================
6aa85aee;Paul Tremberth;2016-05-09 16:43:40 +0200;Merge pull request #1975 from lipis/github
Github >> GitHub
==
==================
3f8be374;Panayiotis Lipiridis;2016-05-09 16:15:18 +0200;Github >> GitHub

==

docs/contributing.rst
docs/topics/selectors.rst
docs/topics/ubuntu.rst
==================
334ee40e;Pengyu CHEN;2016-05-09 20:43:41 +0800;Added: Retrying scrapy.core.downloader.handlers.http11.TunnelError

==

scrapy/downloadermiddlewares/retry.py
==================
064f0534;Mikhail Korobov;2016-04-29 16:55:10 +0600;Merge pull request #1962 from redapple/w3lib-dep
Bump w3lib version dependency in setup.py
==
==================
c8bff237;Paul Tremberth;2016-04-29 10:29:37 +0200;Bump w3lib version dependency in setup.py

==

requirements-py3.txt
setup.py
==================
cb38f389;Paul Tremberth;2016-04-28 17:54:37 +0200;Add notes on botocore support and JsonItemExporter opening/closing brackets

==

docs/news.rst
==================
dc9de752;Paul Tremberth;2016-04-28 15:28:28 +0200;Update release notes with recent features and bug fixes.

==

docs/news.rst
==================
dbef7e2b;Mikhail Korobov;2016-04-27 01:32:42 +0600;Merge pull request #1947 from scrapy/canonicalize-url
[MRG+1] Fix canonicalize_url() on Python 3 and re-enable tests
==
==================
0e11b3e6;Paul Tremberth;2016-04-26 20:03:17 +0200;Add idempotence tests for canonicalize_url

==

tests/test_utils_url.py
==================
efbe75ea;Paul Tremberth;2016-04-26 16:14:15 +0200;Use six.PY2 also for conditional imports

==

scrapy/utils/url.py
==================
25401fd3;Paul Tremberth;2016-04-26 15:12:00 +0200;Use six.PY2 instead of six.PY3 for Python version variations
Also don't test passed encoding against 'utf8';
Just consider that if encoding failed, it must have been another encoding.

==

scrapy/utils/url.py
==================
cf716ea2;Paul Tremberth;2016-04-25 15:21:21 +0200;Merge pull request #1950 from patcon/patch-1
[MRG+1] Place brackets on own lines with JsonItemExporter
==
==================
19a4a0ad;Patrick Connolly;2016-04-24 14:55:08 -0400;Place brackets on own lines with JsonItemExporter.
Placing the opening and closing brackets on their own lines makes it slightly easier to sort lines after the `spider_closed` signal is fired.
==

scrapy/exporters.py
==================
8efa9879;Paul Tremberth;2016-04-21 16:51:17 +0200;Allow more pre-releases with bumpversion

==

.bumpversion.cfg
==================
68dedf54;Paul Tremberth;2016-04-21 14:38:18 +0200;Fix canonicalize_url() on Python 3 and re-enable tests

==

scrapy/utils/url.py
tests/test_utils_url.py
==================
73a5571c;Mikhail Korobov;2016-04-20 19:33:45 +0600;Merge pull request #1923 from scrapy/request-new-safe_url_string
[MRG+1] Use newer w3lib.url.safe_url_string() and re-enable HTTP request tests
==
==================
417279cc;Paul Tremberth;2016-04-20 15:12:19 +0200;Bump up w3lib requirement to v1.14.2

==

requirements.txt
==================
679a6806;Mikhail Korobov;2016-04-20 18:57:33 +0600;Merge pull request #1933 from scrapy/cert-verif-ignore
Ignore HTTPS certificate verification failures
==
==================
cd979ace;Paul Tremberth;2016-04-20 14:42:03 +0200;Add HTTPS tests with non-hostname-maching server certificate

==

tests/keys/example-com.cert.pem
tests/keys/example-com.conf
tests/keys/example-com.gen.README
tests/keys/example-com.key.pem
tests/mockserver.py
tests/test_downloader_handlers.py
==================
3735eb8e;Mikhail Korobov;2016-04-20 17:32:04 +0600;Merge pull request #1912 from redapple/https-proxy-pool-key
[MRG+1] Fix HTTP Pool key for HTTPS proxy tunneled connections (CONNECT method)
==
==================
a8b49472;Mikhail Korobov;2016-04-20 17:30:13 +0600;Merge pull request #1938 from redapple/https-proxy-connect-sni
Set SNI properly when using CONNECT
==
==================
dcea11a7;Paul Tremberth;2016-04-19 10:41:13 +0200;Fall back to no-SNi context factory is Twisted<14 is used

==

scrapy/core/downloader/handlers/http11.py
==================
d6760dba;Paul Tremberth;2016-04-18 18:30:01 +0200;Set SNI properly when using CONNECT

==

scrapy/core/downloader/handlers/http11.py
==================
25ee0235;Paul Tremberth;2016-04-14 17:19:55 +0200;Catch VerificationError but keep the rest of ClientTLSOptions

==

scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/tls.py
==================
a087d259;Paul Tremberth;2016-04-14 00:12:25 +0200;Ignore HTTPS certificate verification failures
Fixes #1930

==

scrapy/core/downloader/contextfactory.py
==================
ba6dbad1;Mikhail Korobov;2016-04-12 18:35:34 +0600;Merge pull request #1926 from redapple/faq-mcve
Reference StackOverflow's "minimal, complete, and verifiable example" guide
==
==================
2849ebf4;Paul Tremberth;2016-04-12 14:07:33 +0200;Reference StackOverflow's "minimal, complete, and verifiable example" guide

==

docs/contributing.rst
==================
47bfac16;Paul Tremberth;2016-04-12 12:15:17 +0200;Merge pull request #1924 from lopuhin/faq-fix-py3
[MRG+1] Fix FAQ entry about python versions support (add Python 3.3+)
==
==================
1ec49c2a;Konstantin Lopuhin;2016-04-12 11:48:57 +0300;Fix FAQ entry about python versions support

==

docs/faq.rst
==================
d42a98d3;Paul Tremberth;2016-04-12 00:33:25 +0200;Use newer w3lib.url.safe_url_string() and re-enable HTTP request tests

==

requirements.txt
scrapy/http/request/__init__.py
tests/test_http_request.py
==================
86e4442d;Paul Tremberth;2016-04-06 20:02:50 +0200;Fix HTTP Pool key for HTTPS proxy tunneled connections (CONNECT method)

==

scrapy/core/downloader/handlers/http11.py
==================
10d03ee4;Paul Tremberth;2016-04-11 15:12:24 +0200;Merge pull request #1916 from nblock/patch-1
Fix spelling mistake
==
==================
a3557dd3;nblock;2016-04-11 14:06:57 +0200;Fix spelling mistake

==

docs/topics/loaders.rst
==================
ff80e1c3;Mikhail Korobov;2016-04-09 22:05:59 +0600;Merge pull request #1913 from redapple/link-extractor-new-w3lib
Fix link extractor tests for non-ASCII characters from latin1 document
==
==================
7b5243a2;Paul Tremberth;2016-04-09 15:15:01 +0200;Add link extractor test for non-ASCII characters in query part of URL

==

tests/sample_data/link_extractor/linkextractor_latin1.html
tests/test_linkextractors_deprecated.py
==================
1656fbcf;Paul Tremberth;2016-04-08 23:25:50 +0200;Fix link extractor tests for non-ASCII characters from latin1 document
URL path component should use UTF-8 before percent-encoding (that's what
browsers do when you open scrapy/tests/sample_data/link_extractor/linkextractor_latin1.html
and follow the links)
This matches current w3lib v1.14.1

==

tests/test_linkextractors_deprecated.py
==================
0ede017d;Paul Tremberth;2016-04-08 12:55:09 +0200;Merge pull request #1891 from djunzu/update_files_images_pipelines
[MRG+1] Change Files/ImagesPipelines class attributes to instance attributes
==
==================
cbb695d0;Paul Tremberth;2016-04-06 15:47:06 +0200;Merge pull request #1881 from nyov/dedupe
[MRG+1] Remove duplicate code now handled by newer w3lib
==
==================
642fedb3;Paul Tremberth;2016-04-04 15:23:03 +0200;Merge pull request #1902 from starrify/case-insensitive-robots-txt-for-sitemap
[MRG+1] Added: Making it case-insensitive when extracting sitemap URLs from a robots.txt
==
==================
6988e9cd;djunzu;2016-03-31 19:20:48 -0300;Update docs.
	modified:   docs/topics/media-pipeline.rst

==

docs/topics/media-pipeline.rst
==================
103f6eaa;Pengyu CHEN;2016-04-02 02:04:50 +0800;Added: Making it case-insensitive when extracting sitemap URLs from a robots.txt

==

scrapy/utils/sitemap.py
==================
bf7f6754;Paul Tremberth;2016-04-01 15:47:06 +0200;Merge pull request #1847 from aron-bordin/add_blocking_storage_path_setting
[MRG+2] added BLOCKING_FEED_STORAGE_PATH to settings
==
==================
9250a5bf;Aron Bordin;2016-03-05 19:36:02 -0300;added FEED_TEMPDIR to settings

==

docs/topics/settings.rst
scrapy/extensions/feedexport.py
scrapy/settings/default_settings.py
tests/test_feedexport.py
==================
53708352;djunzu;2016-03-31 19:20:43 -0300;Change ImagesPipeline class attributes to instance attributes.
	modified:   scrapy/pipelines/images.py

==

scrapy/pipelines/images.py
==================
8228a0c4;djunzu;2016-03-31 19:20:39 -0300;Change FilesPipeline class attributes to instance attributes.
	modified:   scrapy/pipelines/files.py
	modified:   tests/test_pipeline_files.py

==

scrapy/pipelines/files.py
tests/test_pipeline_files.py
==================
c7fc1786;djunzu;2016-03-31 19:20:33 -0300;Move default settings to settings/default_settings.py.
	modified:   scrapy/pipelines/files.py
	modified:   scrapy/pipelines/images.py
	modified:   scrapy/settings/default_settings.py

==

scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/settings/default_settings.py
==================
e9d48f8a;djunzu;2016-03-31 19:19:49 -0300;Add tests.
	modified:   tests/test_pipeline_files.py
	modified:   tests/test_pipeline_images.py

==

tests/test_pipeline_files.py
tests/test_pipeline_images.py
==================
9d8c368c;Paul Tremberth;2016-03-31 12:09:24 +0200;Merge pull request #1879 from scrapy/scrapy-arch-docs
DOC improved Architecture overview
==
==================
9ae4e46f;Paul Tremberth;2016-03-31 11:57:39 +0200;Merge pull request #1883 from lopuhin/botocore-files-store-fix
[MRG+1] Make FilesPipeline work with S3FilesStore using botocore
==
==================
3ba5671f;Paul Tremberth;2016-03-31 11:55:09 +0200;Merge pull request #1851 from nyov/binary_or_text
[MRG+1] Rename isbinarytext function to binary_is_text for clarity
==
==================
3a763f7b;Paul Tremberth;2016-03-31 11:44:44 +0200;Merge pull request #1857 from pawelmhm/fix_response_status_msg
[MRG+1] response_status_message should not fail on non-standard HTTP codes
==
==================
e8ca4675;nyov;2016-03-06 16:45:06 +0000;Rename isbinarytext function to binary_is_text for clarity
Closes #1389

==

scrapy/responsetypes.py
scrapy/utils/python.py
tests/test_utils_python.py
==================
3787fec4;nyov;2016-03-26 22:22:01 +0000;Remove duplicate code now handled by newer w3lib
see https://github.com/scrapy/w3lib/commit/f3029a6a1071ba390472d4dd244fb3280d585c0a

==

requirements.txt
scrapy/downloadermiddlewares/ajaxcrawl.py
scrapy/utils/response.py
setup.py
==================
a38a99e0;Mikhail Korobov;2016-03-30 19:55:48 +0600;Merge pull request #1893 from redapple/sphinx-1.4
Add support for Sphinx 1.4
==
==================
1075587d;Paul Tremberth;2016-03-30 14:31:10 +0200;Add support for Sphinx 1.4
See http://www.sphinx-doc.org/en/stable/changes.html#release-1-4-released-mar-28-2016

sphinx_rtd_theme has become optional, needs to be added to reqs

https://github.com/sphinx-doc/sphinx/pull/2320 changes node entries tuples
to 5 values instead of 4

`sh` syntax highlighting added very locally in selectors.rst
because of this warning/error with Sphinx 1.4:

```
Warning, treated as error:
/home/paul/src/scrapy/docs/topics/selectors.rst:743:
WARNING: Could not lex literal_block as "python". Highlighting skipped.
```

==

docs/_ext/scrapydocs.py
docs/topics/selectors.rst
tox.ini
==================
a583e4d5;nanolab;2016-03-23 11:37:01 +0200;Update httpcache.py
It checks cache directory modification time, but have to check file modification time.
==

scrapy/extensions/httpcache.py
==================
7082454f;Lele;2016-03-18 03:30:31 +0100;Changed sel. to response. for clarity
Changed sel. to response. to comply with the rest of the examples in the same section, to avoid confusion.
==

docs/topics/selectors.rst
==================
fc8cd45a;Konstantin Lopuhin;2016-03-27 21:29:21 +0200;Fix a race condition in the FilesPipeline
Checksum calculation could happen simultaniously with
persisting the file in the store (which is done in a thread):
they operated on the same buf object.
Concretely this lead to a bug with S3FilesStore
when using botocore: the signature did not match because
the position in the buf was already at the end.
The fix is to move checksum calculation before passing buf
to the store.

==

scrapy/pipelines/files.py
==================
5045a4f1;Konstantin Lopuhin;2016-03-25 18:35:55 +0300;Fix handling of meta=None in S3FilesStore.persist_file

==

scrapy/pipelines/files.py
==================
4f335b5a;Mikhail Korobov;2016-03-25 17:03:41 +0500;DOC clarify Architecture docs

==

docs/topics/architecture.rst
==================
3ca977a8;Mikhail Korobov;2016-03-25 07:11:33 +0500;DOC improved Architecture overview
* spiders don't have to work on specific domains;
* explain what to use Downloader middleware for
  and what to use Spider middleware for;
* Engine no longer locates spiders based on domains;
* "Spider middleware output direction" step was missing.

See also: GH-1569.

==

docs/topics/architecture.rst
==================
65c7c050;pawelmhm;2016-03-12 14:07:20 +0100;response_status_message should not fail on non-standard HTTP codes
utility is used in retry middleware and it was failing to handle non-standard HTTP codes.
Instead of raising exceptions when passing through to_native_str it should return
"Unknown status" message.

==

scrapy/utils/response.py
tests/test_utils_response.py
==================
ebef6d7c;Mikhail Korobov;2016-03-07 08:49:25 +0500;Merge pull request #1848 from aron-bordin/small_doc_style_fixes
small doc style fixes
==
==================
2cfe9e42;Aron Bordin;2016-03-05 19:54:06 -0300;small doc style fixes

==

docs/faq.rst
docs/topics/email.rst
docs/topics/media-pipeline.rst
docs/topics/request-response.rst
docs/topics/settings.rst
docs/topics/signals.rst
==================
e122c569;Paul Tremberth;2016-03-04 11:50:26 +0100;Merge pull request #1842 from nyov/nyov/docs
[MRG+1] Update documentation links
==
==================
5876b9aa;nyov;2016-03-02 01:13:02 +0000;Update documentation links

==

docs/contributing.rst
docs/faq.rst
docs/intro/install.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/news.rst
docs/topics/api.rst
docs/topics/architecture.rst
docs/topics/djangoitem.rst
docs/topics/downloader-middleware.rst
docs/topics/email.rst
docs/topics/extensions.rst
docs/topics/feed-exports.rst
docs/topics/firebug.rst
docs/topics/item-pipeline.rst
docs/topics/media-pipeline.rst
docs/topics/practices.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/shell.rst
docs/topics/signals.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
docs/topics/webservice.rst
docs/versioning.rst
==================
9f4fe5dc;Paul Tremberth;2016-03-02 14:20:40 +0100;Merge pull request #1822 from nyov/nyov/scheduler
[MRG+1] Allow core Scheduler priority queue customization
==
==================
6b2871da;Mikhail Korobov;2016-03-02 16:15:51 +0500;Merge pull request #1835 from djunzu/add_pps_to_IGNORED_EXTENSIONS
[MRG+1] Add pps extension to IGNORED_EXTENSIONS
==
==================
0e288d4a;djunzu;2016-03-01 21:02:13 -0300;Add pps extension to IGNORED_EXTENSIONS
	modified:   scrapy/linkextractors/__init__.py

==

scrapy/linkextractors/__init__.py
==================
2a6524ee;nyov;2016-02-27 15:18:31 +0000;Allow core Scheduler priority queue customization

==

scrapy/core/scheduler.py
scrapy/settings/default_settings.py
==================
b8fcb46e;Daniel Graña;2016-03-01 10:44:24 -0300;Merge pull request #1804 from redapple/enable-test-dwnld-timeout
Re-enable HTTPS tests for download timeouts
==
==================
21da4931;Daniel Graña;2016-03-01 10:34:36 -0300;Merge pull request #1828 from scrapy/py3-classifiers
[MRG+1] declare Python 3 support in setup.py
==
==================
cf535fe8;Daniel Graña;2016-03-01 10:34:24 -0300;Merge pull request #1827 from scrapy/proxy-auth-test
[MRG+1] Extract a function to build CONNECT request; add tests for it. 
==
==================
17d3bec6;Mikhail Korobov;2016-03-01 16:34:13 +0500;declare Python 3 support in setup.py

==

setup.py
==================
94e28adf;Mikhail Korobov;2016-03-01 16:29:12 +0500;Extract a function to build CONNECT request; add tests for it. See GH-1701 and GH-1808.

==

scrapy/core/downloader/handlers/http11.py
==================
e8635cd0;Mikhail Korobov;2016-03-01 15:23:57 +0500;Merge pull request #1826 from redapple/universal-wheels
Build universal wheels
==
==================
f3c7a509;Paul Tremberth;2016-03-01 11:00:20 +0100;Build universal wheels

==

setup.cfg
==================
16512a32;Mikhail Korobov;2016-02-29 17:02:18 +0500;Merge pull request #1825 from redapple/relnotes-s3policy
[MRG+1] Update release notes about change of default S3 ACL policy to "private"
==
==================
90c64a6d;Paul Tremberth;2016-02-29 12:27:25 +0100;Update release notes about change of default S3 ACL policy to "private"

==

docs/news.rst
==================
74158611;Paul Tremberth;2016-02-26 23:23:34 +0100;Merge pull request #1818 from lagenar/master
[MRG+1] Refactored SpiderLoader class constructor for easier subclassing
==
==================
241ae9f2;Paul Tremberth;2016-02-26 23:20:33 +0100;Merge pull request #1820 from redapple/http-tls-settings
[MRG+1] Document DOWNLOADER_* settings for HTTP/1.0 and TLS
==
==================
709b4fa8;Paul Tremberth;2016-02-26 18:35:29 +0100;Update release notes about HTTPS downloader

==

docs/news.rst
==================
174f5267;Paul Tremberth;2016-02-26 18:19:52 +0100;Document DOWNLOADER_* settings for HTTP/1.0 and TLS

==

docs/topics/settings.rst
==================
1ce4c86c;Lucas Moauro;2016-02-25 21:08:50 -0300;Refactored SpiderLoader class constructor for easier subclassing

==

scrapy/spiderloader.py
==================
84dea194;Paul Tremberth;2016-02-25 00:59:15 +0100;Update release notes

==

docs/news.rst
==================
c9e78135;Paul Tremberth;2016-02-22 18:44:22 +0100;Explicitly call Twisted transport stopProducing() on HTTP/1.0 timeouts

==

scrapy/core/downloader/webclient.py
==================
ecddc093;Paul Tremberth;2016-02-22 17:52:26 +0100;Explicitly call Twisted transport stopProducing() on HTTP/1.1 timeouts

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
==================
f7a48b0c;Mikhail Korobov;2016-02-25 02:23:33 +0500;Merge pull request #1794 from redapple/twisted-tls
[MRG+1] Use best practices for TLS connections when using Twisted>=14.0
==
==================
4e935013;Paul Tremberth;2016-02-24 22:18:43 +0100;Merge pull request #1796 from lopuhin/s3-acl-private
[MRG+1] Change default S3 ACL to "private" and allow customization via settings
==
==================
0336c250;Paul Tremberth;2016-02-24 16:42:25 +0100;Use context factory class name in warning message

==

scrapy/core/downloader/handlers/http11.py
==================
c29a1b98;Paul Tremberth;2016-02-24 16:01:18 +0100;Make warning message a bit nicer in logs

==

scrapy/core/downloader/handlers/http11.py
==================
6137dd96;Konstantin Lopuhin;2016-02-24 10:16:10 +0300;Fix documentation for S3_STORE_ACL (now settings.FILES_STORE_S3_ACL) settings: it has nothing to do with feed exporters.

==

docs/topics/feed-exports.rst
docs/topics/settings.rst
scrapy/pipelines/files.py
scrapy/settings/default_settings.py
==================
164f3007;Konstantin Lopuhin;2016-02-19 18:22:56 +0300;See #1778 - change default S3 ACL to "private" and allow customization via settings

==

docs/topics/feed-exports.rst
docs/topics/settings.rst
scrapy/pipelines/files.py
scrapy/settings/default_settings.py
==================
c9890d5f;Paul Tremberth;2016-02-24 01:26:04 +0100;Add warning for context factories not accepting `method` param

==

scrapy/core/downloader/handlers/http11.py
==================
095495e9;Paul Tremberth;2016-02-24 01:24:58 +0100;Backward-compatibility for common Scrapy context factory patterns

==

scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/tls.py
==================
513ba7a1;Daniel Graña;2016-02-23 15:00:33 -0300;Merge pull request #1800 from redapple/http11-post-content-length
[MRG+1] Add "Content-Length: 0" for body-less HTTP/1.1 POST requests
==
==================
329a77a3;Elias Dorneles;2016-02-23 13:59:15 -0300;Merge pull request #1808 from scrapy/revert-1701-cleanup-http11-tunneling
Revert "Cleanup http11 tunneling connection after #1678"
==
==================
10bcdb49;Elias Dorneles;2016-02-23 13:16:47 -0300;Merge pull request #1787 from scrapy/improve-errors
[MRG+1] Better tracebacks
==
==================
35fb630c;Paul Tremberth;2016-02-23 16:28:48 +0100;Revert "[MRG+1] Cleanup http11 tunneling connection after #1678"

==

scrapy/core/downloader/handlers/http11.py
==================
62a51716;Mikhail Korobov;2016-02-21 12:33:48 +0500;Merge pull request #1801 from redapple/botocore-notconfigured-exception
Fix SkipTest() message for botocore import test
==
==================
ad4c1169;Paul Tremberth;2016-02-21 01:16:46 +0100;Pass exception directly to SkipTest()
It prints the same as passing `str(e)`

==

scrapy/utils/test.py
==================
e9bd3289;Paul Tremberth;2016-02-21 01:08:50 +0100;Fix SkipTest() message for botocore import test

==

scrapy/utils/test.py
==================
ac8f97c3;Paul Tremberth;2016-02-21 00:49:41 +0100;Fix typo in comment

==

scrapy/core/downloader/handlers/http11.py
==================
61741925;Paul Tremberth;2016-02-20 23:27:04 +0100;Add "Content-Length: 0" for body-less HTTP/1.1 POST requests
GH-823 was fixed only for HTTP/1.0 (in GH-1089)

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
==================
3f946b52;Paul Tremberth;2016-02-20 02:07:45 +0100;Fix super() call

==

scrapy/core/downloader/contextfactory.py
==================
49c757f2;Paul Tremberth;2016-02-20 01:58:59 +0100;Fix import for Ubuntu 12.04 precise (Twisted 11.1.0)
Revert test server certificate change

==

scrapy/core/downloader/contextfactory.py
tests/keys/server.pem
tests/mockserver.py
==================
57990fba;Paul Tremberth;2016-02-20 01:32:21 +0100;Backward compatibility for HTTP/10 context factory
New DOWNLOADER_CLIENT_TLS_METHOD setting to configure TLS method

==

scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/tls.py
scrapy/settings/default_settings.py
tests/keys/server.pem
tests/mockserver.py
==================
2969e34e;Paul Tremberth;2016-02-19 16:44:20 +0100;Merge pull request #1795 from AmbientLighter/patch-1
Fix typos in docstrings
==
==================
523e98da;Victor Mireyev;2016-02-19 17:32:01 +0300;Fix typo in docstring

==

scrapy/utils/reactor.py
==================
5f537420;Victor Mireyev;2016-02-19 17:20:34 +0300;Fix typo in docstring

==

scrapy/utils/misc.py
==================
18a38181;Mikhail Korobov;2016-02-19 18:31:49 +0500;Remove unneeded `raise` (thanks @lopuhin).

==

scrapy/crawler.py
==================
406b9a06;Paul Tremberth;2016-02-19 02:56:26 +0100;Add missing import for implementer
Also remove TLSv1.1 and TLSv1.2 method: these are available only
from pyOpenSSL 0.14
https://github.com/pyca/pyopenssl/releases/tag/v0.14a1

==

scrapy/core/downloader/contextfactory.py
==================
45f972cb;Paul Tremberth;2016-02-19 02:31:57 +0100;Implement IPolicyForHTTPS

==

scrapy/core/downloader/contextfactory.py
==================
30a27eff;Paul Tremberth;2016-02-19 01:54:23 +0100;Use best practices for TLS connections when using Twisted>=14.0

==

scrapy/core/downloader/contextfactory.py
==================
da36b7d3;Paul Tremberth;2016-02-18 15:11:03 +0100;Merge pull request #1761 from lopuhin/py3-s3-botocore
[MRG+1] Py3 S3 botocore
==
==================
104027d7;Paul Tremberth;2016-02-18 11:45:03 +0100;Minor change on quotes
Trying to force Travis CI to build
==

tests/test_commands.py
==================
d61fbcc8;Konstantin Lopuhin;2016-02-18 10:57:02 +0300;Support headers in S3FilesStore.persist_file for botocore

==

scrapy/pipelines/files.py
scrapy/utils/test.py
tests/test_pipeline_files.py
==================
617631f2;Konstantin Lopuhin;2016-02-18 10:10:16 +0300;Fix method name: this always returns unicode keys and values

==

scrapy/core/downloader/handlers/s3.py
scrapy/http/headers.py
==================
f766dd0b;Mikhail Korobov;2016-02-17 23:07:03 +0500;Preserve tracebacks better. Fixes GH-1760.

==

scrapy/crawler.py
tests/test_commands.py
==================
06da7af9;Mikhail Korobov;2016-02-17 23:03:12 +0500;TST clean up RunSpiderCommandTest

==

tests/test_commands.py
==================
4e2b7207;Mikhail Korobov;2016-02-17 21:33:43 +0500;Merge pull request #1786 from redapple/header-encoding
More liberal Content-Disposition header parsing
==
==================
cabed6f1;Paul Tremberth;2016-02-17 16:55:28 +0100;More liberal Content-Disposition header parsing
Fixes #1782

==

scrapy/responsetypes.py
tests/test_responsetypes.py
==================
49313a69;Konstantin Lopuhin;2016-02-15 20:16:40 +0300;use absolute_import to import external boto package

==

scrapy/utils/boto.py
==================
d1ecb8cd;Konstantin Lopuhin;2016-02-15 19:48:28 +0300;Fix S3TestCase for precise env: we reraise TypeError as NotConfigured in this case

==

tests/test_downloader_handlers.py
==================
e7c4806c;Konstantin Lopuhin;2016-02-15 19:33:18 +0300;Update feedstorage docs: add botocore, mention that boto is supported only on Python 2

==

docs/topics/feed-exports.rst
==================
77ebb136;Konstantin Lopuhin;2016-02-15 19:26:15 +0300;fix assertRaises for precise env

==

tests/test_downloader_handlers.py
==================
08bc41cc;Konstantin Lopuhin;2016-02-15 19:15:55 +0300;py3: reviewed s3 downloader handlers

==

tests/py3-ignores.txt
==================
3cb7a567;Konstantin Lopuhin;2016-02-15 19:14:41 +0300;py3 fix for TestS3FilesStore: checksum is a native string

==

tests/test_pipeline_files.py
==================
cfc567f4;Konstantin Lopuhin;2016-02-15 19:12:55 +0300;botocore support for S3FilesStore

==

scrapy/pipelines/files.py
tests/test_feedexport.py
==================
32cd8c91;Konstantin Lopuhin;2016-02-15 17:50:47 +0300;add direct test for S3FilesStore

==

scrapy/utils/test.py
tests/test_feedexport.py
tests/test_pipeline_files.py
tox.ini
==================
d1470e85;Konstantin Lopuhin;2016-02-15 17:28:50 +0300;S3FeedStorageTest: pass on py3, add some non-ascii content to be sure

==

tests/test_feedexport.py
==================
3ada45a9;Konstantin Lopuhin;2016-02-15 17:27:34 +0300;S3FeedStorageTest: add botocore support, and organize boto/botocore checks

==

scrapy/core/downloader/handlers/s3.py
scrapy/extensions/feedexport.py
scrapy/utils/boto.py
scrapy/utils/test.py
tests/test_feedexport.py
==================
5d2f0674;Konstantin Lopuhin;2016-02-15 16:36:15 +0300;S3FeedStorageTest: delete key after test

==

tests/test_feedexport.py
==================
19b2910a;Konstantin Lopuhin;2016-02-15 16:25:29 +0300;Fix assert_aws_environ: check for botocore with boto fallback on PY2

==

scrapy/utils/test.py
tests/test_downloader_handlers.py
==================
408bc158;Konstantin Lopuhin;2016-02-15 16:20:13 +0300;Pass env variables required for running tests against real s3 via tox.

==

tox.ini
==================
bcb92b50;Konstantin Lopuhin;2016-02-05 17:38:47 +0300;check that no extra kwargs are silently discarded

==

scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
d6bea3bf;Konstantin Lopuhin;2016-02-05 15:17:59 +0300;botocore not only does not allow passing our own Date header, but does not handle x-amz-date according to the spec

==

tests/test_downloader_handlers.py
==================
7748ee6b;Konstantin Lopuhin;2016-02-05 14:52:03 +0300;mock date in s3 tests when using botocore

==

scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
c3fec83e;Konstantin Lopuhin;2016-02-05 14:46:56 +0300;use botocore by default, boto is still used in "precise" env

==

tests/requirements-py3.txt
tox.ini
==================
1b1092b7;Konstantin Lopuhin;2016-02-05 14:19:04 +0300;add Headers.to_native_string_dict - useful when interfacing with other libraries

==

scrapy/core/downloader/handlers/s3.py
scrapy/http/headers.py
==================
467553cc;Konstantin Lopuhin;2016-02-05 13:30:22 +0300;fix anon test: in this case we do no signing, just change the url

==

scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
eaf3a239;Konstantin Lopuhin;2016-02-05 12:52:59 +0300;using botocore for s3 request signing: proof of concept

==

scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
41588397;Paul Tremberth;2016-02-11 19:29:53 +0100;Merge pull request #1765 from scrapy/add-deprecation-for-pydispatch
[MRG+1] Add fallback and deprecation warning for pydispatch (fixes #1762)
==
==================
164493df;Elias Dorneles;2016-02-06 00:08:59 -0200;add deprecation for pydispatch (thanks for the help @redapple)

==

docs/news.rst
scrapy/xlib/pydispatch.py
tests/test_pydispatch_deprecated.py
==================
150d1c37;Elias Dorneles;2016-02-10 14:30:11 -0200;Merge pull request #1769 from orangain/stdout-typeerror
[MRG+1] PY3: Fix TypeError when outputting to stdout
==
==================
c0839358;Paul Tremberth;2016-02-08 11:52:00 +0100;Merge pull request #1771 from orangain/secure-cookies
[MRG+1] PY3: Implement some attributes of WrappedRequest required in Python 3
==
==================
44bc4c06;Mikhail Korobov;2016-02-08 10:11:58 +0500;Merge pull request #1767 from orangain/sitemap-robotstxt
[MRG+1] PY3: Fix SitemapSpider to extract sitemap urls from robots.txt properly
==
==================
1f743996;orangain;2016-02-07 14:19:27 +0900;PY3: Implement some attributes of WrappedRequest required in Python 3
This will fix #1770.

==

scrapy/http/cookies.py
tests/test_http_cookies.py
==================
1cb841bf;orangain;2016-02-07 09:41:16 +0900;PY3: Fix TypeError when outputting to stdout
This will fix #1768.

==

scrapy/extensions/feedexport.py
==================
25c56159;orangain;2016-02-06 22:26:46 +0900;Fix SitemapSpider to extract sitemap urls from robots.txt properly
This will fix #1766.

==

scrapy/spiders/sitemap.py
tests/test_spider.py
==================
e328a9b9;Elias Dorneles;2016-02-05 21:18:35 -0200;Merge pull request #1750 from scrapy/spider-is-idle
[MRG+1] more efficient ExecutionEngine.spider_is_idle
==
==================
daf0f660;Elias Dorneles;2016-02-04 17:18:19 -0200;Merge pull request #1662 from NicolasP/send_utf8
[MRG+1] MailSender.send: allow passing a charset.
==
==================
6efc7a9d;Nicolas Pennequin;2016-01-06 22:32:58 +0100;Update the email doc for the charset argument to send().

==

docs/topics/email.rst
==================
061c6359;Nicolas Pennequin;2016-01-04 21:26:49 +0100;MailSender.send: allow passing a charset.
Resolves Issue #348

==

scrapy/mail.py
tests/test_mail.py
==================
8f269558;Daniel Graña;2016-02-03 22:58:21 -0300;Bump version: 1.2.0dev1 → 1.2.0dev2

==

.bumpversion.cfg
scrapy/VERSION
==================
6cf4fdba;Daniel Graña;2016-02-03 22:53:37 -0300;Enable travis builds on tag patterns

==

.travis.yml
==================
aaccdbb4;Elias Dorneles;2016-02-03 21:54:39 -0200;Bump version: 1.1.0rc1 → 1.2.0dev1

==

.bumpversion.cfg
scrapy/VERSION
==================
a0b63a77;Elias Dorneles;2016-02-03 21:52:47 -0200;Bump version: 1.1.0dev1 → 1.1.0rc1

==

.bumpversion.cfg
scrapy/VERSION
==================
94b2c47d;Elias Dorneles;2016-02-03 21:51:10 -0200;Merge pull request #1751 from scrapy/release-notes-1.1
[MRG+1] Release notes 1.1
==
==================
ca083146;Elias Dorneles;2016-02-03 21:38:25 -0200;makes more explicit source of problems in Python 3 limitations

==

docs/news.rst
==================
2167573b;Elias Dorneles;2016-02-03 21:31:27 -0200;fix comment about disabling robots.txt

==

docs/news.rst
==================
3180abc8;Elias Dorneles;2016-02-03 21:28:05 -0200;applying more review comments

==

docs/news.rst
==================
d40add7b;Elias Dorneles;2016-02-03 21:18:25 -0200;add note about robots.txt waiting and make it explicit builtin extensions only are ported

==

docs/news.rst
==================
9cfefd52;Elias Dorneles;2016-02-03 20:59:56 -0200;favor beta over basic to describe PY3 support

==

docs/news.rst
==================
2f697ce5;Elias Dorneles;2016-02-03 20:51:26 -0200;added note about how to revert to old behavior for robotstxt

==

docs/news.rst
==================
89a088b3;Elias Dorneles;2016-02-03 20:45:55 -0200;applying review comments

==

docs/news.rst
==================
a214b131;Daniel Graña;2016-02-03 19:41:43 -0300;Merge pull request #1748 from scrapy/py3-crawlerrunner-stop
[MRG+1] PY3 fixed CrawlerRunner.stop
==
==================
972f1925;Paul Tremberth;2016-02-03 22:58:49 +0100;Blank line before CoC

==

docs/news.rst
==================
728e505e;Paul Tremberth;2016-02-03 22:47:15 +0100;Merge remote-tracking branch 'origin/master' into release-notes-1.1

==
==================
725a209e;Paul Tremberth;2016-02-03 22:37:02 +0100;Merge pull request #1755 from stummjr/add-overview-to-release-notes
Add overview to release notes and other edits
==
==================
dd7b0eb3;Valdir Stumm Jr;2016-02-03 19:23:02 -0200;Updates to release notes

==

docs/news.rst
==================
51dc741f;Paul Tremberth;2016-02-03 16:08:46 +0100;Add 1.0.5 release notes

==

docs/news.rst
==================
0f816524;Valdir Stumm Jr;2016-02-03 15:07:12 -0200;edit API changes, Deprecations, and Relocations sections.

==

docs/news.rst
==================
fd3193da;Paul Tremberth;2016-02-03 18:19:38 +0100;Reword some of "New Features and Enhancements"

==

docs/news.rst
==================
3b2a6abc;Paul Tremberth;2016-02-03 17:37:58 +0100;Format "Code refactoring" subsection

==

docs/news.rst
==================
ed024550;Paul Tremberth;2016-02-03 17:27:43 +0100;Format "Logging" subsection

==

docs/news.rst
==================
a8a6f050;Elias Dorneles;2016-02-03 13:30:06 -0200;Merge pull request #1735 from ArturGaspar/master
[MRG+1] Fix for KeyError in robots.txt middleware
==
==================
e4cd9544;Paul Tremberth;2016-02-03 16:17:59 +0100;Merge pull request #1752 from stummjr/release-notes-1.1
Release notes: edits on "Py3 Support" and "New features" sections
==
==================
43a53aca;Mikhail Korobov;2016-02-03 19:59:24 +0500;Merge pull request #1746 from redapple/shell-settings-logging
[MRG+1] Remove __str__ and __repr__ from settings, introduce copy_to_dict()
==
==================
1fd95c9c;Valdir Stumm Jr;2016-02-03 12:45:48 -0200;fixed references to issues and fit text to 80 cols in the first two sections

==

docs/news.rst
==================
a21c90be;Valdir Stumm Jr;2016-02-03 11:54:46 -0200;edits on Py3 Support and New features sections

==

docs/news.rst
==================
44d8df20;Paul Tremberth;2016-02-03 12:35:26 +0100;Add versionadded note for MEMUSAGE_CHECK_INTERVAL_SECONDS

==

docs/topics/settings.rst
==================
2b033eeb;Paul Tremberth;2016-02-03 12:34:44 +0100;Fix recently added HTTPCACHE_ settings versionadded notes

==

docs/topics/downloader-middleware.rst
==================
142aa217;Paul Tremberth;2016-02-03 12:33:10 +0100;Add AUTOTHROTTLE_TARGET_CONCURRENCY versionadded note

==

docs/topics/autothrottle.rst
==================
db0697bc;Paul Tremberth;2016-02-03 12:32:40 +0100;Add 1.1 release notes (draft)

==

docs/news.rst
==================
c6591b5c;Mikhail Korobov;2016-02-03 05:37:40 +0500;more efficient ExecutionEngine.spider_is_idle

==

scrapy/core/engine.py
==================
65fb67f2;Mikhail Korobov;2016-02-03 01:01:16 +0500;PY3 fixed CrawlerRunner.stop

==

scrapy/crawler.py
==================
8a391a55;Nicolás Alejandro Ramírez Quiros;2016-02-02 12:17:52 -0300;Merge pull request #1741 from scrapy/py3-downloader-gc
[MRG+1] PY3 fix downloader slots GC
==
==================
f2668c31;Julia Medina;2016-02-02 01:35:39 -0300;Merge pull request #1747 from stummjr/fix-xml-exporter-for-nonstring-types
[MRG+1] Fix bug on XMLItemExporter with non-string fields in items
==
==================
268e9122;Paul Tremberth;2016-02-01 12:43:27 +0100;Add pretty-printting of settings as dict if using IPython shell
Suggested by @digenis
see http://ipython.readthedocs.org/en/stable/api/generated/IPython.lib.pretty.html?#extending

==

scrapy/settings/__init__.py
==================
bb2cf7c0;stummjr;2016-01-29 19:23:26 -0200;Fixed bug on XMLItemExporter with non-string fields in items

==

scrapy/exporters.py
tests/test_exporters.py
==================
f9dc02e2;Mikhail Korobov;2016-01-28 02:59:23 +0500;PY3 fix downloader slots GC

==

scrapy/core/downloader/__init__.py
==================
d843a0aa;Paul Tremberth;2016-01-29 21:12:03 +0100;Amend "settings" command to output JSON for dict settings

==

scrapy/commands/settings.py
tests/test_cmdline/__init__.py
==================
aa78758b;Paul Tremberth;2016-01-29 18:59:12 +0100;Update tests for settings copy_to_dict()

==

tests/test_settings/__init__.py
==================
a1ebff83;Paul Tremberth;2016-01-29 18:39:34 +0100;Remove __str__ and __repr__ from settings, introduce copy_to_dict() instead
Settings instances as dict's are easier to print or pretty print in the shell

Fixes #1732

==

scrapy/settings/__init__.py
==================
a35aec71;Mikhail Korobov;2016-01-29 21:03:40 +0500;Merge pull request #1710 from redapple/1550-shell_file-cont
[MRG+1] shell command's ability to open local files + tests
==
==================
78f00401;Paul Tremberth;2016-01-29 16:56:05 +0100;Remove unused import in tests

==

tests/test_command_shell.py
==================
505e8725;Mikhail Korobov;2016-01-29 03:27:38 +0500;Merge pull request #1742 from stummjr/add-tests-to-exporters
[MRG+1] Include tests for non-string items to Exporters
==
==================
cf2ebb06;stummjr;2016-01-27 19:36:16 -0200;Include tests for exporters: JSON, JSON-Lines, Pickle and Marshal.

==

tests/test_exporters.py
==================
e9f6b988;Paul Tremberth;2016-01-28 14:39:19 +0100;Amend guess_scheme() docstring

==

scrapy/utils/url.py
==================
c6f374f2;Paul Tremberth;2016-01-28 14:02:48 +0100;Merge remote-tracking branch 'origin/master' into 1550-shell_file-cont

==
==================
481e2517;Paul Tremberth;2016-01-28 13:51:50 +0100;Move guess_scheme() tests to relevant test module

==

tests/test_command_shell.py
tests/test_utils_url.py
==================
cae26840;Paul Tremberth;2016-01-28 13:42:04 +0100;Move guess_scheme() to scrapy.utils.url

==

scrapy/commands/shell.py
scrapy/utils/url.py
tests/test_command_shell.py
==================
90e3ae1c;Artur Gaspar;2016-01-27 21:00:35 -0200;Do not forget failed requests in robots.txt middleware.

==

scrapy/downloadermiddlewares/robotstxt.py
==================
4c9a6ef3;Mikhail Korobov;2016-01-28 01:39:48 +0500;Merge pull request #1740 from scrapy/response-text-micro-optimize
[MRG+1] micro-optimize response.text
==
==================
3e080c3c;Mikhail Korobov;2016-01-28 00:59:27 +0500;call .text from .body_as_unicode() and not the other way around

==

scrapy/http/response/text.py
==================
394b991e;Mikhail Korobov;2016-01-28 00:46:00 +0500;Merge pull request #1737 from stummjr/fix-py3-exporters-multiple-types
[MRG+1] Fix PythonItemExporter and CSVExporter for non-string item types
==
==================
27758f60;stummjr;2016-01-27 16:28:01 -0200;Changes fallback for CSVItemExporter, avoiding to call to_native_str(str()).

==

scrapy/exporters.py
==================
27fb200e;Paul Tremberth;2016-01-27 18:52:39 +0100;Merge pull request #1727 from redapple/priority-adjust
[MRG+1] Clarify priority adjust settings docs
==
==================
c55ff110;stummjr;2016-01-27 15:43:17 -0200;Fix CSV exporter for non string Python types.

==

scrapy/exporters.py
tests/test_exporters.py
==================
f1d971a5;stummjr;2016-01-27 14:34:46 -0200;fix PythonItemExporter for non-string types

==

scrapy/exporters.py
tests/test_exporters.py
==================
b2beb3e8;Artur Gaspar;2016-01-27 13:09:08 -0200;Fix handling of already failed deferreds when downloading page in robots.txt middleware.

==

scrapy/downloadermiddlewares/robotstxt.py
==================
dc8701ea;Artur Gaspar;2016-01-27 12:56:42 -0200;Add test for already failed deferreds when downloading page in robots.txt middleware.

==

tests/test_downloadermiddleware_robotstxt.py
==================
7d24df37;Mikhail Korobov;2016-01-27 17:56:11 +0500;Merge pull request #1681 from redapple/code-of-conduct
[MRG+1] Add Code of Conduct Version 1.3.0 from http://contributor-covenant.org/
==
==================
7ca9ae19;Mikhail Korobov;2016-01-27 17:54:28 +0500;DOC typo fix

==

docs/topics/request-response.rst
==================
77951095;Elias Dorneles;2016-01-27 10:45:28 -0200;Merge pull request #1730 from scrapy/response-text
[MRG+1] response.text
==
==================
e0f48c48;Paul Tremberth;2016-01-27 13:04:08 +0100;Add link to CoC mardown file on Github

==

README.rst
==================
d999e3f7;Paul Tremberth;2016-01-27 12:57:03 +0100;More explicit description of DEPTH_PRIORITY

==

docs/faq.rst
docs/topics/settings.rst
==================
6ed08d23;Paul Tremberth;2016-01-27 11:53:29 +0100;Add note for DEPTH_PRIORITY

==

docs/topics/settings.rst
==================
4bcbb77b;Mikhail Korobov;2016-01-27 01:28:11 +0500;response.text. Fixes GH-1729.

==

docs/topics/request-response.rst
scrapy/downloadermiddlewares/ajaxcrawl.py
scrapy/downloadermiddlewares/robotstxt.py
scrapy/http/request/form.py
scrapy/http/response/text.py
scrapy/selector/unified.py
scrapy/utils/iterators.py
scrapy/utils/response.py
tests/test_engine.py
tests/test_http_response.py
==================
1c831088;Paul Tremberth;2016-01-26 19:24:11 +0100;Clarify priority adjust settings docs
Fixes #1593

==

docs/topics/settings.rst
==================
85f0596c;Daniel Graña;2016-01-26 14:32:17 -0300;Merge pull request #1725 from redapple/spiderstate-notconfigured
[MRG+1] Disable SpiderState extension if no JOBDIR set
==
==================
6660175d;Mikhail Korobov;2016-01-26 21:29:44 +0500;Merge pull request #1726 from redapple/mwlist-logging-long
Use long classes names for enabled middlewares in startup logs
==
==================
bb1f4013;Paul Tremberth;2016-01-26 17:23:28 +0100;Rewrite warning about shell with local files as note

==

docs/topics/shell.rst
==================
c22a4e3b;Paul Tremberth;2016-01-26 16:41:16 +0100;Use long classes names for enabled middlewares in startup logs

==

scrapy/middleware.py
==================
29695375;Paul Tremberth;2016-01-26 16:33:24 +0100;Add test for raised exception with SpiderState extension when no JOBDIR used

==

tests/test_spiderstate.py
==================
0349bbf9;Paul Tremberth;2016-01-26 15:25:15 +0100;Disable SpiderState extension if no JOBDIR set

==

scrapy/extensions/spiderstate.py
==================
0d368c5d;Paul Tremberth;2016-01-26 14:19:15 +0100;Merge pull request #1724 from scrapy/robotstxt-default
[MRG+1] Enable robots.txt handling by default for new projects.
==
==================
f30758c2;Mikhail Korobov;2016-01-26 17:47:46 +0500;Enable robots.txt handling by default for new projects. Fixes GH-1668.
For backwards compatibility reasons the default value is not changed.

==

docs/topics/settings.rst
scrapy/templates/project/module/settings.py.tmpl
==================
2246280b;Elias Dorneles;2016-01-26 10:35:59 -0200;Merge pull request #1723 from redapple/closespider-notconfigured
[MRG+1] Disable CloseSpider extension if no CLOSPIDER_* setting set
==
==================
52daa1b9;Paul Tremberth;2016-01-26 13:25:21 +0100;Merge pull request #1720 from scrapy/deprecations
[MRG+1] deprecated unused and untested code in scrapy.utils.datatypes
==
==================
1e485745;Mikhail Korobov;2016-01-26 17:21:08 +0500;Merge pull request #1722 from redapple/mwlist-logging
[MRG+1] Fix logging of enabled middlewares
==
==================
6ee8d865;Paul Tremberth;2016-01-26 13:08:42 +0100;Disable CloseSpider extension if no CLOSPIDER_* setting set

==

scrapy/extensions/closespider.py
==================
7608da88;Paul Tremberth;2016-01-26 13:01:12 +0100;Fix logging of enabled middlewares
Wrong middlewares list was being pretty-printed
(introduced in #1263)

==

scrapy/middleware.py
==================
de22b6f3;Elias Dorneles;2016-01-26 09:37:18 -0200;Merge pull request #1721 from Digenis/offsitemw_subdomains
[MRG+1] tests+doc for subdomains in offsite middleware
==
==================
1cffa99e;Νικόλαος-Διγενής Καραγιάννης;2016-01-26 12:35:40 +0200;tests+doc for subdomains in offsite middleware

==

docs/topics/spider-middleware.rst
docs/topics/spiders.rst
tests/test_spidermiddleware_offsite.py
==================
713e1eee;Paul Tremberth;2016-01-26 10:44:38 +0100;Update docs about local files support for "scrapy shell"

==

docs/topics/commands.rst
docs/topics/shell.rst
==================
9c2aa50e;Mikhail Korobov;2016-01-26 13:58:20 +0500;deprecate unused and untested scrapy.utils.datatypes.MultiValueDict

==

scrapy/utils/datatypes.py
==================
7070dae4;Mikhail Korobov;2016-01-26 13:56:16 +0500;deprecate unused and untested scrapy.utils.datatypes.SiteNode

==

scrapy/utils/datatypes.py
==================
a7b86137;Daniel Graña;2016-01-26 01:01:30 -0300;Merge pull request #1499 from scrapy/py3-port-exporters
[MRG+1] PY3 exporters
==
==================
d0eacfe0;Daniel Graña;2016-01-26 00:26:27 -0300;Add test case for marshal item exporter

==

scrapy/exporters.py
tests/test_exporters.py
==================
2dfdde3c;Elias Dorneles;2016-01-25 22:24:35 -0200;fallback to repr when can't convert to native string

==

scrapy/exporters.py
tests/test_exporters.py
==================
23b3336c;Elias Dorneles;2016-01-25 22:11:04 -0200;add test for invalid option

==

tests/test_exporters.py
==================
b2046318;Daniel Graña;2016-01-25 18:24:12 -0300;Merge pull request #1716 from lopuhin/py3-test-pipeline-files-images
[MRG+1] py3: test_pipeline_files and test_pipeline_images
==
==================
fb8ab242;Paul Tremberth;2016-01-25 13:13:35 +0100;Move urlparsing statement in add_http_if_no_scheme()

==

scrapy/utils/url.py
==================
0c44fac2;Elias Dorneles;2016-01-24 19:17:42 -0200;added tests for feed export marshal and pickle

==

tests/test_feedexport.py
==================
4fef2c76;Elias Dorneles;2016-01-24 18:49:22 -0200;Merge pull request #1717 from lopuhin/py3-test-spidermiddleware-httperror
[MRG+1] py3: reviewed passing test_spidermiddleware_httperror.py
==
==================
1be90323;Konstantin Lopuhin;2016-01-24 23:44:56 +0300;py3: properly skip s3 tests on py3

==

tests/test_downloader_handlers.py
==================
4233b3cd;Konstantin Lopuhin;2016-01-24 23:10:03 +0300;py3: reviewed passing test_spidermiddleware_httperror.py

==

tests/py3-ignores.txt
==================
097082cf;Konstantin Lopuhin;2016-01-24 23:05:23 +0300;reviewed py3 compat in pipelines/images.py and pipelines/files.py

==

tests/py3-ignores.txt
==================
333d4c91;Konstantin Lopuhin;2016-01-24 22:52:50 +0300;py3: add boto to py3 test requirements, test_pipeline_files and test_pipeline_images passing now

==

tests/py3-ignores.txt
tests/requirements-py3.txt
==================
85ae2732;Mikhail Korobov;2016-01-24 17:47:57 +0500;Merge pull request #1715 from lopuhin/py3-test-mail
[MRG+1] py3: fix test_mail
==
==================
860353b0;Konstantin Lopuhin;2016-01-24 13:27:41 +0300;py3: unskip test_mail and scrapy/mail.py

==

tests/py3-ignores.txt
==================
9704226e;Konstantin Lopuhin;2016-01-24 13:25:14 +0300;py3: fix test_mail - get_payload returns bytes when decode is True

==

tests/test_mail.py
==================
9fbe6f3e;Elias Dorneles;2016-01-23 17:17:40 -0200;added feedexport test for xml output

==

tests/test_feedexport.py
==================
935b1da8;Elias Dorneles;2016-01-23 16:13:42 -0200;uses ScrapyDeprecationWarning instead of silenced PendingDeprecationWarning

==

scrapy/exporters.py
==================
c75f1fe4;Elias Dorneles;2016-01-23 16:09:57 -0200;restore bytes instead of text, for easier reviewing

==

tests/test_exporters.py
==================
5f09da60;Paul Tremberth;2016-01-22 23:48:58 +0100;Revert "Use pytest.mark.parametrize decorator"
This reverts commit 1a30a7774b7d530394fdd761f2a59403b778fe10.

==

tests/test_command_shell.py
==================
1a30a777;Paul Tremberth;2016-01-22 18:22:19 +0100;Use pytest.mark.parametrize decorator

==

tests/test_command_shell.py
==================
61ca8d58;Paul Tremberth;2016-01-22 18:16:36 +0100;Merge remote-tracking branch 'origin/master' into 1550-shell_file-cont

==
==================
7a51d370;Paul Tremberth;2016-01-22 17:16:27 +0100;Regex-based guess_scheme() + refactor tests

==

scrapy/commands/shell.py
tests/test_command_shell.py
==================
60052b3c;Paul Tremberth;2016-01-22 13:18:08 +0100;Remove unused re import

==

scrapy/commands/shell.py
==================
be239f33;Paul Tremberth;2016-01-22 13:13:46 +0100;Remove unused import

==

scrapy/commands/shell.py
==================
d0955fd0;Elias Dorneles;2016-01-22 10:07:55 -0200;add back test for latin-1 encoding

==

tests/test_exporters.py
==================
6d73e057;Paul Tremberth;2016-01-22 13:07:42 +0100;Extract guess_scheme function and refactor tests

==

scrapy/commands/shell.py
tests/test_command_shell.py
==================
c75f7ed2;Mikhail Korobov;2016-01-22 15:21:26 +0500;Merge pull request #1711 from scrapy/py3-parse-command-tests
PY3 enable tests for scrapy parse command
==
==================
35ada107;Mikhail Korobov;2016-01-22 13:39:27 +0500;PY3 enable tests for scrapy parse command
scrapy parse command is already ported

==

tests/test_commands.py
==================
e9387529;Elias Dorneles;2016-01-21 21:51:59 -0200;add test for PythonItemExporter binary mode

==

scrapy/exporters.py
tests/test_exporters.py
==================
25149732;Elias Dorneles;2016-01-21 21:22:12 -0200;re-enable skipped feed export tests

==

tests/test_feedexport.py
==================
b746d85f;Elias Dorneles;2016-01-21 21:12:43 -0200;PY3 port csv exporter

==

scrapy/exporters.py
tests/test_exporters.py
==================
8bd5b608;Paul Tremberth;2016-01-21 23:23:50 +0100;Remove relpath filepath

==

tests/test_command_shell.py
==================
240ecbf3;Paul Tremberth;2016-01-21 22:59:48 +0100;Add local file tests for scrapy shell command
Continuation of #1579

==

tests/test_command_shell.py
==================
9f35c286;Elias Dorneles;2016-01-21 18:43:36 -0200;fix indentation

==

scrapy/exporters.py
==================
fed7c8b4;Elias Dorneles;2016-01-21 18:39:59 -0200;fix: use is_listlike

==

scrapy/exporters.py
==================
c76190d4;Elias Dorneles;2016-01-21 18:24:06 -0200;PY3: ported json(lines), xml exporters

==

scrapy/exporters.py
tests/test_exporters.py
==================
b6ef1f19;Elias Dorneles;2015-10-09 00:19:05 -0300;make BaseItemExporter export unicode, pushed down previous behavior for classes that need it

==

scrapy/exporters.py
tests/test_exporters.py
==================
a76ecd4e;Elias Dorneles;2015-10-08 22:18:14 -0300;remove test_exporters from py3 ignores

==

tests/py3-ignores.txt
==================
1406cab1;Paul Tremberth;2016-01-21 16:48:16 +0100;Merge remote-tracking branch 'origin/master' into 1550-shell_file

==
==================
e0074d7f;Elias Dorneles;2016-01-21 13:05:20 -0200;Merge pull request #1692 from lopuhin/py3-test-crawl
[MRG+1] Py3: port test crawl
==
==================
5813de88;Konstantin Lopuhin;2016-01-19 18:08:05 +0300;py3: unskip test_closespider - it passes after fixing mockserver.Follow resouce on py3

==

tests/py3-ignores.txt
==================
4607f284;Konstantin Lopuhin;2016-01-19 16:01:43 +0300;py3: unskip test_crawl

==

tests/py3-ignores.txt
==================
bf5f54fa;Konstantin Lopuhin;2016-01-19 16:01:30 +0300;py3: fix getarg

==

tests/mockserver.py
==================
ad2b3321;Konstantin Lopuhin;2016-01-19 13:13:41 +0300;py3 compat: use range, fixes CrawlTestCase.test_start_requests_bug_yielding

==

tests/spiders.py
==================
0680950b;Konstantin Lopuhin;2016-01-19 13:06:31 +0300;py3: pass CrawlTestCase.test_referer_header, fixing Echo resource in mockserver and json decoding in test

==

tests/mockserver.py
tests/test_crawl.py
==================
20b839b4;Konstantin Lopuhin;2016-01-19 12:42:45 +0300;py3: pass first crawl test (test_follow_all): fix mock server

==

tests/mockserver.py
==================
0f500a1f;Daniel Graña;2016-01-21 11:51:27 -0300;Merge pull request #1708 from scrapy/fix-scrapy-bench
PY3 fixed scrapy bench command
==
==================
5346011e;Daniel Graña;2016-01-21 11:49:42 -0300;Merge pull request #1637 from eLRuLL/py3-httpproxy-retry
[MRG+1] py3 fix HttpProxy and Retry Middlewares
==
==================
a06a5f00;Raul Gallegos;2016-01-20 13:52:52 -0500;adding configurable encoding for httpproxy authentication

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/httpproxy.py
scrapy/settings/default_settings.py
tests/test_downloadermiddleware_httpproxy.py
==================
f042ad0f;Raul Gallegos;2015-12-10 23:04:25 -0500;py3 fix HttpProxy and Retry Middlewares

==

scrapy/downloadermiddlewares/httpproxy.py
tests/py3-ignores.txt
tests/test_downloadermiddleware_httpproxy.py
tests/test_downloadermiddleware_retry.py
==================
c9e046d1;Paul Tremberth;2016-01-21 15:17:57 +0100;Merge pull request #1657 from palego/os.mknod-fails-on-macos
[MRG+1] change os.mknod() for open()
==
==================
a18dc244;Mikhail Korobov;2016-01-21 18:44:37 +0500;correctly process arguments for bench server

==

scrapy/utils/benchserver.py
==================
80c55f19;Mikhail Korobov;2016-01-21 18:31:58 +0500;PY3 fixed scrapy bench command

==

scrapy/utils/benchserver.py
tests/test_commands.py
==================
e44ce863;Mikhail Korobov;2016-01-21 16:48:21 +0500;Merge pull request #1706 from scrapy/fix-form-request-formcss-version
Fix version number to appear new feature
==
==================
d4c4ca80;Elias Dorneles;2016-01-21 09:42:15 -0200;fix version number to appear new feature

==

docs/topics/request-response.rst
==================
da83f2dc;Paul Tremberth;2016-01-21 10:59:32 +0100;Merge pull request #1693 from lopuhin/py3-commands-fetch-shell
[MRG+1] Py3: port commands fetch and shell
==
==================
6d8620ff;Paul Tremberth;2016-01-21 10:30:39 +0100;Merge pull request #1691 from lopuhin/py3-test-engine
[MRG+1] Py3: port test_engine
==
==================
a6e5c848;Elias Dorneles;2016-01-21 01:17:47 -0200;Merge pull request #1382 from barraponto/formcss
[MRG+1] Implement FormRequest.from_response CSS support
==
==================
659715ec;Capi Etheriel;2015-07-24 12:07:59 -0300;implements FormRequest.from_response CSS support

==

docs/topics/request-response.rst
scrapy/http/request/form.py
tests/test_http_request.py
==================
fd24e224;Konstantin Lopuhin;2016-01-20 23:30:58 +0300;use byte constants for prefix instead of encoding it

==

scrapy/commands/fetch.py
==================
a5da7531;Konstantin Lopuhin;2016-01-19 18:06:20 +0300;py3 backout skipping test_closespider - it was fixed on another branch

==

tests/py3-ignores.txt
==================
c6d013ec;Konstantin Lopuhin;2016-01-19 16:42:34 +0300;py3 fetch command: it may actually be better to try to print bytes as-is

==

scrapy/commands/fetch.py
==================
47d3c633;Konstantin Lopuhin;2016-01-19 16:28:22 +0300;py3: port fetch and shell commands, and review + enable already passing test_closespider.py and tests/test_utils_template.py

==

scrapy/commands/fetch.py
scrapy/utils/testsite.py
tests/py3-ignores.txt
tests/test_command_fetch.py
tests/test_command_shell.py
==================
c1db6018;Konstantin Lopuhin;2016-01-19 10:07:12 +0300;py3: unskip passing test_engine

==

tests/py3-ignores.txt
==================
0b08b4bf;Konstantin Lopuhin;2016-01-19 10:07:00 +0300;fix engine tests - this callback (spider_closed_callback) should accept one argument, but the error was hidden on py2

==

tests/test_engine.py
==================
a32b59ac;Konstantin Lopuhin;2016-01-18 18:54:32 +0300;py3: fix EngineTest.test_crawler

==

tests/test_engine.py
==================
56b69d2e;Daniel Graña;2016-01-20 16:52:25 -0300;Merge pull request #1689 from scrapy/remove-lsprof
[MRG+1] Remove --lsprof command-line option. 
==
==================
8fb9a6f8;Elias Dorneles;2016-01-20 17:23:25 -0200;Merge pull request #1674 from redapple/tox-py35
[MRG+1] Add Python 3.5 tox env + Python 3.5 tests in Travis
==
==================
8a1255d3;Elias Dorneles;2016-01-20 17:05:54 -0200;Merge pull request #1680 from lopuhin/py3-downloader-middleware
[MRG+1] Py3: port downloader cache and compression middlewares
==
==================
b8497513;Elias Dorneles;2016-01-20 16:38:06 -0200;Merge pull request #1701 from lopuhin/cleanup-http11-tunneling
[MRG+1] Cleanup http11 tunneling connection after #1678
==
==================
29ff84a7;Paul Tremberth;2016-01-20 12:03:38 +0100;Invert PY2/PY3 test for conditional read1() definition

==

scrapy/utils/gz.py
==================
f0cf5463;Konstantin Lopuhin;2016-01-20 12:23:48 +0300;cleanup http11 tunneling connection after #1678 - construct string and then convert to bytes

==

scrapy/core/downloader/handlers/http11.py
==================
ef520541;Elias Dorneles;2016-01-19 16:45:08 -0200;Merge pull request #1699 from scrapy/no-optional-features
[MRG+1] optional_features has been removed
==
==================
176610f9;Daniel Graña;2016-01-19 15:34:26 -0300;optional_features has been removed

==

tests/test_downloader_handlers.py
==================
5ec43198;Daniel Graña;2016-01-19 13:35:23 -0300;Merge pull request #1358 from nyov/nyov/boto-anon-connection
[MRG+1] Support anonymous S3DownloadHandler (boto) connections
==
==================
b1e44436;Daniel Graña;2016-01-19 13:33:50 -0300;Merge pull request #1642 from orangain/doc-metarefresh
[MRG+1] DOC: Update MetaRefreshMiddlware's setting variables
==
==================
d59d3f1e;Daniel Graña;2016-01-19 13:32:36 -0300;Merge pull request #1694 from lopuhin/py3-twisted-version
[MRG+1] Raise minimal twisted version for py3
==
==================
e8b26e2a;Elias Dorneles;2016-01-19 14:18:43 -0200;Merge pull request #1698 from carlosp420/typo-you
fixed typo You -> you
==
==================
e15f361b;carlosp420;2016-01-19 11:12:43 -0500;fixed typo You -> you

==

docs/topics/broad-crawls.rst
==================
b4fb9d35;Elias Dorneles;2016-01-19 14:10:00 -0200;Merge pull request #1678 from lopuhin/py3-http-downloaders
[MRG+1] Py3: port http downloaders
==
==================
2b524583;Paul Tremberth;2016-01-19 17:04:57 +0100;Remove unused import statement

==

scrapy/utils/gz.py
==================
1f223383;Paul Tremberth;2016-01-19 16:58:24 +0100;Use if Py2/Py3 function instead of custom GzipFile class method

==

scrapy/utils/gz.py
==================
4c841728;Konstantin Lopuhin;2016-01-19 18:24:58 +0300;move leveldb to tests/requirements-py3.txt

==

tests/requirements-py3.txt
tox.ini
==================
076ef553;Konstantin Lopuhin;2016-01-19 17:51:42 +0300;Merge branch 'master' into py3-http-downloaders

==
==================
07577c43;Konstantin Lopuhin;2016-01-19 17:39:22 +0300;Merge branch 'master' into py3-http-downloaders

==
==================
9c3117a9;Konstantin Lopuhin;2016-01-19 17:32:53 +0300;more pythonic check of noconnect in proxy params

==

scrapy/core/downloader/handlers/http11.py
==================
bb50c0be;Konstantin Lopuhin;2016-01-19 17:30:59 +0300;remove unused import

==

scrapy/http/response/__init__.py
==================
6827eab2;Nicolás Alejandro Ramírez Quiros;2016-01-19 11:30:54 -0300;Merge pull request #1654 from aron-bordin/show_maxdownsize_warn_once
[MRG+1] show download warnsize once
==
==================
5ac54ed3;Konstantin Lopuhin;2016-01-19 17:25:50 +0300;raise minimal twisted version for py3

==

requirements-py3.txt
==================
49fe631d;Daniel Graña;2016-01-19 11:07:54 -0300;Merge pull request #1676 from lopuhin/py3-webclient
[MRG+1] py3: fix webclient
==
==================
fdc3c9d5;Mikhail Korobov;2016-01-19 00:17:56 +0500;Merge pull request #1624 from side2k/more_verbose_download_cancel
[MRG+1] added more verbosity for log and for exception when download is cancelled because of a size limit
==
==================
ff235fa1;Mikhail Korobov;2016-01-19 00:00:31 +0500;Remove --lsprof command-line option. Fixes GH-1531

==

scrapy/cmdline.py
scrapy/commands/__init__.py
scrapy/xlib/lsprofcalltree.py
==================
fd99ef86;Paul Tremberth;2016-01-18 17:57:55 +0100;Test for AttributeError when pickling objects (Python>=3.5)
Same "fix" as in e.g. https://github.com/joblib/joblib/pull/246

==

scrapy/squeues.py
==================
de98d8d0;Konstantin Lopuhin;2016-01-18 19:27:31 +0300;move comment about test skipped on py3 into a proper place

==

tests/test_downloader_handlers.py
==================
7ffcc587;Konstantin Lopuhin;2016-01-18 19:23:12 +0300;Merge branch 'py3-http-downloaders' into py3-downloader-middleware

==
==================
7fdd3225;Konstantin Lopuhin;2016-01-18 19:09:09 +0300;fix test skipping logic - this is (temporary) py2-only part

==

tests/test_downloader_handlers.py
==================
120fb4ad;Konstantin Lopuhin;2016-01-18 19:00:40 +0300;revert bogus change

==

scrapy/http/response/__init__.py
==================
bcbad290;Paul Tremberth;2016-01-18 15:22:29 +0100;Stick with ValueError for queue/serialization exception tests

==

tests/test_squeues.py
==================
324f2c1a;Konstantin Lopuhin;2016-01-18 16:45:22 +0300;common test_downloadermiddleware.py also passes now due to fixes in compression middleware

==

tests/py3-ignores.txt
==================
0b933641;Konstantin Lopuhin;2016-01-18 16:43:58 +0300;py3: port compression downloader middleware and tests

==

scrapy/downloadermiddlewares/httpcompression.py
tests/py3-ignores.txt
tests/test_downloadermiddleware_httpcompression.py
==================
6edd4dec;Konstantin Lopuhin;2016-01-18 15:51:26 +0300;Merge branch 'py3-http-downloaders' into py3-downloader-middleware

==
==================
f876654a;Konstantin Lopuhin;2016-01-18 15:50:58 +0300;Merge branch 'py3-webclient' into py3-http-downloaders

==
==================
49464345;Konstantin Lopuhin;2016-01-18 15:23:01 +0300;revert most changes to this test, and clarify - it is valid only on py2, because urls are strictly unicode on py3

==

tests/test_webclient.py
==================
a2efd389;Konstantin Lopuhin;2016-01-18 15:09:54 +0300;clarify: rename r_transform to response_transform

==

tests/test_webclient.py
==================
b940606b;Konstantin Lopuhin;2016-01-18 15:06:15 +0300;this is a test for TunnelingTCP4ClientEndpoint - move into Http11ProxyTestCase

==

tests/test_downloader_handlers.py
==================
bc1f5353;Elias Dorneles;2016-01-18 10:02:18 -0200;Merge pull request #1671 from redapple/xmliter-unicode
[MRG+1] Support unicode tags in xml iterators (fixes #1665)
==
==================
7af64e8f;Konstantin Lopuhin;2016-01-18 15:00:43 +0300;py3: remove extra encoding/decoding of url: pass it as bytes only when required

==

scrapy/core/downloader/handlers/http11.py
==================
66f41aba;Mikhail Korobov;2016-01-18 16:48:42 +0500;Merge pull request #1687 from palego/extra-space
[MRG+1] fix indentation
==
==================
0f527849;Konstantin Lopuhin;2016-01-18 14:44:04 +0300;https proxy tunneling - add a test (not perfect, but covers all impl) and fix for py3

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
==================
98c060d0;Konstantin Lopuhin;2016-01-18 12:42:21 +0300;py3: fix http 1.1 test with https, and use self.host everywhere

==

tests/test_downloader_handlers.py
==================
04f69fd1;Konstantin Lopuhin;2016-01-18 12:37:46 +0300;add https 1.1 downloader test - localhost is a valid DNS-ID

==

tests/test_downloader_handlers.py
==================
f403c880;Konstantin Lopuhin;2016-01-18 12:25:51 +0300;Merge branch 'py3-webclient' into py3-http-downloaders

==
==================
f2e2ff5e;Konstantin Lopuhin;2016-01-18 12:20:01 +0300;py3: webclient assumes that urls come from Request.url and are ascii-only

==

scrapy/core/downloader/webclient.py
==================
6b905a9a;palego;2016-01-16 14:23:58 +0100;split-up the assertIn
to deal with OS X intricacies (directories prefixed with /private)
==

tests/test_commands.py
==================
673df5e4;Konstantin Lopuhin;2016-01-18 11:44:49 +0300;add webclient test - check that non-standart body encoding matches Content-Encoding header

==

tests/test_webclient.py
==================
d3c2b0cf;Konstantin Lopuhin;2016-01-18 10:06:14 +0300;py3 webclient: I was mistaken about unicode body, revert conversion to bytes and fix HEAD response

==

scrapy/core/downloader/webclient.py
==================
9ef25d7b;Mikhail Korobov;2016-01-18 11:57:06 +0500;Merge pull request #1686 from cclauss/patch-1
Simplify if statement
==
==================
cd735e37;cclauss;2016-01-18 07:45:36 +0100;Simplify if statement

==

conftest.py
==================
4e447666;Paul Tremberth;2016-01-15 19:51:21 +0100;Use "unicode" string for lxml.etree.tostring() serialization

==

scrapy/utils/iterators.py
==================
3f1f15bc;Elias Dorneles;2016-01-15 16:30:52 -0200;Merge pull request #1683 from rgtk/patch-2
Update Stats Collection documentation for @master
==
==================
79147a61;Ralph Gutkowski;2016-01-15 19:25:56 +0100;Update stats.rst

==

docs/topics/stats.rst
==================
bb38400d;Ralph Gutkowski;2016-01-15 19:00:58 +0100;Update Stats Collection documentation
`pages_crawled` value doesn't exist. Replace it with `downloader/response_count` in order to avoid confusion.
==

docs/topics/stats.rst
==================
73d78ec9;Paul Tremberth;2016-01-15 17:59:20 +0100;Add Code of Conduct Version 1.3.0 from http://contributor-covenant.org/
Closes #1645

==

CODE_OF_CONDUCT.md
README.rst
==================
ee4fadc0;Paul Tremberth;2016-01-15 14:57:15 +0100;Use .read1() if available when using GzipFile

==

.travis.yml
scrapy/utils/gz.py
tests/test_squeues.py
==================
7d44c5dc;Konstantin Lopuhin;2016-01-15 15:41:31 +0300;py3: unskip tests/test_downloadermiddleware_httpcache.py and scrapy/downloadermiddlewares/httpcache.py

==

tests/py3-ignores.txt
==================
085fdd62;Konstantin Lopuhin;2016-01-15 15:40:45 +0300;py3 fix for ignoring cache controls - map is not a list

==

scrapy/extensions/httpcache.py
==================
b0648271;Konstantin Lopuhin;2016-01-15 15:17:30 +0300;py3 fix for rfc1123_to_epoch - "except Exception" was hiding bytes/str error

==

scrapy/extensions/httpcache.py
==================
8330776c;Konstantin Lopuhin;2016-01-15 15:16:12 +0300;fix error reporting in test: we can fail in process_request too, so result should always be defined

==

tests/test_downloadermiddleware_httpcache.py
==================
4398d95a;Konstantin Lopuhin;2016-01-15 14:54:12 +0300;skip this file on py3 again - it has one compression test, sould be done separately

==

tests/py3-ignores.txt
==================
ae6758ee;Konstantin Lopuhin;2016-01-15 14:39:27 +0300;Merge branch 'py3-http-downloaders' into py3-downloader-middleware

==
==================
a4ca1668;Konstantin Lopuhin;2016-01-15 14:20:19 +0300;add https test for http10 handler (no luck with testing https with http11 so far)

==

tests/mockserver.py
tests/test_downloader_handlers.py
==================
96fcf4ce;Konstantin Lopuhin;2016-01-15 13:27:28 +0300;add a check that byte url is not accepted in http.Response on py3

==

tests/test_http_response.py
==================
131f4632;Paul Tremberth;2016-01-15 11:17:52 +0100;Allow failures for Python 3.5 for now

==

.travis.yml
==================
87849780;Konstantin Lopuhin;2016-01-15 13:13:10 +0300;some py3 fixes for RFC2616Policy

==

scrapy/extensions/httpcache.py
tests/test_downloadermiddleware_httpcache.py
==================
ea0471e3;Konstantin Lopuhin;2016-01-15 12:22:41 +0300;py3: fix LeveldbCacheStorage - using bytes as keys and values in leveldb

==

scrapy/extensions/httpcache.py
==================
ddc91dda;Konstantin Lopuhin;2016-01-15 11:49:28 +0300;py3: fix _BaseTest in httpcache

==

tests/test_downloadermiddleware_httpcache.py
==================
e7ed1fd7;Konstantin Lopuhin;2016-01-15 11:48:07 +0300;py3 compat in httpcache - headers are bytes

==

scrapy/extensions/httpcache.py
==================
dbf6cc73;Konstantin Lopuhin;2016-01-15 11:46:56 +0300;py3: add leveldb to py33 test env, fix anydbm module name on py3

==

scrapy/settings/default_settings.py
tox.ini
==================
94ab7bee;Konstantin Lopuhin;2016-01-15 11:26:01 +0300;py3: body to bytes in tests, unskip test file

==

tests/py3-ignores.txt
tests/test_downloadermiddleware.py
==================
99f1f2ad;Konstantin Lopuhin;2016-01-14 19:00:48 +0300;unskip tests and modules ported to py3

==

tests/py3-ignores.txt
==================
81a90c3a;Konstantin Lopuhin;2016-01-14 18:47:06 +0300;unskip part of test_download_gzip_response on py3, file a twisted issue for the remaining part

==

tests/mockserver.py
tests/test_downloader_handlers.py
==================
2aa6c92f;Konstantin Lopuhin;2016-01-14 17:52:50 +0300;py3 fixes in tests.mockserver

==

tests/mockserver.py
==================
f46a9d59;Konstantin Lopuhin;2016-01-14 17:31:58 +0300;skip ftp tests on py3 for now

==

tests/test_downloader_handlers.py
==================
4950f598;Konstantin Lopuhin;2016-01-14 17:24:08 +0300;py3: pass http proxy tests

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
==================
c6f14a39;Konstantin Lopuhin;2016-01-14 16:50:16 +0300;py3: fix http10 downloader - unicode host expected here

==

scrapy/core/downloader/handlers/http10.py
tests/test_downloader_handlers.py
==================
6b79fffa;Konstantin Lopuhin;2016-01-14 16:37:18 +0300;py3: pass all of HttpTestCase

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
==================
3509378b;Konstantin Lopuhin;2016-01-14 16:29:19 +0300;py3: pass first http downloader test, simple crawler works now, yay!

==

scrapy/core/downloader/handlers/http11.py
scrapy/http/response/__init__.py
tests/test_downloader_handlers.py
==================
32bb5b68;Konstantin Lopuhin;2016-01-14 16:11:16 +0300;fix import of test_downloader_handlers.py: use @implementer, move failing on py3 imports into corresponding tests

==

scrapy/core/downloader/handlers/http11.py
tests/test_downloader_handlers.py
==================
5c2241cc;Konstantin Lopuhin;2016-01-14 15:30:28 +0300;py3: fix webclient tests after making ScrapyHTTPClientFactory use bytes as in twisted

==

scrapy/core/downloader/webclient.py
tests/test_webclient.py
==================
8df35bca;Konstantin Lopuhin;2016-01-14 14:52:44 +0300;rm note to self: to be discussed in PR

==

scrapy/core/downloader/webclient.py
==================
ac2cf191;Konstantin Lopuhin;2016-01-14 14:50:58 +0300;py3: remove comments, utf-8 is fine here: as twisted ultimately uses urllib.parse.quote that assepts bytes and assumes utf-8

==

scrapy/core/downloader/webclient.py
==================
e5fb6094;Konstantin Lopuhin;2016-01-14 14:45:02 +0300;make ScrapyHTTPClientFactory comply to twisted HTTPClientFactory protocol - use bytes (encoding are likely wrong at this stage)

==

scrapy/core/downloader/webclient.py
==================
6a412d25;Konstantin Lopuhin;2016-01-14 13:48:48 +0300;all tests pass in test_webclient.py on py3 - removing from py3-ignores

==

tests/py3-ignores.txt
==================
01783561;Konstantin Lopuhin;2016-01-14 13:46:46 +0300;py3 fix testRedirect: url is bytes here

==

tests/test_webclient.py
==================
30c7b4e4;Konstantin Lopuhin;2016-01-14 13:44:14 +0300;py3 compat in test_timeoutTriggering cleanup

==

tests/test_webclient.py
==================
88f55312;Konstantin Lopuhin;2016-01-14 13:43:37 +0300;py3 fix in testFactoryInfo - factory attirbutes are bytes in twisted

==

tests/test_webclient.py
==================
b5f9bc84;Konstantin Lopuhin;2016-01-14 13:04:45 +0300;py3 test fixes in test_webclient - expect bytes as page body

==

tests/test_webclient.py
==================
ae4aa2c3;Konstantin Lopuhin;2016-01-14 13:04:10 +0300;py3 test fix: putChild expects bytes as path

==

tests/test_webclient.py
==================
85b0e6c9;Paul Tremberth;2016-01-14 10:50:51 +0100;Travis: run tox with Python 3.5 + add Python 3.5 tests

==

.travis.yml
==================
325b6af6;Konstantin Lopuhin;2016-01-14 12:29:59 +0300;fix ScrapyHTTPPageGetterTests for py3 - we expect bytes here

==

tests/test_webclient.py
==================
945674eb;Konstantin Lopuhin;2016-01-14 12:25:54 +0300;pass test_externalUnicodeInterference - the logic for py3 is clearly inverse of what was expected in this test, as scrapy Request url must be unicode

==

tests/test_webclient.py
==================
1d5ab671;Konstantin Lopuhin;2016-01-14 12:04:26 +0300;pass test_getPageHead on py3

==

tests/test_webclient.py
==================
73ff87c1;Konstantin Lopuhin;2016-01-14 12:03:08 +0300;decode body from utf-8, as scrapy stores body as bytes, and twisted has already converted  to unicode

==

scrapy/core/downloader/webclient.py
==================
9f2be23a;Konstantin Lopuhin;2016-01-14 11:42:23 +0300;webclient tests, py3: fix setUp, pass test_getPage

==

tests/test_webclient.py
==================
f3889b0b;Konstantin Lopuhin;2016-01-14 11:41:49 +0300;py3 compat: encode delimiter, method and path in ScrapyHTTPPageGetter

==

scrapy/core/downloader/webclient.py
==================
a93d49a6;Paul Tremberth;2016-01-13 12:47:42 +0100;Add Python 3.5 tox env and Python 3.4 tests in Travis CI

==

.travis.yml
tox.ini
==================
1347015a;Paul Tremberth;2016-01-13 12:32:28 +0100;Refactored test code

==

tests/test_utils_iterators.py
==================
d4c7d72b;Paul Tremberth;2016-01-13 12:13:47 +0100;Add tests for input type in xmliter calls

==

tests/test_utils_iterators.py
==================
57f99fc3;Elias Dorneles;2016-01-13 08:59:48 -0200;Merge pull request #1644 from yarikoptic/master
[MRG+1] BF: robustify _monkeypatches check for twisted - str() name first (Closes #1634)
==
==================
9fad25f3;Paul Tremberth;2016-01-13 11:42:41 +0100;Use explicit Unicode and bytes for XML body in tests

==

scrapy/utils/iterators.py
tests/test_utils_iterators.py
==================
2f2c2e80;Paul Tremberth;2016-01-13 11:42:01 +0100;Merge remote-tracking branch 'origin/master' into xmliter-unicode

==
==================
f01fd076;Mikhail Korobov;2016-01-13 10:03:02 +0500;Merge pull request #1661 from redapple/py3-iterators
[MRG+1] PY3: port utils/iterators
==
==================
d7d4ef67;Paul Tremberth;2016-01-12 11:08:49 +0100;Changes following comments

==

scrapy/utils/iterators.py
==================
6ddd8147;Paul Tremberth;2016-01-12 10:48:45 +0100;Support unicode tags in xml iterators (fixes #1665)

==

scrapy/utils/iterators.py
tests/test_utils_iterators.py
==================
d4872940;Paul Tremberth;2016-01-06 21:21:21 +0100;PY3: port utils/iterators

==

scrapy/utils/iterators.py
tests/py3-ignores.txt
tests/test_utils_iterators.py
==================
95e8ff8b;Elias Dorneles;2016-01-06 10:43:08 -0200;Merge pull request #1660 from stummjr/patch-4
[MRG+1] Update deprecated examples
==
==================
2abc9bc9;Valdir Stumm Jr;2016-01-06 10:29:45 -0200;Update deprecated examples
* update the scrapy.org example to deal with the new layout.
* replaced slashdot.org by reddit.com, because it seems that slashdot is blocking requests.
==

docs/topics/shell.rst
==================
d03d262f;palego;2016-01-04 10:00:13 +0100;indentation

==

scrapy/downloadermiddlewares/retry.py
==================
c702c530;palego;2016-01-03 14:33:42 +0100;change os.mknod() for open()
os.mknod() is a privileged command on OS X, making the test fail

==

tests/test_commands.py
==================
1b435b28;Daniel Graña;2015-12-30 15:43:04 -0300;Add 1.0.4 release notes

==

docs/news.rst
==================
f57121c7;Aron Bordin;2015-12-30 13:10:13 -0200;show download warnsize once

==

scrapy/core/downloader/handlers/http11.py
==================
4f49aab7;Yaroslav Halchenko;2015-12-18 16:16:05 -0500;BF: robustify _monkeypatches check for twisted - str() name first (Closes: #1634)
In my case, while running datalad tests using nose, scrapy was failing
since v was None

==

scrapy/_monkeypatches.py
==================
bcce8d3d;orangain;2015-12-17 14:48:37 +0900;DOC: Update MetaRefreshMiddlware's setting variables
* `REDIRECT_MAX_METAREFRESH_DELAY` has been deprecated and was
  renamed to `METAREFRESH_MAXDELAY`.
* Merge duplicate documents about `METAREFRESH_MAXDELAY` appeared both
  in the settings page and the downloader-middlewares page.

==

docs/topics/downloader-middleware.rst
docs/topics/settings.rst
==================
a5db7f86;Mikhail Korobov;2015-12-14 23:33:14 +0500;Merge pull request #1639 from seales/master
Spelling fixes
==
==================
1bc243a8;Mikhail Korobov;2015-12-14 23:32:18 +0500;Merge pull request #1638 from orangain/toc-captions
[MRG+1] DOC: Add captions to toctrees which appear in sidebar
==
==================
719b1353;seales;2015-12-13 19:39:48 -0800;Spelling fixes

==

sep/sep-003.rst
sep/sep-014.rst
sep/sep-018.rst
sep/sep-020.rst
==================
4be4ef03;orangain;2015-12-12 16:21:00 +0900;DOC: Add captions to toctrees which appear in sidebar

==

docs/index.rst
==================
b5285c3f;Daniel Graña;2015-12-05 14:45:17 -0300;Merge pull request #1628 from rolando/conda-docs
[MRG] Removed pywin32 from conda install instructions as it's already declared as dependency.
==
==================
f8ae99d1;Rolando Espinoza;2015-12-05 09:48:17 -0400;DOC Removed pywin32 from install instructions as it's already declared as dependency.

==

docs/intro/install.rst
==================
7d187735;Elias Dorneles;2015-12-04 14:08:44 -0200;Merge pull request #1359 from nyov/nyov/drop-optional_features
[MRG+1] drop deprecated "optional_features" set
==
==================
17aba44f;Daniel Graña;2015-12-04 10:31:13 -0300;Merge pull request #1565 from starrify/fix-1564
[MRG+1] fixed: Issue #1564 (Incorrectly picked URL in `scrapy.linkextractors.regex.RegexLinkExtractor` when there is a `<base>` tag. )
==
==================
dc650263;Daniel Graña;2015-12-04 09:55:12 -0300;Merge pull request #1597 from Digenis/various_formreq_fixes
[MRG+1] Various FormRequest tests+fixes
==
==================
3881eaff;Daniel Graña;2015-12-04 09:54:48 -0300;Merge pull request #1575 from palego/startproject-templates-override
[MRG+1] Startproject templates override
==
==================
a97f28fb;Daniel Graña;2015-12-04 09:51:56 -0300;Merge pull request #1598 from Digenis/disable_dupefilter_in_shell
[MRG+1] Disable dupefilter in shell to prevent hanging.
==
==================
21f638b1;Daniel Graña;2015-12-04 09:40:35 -0300;Merge pull request #1622 from sibiryakov/twisted-1550-fix
[MRG+1] Ignoring xlib/tx folder, depending on Twisted version.
==
==================
015cd789;Mikhail Korobov;2015-12-04 16:28:45 +0500;Merge pull request #1618 from sibiryakov/engine-heartbeats
Nextcall heartbeats in engine (event loop halting)
==
==================
37289815;Leonid Amirov;2015-12-03 16:15:50 +0300;code formatting fix

==

scrapy/core/downloader/handlers/http11.py
==================
016875fd;Leonid Amirov;2015-12-03 15:30:06 +0300;added more verbosity for log and for exception when download is cancelled because of a size limit

==

scrapy/core/downloader/handlers/http11.py
==================
c4d29eca;Alexander Sibiryakov;2015-12-02 17:05:44 +0100;Ignoring xlib/tx folder, depending on Twisted version.

==

conftest.py
==================
5750ce92;Alexander Sibiryakov;2015-11-26 17:19:19 +0100;nextcall repetitive calls (heartbeats).

==

scrapy/core/engine.py
==================
2c251000;palego;2015-10-31 16:19:11 +0100;custom project templates
allow override of TEMPLATES_DIR for startproject
copy full TEMPLATES_DIR/project tree
doc update
==

docs/topics/settings.rst
scrapy/commands/startproject.py
tests/test_commands.py
==================
eb4daa34;Pablo Hoffman;2015-11-26 14:11:28 -0300;Merge pull request #1544 from rolando/conda-docs
Added installation notes about using Conda for Windows.
==
==================
cc8ddb68;Rolando Espinoza;2015-09-29 20:05:50 -0400;Added installation notes about using Conda for Windows and other OSes.

==

docs/intro/install.rst
==================
751155ea;Pengyu CHEN;2015-11-19 00:38:05 +0800;removed: Unused code

==

scrapy/linkextractors/sgml.py
==================
48539af1;Julia Medina;2015-11-16 14:58:07 -0300;Merge pull request #1601 from mvj3/minor-documentation-fixes
Fixed minor grammar issues.
==
==================
0025d5a9;David Chen;2015-11-16 07:30:17 +0800;Fixed minor grammar issues.

==

docs/faq.rst
docs/topics/broad-crawls.rst
docs/topics/extensions.rst
docs/topics/item-pipeline.rst
docs/topics/items.rst
docs/topics/leaks.rst
docs/topics/practices.rst
docs/topics/selectors.rst
==================
ebfdb9bb;Νικόλαος-Διγενής Καραγιάννης;2015-11-14 23:24:07 +0200;readable xpath with exslt

==

scrapy/http/request/form.py
==================
4f98be60;Νικόλαος-Διγενής Καραγιάννης;2015-11-13 18:56:05 +0200;FormRequest: fix unicode xpath exception

==

scrapy/http/request/form.py
==================
395ef805;Νικόλαος-Διγενής Καραγιάννης;2015-11-13 18:54:02 +0200;FormRequest: test unicode xpath expr & exception

==

tests/test_http_request.py
==================
2d25eab0;Νικόλαος-Διγενής Καραγιάννης;2015-11-13 18:05:07 +0200;FormRequest: <input>'s default type must be text

==

scrapy/http/request/form.py
==================
7a438a51;Νικόλαος-Διγενής Καραγιάννης;2015-11-13 18:03:54 +0200;FormRequest: test default <input> type (is text)

==

tests/test_http_request.py
==================
650acad2;Νικόλαος-Διγενής Καραγιάννης;2015-11-13 17:57:46 +0200;FormRequest: fix case-insensitive type attributes

==

scrapy/http/request/form.py
==================
881bf19e;Νικόλαος-Διγενής Καραγιάννης;2015-11-13 17:08:13 +0200;FormRequest: test case-insensitive type attribute

==

tests/test_http_request.py
==================
54216d7a;Julia Medina;2015-11-11 14:08:50 -0300;Merge pull request #1586 from jdemaeyer/fix/backwards-compatible-per-key-priorities
[MRG+1] Backwards compatible per key priorities
==
==================
4f364764;Jakob de Maeyer;2015-11-10 22:48:50 +0100;Simplify BaseSettings.__get__(), .getpriority()

==

scrapy/settings/__init__.py
==================
44f6ada0;Jakob de Maeyer;2015-11-06 15:54:50 +0100;Overwrite, not update, dictionary-like settings

==

scrapy/settings/__init__.py
tests/test_cmdline/__init__.py
tests/test_settings/__init__.py
==================
52ecee6a;Jakob de Maeyer;2015-11-06 13:15:32 +0100;Replace BaseSettings._getcomposite() with public .getwithbase() method

==

scrapy/commands/check.py
scrapy/commands/crawl.py
scrapy/commands/runspider.py
scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/middleware.py
scrapy/core/spidermw.py
scrapy/extension.py
scrapy/extensions/feedexport.py
scrapy/pipelines/__init__.py
scrapy/settings/__init__.py
tests/test_settings/__init__.py
==================
b6a023ce;Jakob de Maeyer;2015-11-06 11:35:59 +0100;Add backwards compatibility for build_component_list

==

scrapy/utils/conf.py
tests/test_utils_conf.py
==================
e66f6498;Jakob de Maeyer;2015-11-06 01:14:49 +0100;Bring back _BASE settings

==

docs/topics/downloader-middleware.rst
docs/topics/extensions.rst
docs/topics/feed-exports.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
scrapy/settings/default_settings.py
==================
9548691f;Mikhail Korobov;2015-11-10 21:33:24 +0500;Merge pull request #1563 from starrify/master
[MRG+1] fixed: Issue #1562 (Incorrectly picked URL in `scrapy.http.FormReques t.from_response` when there is a `<base>` tag)
==
==================
97b51ea3;Leonid Amirov;2015-11-03 14:57:37 +0300;issue GH #1550 - six library is used instead of urlparse for python3 compatibility

==

scrapy/commands/shell.py
==================
dd45b31f;Leonid Amirov;2015-11-03 14:32:30 +0300;issue GH #1550 - rewritten add_http_if_no_scheme()

==

scrapy/utils/url.py
==================
94486bb2;Pengyu CHEN;2015-11-02 23:00:42 +0800;added: Test case for the fix.

==

tests/test_linkextractors_deprecated.py
==================
e19bf4ae;Pengyu CHEN;2015-11-02 22:52:41 +0800;added: Test case for the fix

==

tests/test_http_request.py
==================
bc9db653;Leonid Amirov;2015-11-02 16:08:19 +0300;issue GH #1550 - scrapy shell argument fixes: "example.com" requests "http://example.com"; "example" requests "file://example"; "./example.com" requests "file://example.com"

==

scrapy/commands/shell.py
==================
a41c64bf;Leonid Amirov;2015-11-02 16:06:21 +0300;issue GH #1550 - fixed bugs in scrapy.utils.url.add_http_if_no_scheme(): when given URI where scheme is present, but not 'http' the function gave bad result

==

scrapy/utils/url.py
==================
98a2e77a;Leonid Amirov;2015-11-02 15:30:49 +0300;issue GH #1550 - fixed error: shell command wasn't accepting files URIs

==

scrapy/commands/shell.py
==================
57f87b95;Julia Medina;2015-10-30 12:36:35 -0300;Merge pull request #1528 from scrapy/create-crawler
public Crawler.create_crawler method
==
==================
9424ca0f;Julia Medina;2015-10-30 12:36:25 -0300;Merge pull request #1570 from jdemaeyer/tests/complete-settings-tests
[MRG+1] Add some missing tests for scrapy.settings
==
==================
0000b6e9;Mikhail Korobov;2015-10-30 20:27:03 +0500;TST cleanup scrapy.utils.test.get_crawler

==

scrapy/utils/test.py
==================
a49c82ad;Mikhail Korobov;2015-10-06 17:23:47 +0500;TST improve CrawlerRunner tests
* use CrawlerRunner.create_crawler instead of get_crawler helper in test_crawl;
* add a test for loading spiders by name;
* add a test for passing Crawler objects instead of Spider objects;
* add a test for CrawlerRunner.join

==

scrapy/utils/test.py
tests/test_crawl.py
tests/test_spiderloader/__init__.py
==================
11b11c98;Mikhail Korobov;2015-10-06 02:20:04 +0500;CrawlerRunner.create_crawler method

==

scrapy/crawler.py
==================
72eeead6;Julia Medina;2015-10-30 12:10:38 -0300;Merge pull request #1524 from Digenis/relocate_telnet_console
[MRG+1] Relocate telnetconsole to extensions/
==
==================
32ff4cc1;Jakob de Maeyer;2015-10-29 17:36:02 +0100;PEP8ify scrapy.settings tests

==

tests/test_settings/__init__.py
==================
51ca84c9;Jakob de Maeyer;2015-10-29 09:49:12 +0100;Add missing tests for scrapy.settings module

==

tests/test_settings/__init__.py
==================
caf2080b;Mikhail Korobov;2015-10-29 19:11:07 +0500;Merge pull request #1423 from jdemaeyer/enhancement/executionengine-close
[MRG+1] Add ExecutionEngine.close() method
==
==================
8307c121;Jakob de Maeyer;2015-08-10 23:43:06 +0200;Add ExecutionEngine.close() method

==

scrapy/core/engine.py
scrapy/crawler.py
tests/test_crawl.py
tests/test_engine.py
==================
e379f58c;Pengyu CHEN;2015-10-29 14:52:31 +0800;fixed: Issue #1564 (Incorrectly picked URL in `scrapy.linkextractors.regex.RegexLinkExtractor` when there is a `<base>` tag. )

==

scrapy/linkextractors/regex.py
==================
c34dbe95;Pengyu CHEN;2015-10-29 14:18:59 +0800;fixed: Issue #1562 (Incorrectly picked URL in `scrapy.http.FormRequest.from_response` when there is a `<base>` tag)

==

scrapy/http/request/form.py
==================
dd9f777b;Daniel Graña;2015-10-28 18:21:26 -0300;Merge pull request #1149 from jdemaeyer/enhancement/settings-per-key-priorities
[MRG+1] Per-key priorities for dict-like settings by promoting dicts to Settings instances
==
==================
03f1720a;Jakob de Maeyer;2015-10-27 13:56:14 +0100;Fix backwards-compatibility for users who explicitly set _BASE settings

==

scrapy/settings/__init__.py
tests/test_settings/__init__.py
==================
f249b309;Jakob de Maeyer;2015-08-26 00:26:06 +0200;Move scrapy.utils.conf.remove_none_values to s.u.python.without_none_values

==

scrapy/commands/crawl.py
scrapy/commands/runspider.py
scrapy/core/downloader/handlers/__init__.py
scrapy/downloadermiddlewares/defaultheaders.py
scrapy/extensions/feedexport.py
scrapy/utils/conf.py
scrapy/utils/python.py
tests/test_utils_conf.py
tests/test_utils_python.py
==================
90198e53;Jakob de Maeyer;2015-08-25 23:44:37 +0200;Add __repr__ method for BaseSettings

==

scrapy/settings/__init__.py
==================
9eb3597d;Jakob de Maeyer;2015-08-25 23:43:54 +0200;PEP8ify settings module

==

scrapy/settings/__init__.py
==================
9bd7af8a;Jakob de Maeyer;2015-08-25 23:41:34 +0200;Remove unused import in scrapy.settings

==

scrapy/settings/__init__.py
==================
bb6dee61;Jakob de Maeyer;2015-07-02 16:51:15 +0200;Move Settings documentation to docstrings

==

docs/topics/api.rst
scrapy/settings/__init__.py
==================
26586ef5;Jakob de Maeyer;2015-06-19 15:09:36 +0200;Deprecate _BASE settings, unify _BASE backwards-compatibility

==

docs/topics/downloader-middleware.rst
docs/topics/extensions.rst
docs/topics/feed-exports.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
scrapy/commands/check.py
scrapy/commands/crawl.py
scrapy/commands/runspider.py
scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/middleware.py
scrapy/core/spidermw.py
scrapy/downloadermiddlewares/defaultheaders.py
scrapy/extension.py
scrapy/extensions/feedexport.py
scrapy/pipelines/__init__.py
scrapy/settings/__init__.py
scrapy/settings/default_settings.py
scrapy/utils/conf.py
tests/test_settings/__init__.py
tests/test_utils_conf.py
==================
a769a1ef;Jakob de Maeyer;2015-06-19 15:01:24 +0200;Introduce BaseSettings with full dictionary interface

==

docs/topics/api.rst
scrapy/settings/__init__.py
tests/test_cmdline/__init__.py
tests/test_cmdline/extensions.py
tests/test_settings/__init__.py
tests/test_settings/default_settings.py
==================
4a9f76eb;Mikhail Korobov;2015-10-26 12:30:46 +0500;Merge pull request #1555 from stummjr/patch-1
fix typo in the documentation
==
==================
d577c470;Valdir Stumm Jr;2015-10-26 00:00:20 -0200;fixed a typo in the documentation.

==

docs/topics/media-pipeline.rst
==================
8dc400c6;Pablo Hoffman;2015-10-14 10:58:54 -0300;Merge pull request #1541 from chripede/patch-1
[MRG+1] Version 1 now exists
==
==================
cc76fb3d;Christian Pedersen;2015-10-14 14:07:34 +0200;Version 1 now exists

==

docs/versioning.rst
==================
451318ef;Pablo Hoffman;2015-10-13 16:09:07 -0300;Merge pull request #1530 from scrapy/retry-400
[MRG+1] DOC fix docs after GH-1289.
==
==================
411174cf;Daniel Graña;2015-10-12 20:43:21 -0300;Merge pull request #1535 from scrapy/py3-commands
PY3 port bench, startproject, genspider, list and runspider commands
==
==================
65f4ba34;Daniel Graña;2015-10-12 20:36:12 -0300;Merge pull request #1537 from scrapy/no-coveralls
drop coveralls support
==
==================
09fc9b48;Mikhail Korobov;2015-10-12 18:12:56 +0500;drop coveralls support

==

.travis.yml
==================
215905bd;Mikhail Korobov;2015-10-12 17:59:42 +0500;PY3 port bench, startproject, genspider, list and runspider commands

==

scrapy/commands/genspider.py
scrapy/commands/parse.py
scrapy/utils/template.py
tests/py3-ignores.txt
tests/test_commands.py
==================
0117c811;Julia Medina;2015-10-12 09:33:27 -0300;Merge pull request #1533 from Digenis/xml_iter-nodename_with_dot
[MRG+1] xmliter nodename with dot
==
==================
1b6d60c2;Mikhail Korobov;2015-10-06 23:56:28 +0500;DOC fix docs after GH-1289.

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/retry.py
==================
9676cf8e;Mikhail Korobov;2015-10-09 01:20:45 +0500;Merge pull request #1527 from scrapy/no-pillow-300
TST don't use broken Pillow version in tests
==
==================
f56062d0;Νικόλαος-Διγενής Καραγιάννης;2015-10-07 14:47:23 +0300;escape nodename in xmliter regex

==

scrapy/utils/iterators.py
==================
d66efb13;Νικόλαος-Διγενής Καραγιάννης;2015-10-07 14:43:47 +0300;test xml nodename with dots

==

tests/test_utils_iterators.py
==================
4e9a43c2;Mikhail Korobov;2015-10-07 15:34:21 +0500;Merge pull request #1532 from hoatle/docs-fixes
Docs fixes
==
==================
2869cf8d;hoatle;2015-10-07 15:51:12 +0700;fix another invalid xpath error

==

docs/topics/selectors.rst
==================
4e669554;Hoat Le;2015-10-07 15:43:02 +0700;fix ValueError: Invalid XPath: //div/[id="not-exists"]/text() on selectors.rst
>>> response.xpath('//div/[id="not-exists"]/text()').extract_first() is None
Traceback (most recent call last):
  File "<console>", line 1, in <module>
  File "/home/vagrant/.virtualenvs/scrapy/lib/python2.7/site-packages/scrapy/http/response/text.py", line 109, in xpath
    return self.selector.xpath(query)
  File "/home/vagrant/.virtualenvs/scrapy/lib/python2.7/site-packages/scrapy/selector/unified.py", line 100, in xpath
    raise ValueError(msg if six.PY3 else msg.encode("unicode_escape"))
ValueError: Invalid XPath: //div/[id="not-exists"]/text()
==

docs/topics/selectors.rst
==================
669be0a2;Mikhail Korobov;2015-10-06 17:24:52 +0500;TST don't use broken Pillow version in tests

==

tox.ini
==================
d523c75f;Νικόλαος-Διγενής Καραγιάννης;2015-10-05 13:26:40 +0300;Relocate telnetconsole to extensions/

==

docs/topics/extensions.rst
docs/topics/settings.rst
docs/topics/telnetconsole.rst
scrapy/extensions/telnet.py
scrapy/settings/default_settings.py
scrapy/telnet.py
scrapy/templates/project/module/settings.py.tmpl
scrapy/utils/deprecate.py
==================
91cbf974;Mikhail Korobov;2015-10-03 13:23:38 +0500;Merge pull request #1522 from smirecki/fix-typos-in-docs-topics
DOC Typos corrections
==
==================
8379bea7;smirecki;2015-10-02 23:48:27 -0400;Typos corrections
I've made a few small corrections, some spelling changes and typo fixes.
I've tried to respect regional spelling differences and avoided proposing hyphenating compound words.

 Please enter the commit message for your changes. Lines starting

==

docs/topics/deploy.rst
docs/topics/firebug.rst
docs/topics/loaders.rst
docs/topics/shell.rst
==================
fe15f93e;Daniel Graña;2015-09-30 21:38:58 -0300;Merge pull request #1498 from Preetwinder/scrapy-add_scheme
[MRG+1] #1487 add_scheme_if_missing for `scrapy shell` command
==
==================
0620e764;Marius Gedminas;2015-09-28 12:29:12 +0300;Fix list formatting

==

docs/topics/request-response.rst
==================
eaad10fa;Marius Gedminas;2015-09-28 12:36:34 +0300;Typo

==

docs/topics/spiders.rst
==================
75cd0562;Pablo Hoffman;2015-09-25 16:39:21 -0300;disable log on version command. closes #1426

==

scrapy/commands/version.py
==================
47c8e2ba;preetwinder;2015-09-24 17:57:25 +0000;Restructure tests for add_http_if_no_scheme function

==

tests/test_utils_url.py
==================
9d96e767;preetwinder;2015-09-24 17:31:30 +0000;Minor changes to add_http_if_no_scheme

==

scrapy/utils/url.py
==================
8c629eee;preetwinder;2015-09-18 16:31:37 +0530;adds docstring, tests and correction

==

scrapy/commands/shell.py
scrapy/utils/url.py
tests/test_utils_url.py
==================
c517951a;preetwinder;2015-09-16 14:05:05 +0530;add_scheme_if_missing for scrapy shell command

==

scrapy/commands/shell.py
scrapy/utils/url.py
tests/test_utils_url.py
==================
69398fa1;Daniel Graña;2015-09-21 18:19:59 -0300;Merge pull request #1505 from scrapy/fix-test-suite
TST pin pytest to 2.7.3
==
==================
916141a0;Mikhail Korobov;2015-09-21 21:12:52 +0500;TST pin pytest to 2.7.3

==

tests/requirements-py3.txt
tests/requirements.txt
==================
181f8d27;Mikhail Korobov;2015-09-20 02:47:41 +0500;Merge pull request #1501 from scrapy/disable-log-on-startproject
disable log on startproject command
==
==================
97a52665;Demelziraptor;2015-09-18 17:16:43 +0900;interpreting json-amazonui-streaming as TextResponse

==

scrapy/responsetypes.py
tests/test_responsetypes.py
==================
51b12490;Daniel Graña;2015-09-18 02:27:07 -0300;Revert "test suite requires recent queuelib to pass because it depends on queuelib test suite"
This reverts commit a3390afc66134e77f98ae3bfae7bc23479ed8566.

==

tests/requirements-py3.txt
tests/requirements.txt
==================
a3390afc;Daniel Graña;2015-09-17 19:42:29 -0300;test suite requires recent queuelib to pass because it depends on queuelib test suite

==

tests/requirements-py3.txt
tests/requirements.txt
==================
a57efdb0;Daniel Graña;2015-09-17 14:07:47 -0300;Add PyPI download stats badge

==

README.rst
==================
22327ef4;Pablo Hoffman;2015-09-17 01:05:52 -0300;disable log on startproject command

==

scrapy/commands/startproject.py
==================
3c596dcf;Daniel Graña;2015-09-16 22:03:19 -0300;Merge pull request #1467 from dacjames/master
add support for a nested loaders
==
==================
09f388c3;Mikhail Korobov;2015-09-16 15:39:24 +0500;Merge pull request #1497 from haiiiiiyun/fix_typo_middlware
fix typo middlware
==
==================
14f7f225;hy;2015-09-16 16:59:23 +0800;fix typos in downloader-middleware.rst and exceptions.rst, middlware -> middleware

==

docs/topics/downloader-middleware.rst
docs/topics/exceptions.rst
==================
036109e7;Daniel Collins;2015-09-15 23:49:35 -0700;updte nested loader documentation

==

docs/topics/loaders.rst
==================
ecbfe4bd;nyov;2015-07-12 16:53:54 +0000;drop deprecated "optional_features" set

==

scrapy/__init__.py
scrapy/core/downloader/handlers/http.py
scrapy/utils/log.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware_retry.py
tests/test_toplevel.py
==================
5279da99;Daniel Graña;2015-09-14 17:14:15 -0300;Merge pull request #1496 from scrapy/default-template
[MRG+1] style fixes for settings.py created by `scrapy startproject`
==
==================
3e13740a;Mikhail Korobov;2015-09-15 00:36:50 +0500;Merge pull request #1481 from mlyundin/develop
cleanup
==
==================
4d1c5c3d;Daniel Graña;2015-09-14 02:20:13 -0300;Merge pull request #1488 from scrapy/py3-redirect-downloader-mware
[MRG+1] PY3 redirect downloader mware
==
==================
5a130227;Mikhail Korobov;2015-09-13 21:46:20 +0500;style fixes for settings.py created by scrapy startproject

==

scrapy/templates/project/module/settings.py.tmpl
==================
430e90f4;Elias Dorneles;2015-09-13 12:29:41 -0300;minor refactor on metarefresh redirect mware test

==

tests/test_downloadermiddleware_redirect.py
==================
b06d0706;Elias Dorneles;2015-09-13 11:49:59 -0300;refactoring redirect logic

==

scrapy/downloadermiddlewares/redirect.py
==================
81950f77;Elias Dorneles;2015-09-11 18:51:48 -0300;made encoding conversion more explicit, added test for header with utf-8 encoding replicating what browsers do

==

scrapy/downloadermiddlewares/redirect.py
tests/test_downloadermiddleware_redirect.py
==================
179c4588;Elias Dorneles;2015-09-10 19:36:47 -0300;adding test for latin1 location

==

tests/test_downloadermiddleware_redirect.py
==================
defa8991;Elias Dorneles;2015-09-10 16:31:59 -0300;PY3 port redirect middleware

==

scrapy/downloadermiddlewares/redirect.py
tests/py3-ignores.txt
tests/test_downloadermiddleware_redirect.py
==================
44bd01d5;Elias Dorneles;2015-09-10 16:19:56 -0300;preparatory refactor in redirect mware

==

scrapy/downloadermiddlewares/redirect.py
==================
a7787628;Daniel Graña;2015-09-10 12:09:26 -0300;Merge pull request #1263 from chekunkov/readable-middlewares-list-in-logs
Make list of enabled middlewares more readable
==
==================
563b1500;Alexander Chekunkov;2015-05-29 17:45:45 +0700;Make list of enabled middlewares more readable

==

scrapy/middleware.py
==================
9a64d8ff;Daniel Graña;2015-09-09 15:55:55 -0300;fix scrapy squeue tests after recent changes to queuelib

==

tests/test_squeues.py
==================
600f27c3;Mikhail Korobov;2015-09-09 17:54:35 +0500;Merge pull request #1350 from scrapy/installation-docs-update
Updates in Installation and Contributing sections in the docs
==
==================
eb7b9d50;Julia Medina;2015-09-08 18:49:44 -0300;Add note to ubuntu install section about debian compatibility

==

docs/intro/install.rst
==================
be7821a4;Mikhail Lyundin;2015-09-04 20:35:27 +0300;Optimization - avoid temporary list objects, unnecessary function call

==

scrapy/commands/check.py
scrapy/commands/genspider.py
scrapy/crawler.py
scrapy/loader/__init__.py
scrapy/shell.py
scrapy/utils/defer.py
scrapy/utils/request.py
==================
6490cb53;Daniel Graña;2015-09-07 14:32:27 -0300;Merge pull request #1477 from mlyundin/master
equal_attributes function optimization
==
==================
311d5cd4;Daniel Collins;2015-09-04 12:19:10 -0700;split nested_loader into seperate methods

==

scrapy/loader/__init__.py
tests/test_loader.py
==================
88c92cb6;Daniel Collins;2015-08-29 14:23:25 -0700;provide documentation for nested loaders

==

docs/topics/loaders.rst
==================
425e35ee;Daniel Collins;2015-08-29 12:29:01 -0700;removed commented code and add test for error handling

==

scrapy/loader/__init__.py
tests/test_loader.py
==================
1f95af3c;Daniel Collins;2015-08-29 12:04:00 -0700;add support for a nested loaders

==

scrapy/loader/__init__.py
tests/test_loader.py
==================
70fa3ae9;Daniel Graña;2015-09-04 14:10:59 -0300;Merge pull request #1479 from scrapy/twisted-15.4
fixed compatibility with Twisted 15.4.0
==
==================
16e63040;Daniel Graña;2015-09-04 14:09:21 -0300;Merge pull request #1480 from scrapy/travis-run-once
don't run tests twice on Travis if a PR is made from a scrapy/scrapy branch
==
==================
d30e5390;Mikhail Korobov;2015-09-04 20:55:41 +0500;don't run tests twice on Travis if a PR is made from a scrapy/scrapy branch

==

.travis.yml
==================
faf9265c;Mikhail Korobov;2015-09-04 20:50:48 +0500;fixed compatibility with Twisted 15.4.0

==

scrapy/utils/response.py
==================
d022d3cb;Mikhail Lyundin;2015-09-03 22:49:56 +0300;equal_attributes function optimization

==

scrapy/utils/python.py
==================
6ae89632;Nicolás Alejandro Ramírez Quiros;2015-09-02 17:31:04 -0300;Merge pull request #1476 from mlyundin/master
[MRG+1] Avoid creation of temporary list object in iflatten
==
==================
d9fddabe;Mikhail Lyundin;2015-09-02 23:12:36 +0300;Avoid creation of temporary list object in iflatten

==

scrapy/utils/python.py
==================
dd473145;Daniel Graña;2015-09-02 13:04:26 -0300;Merge pull request #1473 from ArturGaspar/master
[MRG+1] Support for returning deferreds in middlewares
==
==================
833efbfc;Robert Weindl;2015-09-02 17:26:14 +0200;Update tutorial.rst
Add missing "scrapy." prefix.

==

docs/intro/tutorial.rst
==================
dd83f612;Artur Gaspar;2015-09-02 11:36:15 -0300;Test for same response object in downloader middleware test.

==

tests/test_downloadermiddleware.py
==================
2748b385;Artur Gaspar;2015-09-02 11:15:37 -0300;Test for not calling the download function when downloader middleware returns a response in process_request.

==

tests/test_downloadermiddleware.py
==================
1f4af9d8;Artur Gaspar;2015-09-02 10:33:53 -0300;Test for robots.txt middleware for logger not being called when the request for robots.txt is ignored.

==

tests/test_downloadermiddleware_robotstxt.py
==================
668e5fd2;Artur Gaspar;2015-09-02 01:43:22 -0300;Test for robots.txt middleware for processing a request for which the robots.txt parser is ready.

==

tests/test_downloadermiddleware_robotstxt.py
==================
a6a629e7;Artur Gaspar;2015-09-02 01:39:04 -0300;Call actual error logger in robots.txt middleware tests.

==

tests/test_downloadermiddleware_robotstxt.py
==================
9ce9a293;Artur Gaspar;2015-09-01 15:24:55 -0300;Always check robots.txt before making another request in RobotsTxtMiddleware.

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/robotstxt.py
tests/test_downloadermiddleware_robotstxt.py
==================
af087374;Daniel Graña;2015-09-02 00:39:30 -0300;Merge pull request #1289 from pawelmhm/dont_retry_400
[MRG+1] [settings/default_settings.py] dont retry 400
==
==================
3919ad64;Daniel Graña;2015-09-02 00:17:37 -0300;Merge pull request #1470 from scrapy/py3-middlewares
[MRG] port some downloader middlewares to Python 3
==
==================
bc499cb5;Daniel Graña;2015-09-02 00:16:42 -0300;Merge pull request #1472 from olafdietsche/incomplete-submit-button
[MRG+1] Incomplete submit button
==
==================
ca83a0b0;Artur Gaspar;2015-09-01 13:22:43 -0300;Support for returning deferreds in downloader middleware methods.

==

docs/topics/downloader-middleware.rst
scrapy/core/downloader/middleware.py
==================
937277e8;Olaf Dietsche;2015-07-12 13:37:28 +0200;Make sure value attribute values are set.

==

scrapy/http/request/form.py
==================
2c28b53c;Olaf Dietsche;2015-07-12 13:28:06 +0200;Add tests with incomplete buttons

==

tests/test_http_request.py
==================
c44cafe4;Mikhail Korobov;2015-09-01 04:11:33 +0500;PY3 fix UserAgentMiddleware tests

==

scrapy/downloadermiddlewares/useragent.py
tests/py3-ignores.txt
tests/test_downloadermiddleware_useragent.py
==================
3a9c73bc;Mikhail Korobov;2015-09-01 04:09:15 +0500;PY3 fix DownloaderStats middleware tests

==

tests/py3-ignores.txt
tests/test_downloadermiddleware_stats.py
==================
78a4cd0f;Mikhail Korobov;2015-09-01 04:00:26 +0500;PY3 fix HttpAuthMiddleware tests

==

scrapy/downloadermiddlewares/httpauth.py
tests/py3-ignores.txt
tests/test_downloadermiddleware_httpauth.py
==================
179a4409;Mikhail Korobov;2015-09-01 03:58:25 +0500;PY3 enable DownloadTimeoutMiddleware tests

==

tests/py3-ignores.txt
==================
3cf1911a;Mikhail Korobov;2015-09-01 03:57:05 +0500;PY3 fix DefaultHeadersMiddleware tests

==

tests/py3-ignores.txt
tests/test_downloadermiddleware_defaultheaders.py
==================
45101829;Mikhail Korobov;2015-09-01 03:49:52 +0500;PY3 fix AjacCrawlable middleware tests

==

tests/py3-ignores.txt
tests/test_downloadermiddleware_ajaxcrawlable.py
==================
b876755f;Daniel Graña;2015-08-31 19:30:41 -0300;Merge pull request #1469 from olafdietsche/form-submit-button-plain
Form submit button plain
==
==================
121d7535;Olaf Dietsche;2015-07-11 16:11:31 +0200;Allow button cotrols to submit form

==

scrapy/http/request/form.py
==================
e5f26078;Olaf Dietsche;2015-07-11 13:53:21 +0200;Add test: submit form with button control

==

tests/test_http_request.py
==================
0018caf0;Daniel Graña;2015-08-31 11:59:30 -0300;Merge pull request #1461 from scrapy/py3-linkextractors
[MRG] assorted Python 3 porting
==
==================
b4e382c8;Daniel Graña;2015-08-31 10:42:02 -0300;Merge pull request #1318 from yarikoptic/fix-docs-explicit-rtd-theme-path
[MRG+1] DOC(ENH): specify path to rtd theme explicitly
==
==================
44bfcbcf;Mikhail Korobov;2015-08-31 00:49:38 +0500;TST split LinkExtractorTestCase.test_extraction into several methods; remove duplicated test

==

tests/test_linkextractors.py
==================
f7052413;Mikhail Korobov;2015-08-28 23:04:02 +0500;PY3 raise an exception if bytes are passed as url to Link constructor

==

scrapy/link.py
tests/test_link.py
==================
9bfe6ece;Mikhail Korobov;2015-08-28 04:53:32 +0500;Merge branch 'master' into py3-linkextractors
Conflicts:
	scrapy/linkextractors/lxmlhtml.py
	tests/test_linkextractors.py

==
==================
ff24cbbc;Mikhail Korobov;2015-08-28 02:52:17 +0500;PY3 depth, offsite and referer spider middlewares; Crawler

==

scrapy/spidermiddlewares/depth.py
scrapy/spidermiddlewares/offsite.py
tests/py3-ignores.txt
tests/test_spidermiddleware_referer.py
==================
d5984bbe;Mikhail Korobov;2015-08-28 02:12:36 +0500;PY3 port scrapy.spiders

==

scrapy/spiders/crawl.py
scrapy/spiders/init.py
scrapy/spiders/sitemap.py
scrapy/utils/gz.py
tests/py3-ignores.txt
tests/test_spider.py
tests/test_utils_gz.py
==================
f2edbd05;Mikhail Korobov;2015-08-27 17:35:29 +0500;PY3 port LinkExtractor
* tests for other link extractors are moved to test_linkextractors_deprecated.py
* in Python 3 Link is converted to use native strings for urls
* minor cleanups

==

scrapy/link.py
scrapy/linkextractors/__init__.py
scrapy/linkextractors/lxmlhtml.py
tests/py3-ignores.txt
tests/test_link.py
tests/test_linkextractors.py
tests/test_linkextractors_deprecated.py
==================
f46a4500;Mikhail Korobov;2015-08-27 16:44:34 +0500;refactor test_linkextractors
* rename LinkExtractorTestCase to BaseSgmlLinkExtractorTestCase
* add BaseLinkExtractorTestCase link extractor tests can inherit from
  and decouple it from SgmlLinkExtractor
* add an extra check for deny_extensions
* xfail test_restrict_xpaths_with_html_entities for LxmlLinkExtractor explicitly

==

tests/test_linkextractors.py
==================
aa31811c;Julia Medina;2015-08-27 19:57:54 -0300;Merge pull request #1214 from rgtk/link-rel
[MRG+1] Support link rel attribute with multiple values
==
==================
9bfab530;Mikhail Korobov;2015-08-28 02:42:37 +0500;Merge pull request #1462 from tagatac/master
minor: scrapy.Spider docs grammar
==
==================
08162a15;David Tagatac;2015-08-27 17:37:16 -0400;minor: scrapy.Spider docs grammar

==

docs/topics/spiders.rst
==================
cb3007c0;Rafał Gutkowski;2015-05-07 15:30:12 +0200;support link rel attribute with multiple values

==

scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/sgml.py
scrapy/utils/misc.py
tests/test_linkextractors.py
==================
8ecc4544;Mikhail Korobov;2015-08-27 21:37:24 +0500;enable console tests in PY3

==

tests/requirements-py3.txt
==================
9616d91e;Mikhail Korobov;2015-08-27 21:28:05 +0500;Merge pull request #1444 from cyberplant/bpython_support
[MRG +1] bpython support
==
==================
aa88fd79;Rick;2015-08-23 15:58:53 +0200;Small grammatical change

==

docs/intro/tutorial.rst
==================
71bd79e7;Daniel Graña;2015-08-26 14:46:42 -0300;Merge pull request #1212 from Digenis/test-fix-render_template_file
fix utils.template.render_templatefile() bug +test
==
==================
56b3cf07;Νικόλαος-Διγενής Καραγιάννης;2015-05-06 22:36:14 +0300;fix string manipulation in render_templatefile()

==

scrapy/utils/template.py
==================
f5c54072;Νικόλαος-Διγενής Καραγιάννης;2015-05-06 21:21:20 +0300;Test utils.template.render_templatefile()

==

tests/test_utils_template.py
==================
026a1caf;Daniel Graña;2015-08-26 11:46:00 -0300;Merge pull request #1456 from scrapy/py3-fixes
Small Python 3 fixes
==
==================
68a47ade;Mikhail Korobov;2015-08-26 02:34:21 +0500;PY3 port test_logformatter

==

tests/py3-ignores.txt
tests/test_logformatter.py
==================
642af00b;Mikhail Korobov;2015-08-26 02:19:33 +0500;fix Referer logging

==

scrapy/core/scraper.py
scrapy/logformatter.py
scrapy/pipelines/files.py
scrapy/utils/request.py
==================
7da769fe;Mikhail Korobov;2015-08-26 01:58:59 +0500;enable test_stats and test_utils_log tests in Python 3

==

scrapy/statscollectors.py
tests/py3-ignores.txt
tests/test_stats.py
==================
787b5af3;Mikhail Korobov;2015-08-26 01:58:33 +0500;add coverage files to gitignore

==

.gitignore
==================
cfae62f9;Mikhail Korobov;2015-08-23 17:36:09 +0500;Merge pull request #1441 from aivarsk/fix-common-practices
Make common practices sample code match the comments
==
==================
489c76b8;Daniel Graña;2015-08-22 09:46:27 -0300;Merge pull request #1447 from jdemaeyer/fix/redirectmiddleware-respect-meta-attributes
[MRG +1] Fix RedirectMiddleware not honouring handle_httpstatus meta keys
==
==================
d164398a;Jakob de Maeyer;2015-08-21 13:22:42 +0200;Fix RedirectMiddleware not honouring meta handle_httpstatus keys

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/redirect.py
tests/test_downloadermiddleware_redirect.py
==================
ee66382f;Luar Roji;2015-08-21 01:04:19 +0100;Fixed banner display in all 3 python shells

==

scrapy/shell.py
==================
509cc8d4;nyov;2015-03-25 10:24:07 +0000;Add support for bpython console.
Adds support for configuration of shells from scrapy.cfg
and SCRAPY_PYTHON_SHELL.

config snippet:

cat <<EOF >> ~/.scrapy.cfg
[settings]
# shell can be one of ipython, bpython or python;
# to be tried as the interactive python console
# (in above order, unless set here).
shell = python
EOF

(closes #270, #1100, #1301)

==

docs/topics/commands.rst
docs/topics/shell.rst
scrapy/shell.py
scrapy/utils/console.py
tests/requirements.txt
tests/test_utils_console.py
==================
b8b1e8e5;Aivars Kalvāns;2015-08-19 16:54:10 +0300;Make common practices sample code match the comments

==

docs/topics/practices.rst
==================
d3c3408c;Julia Medina;2015-08-19 03:19:27 -0300;Replace alternative OSX install workaround with virtualenv

==

docs/intro/install.rst
==================
46ee1c6e;Julia Medina;2015-08-19 02:21:08 -0300;Reference Homebrew's homepage for installation instructions

==

docs/intro/install.rst
==================
280eab24;Daniel Graña;2015-08-16 00:42:55 -0300;Merge pull request #1352 from nyov/le-bogus-links
[MRG+1] [LinkExtractors] Ignore bogus links (#907)
==
==================
de15fcdf;Andrew Scorpil;2014-10-24 15:58:12 +0300;[LinkExtractors] Ignore bogus links
(rebased the code for scrapy 1.0 and made a few code improvements --nyov)

==

scrapy/linkextractors/htmlparser.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/regex.py
scrapy/linkextractors/sgml.py
tests/test_linkextractors.py
==================
1b4fd3a8;nyov;2015-07-12 18:27:41 +0000;Support anonymous connections in S3DownloadHandler
Also consider any unknown keyword args for S3DownloadHandler as
arguments to pass on to S3Connection (e.g. proxy settings).

==

scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
9adb5c31;Mikhail Korobov;2015-08-14 05:21:10 +0500;Merge pull request #1433 from scrapy/codecov
Coverage and reports at codecov.io and coveralls.io
==
==================
27077d2b;Daniel Graña;2015-08-13 20:52:38 -0300;Forward coverage envvars needed to cover subprocess

==

tests/__init__.py
==================
43fc2f23;Daniel Graña;2015-08-13 19:30:06 -0300;Increase coverage of version command

==

tests/test_command_version.py
==================
54f98378;Daniel Graña;2015-08-13 19:02:51 -0300;Document how to get coverage report

==

docs/contributing.rst
==================
cb9577a6;Daniel Graña;2015-08-13 19:02:36 -0300;Do not be verbose with coverage report by default

==

tox.ini
==================
108c3e63;Daniel Graña;2015-08-12 16:40:04 -0300;Add coverage report trough codecov.io

==

.coveragerc
.travis.yml
README.rst
tests/requirements-py3.txt
tests/requirements.txt
tox.ini
==================
12bebb61;Daniel Graña;2015-08-12 14:29:34 -0300;Merge pull request #1431 from dangra/moved-to-parsel
Replace usage of deprecated class by its parsel\'s counterpart
==
==================
6c2c9a4b;Daniel Graña;2015-08-12 14:24:43 -0300;Merge pull request #1430 from dangra/openssl-version
Add openssl version to version command
==
==================
7f634598;Daniel Graña;2015-08-12 13:13:07 -0300;Add openssl version to version command

==

scrapy/commands/version.py
==================
4ce0f53f;Daniel Graña;2015-08-12 14:21:55 -0300;Replace usage of deprecated class by its parsel\'s counterpart

==

scrapy/linkextractors/__init__.py
==================
68d23112;Daniel Graña;2015-08-12 11:15:33 -0300;Merge pull request #1427 from scrapy/python3-porting-status
add Python 3 porting status badge to README
==
==================
1ed6a01c;Mikhail Korobov;2015-08-12 19:13:54 +0500;Add Python 3 porting status badge to the README

==

README.rst
==================
15c1300d;Daniel Graña;2015-08-11 16:22:58 -0300;Merge pull request #1409 from eliasdorneles/migrate-parsel
[MRG+1] Migrating selectors to use parsel
==
==================
a5abd19e;Elias Dorneles;2015-08-11 15:58:29 -0300;make Parsel's Selector more private, remove direct dependency of ParselSelectorList

==

scrapy/selector/unified.py
==================
766c2551;Elias Dorneles;2015-08-11 15:20:33 -0300;upgrade parsel and add shim for deprecated selectorlist methods

==

requirements.txt
scrapy/selector/unified.py
tests/test_selector.py
==================
457b97c1;Daniel Graña;2015-08-11 14:16:34 -0300;Merge pull request #1388 from scrapy/dupefilter-persist
Dupefilter persistence
==
==================
e2f31f30;Daniel Graña;2015-08-11 14:09:49 -0300;explicit close file on file:// scheme handler

==

scrapy/core/downloader/handlers/file.py
==================
e50610bd;Elias Dorneles;2015-08-11 14:06:24 -0300;set base_url in kwargs to be fully backward compatible

==

scrapy/selector/unified.py
tests/test_selector.py
==================
8ef5aa2f;Elias Dorneles;2015-08-11 13:58:53 -0300;using bytes for response body in tests

==

tests/test_selector.py
==================
3a03ef7c;Elias Dorneles;2015-08-09 15:23:43 -0300;cleanup tests for selectors and translators

==

tests/py3-ignores.txt
tests/test_selector.py
tests/test_selector_csstranslator.py
==================
12579b9a;Elias Dorneles;2015-08-09 01:21:39 -0300;warning when ambiguous root arguments and minor cleanups

==

scrapy/linkextractors/sgml.py
scrapy/selector/unified.py
tests/test_selector.py
==================
26ebccd3;Elias Dorneles;2015-08-07 17:33:59 -0300;upgrade parsel and use its function to instantiate root for finding form

==

requirements.txt
scrapy/http/request/form.py
setup.py
==================
2fe6d128;Elias Dorneles;2015-08-07 15:26:54 -0300;upgrade parsel and using promoted root attribute

==

requirements.txt
scrapy/linkextractors/lxmlhtml.py
scrapy/selector/unified.py
setup.py
tests/test_selector.py
==================
67c98b18;Elias Dorneles;2015-08-06 23:31:06 -0300;avoid harcoded check for selector type

==

scrapy/selector/unified.py
==================
94c3a345;Elias Dorneles;2015-08-06 22:35:43 -0300;remove deprecated module lxmldocument

==

scrapy/selector/lxmldocument.py
tests/py3-ignores.txt
tests/test_selector_lxmldocument.py
==================
6287fc31;Elias Dorneles;2015-08-06 21:55:05 -0300;remove lxmldocument dependency from http.request.form

==

scrapy/http/request/form.py
==================
35c1dcdb;Elias Dorneles;2015-08-05 19:47:16 -0300;use response.selector in link extractors instead of instantiating new Selector

==

scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/sgml.py
==================
17d7347a;Elias Dorneles;2015-08-05 16:57:41 -0300;update minimal parsel version, add deprecated classes for csstranslator modules, fix test

==

requirements.txt
scrapy/selector/csstranslator.py
setup.py
tests/test_selector.py
==================
01d948f0;Elias Dorneles;2015-08-04 16:28:02 -0300;remove selector support for LxmlDocument DOM cache and add deprecation warning for _root argument

==

scrapy/selector/unified.py
tests/test_selector.py
==================
3a572e2f;Elias Dorneles;2015-08-03 20:38:15 -0300;cleanup csstranslator module, keeping only imports

==

scrapy/selector/csstranslator.py
==================
c7b29d11;Elias Dorneles;2015-08-03 20:37:42 -0300;fix support to legacy _root argument

==

scrapy/selector/unified.py
==================
ce21884a;Elias Dorneles;2015-08-03 20:15:21 -0300;migrating scrapy Selector to use Parsel

==

requirements.txt
scrapy/selector/unified.py
setup.py
tests/test_selector.py
==================
f67a808d;Daniel Graña;2015-08-11 13:47:04 -0300;Add 1.0.3 release notes

==

docs/news.rst
==================
342c29af;Daniel Graña;2015-08-11 13:34:36 -0300;Merge pull request #1425 from scrapy/service-identity
add service_identity to scrapy install_requires. Fix GH-1418 and GH-850.
==
==================
75d3d033;Mikhail Korobov;2015-08-11 20:14:22 +0500;add service_identity to scrapy install_requires

==

requirements-py3.txt
requirements.txt
setup.py
tox.ini
==================
fa123b33;Mikhail Korobov;2015-08-11 18:59:47 +0500;Merge pull request #1421 from dangra/nyov/lazyload-downloadhandlers
lazy-load downloadhandlers (continuation of #1357)
==
==================
7717501a;Daniel Graña;2015-08-11 10:38:31 -0300;Use log formatting and pass crawler reference

==

scrapy/core/downloader/handlers/__init__.py
==================
fa3d84b0;Mikhail Korobov;2015-08-11 18:21:34 +0500;Merge pull request #1420 from scrapy/py3-trackrefs
PY3: port scrapy.utils.trackref
==
==================
8738521d;Daniel Graña;2015-08-10 19:35:57 -0300;Add docstrings

==

scrapy/utils/trackref.py
==================
eb44152a;Daniel Graña;2015-08-10 18:25:11 -0300;lints

==

scrapy/core/downloader/handlers/__init__.py
==================
15ccf79c;Daniel Graña;2015-08-10 18:18:13 -0300;Log errors importing or initializing download handlers

==

scrapy/core/downloader/handlers/__init__.py
==================
d3804b34;Daniel Graña;2015-08-10 16:52:36 -0300;log errors importing or instanciating handlers

==

scrapy/core/downloader/handlers/__init__.py
==================
8c799708;nyov;2015-07-12 16:40:51 +0000;lazy-loading for DownloadHandlers

==

scrapy/core/downloader/handlers/__init__.py
tests/test_downloader_handlers.py
==================
666ebfa1;Daniel Graña;2015-08-10 16:45:27 -0300;py3: port dictionary itervalues call

==

scrapy/core/downloader/__init__.py
==================
bdcc78b4;Mikhail Korobov;2015-08-11 00:37:00 +0500;Merge pull request #1419 from scrapy/httprepr-on-file-scheme
Do not fail representing non-http requests
==
==================
accd28cc;Daniel Graña;2015-08-10 15:13:25 -0300;PY3: port scrapy.utils.trackref

==

scrapy/utils/trackref.py
tests/test_utils_trackref.py
==================
8d45b3c4;Daniel Graña;2015-08-10 14:10:58 -0300;Do not fail representing non-http requests

==

scrapy/utils/request.py
tests/test_utils_request.py
==================
5c4666a3;Daniel Graña;2015-08-10 11:17:20 -0300;Workaround for travis#253

==

.travis.yml
==================
1b9b2111;Daniel Graña;2015-08-08 12:23:44 -0300;Merge pull request #1415 from scrapy/nyov-py3
nyov's PY3 changes
==
==================
93accb7f;Mikhail Korobov;2015-08-08 05:20:48 +0500;PY3 nicer log messages in FilesPipeline

==

scrapy/pipelines/files.py
==================
56be610e;Mikhail Korobov;2015-08-08 04:54:47 +0500;TST a test for --profile option

==

tests/test_cmdline/__init__.py
==================
17b5e9fb;nyov;2015-07-29 20:52:25 +0000;PY3 response bodies as bytes

==

tests/test_selector_csstranslator.py
tests/test_selector_lxmldocument.py
tests/test_utils_iterators.py
tests/test_utils_reqser.py
==================
45d441d4;nyov;2015-07-29 16:16:51 +0000;PY3 fix test loader

==

tests/py3-ignores.txt
tests/requirements-py3.txt
tests/test_loader.py
==================
34eced0e;nyov;2015-07-29 17:48:27 +0000;PY3 fix tests pipelines images

==

scrapy/pipelines/images.py
tests/test_pipeline_images.py
==================
99119700;nyov;2015-07-29 17:38:13 +0000;PY3 fix tests pipelines files

==

scrapy/pipelines/files.py
tests/test_pipeline_files.py
==================
6e762ce2;nyov;2015-07-29 15:34:27 +0000;PY3 renames (six types)

==

scrapy/core/downloader/handlers/s3.py
scrapy/core/downloader/middleware.py
scrapy/core/spidermw.py
scrapy/linkextractors/htmlparser.py
tests/test_crawl.py
==================
3e6d6c43;nyov;2015-07-29 15:33:52 +0000;PY3 fix test cmdline

==

scrapy/cmdline.py
scrapy/utils/testproc.py
tests/py3-ignores.txt
tests/test_cmdline/__init__.py
tests/test_command_version.py
==================
4d41cc0d;nyov;2015-07-29 16:32:11 +0000;PY3 split requirements into files

==

requirements-py3.txt
tests/requirements-py3.txt
tox.ini
==================
57fafc70;Daniel Graña;2015-08-06 18:01:51 -0300;Add 1.0.2 release notes

==

docs/news.rst
==================
ad99a552;Mikhail Korobov;2015-08-07 01:22:17 +0500;Merge pull request #1414 from scrapy/twisted-bug-7989-2
Twisted 15.3.0 does not raises expected exception serializing lambdas
==
==================
c5ffa1a5;Daniel Graña;2015-08-05 20:33:25 -0300;Twisted 15.3.0 does not raises expected exception serializing lambda functions

==

scrapy/_monkeypatches.py
tests/test_squeues.py
==================
2bca27ef;Mikhail Korobov;2015-08-06 00:54:42 +0500;Merge pull request #1412 from mlyundin/master
Minor method name fix
==
==================
ea4199f8;Mikhail Lyundin;2015-08-05 22:42:53 +0300;Minor method name fix

==

docs/intro/tutorial.rst
==================
311293ff;Daniel Graña;2015-08-03 20:09:14 -0300;Merge pull request #1408 from scrapy/py3-utils-reqser
PY3 port scrapy.utils.reqser
==
==================
91991e0b;Mikhail Korobov;2015-08-04 02:17:46 +0500;PY port scrapy.utils.reqser

==

scrapy/utils/reqser.py
tests/py3-ignores.txt
tests/test_utils_reqser.py
==================
95e6bd2f;Mikhail Korobov;2015-08-04 01:23:37 +0500;Merge pull request #1398 from scrapy/py3-cookies
PY3 port http cookies handling
==
==================
f4fc05c2;Daniel Graña;2015-08-03 17:18:08 -0300;Do not propagate cookie log messages in tests so TopLevelFormatter does not rewrite them

==

tests/test_downloadermiddleware_cookies.py
==================
c6adf648;Daniel Graña;2015-08-03 16:28:29 -0300;PY3 port COOKIES_DEBUG and add tests

==

scrapy/downloadermiddlewares/cookies.py
scrapy/mail.py
tests/test_downloadermiddleware_cookies.py
==================
dba7e39f;Daniel Graña;2015-08-03 10:53:40 -0300;Do not break cookie parsing on non-utf8 headers

==

scrapy/http/cookies.py
tests/test_downloadermiddleware_cookies.py
==================
cbfb24db;Daniel Graña;2015-08-03 09:49:50 -0300;Merge pull request #1353 from nyov/test-no-proxies
[MRG+1] Unset environment proxies for tests
==
==================
5e6c4929;Daniel Graña;2015-08-02 23:00:00 -0300;Merge pull request #1364 from jdemaeyer/enhancement/spider-handles-redirects
[MRG+1] Make RedirectMiddleware respect Spider.handle_httpstatus_list
==
==================
b6afd1cf;Daniel Graña;2015-08-02 22:58:19 -0300;Merge pull request #1390 from nyov/nyov/lazyload-s3-boto
[MRG+1] lazy-load s3 boto
==
==================
5f02ef82;Daniel Graña;2015-07-31 17:27:53 -0300;PY3 port http cookies handling

==

scrapy/http/cookies.py
tests/py3-ignores.txt
tests/test_downloadermiddleware_cookies.py
tests/test_http_cookies.py
==================
b2fd9bdb;nyov;2015-07-12 16:38:18 +0000;lazy-load s3 boto

==

scrapy/__init__.py
scrapy/core/downloader/handlers/s3.py
scrapy/pipelines/files.py
tests/test_downloader_handlers.py
==================
e8d527c9;Mikhail Korobov;2015-08-01 02:07:42 +0500;Merge pull request #1399 from tagatac/master
DOC scrapy.Spider grammar and clarity
==
==================
08123207;David Tagatac;2015-07-31 17:01:59 -0400;minor: scrapy.Spider grammar and clarity

==

docs/topics/spiders.rst
==================
71c6bd92;Daniel Graña;2015-07-31 17:53:53 -0300;Merge pull request #1396 from scrapy/py3-utils-response
PY3 port scrapy.utils.response
==
==================
a7261d2c;Daniel Graña;2015-07-31 17:51:32 -0300;Merge pull request #1397 from scrapy/testsite-is-not-a-test
remove scrapy.utils.testsite from PY3 ignores
==
==================
805a4916;Daniel Graña;2015-07-31 16:46:40 -0300;Merge branch 'travis-containers'

==
==================
49fd77d6;Daniel Graña;2015-07-31 16:45:43 -0300;indent travis yaml

==

.travis.yml
==================
9316b231;Mikhail Korobov;2015-08-01 00:43:13 +0500;remove scrapy.utils.testsite from PY3 ignores

==

conftest.py
scrapy/utils/testsite.py
tests/py3-ignores.txt
==================
5d4cdb59;Daniel Graña;2015-07-31 16:39:12 -0300;cache pip cache

==

.travis.yml
==================
b01292df;Mikhail Korobov;2015-08-01 00:36:16 +0500;fix request_httprepr docstring

==

scrapy/utils/request.py
==================
7f927f68;Mikhail Korobov;2015-08-01 00:35:43 +0500;PY3 port scrapy.utils.response

==

scrapy/utils/response.py
tests/py3-ignores.txt
tests/test_utils_response.py
==================
5ae94ae4;Daniel Graña;2015-07-31 16:33:37 -0300;Use new travis-ci container based builds

==

.travis-workarounds.sh
.travis.yml
==================
d05cf6e0;Mikhail Korobov;2015-07-31 23:50:06 +0500;Merge branch 'responsetypes'

==
==================
02b51826;Mikhail Korobov;2015-07-31 23:48:49 +0500;small ResponseTypes cleanup

==

scrapy/responsetypes.py
tests/py3-ignores.txt
==================
de6e013b;Daniel Graña;2015-07-31 14:54:07 -0300;fix form requests tests on py3

==

tests/test_http_request.py
==================
786f6266;Daniel Graña;2015-07-31 11:00:57 -0300;Merge pull request #1137 from DharmeshPandav/patch-1
Update form.py to improve existing capability
==
==================
06b91da9;Gregory Vigo Torres;2015-07-31 14:31:11 +0200;using bytes for body constant

==

tests/test_responsetypes.py
==================
936266a6;Mikhail Korobov;2015-07-31 03:18:19 +0500;Merge pull request #934 from Dineshs91/zsh-support
[MRG+1] Added zsh completion for Scrapy command-line tool and updated bash completion
==
==================
81773874;Daniel Graña;2015-07-30 12:33:54 -0300;Merge pull request #1384 from scrapy/tmp-py3
In-progress Python 3 port
==
==================
5d75d44f;Gregory Vigo Torres;2015-07-30 13:07:42 +0200;removed test_responsetypes from py3ignores

==

tests/py3-ignores.txt
==================
b6eb3404;Mikhail Korobov;2015-07-30 15:33:02 +0500;Merge pull request #1335 from jdemaeyer/fix/docs-scrapy-path
Make Sphinx autodoc use local, not system-wide Scrapy
==
==================
9c12a3f2;Jakob de Maeyer;2015-07-30 12:12:08 +0200;Remove incorrect path for Sphinx autodoc

==

docs/conf.py
==================
42b8988e;Gregory Vigo Torres;2015-07-29 20:09:06 +0200;PY3 port responsetypes from_body

==

scrapy/responsetypes.py
==================
36ae635f;Gregory Vigo Torres;2015-07-29 20:07:26 +0200;from_content_type

==

scrapy/responsetypes.py
==================
9d17d594;Gregory Vigo Torres;2015-07-29 20:05:45 +0200;from_content_disposition

==

scrapy/responsetypes.py
==================
dafcfd5b;Mikhail Korobov;2015-07-29 19:26:50 +0500;Merge pull request #1386 from nyov/tmp-py3
[MRG+1] [py3] replace rfc822 with email.utils
==
==================
e044bfa6;nyov;2015-07-25 20:51:27 +0000;PY3 fix test downloadermiddleware decompression

==

scrapy/responsetypes.py
tests/py3-ignores.txt
tests/test_downloadermiddleware_decompression.py
tests/test_responsetypes.py
==================
ec8afbc0;nyov;2015-07-25 17:56:46 +0000;PY3 fix test pipeline media

==

tests/py3-ignores.txt
tests/test_pipeline_files.py
tests/test_pipeline_media.py
==================
8ab1648a;nyov;2015-07-25 16:58:30 +0000;PY3 fix test middleware

==

tests/py3-ignores.txt
tests/test_middleware.py
==================
683ef2a8;nyov;2015-07-25 16:44:28 +0000;replace rfc822 with email.utils

==

scrapy/pipelines/files.py
scrapy/utils/defer.py
scrapy/utils/misc.py
==================
757f983a;Mikhail Korobov;2015-07-29 18:37:04 +0500;PY3: enable RobotsTxtMiddleware tests

==

tests/py3-ignores.txt
==================
56fa9e2c;Mikhail Korobov;2015-07-29 18:21:54 +0500;Merge pull request #1391 from nyov/py3-robots
PY3 port scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware
==
==================
1a1bc2c6;nyov;2015-07-25 17:57:46 +0000;PY3 port scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware

==

scrapy/downloadermiddlewares/robotstxt.py
tests/test_downloadermiddleware_robotstxt.py
==================
836cb84b;Mikhail Korobov;2015-07-28 14:32:14 +0500;fixed RFPDupeFilter persistence

==

scrapy/dupefilters.py
==================
c78e2636;Mikhail Korobov;2015-07-28 14:31:42 +0500;TST a test to show that dupefilter persistence is not working

==

tests/test_dupefilters.py
==================
2c937f35;Daniel Graña;2015-07-25 18:10:29 +0200;PY3 port scrapy.dupefilters

==

tests/py3-ignores.txt
tests/test_dupefilters.py
==================
776064ae;Daniel Graña;2015-07-25 17:38:07 +0200;PY3 port signals

==

requirements.txt
scrapy/signalmanager.py
scrapy/utils/signal.py
scrapy/xlib/pydispatch/__init__.py
scrapy/xlib/pydispatch/dispatcher.py
scrapy/xlib/pydispatch/errors.py
scrapy/xlib/pydispatch/license.txt
scrapy/xlib/pydispatch/robust.py
scrapy/xlib/pydispatch/robustapply.py
scrapy/xlib/pydispatch/saferef.py
setup.py
tests/py3-ignores.txt
tests/test_engine.py
tests/test_utils_signal.py
==================
82304c4f;Mikhail Korobov;2015-07-25 17:48:34 +0200;PY3: fixed scrapy.utils.defer

==

scrapy/utils/defer.py
==================
c53d6d74;Mikhail Korobov;2015-07-25 17:43:50 +0200;Merge pull request #1383 from zoliszeredi/py3/fix_test_utils_defer
Py3/fix test utils defer
==
==================
7874bb9f;Mikhail Korobov;2015-07-25 17:14:56 +0200;PY3 port utils.request

==

scrapy/utils/request.py
tests/py3-ignores.txt
tests/test_utils_request.py
==================
f750ee4c;Daniel Graña;2015-07-25 16:50:54 +0200;Remove ignored passing tests from py3 branch

==

tests/py3-ignores.txt
==================
ea56067e;Daniel Graña;2015-07-25 16:39:02 +0200;ignore moved files from py3 tests

==

tests/py3-ignores.txt
==================
e438df70;Mikhail Korobov;2015-07-25 13:10:13 +0200;PY3 enable Request and Response tests

==

tests/py3-ignores.txt
==================
e853d9e9;Mikhail Korobov;2015-07-25 13:08:44 +0200;partial port of Request and Response

==

scrapy/http/request/__init__.py
scrapy/http/request/form.py
scrapy/http/response/__init__.py
scrapy/http/response/text.py
scrapy/selector/unified.py
scrapy/utils/misc.py
tests/test_http_request.py
tests/test_http_response.py
==================
1bf7a980;Zoltán Szeredi;2015-07-25 13:05:50 +0200;Remove test_utils_defer from ignores.

==

tests/py3-ignores.txt
==================
9aaa8f81;Zoltán Szeredi;2015-07-25 12:58:39 +0200;Improve python3 support for test_utils_defer.

==

tests/test_utils_defer.py
==================
9d9d4238;Julia Medina;2015-07-24 21:30:14 -0300;Merge pull request #1380 from nyov/contributing
Put a blurb about support channels in CONTRIBUTING
==
==================
f576b3ff;Mikhail Korobov;2015-07-25 00:40:45 +0200;[tmp] improve python 3 support for scrapy.utils.url

==

scrapy/utils/python.py
scrapy/utils/url.py
tests/test_utils_url.py
==================
335aa5f2;Mikhail Korobov;2015-07-24 12:17:16 +0200;Merge pull request #1379 from scrapy/py3-utils-python
PY3 port scrapy.utils.python
==
==================
b3dda1e9;nyov;2015-07-24 01:48:43 +0000;Put a blurb about support channels in CONTRIBUTING

==

CONTRIBUTING.md
==================
a7b4a3e7;Mikhail Korobov;2015-07-23 20:03:33 +0200;cleanup
* run test_utils_python in Python 3;
* make tests for 'errors' argument more explicit
* add missing test_ prefix utf_16_strings_contain_null_bytes;
* cleanup test names.

==

tests/py3-ignores.txt
tests/test_utils_python.py
==================
40734986;Mikhail Korobov;2015-07-23 18:33:56 +0200;port utils.python
* stringify_dict is deprecated
* is_writable is deprecated
* setattr_default is deprecated
* get_spec is untested
* re_rsearch is untested
* retry_on_eintr is untested

==

scrapy/utils/python.py
tests/test_utils_python.py
==================
41bcae5d;Mikhail Korobov;2015-07-23 17:35:23 +0200;TST fix to_bytes and to_unicode tests in Python 3.x

==

tests/test_utils_python.py
==================
887936eb;Mikhail Korobov;2015-07-23 17:26:20 +0200;PY3 port flatten and iflatten

==

scrapy/utils/python.py
==================
61cd27e5;Mikhail Korobov;2015-07-23 15:00:06 +0200;Rename unicode_to_str and str_to_unicode method. Fixes GH-778.

==

scrapy/http/request/form.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/sgml.py
scrapy/selector/unified.py
scrapy/utils/iterators.py
scrapy/utils/python.py
scrapy/utils/url.py
tests/test_exporters.py
tests/test_utils_python.py
==================
f93acfff;Mikhail Korobov;2015-07-18 22:16:28 +0500;Merge pull request #1366 from radarhere/patch-1
Fixed typos
==
==================
c153217b;Jakob de Maeyer;2015-07-17 16:11:53 +0200;Fix RedirectMiddleware test

==

tests/test_downloadermiddleware_redirect.py
==================
198be7d6;Andrew Murray;2015-07-16 23:59:02 +1000;Fixed typos

==

docs/news.rst
==================
c908d316;Jakob de Maeyer;2015-07-16 12:50:26 +0200;Make RedirectMiddleware respect Spider.handle_httpstatus_list

==

docs/topics/downloader-middleware.rst
scrapy/downloadermiddlewares/redirect.py
tests/test_downloadermiddleware_redirect.py
==================
4f56c6c7;nyov;2015-07-11 11:27:33 +0000;Unset environment proxies for tests
because urllib doesn't handle $no_proxy correctly
and the unittest webserver is always local.

==

tests/__init__.py
==================
d706310d;Julia Medina;2015-07-11 08:06:20 -0300;Merge pull request #1151 from marven/cache-control
[MRG+1] RFC2616 policy enhancements + tests
==
==================
320d3a59;Julia Medina;2015-07-10 19:15:14 -0300;Add oldest supported tox version to contributing docs
Better fix for #1337

==

docs/contributing.rst
==================
439b376d;Julia Medina;2015-07-10 19:06:23 -0300;Note in install docs about pip being already included in python>=2.7.9

==

docs/intro/install.rst
==================
5723e6b4;Julia Medina;2015-07-10 18:52:01 -0300;Add non-python dependencies to Ubuntu install section in the docs
Closes #1314 and closes #1198.

==

docs/intro/install.rst
==================
290ebee0;Julia Medina;2015-07-10 17:14:50 -0300;Add OS X installation section to docs
Closes #1342 and (possibly) #1126

==

docs/intro/install.rst
==================
6ac971eb;Julia Medina;2015-07-10 20:08:25 -0300;Merge pull request #1351 from scrapy/fix-regression-in-mock
Fix a recent mock regression by not using it in a test
==
==================
d3d61fde;Julia Medina;2015-07-10 19:58:38 -0300;Fix a recent mock regression by not using it in a test

==

tests/test_settings/__init__.py
==================
306b028a;Julia Medina;2015-07-09 23:17:53 -0300;Merge pull request #1348 from nzp/tutorial-ref-fix
Fix reference in tutorial.
==
==================
7bef61db;Nikola Pavlović;2015-07-10 02:35:27 +0200;Fix reference.

==

docs/intro/tutorial.rst
==================
d438075a;Jakob de Maeyer;2015-07-03 16:51:53 +0200;Make Sphinx autodoc use local, not system-wide Scrapy

==

docs/conf.py
==================
8b3ca4f2;Julia Medina;2015-07-03 00:56:32 -0300;Merge pull request #1302 from eliasdorneles/improving-access-settings-docs
[MRG+1] Improvements for docs on how to access settings
==
==================
2a7dc31f;Daniel Graña;2015-07-02 15:20:47 -0300;Merge pull request #1333 from demelziraptor/x-json-response
interpreting application/x-json as TextResponse
==
==================
9a15fcf8;Demelziraptor;2015-07-02 19:51:49 +0200;interpreting application/x-json as TextResponse

==

scrapy/responsetypes.py
tests/test_responsetypes.py
==================
3fc4e0b3;Daniel Graña;2015-07-02 13:50:55 -0300;Merge pull request #1282 from otherchirps/memusage-check-interval
[MRG+1] Added MEMUSAGE_CHECK_INTERVAL_SECONDS to Memory usage extension options.
==
==================
6fa3f242;Daniel Graña;2015-07-01 01:49:05 -0300;Add 1.0.1 release notes

==

docs/news.rst
==================
07f4f12e;Daniel Graña;2015-06-30 19:58:16 -0300;Merge pull request #1313 from eliasdorneles/support-empty-passwd-for-http-proxy
[MRG+1] Support empty password for http_proxy config
==
==================
98707e15;Daniel Graña;2015-06-26 22:26:06 -0300;Merge pull request #1324 from scrapy/autothrottle
Autothrottle enhancements
==
==================
d850238c;Mikhail Korobov;2015-06-27 04:59:42 +0500;add AUTOTHROTTLE_TARGET_CONCURRENCY option and expand AutoThrottle docs

==

docs/topics/autothrottle.rst
docs/topics/settings.rst
scrapy/extensions/throttle.py
scrapy/settings/default_settings.py
==================
63317531;Mikhail Korobov;2015-06-26 20:47:58 +0500;DOC fix authrottle docs
see https://github.com/scrapy/scrapy/pull/502/files#r8574692

==

docs/topics/autothrottle.rst
==================
1fef9f11;Mikhail Korobov;2015-06-26 19:09:26 +0500;AutoThrottle: respect download_delay=0 spider attribute

==

scrapy/extensions/throttle.py
==================
17cb5131;Mikhail Korobov;2015-06-26 19:07:54 +0500;drop support for AUTOTHROTTLE_MIN_DOWNLOAD_DELAY
it was deprecated for years

==

scrapy/extensions/throttle.py
==================
584252e8;Mikhail Korobov;2015-06-26 18:58:29 +0500;move AutoThrottle default options to default_settings.py

==

scrapy/extensions/throttle.py
scrapy/settings/default_settings.py
==================
e6272e52;Mikhail Korobov;2015-06-26 18:44:23 +0500;make AutoThrottle._adjust_delay easier to understand

==

scrapy/extensions/throttle.py
==================
7c988559;Daniel Graña;2015-06-26 00:32:02 -0300;Merge pull request #1321 from yarikoptic/upstream-master
ENH: include tests/ to source distribution in MANIFEST.in
==
==================
5bcda9b7;Daniel Graña;2015-06-26 00:21:23 -0300;Merge pull request #1290 from scrapy/crawler-runner-cleanup
extract CrawlerRunner._crawl method which always expects Crawler
==
==================
5207d440;Yaroslav Halchenko;2015-06-25 23:00:00 -0400;ENH: include tests/ to source distribution in MANIFEST.in

==

MANIFEST.in
==================
148fb140;Daniel Graña;2015-06-25 23:35:42 -0300;Merge pull request #1319 from yarikoptic/fix-fail-if-docsbuild-fails
[MRG+1] BF: fail if docs failed to build
==
==================
5f3e1e9a;Yaroslav Halchenko;2015-06-25 21:30:35 -0400;ENH: make explicit build-ignore-errors to be used by linkfix

==

docs/Makefile
==================
2e55e65e;Mikhail Korobov;2015-06-25 23:20:46 +0500;Merge pull request #1320 from barraponto/patch-2
Fix SelectJmes documentation
==
==================
4cea1c12;Capi Etheriel;2015-06-25 15:11:56 -0300;Fix SelectJmes documentation

==

scrapy/loader/processors.py
==================
48582be9;Yaroslav Halchenko;2015-06-25 10:46:22 -0400;DOC(ENH): specify path to rtd theme explicitly

==

docs/conf.py
==================
49fe9157;Yaroslav Halchenko;2015-06-25 10:12:56 -0400;BF: fail if docs failed to build

==

docs/Makefile
==================
8a140b6b;Pablo Hoffman;2015-06-24 16:25:13 -0300;Merge pull request #1315 from scrapy/downloader-slots-cleanup
Small downloader slots cleanup
==
==================
ea4b175c;Mikhail Korobov;2015-06-24 18:04:45 +0500;Merge pull request #1254 from scrapy/bugfix-1232
[MRG +1] Unquote request path before passing to FTPClient, it already escape paths
==
==================
08501bff;Mikhail Korobov;2015-06-24 17:38:12 +0500;Merge pull request #1316 from dallagi/patch-1
DOC Bring Ubuntu and Archlinux outside of Windows subsection
==
==================
44c8ef2d;Marco DallaG;2015-06-24 11:44:48 +0200;DOC Bring Ubuntu and Archlinux outside of Windows subsection
In the installation guide, in the "Platform specific installation notes" section, Ubuntu and ArchLinux are currently subsections of Windows, which does not make sense imho.
This commit changes the section tree from:

Platform specific installation notes
- Windows
  -- Archlinux
  -- Ubuntu

To:

Platform specific installation notes
- Windows
- Ubuntu
- Archlinux
==

docs/intro/install.rst
==================
cb0445e8;Mikhail Korobov;2015-06-24 03:22:23 +0500;Slot.__str__ and __repr__ methods; remove unused import

==

scrapy/core/downloader/__init__.py
==================
8da9836d;Mikhail Korobov;2015-06-24 03:20:46 +0500;don't access settings from downloader.Slot

==

scrapy/core/downloader/__init__.py
==================
eb8fed4e;Elias Dorneles;2015-06-23 00:43:15 -0300;support empty password for http_proxy config

==

scrapy/downloadermiddlewares/httpproxy.py
tests/test_downloadermiddleware_httpproxy.py
==================
38e5bfb6;Pablo Hoffman;2015-06-22 10:57:24 -0300;remove version suffix from ubuntu package

==

docs/topics/ubuntu.rst
==================
af97c373;Julia Medina;2015-06-19 18:49:13 -0300;Update release date for 1.0
(cherry picked from commit c89fa29c415f669fd42ad4bae88e754ed0194a4f)

==

docs/news.rst
==================
f4dd8bcd;Νικόλαος-Διγενής Καραγιάννης;2015-06-16 17:31:37 +0300;Disable dupefilter in shell

==

scrapy/commands/shell.py
==================
47b1b748;Daniel Graña;2015-06-15 20:51:37 -0300;Generated version as pep440 and dpkg compatible

==

Makefile.buildbot
debian/control
==================
ec56ed58;Daniel Graña;2015-06-15 18:02:14 -0300;Merge pull request #1307 from agusc/master
removed SUFFIX from scrapy package name
==
==================
140f5825;agusc;2015-06-15 14:39:10 -0300;removed SUFFIX from scrapy name package

==

Makefile.buildbot
debian/changelog
debian/control
extras/makedeb.py
==================
2de5c660;Elias Dorneles;2015-06-14 12:39:29 -0300;improvements for docs on how to access settings

==

docs/Makefile
docs/topics/settings.rst
==================
f958fb9d;Julia Medina;2015-06-12 16:39:02 -0300;Update release notes for 1.0.0rc3

==

docs/news.rst
==================
fa1c25c8;Julia Medina;2015-06-12 13:22:42 -0300;Merge pull request #1286 from scrapy/configure_logging
configure_logging: change the meaning of settings=None
==
==================
36bc912c;Julia Medina;2015-06-12 12:56:57 -0300;DOC indent additional docs for configure_logging

==

docs/topics/logging.rst
==================
d862f5ac;Daniel Graña;2015-06-12 11:16:16 -0300;Merge pull request #1297 from darkrho/leveldb-compact
Do leveldb compactation for httpcache on closing.
==
==================
aaaba9f3;Mikhail Korobov;2015-06-12 16:02:53 +0500;Merge pull request #1298 from bcrowe/fix-typos
Fix a couple typos
==
==================
6a4c475e;Bryan Crowe;2015-06-11 19:47:30 -0400;Fix a couple typos

==

docs/topics/selectors.rst
==================
877c2579;Rolando Espinoza;2015-06-11 13:27:49 -0400;Do leveldb compactation for the httpcache on closing.

==

scrapy/extensions/httpcache.py
==================
5bd0395b;Daniel Graña;2015-06-10 16:28:35 -0300;Merge pull request #1291 from scrapy/signalmanager-docstrings
DOC SignalManager docstrings. See GH-713.
==
==================
64466526;Daniel Graña;2015-06-10 16:07:21 -0300;Merge pull request #1294 from berkerpeksag/ignore-warnings
Ignore ScrapyDeprecationWarning warnings properly.
==
==================
6c9daf3a;Mikhail Korobov;2015-06-10 01:44:19 +0500;DOC remove unnecessary links; fix references in send_catch_log_deferred docstring

==

docs/topics/api.rst
scrapy/signalmanager.py
==================
a611f8dd;Mikhail Korobov;2015-06-09 22:57:18 +0500;DOC remove FailureFormatter mentions, stop copy-pasting configure_logging docstring

==

docs/topics/logging.rst
scrapy/utils/log.py
==================
8a48d9c6;Berker Peksag;2015-06-09 04:48:33 +0300;Ignore ScrapyDeprecationWarning warnings properly.
Conflicts:

	tests/test_utils_deprecate.py

==

scrapy/linkextractors/sgml.py
tests/test_selector.py
tests/test_utils_deprecate.py
==================
90aa5c07;Daniel Graña;2015-06-09 11:21:24 -0300;Merge pull request #1284 from scrapy/crawler-cleanup
CrawlerProcess cleanup
==
==================
f91461c2;Julia Medina;2015-06-09 11:19:10 -0300;Merge pull request #1292 from scrapy/spidererror-docs
spider_error doesn't support deferreds
==
==================
9ca87c5b;Julia Medina;2015-06-09 11:08:10 -0300;Merge pull request #1293 from berkerpeksag/fix-typos
Fix typos in scrapy/commands/setting.py
==
==================
66e5591e;Berker Peksag;2015-06-09 04:26:42 +0300;Fix typos in scrapy/commands/setting.py
* intepreted -> interpreted
* "a list" instead of "an float" in --getlist help
* "an float"-> "a float"

Also, backslashes were redundant. So I removed them.

==

scrapy/commands/settings.py
==================
790c67b6;Mikhail Korobov;2015-06-09 02:20:10 +0500;DOC spider_error doesn't support deferreds

==

docs/topics/signals.rst
==================
1740fcf1;Mikhail Korobov;2015-06-08 21:05:58 +0500;DOC SignalManager docstrings. See GH-713.
This change is not 100% backwards compatible because of *args changes.
Their usage was not documented, so we're not breaking public interface.

==

docs/topics/api.rst
scrapy/signalmanager.py
==================
9a787893;Mikhail Korobov;2015-06-06 04:05:54 +0500;(backwards-incompatible) allow to pass settings=None to configure_logging
* use explicit argument for disabling root handler;
* handle LOG_STDOUT even if install_root_handler is False

==

docs/topics/logging.rst
docs/topics/practices.rst
scrapy/utils/log.py
==================
3cbf8a0b;Mikhail Korobov;2015-06-08 18:35:44 +0500;extract CrawlerRunner._crawl method which always expects Crawler
It provides an extension point where crawler instance is available;
it should make it easier to write alternative CrawlerRunner.crawl
implementations.

See also: https://github.com/scrapy/scrapy/pull/1256

==

scrapy/crawler.py
==================
e575f444;Pawel Miech;2015-06-08 10:52:42 +0200;[settings/default_settings.py] dont retry 400
As in HTTP specs:

"10.4.1 400 Bad Request

The request could not be understood by the server due to malformed
syntax. The client SHOULD NOT repeat the request without
modifications."

Scrapy should not retry 400 by default.

==

scrapy/settings/default_settings.py
==================
87293965;Daniel Graña;2015-06-07 20:29:24 -0300;Merge pull request #1285 from scrapy/optional-settings-arguments
make it easier to use default settings
==
==================
61dec83f;Chris Nilsson;2015-06-06 11:19:29 +1000;Moved default value of MEMUSAGE_CHECK_INTERVAL_SECONDS to default_settings

==

scrapy/extensions/memusage.py
scrapy/settings/default_settings.py
==================
0c532baf;Chris Nilsson;2015-06-06 11:18:13 +1000;Removed typo, and clarified time unit of setting

==

docs/topics/settings.rst
==================
d047665c;Mikhail Korobov;2015-06-06 03:23:13 +0500;make "settings" argument optional for Crawler, CrawlerRunner and CrawlerProcess

==

docs/topics/practices.rst
scrapy/crawler.py
tests/test_crawler.py
==================
64399d18;Mikhail Korobov;2015-06-06 02:53:36 +0500;Stop reactor on Ctrl-C regardless of 'stop_after_crawl'. Fixes GH-1279.

==

scrapy/crawler.py
==================
33d145e2;Mikhail Korobov;2015-06-06 02:49:39 +0500;CrawlerProcess cleanup
* remove unneeded lambda;
* extract _get_dns_resolver method and format code to pep8.

==

scrapy/crawler.py
==================
24d8a852;Julia Medina;2015-06-05 17:10:18 -0300;Update release notes for 1.0.0rc2
(cherry picked from commit 6e61d54168cf471363be3e7e54d75ad544b9f6e1)

==

docs/news.rst
==================
eae25a04;Chris Nilsson;2015-06-06 00:39:14 +1000;Added MEMUSAGE_CHECK_INTERVAL_SECONDS to Memory usage extension options.
Kept the default as it was, at 60.0 seconds. But added a setting to
allow this to be changed as desired.

==

docs/topics/extensions.rst
docs/topics/settings.rst
scrapy/extensions/memusage.py
==================
d9bcd486;Daniel Graña;2015-06-04 13:39:01 -0300;Merge pull request #1278 from Curita/remove-tz-aware-logformat
Remove deprecated %z formatting from the default LOG_DATEFORMAT
==
==================
367ea81e;Julia Medina;2015-06-04 03:51:48 +0800;Remove deprecated %z formatting from the default LOG_DATEFORMAT

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
f312ffcb;Mikhail Korobov;2015-06-03 22:14:04 +0500;Merge pull request #1276 from scrapy/fix-spider-settings
Fix Spider.custom_settings
==
==================
d42c420a;Mikhail Korobov;2015-06-03 04:29:10 +0500;fixed spider custom_settings
https://github.com/scrapy/scrapy/pull/1128 moved spidercls.update_settings
call to a later stage; this commit moves it back.

==

scrapy/crawler.py
==================
cc2f3e1b;Mikhail Korobov;2015-06-03 04:26:20 +0500;TST a test case to show custom_settings doesn't always work

==

tests/test_crawler.py
==================
d52cf8bb;Daniel Graña;2015-06-01 20:31:46 -0300;Merge pull request #1267 from Curita/fix-1265
Fix #1265
==
==================
ffc7b7fd;Julia Medina;2015-05-29 15:04:29 -0300;Add helper to update deprecated class paths

==

scrapy/utils/conf.py
scrapy/utils/deprecate.py
tests/test_utils_conf.py
tests/test_utils_deprecate.py
==================
bd2fe996;Ally Weir;2015-06-01 16:42:51 +0100;Spelling correction
incorrect use of "too" instead of "to"

==

docs/faq.rst
==================
9d1cf230;Julia Medina;2015-06-01 12:35:54 -0300;Merge pull request #1268 from scrapy/crawlerprocess-dict-settings
fixed CrawlerProcess when settings are passed as dicts
==
==================
8771d1f7;Marven Sanchez;2015-06-01 18:20:59 +0800;Update HTTPCache middleware docs

==

docs/topics/downloader-middleware.rst
==================
bb3ebf13;Marven Sanchez;2015-06-01 18:20:12 +0800;Add tests for RFC2616 policy enhancements Add `scrapy/downloadermiddlewares/httpcache.py` to `tests/py3-ignores.txt

==

tests/py3-ignores.txt
tests/test_downloadermiddleware_httpcache.py
==================
19915504;Jamey Sharp;2014-12-29 14:06:04 -0800;Allow client to bound max-age for revalidation.
Unlike specifying "Cache-Control: no-cache", if the request specifies
"max-age=0", then the cached validators will be used if possible to
avoid re-fetching unchanged pages.

That said, it's still useful to be able to specify "no-cache" on the
request, in cases where the origin server may have changed page contents
without changing validators.

==

scrapy/extensions/httpcache.py
==================
c3b2cabf;Jamey Sharp;2014-12-28 20:04:36 -0800;Allow setting RFC2616Policy to cache unconditionally.
A spider may wish to have all responses available in the cache, for
future use with "Cache-Control: max-stale", for instance. The
DummyPolicy caches all responses but never revalidates them, and
sometimes a more nuanced policy is desirable.

This setting still respects "Cache-Control: no-store" directives in
responses. If you don't want that, filter "no-store" out of the
Cache-Control headers in responses you feed to the cache middleware.

==

scrapy/extensions/httpcache.py
scrapy/settings/default_settings.py
==================
e23a3813;Jamey Sharp;2014-12-28 19:43:16 -0800;Let spiders ignore bogus Cache-Control headers.
Sites often set "no-store", "no-cache", "must-revalidate", etc., but get
upset at the traffic a spider can generate if it respects those
directives.

Allow the spider's author to selectively ignore Cache-Control directives
that are known to be unimportant for the sites being crawled.

We assume that the spider will not issue Cache-Control directives in
requests unless it actually needs them, so directives in requests are
not filtered.

==

scrapy/extensions/httpcache.py
scrapy/settings/default_settings.py
==================
dd3a4629;Jamey Sharp;2014-12-28 19:21:45 -0800;Support "Cache-Control: max-stale" in requests.
This allows spiders to be configured with the full RFC2616 cache policy,
but avoid revalidation on a request-by-request basis, while remaining
conformant with the HTTP spec.

==

scrapy/extensions/httpcache.py
==================
4446baae;Jamey Sharp;2014-12-28 19:16:31 -0800;Use cached responses if revalidation errors out.

==

scrapy/downloadermiddlewares/httpcache.py
scrapy/extensions/httpcache.py
==================
aa6a7270;Mikhail Korobov;2015-05-30 06:59:15 +0500;fixed CrawlerProcess when settings are passed as dicts
See https://github.com/scrapy/scrapy/pull/1156

==

scrapy/crawler.py
tests/test_crawler.py
==================
342cb622;Mikhail Korobov;2015-05-27 23:04:58 +0500;DOC fix non-working link (by removing it).
See https://github.com/scrapy/scrapy/pull/1260

==

docs/topics/media-pipeline.rst
==================
343d20d7;Julia Medina;2015-05-27 11:53:54 -0300;Update 1.0 release notes

==

docs/news.rst
==================
62a6eff2;Julia Medina;2015-05-27 11:42:19 -0300;Merge pull request #1259 from chekunkov/log-counter-handler-is-never-removed
[MRG +1] LogCounterHandler is never removed from root handlers list, fix that
==
==================
26f50d3f;Julia Medina;2015-05-27 09:17:18 -0300;Extend regex for tags that deploy to PyPI to support new release cycle

==

.travis.yml
==================
b2765aab;Alexander Chekunkov;2015-05-27 13:52:47 +0700;LogCounterHandler is never removed from root handlers list, fix that
lambda is garbage collected and because receiver is added as weak reference by default - when signals.engine_stopped is fired logging.root.removeHandler is not executed. Fixed that by assigning lambda to a private argument and not by using connect(..., weak=False) because I belive this lambda function should be collected with crawler object

==

scrapy/crawler.py
==================
5ee08865;Daniel Graña;2015-05-26 15:32:24 -0300;Merge pull request #1258 from chekunkov/crawler-process-stopping-is-no-more
[MRG+1] Remove CrawlerProcess.stopping as it isn't used any more
==
==================
b0ea3e38;Alexander Chekunkov;2015-05-26 17:37:16 +0700;remove CrawlerProcess.stopping as it isn't used any more

==

scrapy/crawler.py
==================
545c4224;Pablo Hoffman;2015-05-25 16:01:54 -0300;update old crawlera link

==

docs/topics/practices.rst
==================
ebe889a6;Daniel Graña;2015-05-23 20:50:30 -0300;Unquote request path before passing to FTPClient, it already escape paths

==

scrapy/core/downloader/handlers/ftp.py
tests/test_downloader_handlers.py
==================
35454683;Daniel Graña;2015-05-23 18:09:20 -0300;Merge branch 'deferdelay'

==
==================
d439c26d;Daniel Graña;2015-05-22 17:12:43 -0300;update docstring and release notes

==

docs/news.rst
scrapy/utils/defer.py
==================
27ce3225;Alexey Vishnevsky;2015-03-16 11:00:27 +0200;Makes scrapy more async by letting to reactor spend another couple of cycles to accomplish its needs.

==

scrapy/utils/defer.py
==================
4b2763c6;Julia Medina;2015-05-22 13:24:50 -0300;Bump version: 1.0.0rc1 → 1.1.0dev1

==

.bumpversion.cfg
scrapy/VERSION
==================
de6d232a;Julia Medina;2015-05-22 13:24:27 -0300;Bump version: 0.25.1 → 1.0.0rc1

==

.bumpversion.cfg
scrapy/VERSION
==================
29529e5e;Julia Medina;2015-05-22 13:21:17 -0300;Merge pull request #1244 from Curita/1.0-release-notes
1.0 release notes
==
==================
60016459;Julia Medina;2015-05-22 01:04:57 -0300;New release cycle in .bumpversion.cfg
1.0.0dev1 -> 1.0.0rc1 -> 1.0.0 -> 1.1.0dev1 -> ...

==

.bumpversion.cfg
==================
afcf70cd;Julia Medina;2015-05-18 23:00:57 -0300;Add 1.0 release notes

==

docs/news.rst
==================
cc2258b2;Mikhail Korobov;2015-05-21 22:03:54 +0500;Merge pull request #1145 from bosnj/master
[MRG+1] default return value for extract_first
==
==================
58717472;Daniel Graña;2015-05-21 10:46:39 -0300;Merge pull request #1250 from chekunkov/scrapy-log-fix-incompatible-change
[MRG+1] Keep level_names in scrapy.log for backwards compatibility
==
==================
795ca394;Alexander Chekunkov;2015-05-21 15:53:05 +0700;keep level_names in scrapy.log for backwards compatibility

==

scrapy/log.py
==================
ee591124;Daniel Graña;2015-05-19 16:36:05 -0300;Merge pull request #1224 from scrapy/fix-empty-feed-export-fields
[MRG] fixed FEED_EXPORT_FIELDS handling (see #1223)
==
==================
5beb9d25;Daniel Graña;2015-05-19 12:20:51 -0300;Merge pull request #1243 from scrapy/remove-contrib-from-py3-ignores
remove unnecessary lines from py3-ignores
==
==================
7a5b5ec4;Mikhail Korobov;2015-05-19 00:57:39 +0500;TST remove unnecessary lines from py3-ignores
scrapy/contrib is already skipped - see https://github.com/scrapy/scrapy/pull/1165

==

tests/py3-ignores.txt
==================
21b17734;Mikhail Korobov;2015-05-19 00:10:30 +0500;Merge pull request #1242 from Curita/exporters-single-module
Move exporters/__init__.py to exporters.py
==
==================
044f31cb;Julia Medina;2015-05-18 14:54:11 -0300;Merge pull request #1240 from scrapy/fix-feedexport-logging
MRG+1 fixed FeedExporter shutdown log messages
==
==================
af0c8f82;Julia Medina;2015-05-18 14:46:23 -0300;Move exporters/__init__.py to exporters.py

==

scrapy/exporters.py
==================
60e79db3;Mikhail Korobov;2015-05-18 19:28:37 +0500;fixed FeedExporter shutdown log messages

==

scrapy/extensions/feedexport.py
==================
9b0ca1b7;Mikhail Korobov;2015-05-18 17:13:25 +0500;drop support for FEED_EXPORT_FIELD=[] meaning "no fields"

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
9fb31833;Mikhail Korobov;2015-05-13 00:33:48 +0500;support FEED_EXPORT_FIELDS=[]

==

docs/topics/feed-exports.rst
scrapy/extensions/feedexport.py
tests/test_feedexport.py
==================
c4120348;Mikhail Korobov;2015-05-12 18:45:08 +0500;Fix GH-1223

==

scrapy/extensions/feedexport.py
==================
e1efd191;Mikhail Korobov;2015-05-12 18:44:23 +0500;TST, DOC document that Scrapy only infers field names for CSV

==

docs/topics/feed-exports.rst
tests/test_feedexport.py
==================
8d9e3b7e;Mikhail Korobov;2015-05-12 18:27:57 +0500;TST add a test for JSON lines item exporter

==

tests/test_feedexport.py
==================
3a4d57b3;Daniel Graña;2015-05-15 15:00:36 -0300;Merge pull request #1236 from Curita/fix-failure-tracebacks
Replace FailureFormatter with direct failure to exc_info conversions in log calls
==
==================
e7574a80;Julia Medina;2015-05-15 14:51:14 -0300;Use method to get traceback of failures in failure_to_exc_info

==

scrapy/utils/log.py
==================
6dccb3a9;Julia Medina;2015-05-15 04:56:09 -0300;Replace FailureFormatter with direct exc_info conversions in log calls

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/downloadermiddlewares/robotstxt.py
scrapy/extensions/feedexport.py
scrapy/log.py
scrapy/pipelines/files.py
scrapy/pipelines/media.py
scrapy/utils/log.py
scrapy/utils/signal.py
tests/test_pipeline_media.py
tests/test_utils_log.py
==================
2d216771;Daniel Graña;2015-05-15 01:44:45 -0300;Merge pull request #1235 from Curita/remove-log-exception-calls
Replace logger.exception calls to logger.error for Python compatibility
==
==================
157cec7f;Julia Medina;2015-05-15 00:56:47 -0300;Replace logger.exception calls for Python compatibility

==

scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/pipelines/files.py
scrapy/utils/signal.py
tests/test_utils_log.py
==================
faba9bb0;Daniel Graña;2015-05-14 23:19:47 -0300;Merge pull request #1206 from Curita/clean-test-collection
Fix remaining warnings from pytest while collecting tests
==
==================
5e5e44e9;Daniel Graña;2015-05-14 23:09:24 -0300;Merge pull request #1228 from nramirezuy/item_fields_defined_on_fields
item fields defined on fields class attribute fix
==
==================
fc1aaeb7;Daniel Graña;2015-05-14 23:02:49 -0300;Merge pull request #1234 from Curita/add-docs-build-to-travis
Add docs build to travis
==
==================
cbebcbdd;Julia Medina;2015-05-14 20:42:34 -0300;Add docs toxenv to .travis.yml

==

.travis.yml
==================
ec549429;Julia Medina;2015-05-14 20:41:55 -0300;Create separate testenvs to build docs and check links

==

tox.ini
==================
a5557780;Julia Medina;2015-05-14 20:40:12 -0300;Build docs in a temporary folder to avoid caching

==

tox.ini
==================
564aca11;Mikhail Korobov;2015-05-15 04:31:39 +0500;Merge pull request #1233 from Curita/docs-fix
Fix in docs for error introduced in #1218
==
==================
7c61bd89;Julia Medina;2015-05-14 20:09:19 -0300;Fix in docs for error introduced in #1218

==

docs/topics/link-extractors.rst
==================
1195f906;Daniel Graña;2015-05-14 18:28:17 -0300;Merge pull request #1218 from Curita/move-base-to-packages
Move base classes to their packages
==
==================
773ea5a5;nramirezuy;2015-05-13 13:27:42 -0300;item fields defined on fields class attribute fix

==

scrapy/item.py
tests/test_item.py
==================
65aa9ccc;Pablo Hoffman;2015-05-13 14:43:19 -0300;Merge pull request #1220 from eliasdorneles/building-settingslist-from-docs
Building settings list from docs
==
==================
6884b73e;Elias Dorneles;2015-05-11 22:11:30 -0300;sort settings list by name and wrap it in a bullet list

==

docs/_ext/scrapydocs.py
==================
5753e498;Elias Dorneles;2015-05-09 16:15:06 -0300;fixes referencing, and list only settings not documented in current document

==

docs/_ext/scrapydocs.py
docs/topics/settings.rst
==================
e521740b;Mikhail Korobov;2015-05-09 13:55:22 +0500;Merge pull request #1219 from Curita/fix-sphinx-warnings
Fix Sphinx warnings
==
==================
42c2c4b6;Julia Medina;2015-05-09 05:23:12 -0300;Wrong topic link in docs/intro/overview.rst

==

docs/intro/overview.rst
==================
c271d8f0;Julia Medina;2015-05-09 05:20:54 -0300;Title underline too short in docs/topics/selectors.rst

==

docs/topics/selectors.rst
==================
6fd7d854;Julia Medina;2015-05-09 05:19:15 -0300;Wrong bullet list indentation in docs/topics/media-pipeline.rst

==

docs/topics/media-pipeline.rst
==================
acc13c98;Julia Medina;2015-05-09 05:15:17 -0300;Delete tab used as indentation in docs/topics/loaders.rst

==

docs/topics/loaders.rst
==================
819a8ece;Julia Medina;2015-05-09 05:12:35 -0300;Mark as orphan the doc topics not listed in the index

==

docs/topics/djangoitem.rst
docs/topics/scrapyd.rst
==================
53fdaa3f;Julia Medina;2015-05-09 04:21:50 -0300;scrapy/spider.py shim

==

conftest.py
scrapy/spider.py
==================
d3f576a8;Julia Medina;2015-05-09 04:20:09 -0300;Move scrapy/spider.py to scrapy/spiders/__init__.py

==

docs/intro/tutorial.rst
docs/topics/api.rst
docs/topics/downloader-middleware.rst
docs/topics/item-pipeline.rst
docs/topics/leaks.rst
docs/topics/logging.rst
docs/topics/request-response.rst
docs/topics/settings.rst
docs/topics/shell.rst
docs/topics/signals.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
extras/qpsclient.py
scrapy/__init__.py
scrapy/crawler.py
scrapy/shell.py
scrapy/spiders/__init__.py
scrapy/spiders/crawl.py
scrapy/spiders/feed.py
scrapy/spiders/init.py
scrapy/spiders/sitemap.py
scrapy/utils/spider.py
scrapy/utils/test.py
tests/spiders.py
tests/test_commands.py
tests/test_contracts.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware.py
tests/test_downloadermiddleware_ajaxcrawlable.py
tests/test_downloadermiddleware_cookies.py
tests/test_downloadermiddleware_decompression.py
tests/test_downloadermiddleware_defaultheaders.py
tests/test_downloadermiddleware_downloadtimeout.py
tests/test_downloadermiddleware_httpauth.py
tests/test_downloadermiddleware_httpcache.py
tests/test_downloadermiddleware_httpcompression.py
tests/test_downloadermiddleware_httpproxy.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_retry.py
tests/test_downloadermiddleware_stats.py
tests/test_downloadermiddleware_useragent.py
tests/test_engine.py
tests/test_logformatter.py
tests/test_pipeline_media.py
tests/test_spider.py
tests/test_spiderloader/__init__.py
tests/test_spiderloader/test_spiders/spider0.py
tests/test_spiderloader/test_spiders/spider1.py
tests/test_spiderloader/test_spiders/spider2.py
tests/test_spiderloader/test_spiders/spider3.py
tests/test_spidermiddleware_depth.py
tests/test_spidermiddleware_httperror.py
tests/test_spidermiddleware_offsite.py
tests/test_spidermiddleware_referer.py
tests/test_spidermiddleware_urllength.py
tests/test_spiderstate.py
tests/test_stats.py
tests/test_toplevel.py
tests/test_utils_reqser.py
tests/test_utils_url.py
==================
d4926091;Julia Medina;2015-05-09 03:32:01 -0300;Delete scrapy/spiders/__init__.py

==

scrapy/spiders/__init__.py
==================
32945242;Julia Medina;2015-04-28 15:44:22 -0300;scrapy/linkextractor.py shim

==

conftest.py
scrapy/linkextractor.py
==================
d7253668;Julia Medina;2015-04-28 15:42:59 -0300;Move scrapy/linkextractor.py to scrapy/linkextractors/__init__.py

==

docs/topics/link-extractors.rst
scrapy/linkextractors/__init__.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/sgml.py
==================
896b6dd4;Julia Medina;2015-05-09 03:23:24 -0300;Delete scrapy/linkextractors/__init__.py

==

scrapy/linkextractors/__init__.py
==================
cfd40ed5;Julia Medina;2015-04-28 15:28:58 -0300;scrapy/command.py shim

==

conftest.py
scrapy/command.py
==================
616aec92;Julia Medina;2015-04-28 15:26:58 -0300;Move scrapy/command.py to scrapy/commands/__init__.py

==

scrapy/cmdline.py
scrapy/commands/__init__.py
scrapy/commands/bench.py
scrapy/commands/check.py
scrapy/commands/crawl.py
scrapy/commands/edit.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/parse.py
scrapy/commands/runspider.py
scrapy/commands/settings.py
scrapy/commands/shell.py
scrapy/commands/startproject.py
scrapy/commands/version.py
scrapy/commands/view.py
==================
ce735fee;Julia Medina;2015-05-09 03:12:35 -0300;Delete scrapy/commands/__init__.py

==

scrapy/commands/__init__.py
==================
9576fb57;Daniel Graña;2015-05-06 02:40:39 -0300;Merge pull request #1205 from Curita/htmlparser-deprecation
[MRG+1] Deprecate htmlparser link extractor
==
==================
de9b2348;Julia Medina;2015-05-05 14:33:08 -0300;Merge pull request #1210 from scrapy/relocations-fix
fixed backwards compatibility for scrapy.contrib.exporter.PythonItemExporter
==
==================
3fb58a30;Mikhail Korobov;2015-05-05 22:06:18 +0500;fixed backwards compatibility for scrapy.contrib.exporter.PythonItemExporter

==

scrapy/contrib/exporter/__init__.py
==================
a4785954;Julia Medina;2015-05-04 18:10:04 -0300;Don't collect tests by their class name

==

pytest.ini
==================
4d0d04a9;Julia Medina;2015-05-04 17:48:24 -0300;Merge pull request #1165 from scrapy/dont-collect-deprecated
TST don't collect tests from deprecated modules.
==
==================
5e59f795;Julia Medina;2015-05-04 17:11:30 -0300;Increase stacklevel in deprecation warnings from linkextractors

==

scrapy/linkextractors/htmlparser.py
scrapy/linkextractors/sgml.py
==================
389f6e95;Julia Medina;2015-05-04 17:11:05 -0300;Add deprecation warning to HtmlParserLinkExtractor

==

scrapy/linkextractors/htmlparser.py
==================
8ae05478;bosnj;2015-05-04 21:22:17 +0200;added docs and test case, fixed handling empty string vs None

==

docs/topics/selectors.rst
scrapy/selector/unified.py
tests/test_selector.py
==================
d1053d2a;Elias Dorneles;2015-05-03 18:59:17 -0300;automatic settings list for docs [WIP]

==

docs/_ext/scrapydocs.py
docs/topics/settings.rst
==================
8301d00f;Mikhail Korobov;2015-04-16 18:20:50 +0500;TST don't collect tests from deprecated modules.
This removes some deprecation warnings in tests.

==

conftest.py
==================
d00e43f3;Pablo Hoffman;2015-05-01 05:24:49 -0300;restore wrongly commented line in sphinx conf.py

==

docs/conf.py
==================
b84b3585;Pablo Hoffman;2015-05-01 01:53:51 -0300;remove empty experimental section from doc

==

docs/experimental/index.rst
docs/index.rst
==================
a5a8f82b;Pablo Hoffman;2015-05-01 01:51:56 -0300;move documentation about registering commands via setup.py to commands doc

==

docs/conf.py
docs/experimental/index.rst
docs/topics/commands.rst
==================
9ee17fd5;Pablo Hoffman;2015-05-01 01:39:03 -0300;add note to doc README about using 'make watch'

==

docs/README
==================
4d43b25a;Pablo Hoffman;2015-04-30 23:39:36 -0300;Merge pull request #1197 from torymur/master
Test for robotstxt error
==
==================
667864ae;Victoria Terenina (torymur);2015-04-30 16:28:57 +0300;testing robotstxt error

==

tests/test_downloadermiddleware_robotstxt.py
==================
5b884d1b;Julia Medina;2015-04-29 23:27:18 -0300;Merge pull request #1190 from Curita/crawlerprocess-docs
CrawlerProcess documentation
==
==================
c1634e49;Julia Medina;2015-04-26 18:20:23 -0300;Add CrawlerProcess to "Running multiple spiders[...]" doc section

==

docs/topics/practices.rst
==================
d6a06a76;Julia Medina;2015-04-26 18:04:15 -0300;Add CrawlerProcess to "Run Scrapy from a script" doc section

==

docs/topics/practices.rst
==================
3a71504d;Julia Medina;2015-04-24 18:30:00 -0300;Extend CrawlerProcess documentation

==

docs/topics/api.rst
scrapy/crawler.py
==================
8f276b8e;Julia Medina;2015-04-24 18:28:48 -0300;Property for CrawlerRunner.crawlers so it can be autodocumented with Sphinx

==

scrapy/crawler.py
==================
a2ce78db;Julia Medina;2015-04-24 18:26:49 -0300;Use autoclass for CrawlerRunner in docs/topics/api.rst

==

docs/topics/api.rst
scrapy/crawler.py
==================
353672d2;Julia Medina;2015-04-24 18:25:47 -0300;Add autodocs Sphinx extension

==

docs/conf.py
==================
3243a13b;Julia Medina;2015-04-29 23:04:34 -0300;Allow configure_logging to accept dicts as Settings objects

==

scrapy/utils/log.py
==================
5155162e;Julia Medina;2015-04-29 22:34:31 -0300;Merge pull request #1181 from Curita/module-relocation
Module relocation
==
==================
62191de6;Julia Medina;2015-04-23 13:10:15 -0300;scrapy/statscol.py shim

==

scrapy/statscol.py
==================
b827097c;Julia Medina;2015-04-23 13:07:48 -0300;Rename scrapy/statscol.py to scrapy/statscollectors.py

==

docs/topics/api.rst
docs/topics/settings.rst
docs/topics/stats.rst
scrapy/settings/default_settings.py
scrapy/statscollectors.py
tests/test_spidermiddleware_depth.py
tests/test_stats.py
==================
4ddf152b;Julia Medina;2015-04-23 11:58:46 -0300;scrapy/dupefilter.py shim

==

scrapy/dupefilter.py
==================
9a3e3ba5;Julia Medina;2015-04-21 13:48:28 -0300;Move scrapy/contrib remaining top-level files to scrapy/extensions

==

docs/topics/downloader-middleware.rst
docs/topics/extensions.rst
docs/topics/feed-exports.rst
docs/topics/settings.rst
scrapy/downloadermiddlewares/httpcache.py
scrapy/extensions/__init__.py
scrapy/extensions/closespider.py
scrapy/extensions/corestats.py
scrapy/extensions/debug.py
scrapy/extensions/feedexport.py
scrapy/extensions/httpcache.py
scrapy/extensions/logstats.py
scrapy/extensions/memdebug.py
scrapy/extensions/memusage.py
scrapy/extensions/spiderstate.py
scrapy/extensions/statsmailer.py
scrapy/extensions/throttle.py
scrapy/settings/default_settings.py
scrapy/templates/project/module/settings.py.tmpl
tests/py3-ignores.txt
tests/test_downloadermiddleware_httpcache.py
tests/test_feedexport.py
tests/test_spiderstate.py
==================
54a4ce06;Julia Medina;2015-04-23 11:57:14 -0300;Rename scrapy/dupefilter.py to scrapy/dupefilters.py

==

docs/topics/settings.rst
scrapy/dupefilters.py
scrapy/settings/default_settings.py
tests/py3-ignores.txt
tests/test_dupefilters.py
==================
e262c5b8;Julia Medina;2015-04-21 13:26:53 -0300;scrapy/contrib/spiders shims

==

scrapy/contrib/spiders/__init__.py
scrapy/contrib/spiders/crawl.py
scrapy/contrib/spiders/feed.py
scrapy/contrib/spiders/init.py
scrapy/contrib/spiders/sitemap.py
==================
78dcd4e1;Julia Medina;2015-04-23 11:52:58 -0300;scrapy/squeue.py shim

==

scrapy/squeue.py
==================
fc346cba;Julia Medina;2015-04-21 13:20:08 -0300;Move scrapy/contrib/spiders to scrapy/spiders

==

docs/intro/tutorial.rst
docs/topics/commands.rst
docs/topics/downloader-middleware.rst
docs/topics/firebug.rst
docs/topics/link-extractors.rst
docs/topics/spiders.rst
scrapy/contrib/spiders/__init__.py
scrapy/spiders/__init__.py
scrapy/spiders/crawl.py
scrapy/spiders/feed.py
scrapy/spiders/init.py
scrapy/spiders/sitemap.py
scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
tests/test_spider.py
tests/test_utils_spider.py
==================
f5bdf64f;Julia Medina;2015-04-23 11:51:07 -0300;Rename scrapy/squeue.py to scrapy/squeues.py

==

docs/faq.rst
scrapy/settings/default_settings.py
scrapy/squeues.py
tests/test_squeues.py
==================
593b4ef5;Julia Medina;2015-04-23 11:46:56 -0300;scrapy/utils/decorator.py shim

==

scrapy/utils/decorator.py
==================
7a7c5391;Julia Medina;2015-04-23 11:44:49 -0300;Rename scrapy/utils/decorator.py to scrapy/utils/decorators.py

==

scrapy/core/downloader/handlers/file.py
scrapy/loader/__init__.py
scrapy/selector/unified.py
scrapy/utils/decorators.py
scrapy/utils/response.py
==================
645cdcbf;Julia Medina;2015-04-23 11:41:59 -0300;Rename scrapy/loader/processor.py to scrapy/loader/processors.py

==

docs/topics/loaders.rst
scrapy/contrib/loader/processor.py
scrapy/loader/__init__.py
scrapy/loader/processors.py
tests/test_loader.py
==================
fe4b260e;Julia Medina;2015-04-21 13:54:28 -0300;Top-level scrapy/contrib shims

==

scrapy/contrib/closespider.py
scrapy/contrib/corestats.py
scrapy/contrib/debug.py
scrapy/contrib/feedexport.py
scrapy/contrib/httpcache.py
scrapy/contrib/logstats.py
scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/contrib/spiderstate.py
scrapy/contrib/statsmailer.py
scrapy/contrib/throttle.py
==================
b2a15ddb;Julia Medina;2015-04-21 13:11:56 -0300;scrapy/contrib/spidermiddleware shims

==

scrapy/contrib/spidermiddleware/__init__.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/httperror.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/referer.py
scrapy/contrib/spidermiddleware/urllength.py
==================
180272c0;Julia Medina;2015-04-21 13:07:24 -0300;Move scrapy/contrib/spidermiddleware to scrapy/spidermiddlewares

==

docs/faq.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
scrapy/settings/default_settings.py
scrapy/spidermiddlewares/__init__.py
scrapy/spidermiddlewares/depth.py
scrapy/spidermiddlewares/httperror.py
scrapy/spidermiddlewares/offsite.py
scrapy/spidermiddlewares/referer.py
scrapy/spidermiddlewares/urllength.py
tests/test_spidermiddleware_depth.py
tests/test_spidermiddleware_httperror.py
tests/test_spidermiddleware_offsite.py
tests/test_spidermiddleware_referer.py
tests/test_spidermiddleware_urllength.py
==================
c97a69c9;Julia Medina;2015-04-20 23:47:30 -0300;scrapy/contrib/pipeline shims

==

scrapy/contrib/pipeline/__init__.py
scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/media.py
==================
8021df18;Julia Medina;2015-04-20 23:43:38 -0300;Move scrapy/contrib/pipeline to scrapy/pipelines

==

docs/topics/media-pipeline.rst
scrapy/pipelines/__init__.py
scrapy/pipelines/files.py
scrapy/pipelines/images.py
scrapy/pipelines/media.py
scrapy/settings/default_settings.py
tests/py3-ignores.txt
tests/test_pipeline_files.py
tests/test_pipeline_images.py
tests/test_pipeline_media.py
==================
d7e60f3c;Julia Medina;2015-04-20 23:27:41 -0300;scrapy/contrib/loader shims

==

scrapy/contrib/loader/__init__.py
scrapy/contrib/loader/common.py
scrapy/contrib/loader/processor.py
==================
b47228ad;Julia Medina;2015-04-20 23:21:41 -0300;Move scrapy/contrib/loader to scrapy/loader

==

docs/contributing.rst
docs/topics/loaders.rst
scrapy/loader/__init__.py
scrapy/loader/common.py
scrapy/loader/processor.py
tests/py3-ignores.txt
tests/test_loader.py
tests/test_squeue.py
==================
569156be;Julia Medina;2015-04-20 23:03:07 -0300;scrapy/contrib/linkextractors shims

==

scrapy/contrib/linkextractors/__init__.py
scrapy/contrib/linkextractors/htmlparser.py
scrapy/contrib/linkextractors/lxmlhtml.py
scrapy/contrib/linkextractors/regex.py
scrapy/contrib/linkextractors/sgml.py
==================
cf064b14;Julia Medina;2015-04-20 22:55:33 -0300;Move scrapy/contrib/linkextractors to scrapy/linkextractors

==

docs/topics/firebug.rst
docs/topics/link-extractors.rst
docs/topics/spiders.rst
scrapy/commands/bench.py
scrapy/link.py
scrapy/linkextractor.py
scrapy/linkextractors/__init__.py
scrapy/linkextractors/htmlparser.py
scrapy/linkextractors/lxmlhtml.py
scrapy/linkextractors/regex.py
scrapy/linkextractors/sgml.py
scrapy/templates/spiders/crawl.tmpl
tests/py3-ignores.txt
tests/spiders.py
tests/test_engine.py
tests/test_linkextractors.py
tests/test_spider.py
==================
152594ce;Julia Medina;2015-04-20 22:46:23 -0300;scrapy/contrib/exporter shims

==

scrapy/contrib/exporter/__init__.py
==================
7804b3d7;Julia Medina;2015-04-20 22:41:06 -0300;Move scrapy/contrib/exporter to scrapy/exporters

==

docs/faq.rst
docs/topics/exporters.rst
docs/topics/feed-exports.rst
scrapy/exporters/__init__.py
scrapy/settings/default_settings.py
tests/py3-ignores.txt
tests/test_exporters.py
==================
6b4c00cc;Julia Medina;2015-04-20 22:15:41 -0300;scrapy/contrib/downloadermiddleware shims

==

scrapy/contrib/downloadermiddleware/__init__.py
scrapy/contrib/downloadermiddleware/ajaxcrawl.py
scrapy/contrib/downloadermiddleware/chunked.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/decompression.py
scrapy/contrib/downloadermiddleware/defaultheaders.py
scrapy/contrib/downloadermiddleware/downloadtimeout.py
scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/contrib/downloadermiddleware/httpproxy.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/downloadermiddleware/stats.py
scrapy/contrib/downloadermiddleware/useragent.py
==================
d7c444fe;Julia Medina;2015-04-20 21:23:05 -0300;Move scrapy/contrib/downloadermiddleware to scrapy/downloadermiddlewares

==

docs/faq.rst
docs/topics/downloader-middleware.rst
docs/topics/settings.rst
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/downloadermiddlewares/__init__.py
scrapy/downloadermiddlewares/ajaxcrawl.py
scrapy/downloadermiddlewares/chunked.py
scrapy/downloadermiddlewares/cookies.py
scrapy/downloadermiddlewares/decompression.py
scrapy/downloadermiddlewares/defaultheaders.py
scrapy/downloadermiddlewares/downloadtimeout.py
scrapy/downloadermiddlewares/httpauth.py
scrapy/downloadermiddlewares/httpcache.py
scrapy/downloadermiddlewares/httpcompression.py
scrapy/downloadermiddlewares/httpproxy.py
scrapy/downloadermiddlewares/redirect.py
scrapy/downloadermiddlewares/retry.py
scrapy/downloadermiddlewares/robotstxt.py
scrapy/downloadermiddlewares/stats.py
scrapy/downloadermiddlewares/useragent.py
scrapy/settings/default_settings.py
scrapy/utils/misc.py
tests/py3-ignores.txt
tests/test_downloadermiddleware_ajaxcrawlable.py
tests/test_downloadermiddleware_cookies.py
tests/test_downloadermiddleware_decompression.py
tests/test_downloadermiddleware_defaultheaders.py
tests/test_downloadermiddleware_downloadtimeout.py
tests/test_downloadermiddleware_httpauth.py
tests/test_downloadermiddleware_httpcache.py
tests/test_downloadermiddleware_httpcompression.py
tests/test_downloadermiddleware_httpproxy.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_retry.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_downloadermiddleware_stats.py
tests/test_downloadermiddleware_useragent.py
==================
9441761a;Pablo Hoffman;2015-04-29 17:48:19 -0300;Merge pull request #1196 from mineo/patch-1
Remove a duplicate word
==
==================
de6501ed;Wieland Hoffmann;2015-04-29 22:31:48 +0200;Remove a duplicate word

==

docs/topics/api.rst
==================
3d2b74a6;Pablo Hoffman;2015-04-29 16:49:43 -0300;Merge pull request #1188 from eliasdorneles/favoring_web_scraping_over_screen_scraping
[MRG+1] Favoring web scraping over screen scraping in the descriptions
==
==================
fbb1078f;Mikhail Korobov;2015-04-29 23:20:34 +0500;Merge pull request #1060 from Curita/python-logging
[MRG+1] Python logging
==
==================
5eb098a9;Daniel Graña;2015-04-28 23:48:58 -0300;Merge pull request #1168 from scrapy/service-identity
install service_identity package in tests to prevent warnings
==
==================
3d3633f3;Elias Dorneles;2015-04-25 11:20:20 -0300;favoring web scraping over screen scraping in the descriptions

==

README.rst
debian/control
docs/intro/overview.rst
docs/topics/selectors.rst
scrapy/__init__.py
setup.py
==================
fa1039f5;Mikhail Korobov;2015-04-24 03:40:10 +0500;Merge pull request #1187 from Curita/relax-spiderloader-check
Relax SpiderLoader interface check
==
==================
cc4c31e4;Julia Medina;2015-04-23 15:08:04 -0300;Relax SpiderLoader interface check

==

scrapy/crawler.py
tests/test_crawler.py
==================
1d8f8221;Julia Medina;2015-04-22 16:50:32 -0300;Add backward compatibility to LogFormatter

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/utils/log.py
==================
4858af4e;Julia Medina;2015-04-22 14:34:11 -0300;Fix backward compatible functions in scrapy.log

==

scrapy/log.py
==================
7a92dae4;Julia Medina;2015-03-19 15:02:54 -0300;Change Scrapy log output through docs

==

docs/intro/tutorial.rst
docs/topics/benchmarking.rst
docs/topics/downloader-middleware.rst
docs/topics/shell.rst
==================
6d120506;Julia Medina;2015-03-19 14:25:38 -0300;Add a filter to replace '__name__' loggers with 'scrapy'

==

scrapy/utils/log.py
tests/test_utils_log.py
==================
4f54ca32;Julia Medina;2015-03-19 13:24:51 -0300;Change 'scrapy' logger for '__name__' on every module

==

scrapy/commands/parse.py
scrapy/contrib/debug.py
scrapy/contrib/downloadermiddleware/ajaxcrawl.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/decompression.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/feedexport.py
scrapy/contrib/logstats.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/httperror.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/urllength.py
scrapy/contrib/spiders/sitemap.py
scrapy/contrib/throttle.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/core/scraper.py
scrapy/crawler.py
scrapy/dupefilter.py
scrapy/log.py
scrapy/mail.py
scrapy/middleware.py
scrapy/statscol.py
scrapy/telnet.py
scrapy/utils/iterators.py
scrapy/utils/log.py
scrapy/utils/signal.py
scrapy/utils/spider.py
==================
69a3d581;Julia Medina;2015-03-19 13:12:03 -0300;Basic example on manually configuring log handlers

==

docs/topics/logging.rst
==================
bd0b639b;Julia Medina;2015-03-10 15:59:44 -0300;Fix logging usage across docs

==

docs/topics/debug.rst
docs/topics/extensions.rst
docs/topics/practices.rst
docs/topics/request-response.rst
docs/topics/spiders.rst
==================
4811d16f;Julia Medina;2015-03-10 15:53:38 -0300;Update `logger` attr and `log` method in the Spiders topic on docs

==

docs/topics/spiders.rst
==================
d47a7edc;Julia Medina;2015-03-10 15:52:45 -0300;Update Logging topic on docs

==

docs/index.rst
docs/topics/logging.rst
==================
ccdd8bfb;Julia Medina;2015-03-05 05:04:21 -0300;Parametrize log formatting strings

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
scrapy/utils/log.py
==================
21b9f377;Julia Medina;2015-03-04 15:13:57 -0300;Deprecate more frequently used functions from scrapy/log.py

==

scrapy/log.py
==================
c174d78f;Julia Medina;2015-02-28 09:30:28 -0300;Deprecate scrapy/log.py

==

scrapy/log.py
tests/py3-ignores.txt
tests/test_log.py
==================
6acb3848;Julia Medina;2015-02-28 08:17:37 -0300;Stdout redirect in configure_logging

==

scrapy/utils/log.py
tests/test_utils_log.py
==================
ffd97f2f;Julia Medina;2015-02-28 08:16:12 -0300;Set root handlers based on settings in configure_logging

==

scrapy/utils/log.py
==================
1c8708eb;Julia Medina;2015-02-28 06:56:53 -0300;Create a logger for every Spider and adapt Spider.log to log through it

==

scrapy/spider.py
tests/spiders.py
tests/test_commands.py
tests/test_spider.py
==================
ac40ef61;Julia Medina;2015-02-28 06:36:35 -0300;Custom handler to count log level occurrences in a crawler

==

scrapy/commands/shell.py
scrapy/crawler.py
scrapy/utils/log.py
tests/py3-ignores.txt
tests/test_utils_log.py
==================
b75556ef;Julia Medina;2015-02-28 08:14:53 -0300;Add a logging filter to mimic Twisted's log.err formating for Failures

==

scrapy/utils/log.py
tests/test_utils_log.py
==================
8baad552;Julia Medina;2015-02-28 06:33:03 -0300;New scrapy/utils/log.py file with basic log helpers
There are two functions, `configure_logging` and `log_scrapy_info` which
intend to replace scrapy.log.start and scrapy.log.scrapy_info
respectively.

Creating new functions makes evident the backward incompatible change of
using another logging system, and since the Python logging module is a
standard builtin, additional helpers make sense to be on a scrapy/utils
file.

==

scrapy/crawler.py
scrapy/utils/log.py
==================
6f9b4232;Julia Medina;2015-02-28 03:22:06 -0300;Restructure LogFormatter to comply with std logging calls

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/logformatter.py
tests/test_logformatter.py
==================
c2d71680;Julia Medina;2015-02-28 07:23:54 -0300;Use LogCapture in testfixtures package for tests
This allows to remove `get_testlog` helper, `flushLoggedErrors` from
twisted.trial.unittest.TestCase and Twisted log observers created for
each test on conftest.py.

==

conftest.py
pytest.ini
scrapy/utils/test.py
tests/requirements.txt
tests/test_closespider.py
tests/test_crawl.py
tests/test_pipeline_media.py
tests/test_proxy_connect.py
tests/test_spidermiddleware_httperror.py
tests/test_utils_defer.py
tests/test_utils_signal.py
tox.ini
==================
7a958f90;Julia Medina;2015-02-27 23:36:30 -0300;Replace scrapy.log calls for their equivalents in the logging std module
Changes:
 - Each module takes 'scrapy' logger and logs through it
 - Lazy string evaluation in all log messages
 - Added missing log messages in scrapy/core/engine.py
 - Contextual data such as crawler or spider instances, and failures

==

scrapy/commands/parse.py
scrapy/commands/shell.py
scrapy/contrib/debug.py
scrapy/contrib/downloadermiddleware/ajaxcrawl.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/decompression.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/feedexport.py
scrapy/contrib/logstats.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/httperror.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/urllength.py
scrapy/contrib/spiders/sitemap.py
scrapy/contrib/throttle.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/core/scraper.py
scrapy/crawler.py
scrapy/dupefilter.py
scrapy/mail.py
scrapy/middleware.py
scrapy/statscol.py
scrapy/telnet.py
scrapy/utils/iterators.py
scrapy/utils/signal.py
scrapy/utils/spider.py
tests/test_commands.py
==================
571bf68d;Daniel Graña;2015-04-22 05:37:41 -0300;Merge pull request #353 from nramirezuy/item-multi_inherit
[MRG] Item multi inheritance fix
==
==================
7871acd6;nramirezuy;2013-07-17 15:22:08 -0300;Item multi inherit fixed

==

scrapy/item.py
tests/test_item.py
==================
ded3f9cb;Daniel Graña;2015-04-21 17:17:14 -0300;Merge pull request #1185 from scrapy/fix-spiderloader-backwards-compatibility
[MRG +1]fixed backwards compatibility for SPIDER_MANAGER_CLASS option
==
==================
c3d3a949;Mikhail Korobov;2015-04-22 00:29:40 +0500;fixed backwards compatibility for SPIDER_MANAGER_CLASS option

==

scrapy/crawler.py
tests/test_crawler.py
==================
0a5bbbae;Pablo Hoffman;2015-04-21 15:54:24 -0300;Merge pull request #1159 from scrapy/feed-export-fields
[MRG+1] FEED_EXPORT_FIELDS option
==
==================
4c4eb4f7;Pablo Hoffman;2015-04-21 15:49:39 -0300;Merge pull request #1180 from eliasdorneles/tutorial-improvements
Some improvements for Scrapy tutorial
==
==================
e034947b;Daniel Graña;2015-04-21 15:42:17 -0300;Merge pull request #1166 from scrapy/spider-loader
[MRG+1] rename SpiderManager to SpiderLoader
==
==================
06e1ca9e;Pablo Hoffman;2015-04-21 15:35:47 -0300;Merge pull request #1177 from Curita/remove-djangoitem
Remove djangoitem
==
==================
e4122cdd;Pablo Hoffman;2015-04-21 15:28:47 -0300;Merge pull request #1150 from eliasdorneles/docs-files-pipeline
Documenting Files Pipeline together with Images Pipeline
==
==================
d6356753;Elias Dorneles;2015-04-21 11:30:48 -0300;change data extraction in crawl example to be consistent with tutorial, removed statement implying mandatory usage of Item

==

docs/intro/tutorial.rst
==================
f7da69d1;Elias Dorneles;2015-04-21 11:19:10 -0300;fixing example CSS expr

==

docs/intro/tutorial.rst
==================
ff007afb;Elias Dorneles;2015-04-21 10:57:44 -0300;expanded crawling primer with examples, and applied other suggestions from the review

==

docs/intro/tutorial.rst
==================
c8ccb7c5;Mikhail Korobov;2015-04-21 12:34:59 +0500;Merge pull request #722 from Digenis/loader-iteration
[MRG +1]ItemLoader.load_item: iterate over copy of fields
==
==================
595146e1;Elias Dorneles;2015-04-20 21:09:03 -0300;some improvements for Scrapy tutorial

==

docs/Makefile
docs/intro/tutorial.rst
==================
0bf1ec16;Julia Medina;2015-04-20 20:36:33 -0300;Merge branch 'nyov/remove-deploy' from pull request #1102

==
==================
7ae37d61;nyov;2015-03-24 07:38:09 +0000;remove scrapy deploy command
(closes #1027, #1095, #1102)

==

docs/topics/commands.rst
extras/scrapy_bash_completion
scrapy/commands/deploy.py
scrapy/templates/project/scrapy.cfg
==================
6da091f1;Julia Medina;2015-04-20 20:19:28 -0300;Remove djangoitem topic from index

==

docs/index.rst
==================
d39722f6;Nikolaos-Digenis Karagiannis;2015-04-20 11:05:56 +0300;ItemLoader.load_item: iterate over copy of fields

==

scrapy/contrib/loader/__init__.py
==================
017fb25b;Nikolaos-Digenis Karagiannis;2015-04-20 11:04:31 +0300;loader test with processors that use item's values

==

tests/test_contrib_loader.py
==================
16a1a938;Daniel Graña;2015-04-20 01:39:52 -0300;Add 0.24.6 release notes

==

docs/news.rst
==================
1794a893;Mikhail Korobov;2015-04-19 21:41:29 +0500;Merge pull request #1172 from bagratte/docs
minor corrections in documentation.
==
==================
ffc60910;Julia Medina;2015-04-19 13:09:25 -0300;Remove djangoitem since we moved it to scrapy/scrapy-djangoitem

==

conftest.py
docs/topics/djangoitem.rst
scrapy/__init__.py
scrapy/contrib/djangoitem.py
tests/py3-ignores.txt
tests/test_djangoitem/__init__.py
tests/test_djangoitem/models.py
tests/test_djangoitem/settings.py
tox.ini
==================
1312bcd0;bagratte;2015-04-19 18:58:15 +0400;minor corrections in documentation.

==

.gitignore
docs/topics/feed-exports.rst
docs/topics/item-pipeline.rst
docs/topics/link-extractors.rst
==================
beea9267;bagratte;2015-04-18 19:48:25 +0400;minor corrections in documentation.

==

.gitignore
docs/intro/tutorial.rst
docs/topics/commands.rst
docs/topics/loaders.rst
docs/topics/selectors.rst
docs/topics/spiders.rst
==================
bb4c8c33;Mikhail Korobov;2015-04-18 14:13:10 +0500;Merge pull request #1171 from rajathkumarmp/edit-doc
Added link to ipython in Tutorial.
==
==================
02629b5f;rajathkumarmp;2015-04-18 13:00:34 +0530;Added link to ipython in doc.

==

docs/intro/tutorial.rst
==================
757309ef;Pablo Hoffman;2015-04-17 19:52:11 -0300;Merge pull request #1169 from bagratte/docs
add some minor stylistic and grammar corrections to tutorial.rst.
==
==================
dffc4549;José Ricardo;2015-04-17 14:27:11 -0400;Fix small typo in the docs

==

docs/topics/leaks.rst
==================
8d339da4;bagratte;2015-04-17 20:55:02 +0400;add some minor stylistic and grammar corrections to tutorial.rst.

==

docs/intro/tutorial.rst
==================
ad587ea7;Mikhail Korobov;2015-04-17 01:54:26 +0500;rename CrawlerRunner.spiders to CrawlerRunner.spider_loader

==

scrapy/commands/check.py
scrapy/commands/edit.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/parse.py
scrapy/commands/shell.py
scrapy/crawler.py
scrapy/spiderloader.py
scrapy/utils/spider.py
tests/test_crawler.py
tests/test_spiderloader/__init__.py
==================
fee55657;Mikhail Korobov;2015-04-17 01:25:48 +0500;don't expose deprecated crawler.spiders attribute in telnet console

==

scrapy/telnet.py
==================
271f7f54;Mikhail Korobov;2015-04-16 22:54:51 +0500;TST install service_identity package in tests to prevent warnings
Also, Twisted version is bumped for Python 3.x tests, just in case.

service_identity is not added to Scrapy requirements because Scrapy
supports older Twisted / PyOpenSSL versions which don't use it.

==

tox.ini
==================
403e7c7c;Mikhail Korobov;2015-04-16 20:07:53 +0500;rename scrapy.spidermanager.SpiderManager to scrapy.spiderloader.SpiderLoader

==

docs/topics/api.rst
docs/topics/settings.rst
scrapy/crawler.py
scrapy/interfaces.py
scrapy/settings/default_settings.py
scrapy/spider.py
scrapy/spiderloader.py
scrapy/spidermanager.py
scrapy/utils/spider.py
tests/py3-ignores.txt
tests/test_crawler.py
tests/test_spiderloader/__init__.py
tests/test_spiderloader/test_spiders/__init__.py
tests/test_spiderloader/test_spiders/spider0.py
tests/test_spiderloader/test_spiders/spider1.py
tests/test_spiderloader/test_spiders/spider2.py
tests/test_spiderloader/test_spiders/spider3.py
==================
a1f3b3c7;Elias Dorneles;2015-04-15 14:26:08 -0300;images.rst -> media-pipeline.rst

==

docs/index.rst
docs/topics/media-pipeline.rst
scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
==================
fd1c688a;Elias Dorneles;2015-04-15 14:21:48 -0300;addressing issues from review at #1150

==

docs/topics/images.rst
==================
fb85bd4b;Pablo Hoffman;2015-04-15 14:08:19 -0300;Merge pull request #1132 from sibiryakov/dns-options2
[MRG+1] Dns cache size and timeout options
==
==================
20c8d712;Pablo Hoffman;2015-04-15 13:57:51 -0300;Merge pull request #1164 from scrapy/deploy-docs-2
deployment docs tweaks
==
==================
cb5280ab;Mikhail Korobov;2015-04-15 19:25:22 +0500;DOC tweak deployment docs

==

docs/topics/deploy.rst
==================
e054b3c4;Nicolás Alejandro Ramírez Quiros;2015-04-15 10:34:19 -0300;Merge pull request #1160 from scrapy/docs-theme
Change local docs theme
==
==================
954c8fce;mrpandav;2015-04-15 16:49:09 +0530;changes `test_from_response_formname_notexists_fallback_formid` unit test for pull request #1137 - addition of new shortcut for html form election by formid attribute

==

tests/test_http_request.py
==================
a11bd3e8;Mikhail Korobov;2015-04-15 11:50:57 +0500;DOC update docs readme file - sphinx >= 1.3 is now required.

==

docs/README
==================
020a32a3;mrpandav;2015-04-15 11:23:25 +0530;Adding tests for pull request #1137 - addition of new shortcut for html form election by formid attribute

==

tests/test_http_request.py
==================
526aa07f;Julia Medina;2015-04-15 02:15:32 -0300;Merge pull request #1156 from kmike/crawlers-accept-dicts
allow Crawler, CrawlerRunner and CrawlerProcess to accept dicts instead of Setting objects
==
==================
c013baa6;Daniel Graña;2015-04-15 00:32:42 -0300;Merge pull request #1161 from scrapy/telnet-disable
disable scrapy.telnet if twisted.conch is not available
==
==================
e3aaeb7f;Daniel Graña;2015-04-15 00:32:03 -0300;Merge pull request #1162 from kmike/ajaxcrawl-py3
fix Python 3 syntax errors in ajaxcrawl.py
==
==================
0b764876;Mikhail Korobov;2015-04-15 04:16:26 +0500;PY3 fix Python 3 syntax errors in ajaxcrawl.py
Tests for _has_ajaxcrawlable_meta passin Python 3.

==

scrapy/contrib/downloadermiddleware/ajaxcrawl.py
tests/py3-ignores.txt
==================
378b6efc;Mikhail Korobov;2015-04-15 04:06:36 +0500;PY3 disable scrapy.telnet if twisted.conch is not available

==

scrapy/telnet.py
tests/py3-ignores.txt
==================
f40587c6;Mikhail Korobov;2015-04-15 03:52:07 +0500;Merge pull request #1131 from torymur/master
Fix #1130
==
==================
dd84f4bd;Mikhail Korobov;2015-04-15 03:44:49 +0500;DOC remove css file which isno longer needed

==

docs/_static/scrapydoc.css
==================
7dcd7f3c;Mikhail Korobov;2015-04-15 03:43:30 +0500;DOC make local docs use the same theme as readthedocs.org
sphinx_rtd_theme is builtin in recent Sphinx versions.

==

docs/conf.py
==================
abeb8e3a;Mikhail Korobov;2015-04-15 03:27:11 +0500;TST skip a test in Python 3 because it imports some parts of Twisted which are not ported yet

==

tests/test_contrib_feedexport.py
==================
647eeaea;Mikhail Korobov;2015-04-15 03:23:30 +0500;TST add a test for GH-1050.

==

tests/test_contrib_feedexport.py
==================
1534e854;Mikhail Korobov;2015-04-15 02:48:26 +0500;FEED_EXPORT_FIELDS option

==

docs/topics/feed-exports.rst
scrapy/contrib/feedexport.py
scrapy/settings/default_settings.py
tests/mockserver.py
tests/test_contrib_feedexport.py
==================
76448132;Mikhail Korobov;2015-04-14 23:26:05 +0500;allow Crawler, CrawlerRunner and CrawlerProcess to accept dicts instead of Setting objects

==

docs/topics/practices.rst
scrapy/crawler.py
tests/test_crawler.py
==================
c2c80985;Nicolás Alejandro Ramírez Quiros;2015-04-14 14:09:10 -0300;Merge pull request #1155 from kmike/remove-deprecated
remove deprecated code from FeedExporter
==
==================
5436ba11;Mikhail Korobov;2015-04-14 20:19:28 +0500;remove deprecated code from FeedExporter

==

scrapy/contrib/feedexport.py
==================
973c31f7;Mikhail Korobov;2015-04-14 20:11:46 +0500;TST cleanup: use assertIn instead of assert_

==

scrapy/utils/testproc.py
tests/test_commands.py
==================
71c0afac;Pablo Hoffman;2015-04-13 14:25:32 -0300;Merge pull request #1148 from Curita/verify-spidermanager-interface
Verify SPIDER_MANAGER_CLASS interface while loading it in CrawlerRunner
==
==================
e85679fa;Daniel Graña;2015-04-13 14:23:15 -0300;Merge pull request #1147 from Curita/pass-crawlers-to-runner-crawl-calls
Allow passing Crawler instances directly to CrawlerRunner.crawl()
==
==================
5af557e6;Julia Medina;2015-04-12 23:56:40 -0300;Merge pull request #1152 from jdemaeyer/fix/tests-settings-api
Fix deprecated settings API in tests
==
==================
f71175a4;Daniel Graña;2015-04-12 21:56:23 -0300;More replaces of references to old `sel` shortcut

==

docs/topics/selectors.rst
==================
f9208dbc;Daniel Graña;2015-04-12 21:55:35 -0300;Merge pull request #1154 from dianakhuang/patch-2
Remove references to the `sel` object in shell.rst
==
==================
91a60d9f;Diana Huang;2015-04-12 13:44:32 -0400;Remove references to the `sel` object in shell.rst
The current documentation has references to the deprecated `sel` when interacting with the shell. I've removed them and replaced uses of `sel.xpath` with `response.xpath` instead.
==

docs/topics/shell.rst
==================
cf9d848f;Jakob de Maeyer;2015-04-12 14:18:47 +0200;Fixed deprecated settings API in cmdline test

==

tests/test_cmdline/settings.py
==================
1eccd34a;mrpandav;2015-04-12 11:11:28 +0530;adding feature improvement  for selecting form using form-id, in addition to formname , formnumer before we go for xpath.. making it more idiomatic in nature

==

scrapy/http/request/form.py
==================
dce48b86;Elias Dorneles;2015-04-11 13:57:55 -0300;documenting Files Pipeline together with Images Pipeline

==

docs/index.rst
docs/topics/images.rst
==================
6f000b8c;Mikhail Korobov;2015-04-11 00:38:42 +0500;Merge pull request #952 from Digenis/unicode_xpath_exception
[MRG+1] encode unicode selector exception
==
==================
bf301b73;Nikolaos-Digenis Karagiannis;2014-11-17 19:30:08 +0200;encode invalid xpath with unicode_escape under PY2
The exception quotes an xpath string
which may be unicode.

==

scrapy/selector/unified.py
tests/test_selector.py
==================
24a07fd8;Julia Medina;2015-04-10 13:43:33 -0300;Verify SPIDER_MANAGER_CLASS interface in CrawlerRunner

==

scrapy/crawler.py
tests/test_crawler.py
==================
3dabde67;Julia Medina;2015-04-10 12:09:07 -0300;Update docs for CrawlerRunner.crawl() new usage

==

docs/topics/api.rst
==================
86b09513;Julia Medina;2015-04-10 12:06:27 -0300;Delete `crawler_deferreds` doc in CrawlerRunner
This attribute is now an internal one since it's main use-case was
covered by CrawlerRunner.stop().

==

docs/topics/api.rst
==================
bc705843;Julia Medina;2015-04-10 11:52:57 -0300;Support crawlers as first positional arg in CrawlerRunner.crawl()

==

scrapy/crawler.py
==================
f8ca5d10;Julia Medina;2015-04-10 10:33:43 -0300;Merge pull request #1134 from nyov/remove-contrib
[MRG+1] dissolve contrib_exp
==
==================
6b4439ea;bosnj;2015-04-10 15:32:32 +0200;default return value for extract_first

==

scrapy/selector/unified.py
==================
543d02bc;Julia Medina;2015-04-09 21:36:24 -0300;Avoid name clashing in deploy.py, fixes #1143

==

scrapy/commands/deploy.py
==================
39fd2e62;Pablo Hoffman;2015-04-09 18:01:11 -0300;fix typo in deploy.rst

==

docs/topics/deploy.rst
==================
1a12922b;Pablo Hoffman;2015-04-09 17:39:01 -0300;improve scrapy deploy documentation

==

docs/faq.rst
docs/index.rst
docs/topics/deploy.rst
==================
9ea309c3;Pablo Hoffman;2015-04-09 16:56:35 -0300;rename deployment.rst -> deploy.rst (consist with others like debug.rst)

==

docs/topics/deploy.rst
==================
d8184a72;Pablo Hoffman;2015-04-09 16:53:25 -0300;Merge pull request #1124 from rdowinton/deployment-doc
Added deployment section covering scrapyd-deploy and shub
==
==================
6d48c19a;nyov;2015-04-03 13:02:56 +0000;dissolve `scrapy.contrib_exp`

==

scrapy/contrib/downloadermiddleware/decompression.py
scrapy/contrib_exp/__init__.py
scrapy/contrib_exp/djangoitem.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/contrib_exp/iterators.py
scrapy/utils/iterators.py
tests/test_downloadermiddleware_decompression.py
tests/test_utils_iterators.py
==================
4b11501e;Pablo Hoffman;2015-04-07 18:13:01 -0300;Merge pull request #963 from tpeng/fix-xmliter-lxml
[MRG+1] support namespace prefix in xmliter_lxml
==
==================
5a96a169;Dharmesh Pandav;2015-04-06 14:44:47 +0530;Update form.py to improve existing capability
Add capability to search HTML Form using formid when using `FormRequest.from_response()`

refrenced issue :https://github.com/scrapy/scrapy/issues/1136
==

scrapy/http/request/form.py
==================
d55ae535;dinesh;2015-04-05 17:50:12 +0530;Remove deploy and server commands from bash completion

==

extras/scrapy_bash_completion
==================
b1247355;dinesh;2015-04-05 17:48:54 +0530;Remove server command

==

extras/scrapy_zsh_completion
==================
97061193;Daniel Graña;2015-04-04 18:08:05 -0300;Merge pull request #1128 from Curita/move-spider-settings-population-to-crawler
[MRG+1] Move spider settings population from CrawlerRunner to Crawler.__init__
==
==================
843a9cdb;dinesh;2015-04-03 21:24:31 +0530;Remove deploy command from arguments
As scrapy deploy is being removed

==

extras/scrapy_zsh_completion
==================
7129dc36;dinesh;2015-04-03 21:20:06 +0530;Move scrapy_zsh_completion inside extras directory

==

extras/scrapy_zsh_completion
==================
e2b4fabb;dinesh;2015-04-03 08:34:16 +0530;Fix zsh completion path

==

debian/scrapy.install
scrapy_zsh_completion
==================
9d0ea5a3;dinesh;2014-11-02 22:24:00 +0530;Added zsh completion for the Scrapy command-line tool

==

debian/scrapy.install
extras/_scrapy_zsh_completion
==================
fcf97001;Julia Medina;2015-04-02 22:33:43 -0300;Merge pull request #1121 from nyov/nyov/py3-urllib
[MRG+1] more python3 compatibility changes for urllib
==
==================
42f76746;Victoria Terenina (torymur);2015-04-02 17:48:38 +0300;fixed unhandled error in deferred (RobotsTxtMiddleware)

==

scrapy/contrib/downloadermiddleware/robotstxt.py
==================
85aa3c75;Alexander Sibiryakov;2015-04-02 18:30:59 +0200;Dns cache size and timeout options

==

docs/topics/settings.rst
scrapy/crawler.py
scrapy/resolver.py
scrapy/settings/default_settings.py
==================
6f9265b4;Julia Medina;2015-04-01 23:29:10 -0300;Move spider settings population to Crawler.__init__

==

scrapy/crawler.py
tests/test_crawler.py
==================
66aef048;Julia Medina;2015-04-01 17:02:28 -0300;Merge pull request #1127 from nyov/docs-fix
documentation build warning fixes
==
==================
dc88be75;nyov;2015-03-30 14:56:02 +0000;more python3 compatibility changes for urllib

==

scrapy/commands/deploy.py
scrapy/contrib/downloadermiddleware/httpproxy.py
scrapy/http/request/form.py
scrapy/utils/url.py
tests/mockserver.py
==================
92b57430;nyov;2015-04-01 19:46:21 +0000;documentation build warning fixes

==

docs/topics/commands.rst
docs/topics/items.rst
==================
27591b55;Daniel Graña;2015-04-01 15:08:03 -0300;Merge pull request #1123 from sibiryakov/reactor-threadpool-size
[MRG+1] Reactor threadpool max size setting
==
==================
b794cdaf;Alexander Sibiryakov;2015-04-01 12:07:03 +0200;Broad crawls notes.

==

docs/topics/broad-crawls.rst
==================
e7b274ed;Alexander Sibiryakov;2015-04-01 11:49:55 +0200;Reformat to 80 characters per line.

==

docs/topics/settings.rst
==================
94fceb4c;Alexander Sibiryakov;2015-04-01 11:25:10 +0200;Fixing underscore size.

==

docs/topics/settings.rst
==================
5916df64;Alexander Sibiryakov;2015-04-01 11:24:12 +0200;Removing unnecessary import.

==

scrapy/crawler.py
==================
ec4251af;Daniel Graña;2015-03-31 17:30:08 -0300;Merge pull request #1089 from drack3800/master
[MRG+1] Add test for webclient with POST method and no body given
==
==================
2d142d64;Richard Dowinton;2015-03-31 12:17:31 +0100;Added deployment section covering scrapyd-deploy and shub

==

docs/index.rst
docs/topics/deployment.rst
==================
5864d291;Alexander Sibiryakov;2015-03-31 11:10:56 +0200;Setting documentation.

==

docs/topics/settings.rst
==================
c1cd019f;Alexander Sibiryakov;2015-03-31 10:56:31 +0200;Setting maximum thread pool size in reactor.

==

scrapy/crawler.py
scrapy/settings/default_settings.py
==================
0c748218;Elias Dorneles;2015-03-27 21:23:55 -0300;Merge pull request #1112 from eliasdorneles/minor-grammar-fixes
Some minor grammar fixes
==
==================
18c5bc75;Elias Dorneles;2015-03-27 21:00:21 -0300;some more minor grammar fixes

==

docs/intro/overview.rst
==================
7135c4e6;Elias Dorneles;2015-03-27 17:56:56 -0300;some minor grammar fixes

==

docs/intro/overview.rst
==================
a3702e74;Nicolás Alejandro Ramírez Quiros;2015-03-27 15:37:26 -0300;Merge pull request #1073 from eliasdorneles/add-more-settings-to-template
[MRG+1] Adding more settings to project template
==
==================
bb4c922d;Pablo Hoffman;2015-03-27 15:19:27 -0300;Merge pull request #1081 from scrapy/dict-items
Allow spiders to return dicts. 
==
==================
55a23d10;Daniel Graña;2015-03-27 15:17:54 -0300;Merge pull request #1086 from Curita/response-urljoin
Add Response.urljoin() helper
==
==================
f4e241a0;Julia Medina;2015-03-27 15:16:33 -0300;Merge pull request #1106 from eliasdorneles/overview-page-improvements
[MRG+1] some improvements to overview page
==
==================
84edc2eb;nyov;2015-03-24 11:42:33 +0000;Add Response.urljoin() testcase
and add evaluation of base-url for HtmlResponse.

==

scrapy/http/response/__init__.py
scrapy/http/response/text.py
scrapy/utils/response.py
tests/test_http_response.py
==================
39085ae1;Mikhail Korobov;2015-03-27 02:11:35 +0500;Merge pull request #1098 from nyov/nyov/userconfig
[+1 MRG]look in ~/.config/scrapy.cfg for user config
==
==================
1134a9ca;nyov;2015-03-24 03:12:58 +0000;config: look in ~/.config/scrapy.cfg as well

==

docs/topics/commands.rst
docs/topics/settings.rst
scrapy/utils/conf.py
==================
1ce04255;Mikhail Korobov;2015-03-27 00:52:17 +0500;Merge pull request #1108 from pbronez/master
Converted sel.xpath() calls to response.xpath() in Extracting the data. Fixes GH-1107.
==
==================
475766c7;Peter Bronez;2015-03-26 15:34:30 -0400;Converted sel.xpath() calls to response.xpath() in Extracting the data

==

docs/intro/tutorial.rst
==================
4dcecc98;Elias Dorneles;2015-03-26 15:45:17 -0300;moved example data to a better place

==

docs/intro/overview.rst
==================
7402e272;Elias Dorneles;2015-03-26 15:35:31 -0300;fix community link

==

docs/intro/overview.rst
==================
729861c8;Elias Dorneles;2015-03-26 15:31:42 -0300;fixing indentation

==

docs/intro/overview.rst
==================
13d0ecde;Elias Dorneles;2015-03-26 15:26:16 -0300;addressing more review comments, to avoid ambiguity on desired reading flow

==

docs/intro/overview.rst
==================
76e3bf12;Elias Dorneles;2015-03-26 14:26:20 -0300;addressing comments from the review plus further editing

==

docs/intro/overview.rst
docs/topics/autothrottle.rst
==================
8f4a268f;Elias Dorneles;2015-03-26 12:14:56 -0300;added bit about async requests, improved phrasing

==

docs/intro/overview.rst
==================
32423d4a;Elias Dorneles;2015-03-25 19:24:36 -0300;some improvements to overview page

==

docs/intro/overview.rst
==================
e3e60da6;Mikhail Korobov;2015-03-26 03:19:39 +0500;Merge pull request #1105 from ramiro/patch-1
Add missing callback arg in jobs topic example.
==
==================
933dbc6b;Ramiro Morales;2015-03-25 18:33:17 -0300;Oops

==

docs/topics/jobs.rst
==================
ca257500;Ramiro Morales;2015-03-25 18:32:20 -0300;Add missing callback arg in jobs topic example.

==

docs/topics/jobs.rst
==================
6afd1a78;drack3800;2015-03-25 20:43:07 +0300;style fix

==
==================
ad36de4e;Daniel Graña;2015-03-24 18:21:10 -0300;Merge pull request #1101 from nyov/nyov/tls-sni
handle TLS SNI
==
==================
aaeb837d;nyov;2015-03-24 07:11:48 +0000;handle TLS SNI if we have twisted>=14.0
(closes #981, #1101)

==

scrapy/core/downloader/contextfactory.py
==================
5ac91e48;Mikhail Korobov;2015-03-23 18:11:35 +0500;DOC remove Dynamic Creation of Item Classes section
It was a hack, and dicts-as-items cover most use cases.

Dicts don't allow to attach metadata to fields,
but e.g. adding "_meta" key and removing it in a custom serializer
is no worse than creating classes dynamically.

==

docs/topics/practices.rst
==================
54988259;drack3800;2015-03-22 19:25:08 +0300;Fixed bug with no specified Content-Length header by ScrapyHTTPClientFactory for POST request with no given body

==

scrapy/core/downloader/webclient.py
==================
deb5bb53;drack3800;2015-03-22 19:25:08 +0300;Fixed bug with no specified Content-Length header by ScrapyHTTPClientFactory for POST request with no given body

==

scrapy/core/downloader/webclient.py
==================
1b6d5a01;drack3800;2015-03-21 04:02:51 +0300;Added webclient test for checking Content-Length header in response for POST request with no given body

==

tests/test_webclient.py
==================
cda39225;Julia Medina;2015-03-19 16:59:52 -0300;Add Response.urljoin() helper

==

docs/topics/request-response.rst
scrapy/http/response/__init__.py
==================
c81eefaf;Pablo Hoffman;2015-03-19 17:42:48 -0300;fix doc links

==

docs/topics/downloader-middleware.rst
docs/topics/telnetconsole.rst
==================
d7cb2b9a;Elias Dorneles;2015-03-19 15:41:43 -0300;making commented code indentation consistent

==

scrapy/templates/project/module/settings.py.tmpl
==================
8ac39767;Mikhail Korobov;2015-03-19 21:41:36 +0500;DOC move .. module: declaration to a proper place

==

docs/topics/spiders.rst
==================
67a85c77;Julia Medina;2015-03-18 23:55:42 -0300;Merge branch 'coder46-master' from pull request #647

==
==================
643984e1;Faisal Anees;2014-03-23 01:00:37 +0530;Updated architecture.rst
Added http://krondo.com/blog/?page_id=1327 as a resource

==

docs/topics/architecture.rst
==================
ff645848;Julia Medina;2015-03-18 21:29:49 -0300;Merge branch 'ananana-selectorlist-extract-first' from pull request #624

==
==================
f16a33f3;Mikhail Korobov;2015-03-19 05:25:15 +0500;DOC change structure of spider docs:
* start with scrapy.Spider, then mention spider arguments,
  then describe generic spiders;
* change wording regarding start_urls/start_requests;
* show an example of start_requests vs start_urls;
* show an example of dicts as items;
* as defining Item is an optional step now, docs for Items are
  moved below Spider docs.

==

docs/index.rst
docs/topics/spiders.rst
==================
817dbc6c;Mikhail Korobov;2015-03-19 05:16:14 +0500;DOC mention dicts in documentation; explain better what are Items for

==

docs/topics/architecture.rst
docs/topics/exporters.rst
docs/topics/images.rst
docs/topics/item-pipeline.rst
docs/topics/items.rst
docs/topics/practices.rst
docs/topics/signals.rst
docs/topics/spider-middleware.rst
==================
959aaad2;Julia Medina;2015-03-18 21:04:15 -0300;Document `re_first`

==

docs/topics/selectors.rst
==================
0dade731;Julia Medina;2015-03-18 20:50:17 -0300;Use generator sintax in re_first

==

scrapy/selector/unified.py
==================
f92bc09b;Mateusz Golewski;2014-02-02 15:45:43 +0100;Add re_first() to SelectorList and iflatten() to utils.python

==

scrapy/selector/unified.py
scrapy/utils/python.py
tests/test_selector.py
==================
127c6c69;Mateusz Golewski;2014-02-02 15:02:25 +0100;Fix extract_first() docs

==

docs/topics/selectors.rst
==================
012211ac;Mateusz Golewski;2014-01-30 23:39:15 +0100;Add docs for extract_first()

==

docs/topics/selectors.rst
==================
2742b4d8;Mateusz Golewski;2014-01-30 23:10:53 +0100;Add tests to extract_first()

==

tests/test_selector.py
==================
bd126be3;Mateusz Golewski;2014-01-30 21:48:50 +0100;Optimize extract_first()

==

scrapy/selector/unified.py
==================
6c7bd54f;Mateusz Golewski;2014-01-30 21:33:46 +0100;Add extract_first() method to SelectorList

==

scrapy/selector/unified.py
==================
12eedd90;Daniel Graña;2015-03-18 20:46:18 -0300;fix truncated 0.24.5 release notes. closes #1084

==

docs/news.rst
==================
e17f97e6;Julia Medina;2015-03-18 20:05:50 -0300;Merge branch 'dufferzafar-fix-linkcheck-606' from pull request #1041

==
==================
4fb818a2;Julia Medina;2015-03-18 20:04:14 -0300;Run linkfix over current docs

==

docs/topics/downloader-middleware.rst
docs/topics/loaders.rst
==================
ff987fb5;Julia Medina;2015-03-18 20:00:03 -0300;Add linkfix rule to docs Makefile

==

docs/Makefile
==================
c05f5f17;Shadab Zafar;2015-03-12 06:57:47 +0530;Added linkfix script to docs/utils
https://github.com/scrapy/scrapy/pull/1041#issuecomment-78143576

==

docs/utils/linkfix.py
==================
5a58d641;Shadab Zafar;2015-02-06 22:46:18 +0530;Fix some redirection links in documentation
Fixes #606

==

docs/contributing.rst
docs/faq.rst
docs/index.rst
docs/intro/examples.rst
docs/intro/install.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/news.rst
docs/topics/commands.rst
docs/topics/downloader-middleware.rst
docs/topics/email.rst
docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/firebug.rst
docs/topics/firefox.rst
docs/topics/images.rst
docs/topics/items.rst
docs/topics/leaks.rst
docs/topics/logging.rst
docs/topics/request-response.rst
docs/topics/scrapyd.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
==================
4c11201d;Mikhail Korobov;2015-03-18 23:33:10 +0500;Merge pull request #1082 from iKevinY/readme-badges
Use Shields.io SVGs for README badges
==
==================
ee82fe0e;Nicolás Alejandro Ramírez Quiros;2015-03-18 08:11:25 -0300;Merge pull request #1016 from SudShekhar/jsonProcessor
[MRG+1] Added JmesSelect
==
==================
776616bd;Kevin Yap;2015-03-17 22:20:45 -0700;Use Shields.io SVGs for README badges
- Use SVGs for badges (more friendly to retina displays).
- Add alt text to PyPI version and build status badges.

==

README.rst
==================
5846d615;Pablo Hoffman;2015-03-18 00:24:16 -0300;emphasize web crawling over screen scraping on scrapy description. closes #586

==

README.rst
debian/control
scrapy/__init__.py
setup.py
==================
39635e5f;Mikhail Korobov;2015-03-18 07:26:56 +0500;Allow spiders to return dicts. See GH-1064.

==

docs/topics/exporters.rst
scrapy/commands/parse.py
scrapy/contracts/default.py
scrapy/contrib/exporter/__init__.py
scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
scrapy/core/scraper.py
tests/spiders.py
tests/test_commands.py
tests/test_contracts.py
tests/test_contrib_exporter.py
tests/test_engine.py
tests/test_pipeline_files.py
tests/test_pipeline_images.py
==================
da90449e;Mikhail Korobov;2015-03-18 07:24:15 +0500;typo fix in scrapy.contrib.pipeline.media

==

scrapy/contrib/pipeline/media.py
==================
d14c972e;Mikhail Korobov;2015-03-18 04:44:50 +0500;Merge pull request #1079 from kmike/feed-iterate-spider-output
CSVFeedSpider cleanup: use iterate_spider_output
==
==================
3f15b6df;Pablo Hoffman;2015-03-17 16:36:43 -0300;Merge pull request #1078 from kmike/iter-spider-output
remove unnecessary check from scrapy.utils.spider.iter_spider_output
==
==================
69749023;Mikhail Korobov;2015-03-17 23:31:29 +0500;CSVFeedSpider cleanup: use iterate_spider_output
A similar fix was made for XMLFeedSpider in https://github.com/scrapy/scrapy/commit/95fde0a4987acaa75a6749223c8b7f9bd7081c23

==

scrapy/contrib/spiders/feed.py
==================
8ce4ad06;Mikhail Korobov;2015-03-17 23:07:39 +0500;remove unnecessary check from scrapy.utils.spider.iter_spider_output
arg_to_iter handles Items since https://github.com/scrapy/scrapy/commit/2bbd92742b796e1a565d4914a77889c884dd01ac

==

scrapy/utils/spider.py
==================
62c4481d;Mikhail Korobov;2015-03-17 22:42:31 +0500;Merge pull request #992 from chekunkov/pydispatch_pep8
Pydispatch pep8
==
==================
934584a3;Pablo Hoffman;2015-03-17 14:32:06 -0300;Merge pull request #1020 from jojje/gzip_http_cache
[MRG+1] add gzip compression to filesystem http cache backend
==
==================
fd67fe27;Elias Dorneles;2015-03-17 09:34:54 -0300;using default values for settings that are off by default

==

scrapy/templates/project/module/settings.py.tmpl
==================
f9245675;Pablo Hoffman;2015-03-17 01:07:47 -0300;Merge pull request #983 from ArturGaspar/linkextractor_css
[MRG+1] CSS support in link extractors
==
==================
b461c6f1;Pablo Hoffman;2015-03-17 01:04:36 -0300;Merge pull request #821 from nramirezuy/httpcache_dont_cache-19-689
[MRG+1] httpcache dont_cache meta #19 #689
==
==================
f52b1de6;Daniel Graña;2015-03-16 23:55:15 -0300;Merge pull request #1077 from kmike/contribute-to-master
DOC contribute to master branch
==
==================
05cb31d3;Alexander Chekunkov;2014-12-19 21:06:58 +0200;pydispatch - pep8
reformat files - proper spacing

==

scrapy/xlib/pydispatch/dispatcher.py
scrapy/xlib/pydispatch/errors.py
scrapy/xlib/pydispatch/robust.py
scrapy/xlib/pydispatch/robustapply.py
scrapy/xlib/pydispatch/saferef.py
==================
64082b46;Mikhail Korobov;2015-03-17 01:46:45 +0500;DOC contribute to master branch
See GH-975 and GH-1029.

==

README.rst
==================
aa56dd30;Elias Dorneles;2015-03-16 17:36:46 -0300;updating new settings to template, as pointed in PR review

==

scrapy/templates/project/module/settings.py.tmpl
==================
c13e2364;nramirezuy;2014-07-28 17:58:56 -0300;httpcache dont_cache meta #19 #689

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
scrapy/contrib/downloadermiddleware/httpcache.py
tests/test_downloadermiddleware_httpcache.py
==================
05a88152;Elias Dorneles;2015-03-14 16:12:37 -0300;adding more settings to project template

==

scrapy/templates/project/module/settings.py.tmpl
==================
c1bf8365;Mikhail Korobov;2015-03-13 16:40:47 +0500;Merge pull request #1022 from scrapy/docs-reorder
DOC reorder topics
==
==================
baf5c593;Mikhail Korobov;2015-03-13 16:38:19 +0500;Merge pull request #1071 from eliasdorneles/updating-request-meta-special-keys
updating list of Request.meta special keys
==
==================
57a5ee00;Elias Dorneles;2015-03-12 23:20:44 -0300;added example value to set for proxy meta key

==

docs/topics/downloader-middleware.rst
==================
f7031c08;Elias Dorneles;2015-03-10 22:29:07 -0300;updating list of Request.meta special keys

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
==================
645366a0;Mikhail Korobov;2015-03-08 22:54:57 +0500;Merge pull request #1070 from berkerpeksag/items-equal
assertItemsEqual was renamed to assertCountEqual in Python 3.
==
==================
671d0a75;Mikhail Korobov;2015-03-08 22:07:22 +0500;Merge pull request #1066 from berkerpeksag/mock-import
Import unittest.mock if available.
==
==================
c86e1beb;Berker Peksag;2015-03-08 15:18:49 +0200;assertItemsEqual was renamed to assertCountEqual in Python 3.

==

tests/test_settings/__init__.py
==================
31e5f164;Berker Peksag;2015-03-06 15:45:04 +0200;Import unittest.mock if available.
mock is in the stdlib since Python 3.3.

==

tests/__init__.py
tests/test_crawl.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_pipeline_files.py
tests/test_settings/__init__.py
tests/test_spider.py
tests/test_utils_deprecate.py
tox.ini
==================
c9d7386a;Daniel Graña;2015-02-25 18:03:53 -0200;Add 0.24.5 release notes

==

docs/news.rst
==================
839ffba9;Sudhanshu Shekhar;2015-01-14 02:31:03 +0530;Added the first version of SelectJmes
Utilizes jmespath. Also, added tests and documentation for the same.

==

docs/topics/loaders.rst
scrapy/contrib/loader/processor.py
tests/requirements.txt
tests/test_contrib_loader.py
==================
ee179029;Julia Medina;2015-02-16 16:16:42 -0300;Merge pull request #1049 from scrapy/twisted-15-support
Twisted 15.0.0 Support
==
==================
d67ca77e;Julia Medina;2015-02-15 21:14:47 -0300;Support new _getEndpoint Agent signatures on Twisted 15.0.0

==

scrapy/core/downloader/handlers/http11.py
==================
7a745b10;Mikhail Korobov;2015-02-10 15:03:34 +0500;Merge pull request #1044 from klangner/master
py3-ignores.txt supports comments
==
==================
a0299d97;klangner@gmail.com;2015-02-10 10:34:44 +0100;fixed variable name

==

conftest.py
==================
5ea4a72b;klangner;2015-02-09 10:28:22 +0100;py3-ignores.txt supports comments

==

.gitignore
conftest.py
==================
75f1560f;Mikhail Korobov;2015-02-04 15:43:00 +0500;Merge pull request #1033 from maikroeder/patch-1
DOC typo fix in form.py
==
==================
721d8d5d;Maik Röder;2015-02-04 11:38:37 +0100;Update form.py
Typo fixed
==

scrapy/http/request/form.py
==================
6419f76b;Mikhail Korobov;2015-02-03 02:10:47 +0500;Merge pull request #1029 from dangra/contribute-to-master
DOC contribute to master branch
==
==================
8a3b9b61;Nicolás Alejandro Ramírez Quiros;2015-01-30 15:45:52 -0200;Merge pull request #1011 from SudShekhar/master
Extension example fix to something that makes more sense
==
==================
e42a1ac1;Sudhanshu Shekhar;2015-01-14 02:31:03 +0530;Reset items_scraped instead of item_count
items_scraped is the counter that needs to be reset each time we have scraped a specific number of items in the code instead of item_count (which represents the specific number of items needed before a message is logged). Updating the source code to reflect this.
Removed some irrelevant words from the log message.
Signed-off-by: Sudhanshu Shekhar <sudshekhar02@gmail.com>

==

docs/topics/extensions.rst
==================
f0bdc145;Daniel Graña;2015-01-29 15:40:12 -0200;Tentative attention message about what document to read for contributions

==

docs/contributing.rst
==================
074b4a93;Daniel Graña;2015-01-29 14:53:37 -0200;Contribute to master branch
ref #975

==

CONTRIBUTING.md
==================
a07b4353;Mikhail Korobov;2015-01-22 22:58:10 +0500;DOC reorder topics
* duplicate "topics/commands" link is removed;
* Request/Response docs are moved to "Basic Concepts";
* settings docs are moved to "Basic Concepts";
* exceptions docs are moved to "Basic Concepts";
* "signals" and "exporters" docs are moved to "Extending Scrapy";
* "Reference" section is dropped because it is empty now.

==

docs/index.rst
==================
bd5d99a2;Jonas Tingeborn;2015-01-21 20:18:11 +0100;add gzip compression to filesystem http cache backend

==

docs/topics/downloader-middleware.rst
scrapy/contrib/httpcache.py
scrapy/settings/default_settings.py
tests/test_downloadermiddleware_httpcache.py
==================
21839848;Nicolás Alejandro Ramírez Quiros;2015-01-19 18:12:02 -0200;Merge pull request #1018 from barraponto/dynamic_item_practice_docs
Updates documentation on dynamic item classes.
==
==================
4bc14da5;Capi Etheriel;2015-01-19 17:21:55 -0200;Updates documentation on dynamic item classes.
Fixes #398

==

docs/topics/practices.rst
==================
283d6a53;Mikhail Korobov;2015-01-19 22:07:03 +0500;DOC a couple more references are fixed

==

docs/topics/spider-middleware.rst
==================
73e6b356;Mikhail Korobov;2015-01-19 22:02:46 +0500;DOC fix a reference

==

docs/topics/spider-middleware.rst
==================
5bcb6524;Daniel Graña;2015-01-19 13:57:18 -0200;Merge pull request #1017 from Curita/external-url-fix
Don't rely on external urls for tests
==
==================
d68615a5;Julia Medina;2015-01-19 10:28:25 -0300;Test the parse command locally instead of against an external url

==

scrapy/utils/testsite.py
tests/test_commands.py
==================
f3110aae;Daniel Graña;2014-12-31 01:52:44 -0200;Merge pull request #999 from Curita/fix-985
Patch hanging HTTPConnectionPool.closeCachedConnections call
==
==================
09ba4ff6;Julia Medina;2014-12-30 19:53:50 -0300;Patches Twisted issue while closing the connection pool on HTTPDownloadHandler

==

scrapy/core/downloader/handlers/http11.py
==================
79c32748;Nicolás Alejandro Ramírez Quiros;2014-12-17 11:28:59 -0200;Merge pull request #987 from nyov/nyov/resolver
t.i.b.ThreadedResolver is now a new-style class
==
==================
880c9e52;nyov;2014-12-16 19:28:39 +0000;t.i.b.ThreadedResolver is now a new-style class
since 2009 / twisted-9.0.0
https://github.com/twisted/twisted/commit/663d669dce6ee5009eee8c6d2a81f5199855178b

==

scrapy/resolver.py
==================
78954bc7;Pablo Hoffman;2014-12-15 17:15:11 -0200;Merge pull request #978 from immerrr/fix-s3-authorization-for-quoted-paths
S3DownloadHandler: fix auth for requests with quoted paths/query params
==
==================
82d138e8;tpeng;2014-12-01 14:15:15 +0100;support namespace prefix in xmliter_lxml

==

scrapy/contrib_exp/iterators.py
tests/test_utils_iterators.py
==================
22247cf7;Artur Gaspar;2014-12-15 09:18:15 -0200;move restrict_css argument to end of argument list in link extractors for backwards compatibility, use keyword arguments in link extractor super().__init__() calls

==

scrapy/contrib/linkextractors/lxmlhtml.py
scrapy/contrib/linkextractors/sgml.py
scrapy/linkextractor.py
==================
b0730a1d;Artur Gaspar;2014-12-11 18:22:08 -0200;documentation for CSS support in link extractors

==

docs/topics/link-extractors.rst
==================
403fc686;Artur Gaspar;2014-12-11 18:20:30 -0200;tests for CSS support in link extractors

==

tests/test_contrib_linkextractors.py
==================
d4cb03ed;Artur Gaspar;2014-12-11 16:45:20 -0200;add CSS support for link extractors

==

scrapy/contrib/linkextractors/lxmlhtml.py
scrapy/contrib/linkextractors/sgml.py
scrapy/linkextractor.py
==================
82b187f2;immerrr;2014-12-11 17:49:20 +0300;S3DownloadHandler: fix auth for requests with quoted paths/query params

==

scrapy/core/downloader/handlers/s3.py
tests/test_downloader_handlers.py
==================
c485a055;Mikhail Korobov;2014-12-11 03:02:33 +0500;Merge pull request #976 from aufziehvogel/fixed_mailsender_vartypes
fixed the variable types in mailsender documentation
==
==================
3602fc4f;Stefan;2014-12-10 22:48:09 +0100;fixed the variable types in mailsender documentation

==

docs/topics/email.rst
==================
1b03b129;Pablo Hoffman;2014-12-02 19:46:43 -0200;Merge pull request #961 from ldmberman/task_977_request_dropped
An attempt to resolve #957, add signal to be sent when request is dropped by the scheduler  
==
==================
fdb6bb07;Lev Berman;2014-11-28 10:53:33 +0300;#977 - test dropping requests

==

tests/test_engine.py
==================
e04b0aff;Lev Berman;2014-11-27 15:10:15 +0300;An attempt to resolve #977, add signal to be sent when request is dropped by the scheduler

==

docs/topics/signals.rst
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/signals.py
tests/test_engine.py
==================
c31fb873;Pablo Hoffman;2014-11-26 17:14:18 -0200;Merge pull request #954 from kalessin/int-download-timeout
Force to read DOWNLOAD_TIMEOUT as int (for example to pass using environment variable)
==
==================
dedea727;Pablo Hoffman;2014-11-25 17:57:55 -0200;Merge pull request #946 from tpeng/limit-response-size
avoid download large response
==
==================
cd193827;tpeng;2014-11-25 14:09:51 +0100;attemp to fix travis fails

==

tests/mockserver.py
tests/test_downloader_handlers.py
==================
8d8e1b2c;Daniel Graña;2014-11-21 12:15:02 -0200;mitmproxy 0.10.1 needs netlib 0.10.1 too

==

tests/requirements.txt
==================
314db3db;Daniel Graña;2014-11-21 10:54:43 -0200;pin mitmproxy 0.10.1 as >0.11 does not work with tests

==

tests/requirements.txt
==================
7910fa01;Martin Olveyra;2014-11-21 01:09:32 -0200;Force to read DOWNLOAD_TIMEOUT as int (for example to pass using environment variable)

==

scrapy/contrib/downloadermiddleware/downloadtimeout.py
tests/test_downloadermiddleware_downloadtimeout.py
==================
a69f042d;tpeng;2014-11-19 11:50:07 +0100;add 2 more test cases and minor doc fixes

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
tests/mockserver.py
tests/test_downloader_handlers.py
==================
fa84730e;tpeng;2014-11-12 12:28:02 +0100;avoid download large response
introduce DOWNLOAD_MAXSIZE and DOWNLOAD_WARNSIZE in settings and
download_maxsize/download_warnsize in spider/request meta, so
downloader stop downloading as soon as the received data exceed the
limit. also check the twsisted response's length in advance to stop
downloading as early as possible.

==

docs/topics/settings.rst
scrapy/core/downloader/handlers/http11.py
scrapy/settings/default_settings.py
tests/test_downloader_handlers.py
==================
ed84231b;Pablo Hoffman;2014-11-10 14:03:00 -0200;Merge pull request #944 from JeffPaine/patch-1
Update docs copyright year range
==
==================
b422312a;Jeff Paine;2014-11-09 21:08:27 -0500;Update docs copyright year range

==

docs/conf.py
==================
13f83f0d;Lazar-T;2014-11-09 00:04:22 +0100;typo

==

docs/topics/autothrottle.rst
==================
b21a28cc;HalfCrazy;2014-11-06 00:48:11 +0800;Afterwords->Afterwards

==

docs/topics/loaders.rst
==================
2c67bd6c;Daniel Graña;2014-11-05 23:05:51 -0200;pywin32 is required by Twisted. closes #937
see:
* http://twistedmatrix.com/trac/ticket/6032
* https://tahoe-lafs.org/trac/tahoe-lafs/ticket/2028

==

docs/intro/install.rst
==================
6cb89957;Daniel Graña;2014-11-05 22:49:40 -0200;Update install.rst
fixes #937

==

docs/intro/install.rst
==================
efe589c6;Pablo Hoffman;2014-11-04 11:32:59 -0200;Merge pull request #882 from ahlen/feature/csvfeed-quotechar
[MRG+1] Allow to specify the quotechar in CSVFeedSpider
==
==================
38dcf50c;Lazar-T;2014-10-25 00:21:16 +0200;comma instead of fullstop

==

docs/topics/extensions.rst
==================
675fd5ba;Pablo Hoffman;2014-10-24 16:52:42 -0200;Merge pull request #898 from scrapy/download-timeout
[MRG] DOC document download_timeout 
==
==================
5de6a11f;Pablo Hoffman;2014-10-22 18:23:19 -0200;Merge pull request #925 from Digenis/master
a leftover for.15 compatibility
==
==================
22278056;Nikolaos-Digenis Karagiannis;2014-10-08 17:46:07 +0300;Compatibility with .15 leftover

==

scrapy/core/engine.py
==================
0dce2834;Pablo Hoffman;2014-10-21 17:13:59 -0200;Merge pull request #893 from kmike/less-ads
[MRG] DOC simplify extension docs
==
==================
44cbbecb;Daniel Graña;2014-10-09 14:58:36 -0200;Merge pull request #914 from brunsgaard/master
Deleted bin folder from root, fixes #913
==
==================
aa61f615;Pablo Hoffman;2014-10-07 20:57:48 -0200;Merge pull request #795 from chekunkov/spider_error_processing_referer
Add referer to "Spider error processing" log message
==
==================
db2474f7;Jonas Brunsgaard;2014-10-07 13:54:04 +0200;Deleted bin folder from root, fixes #913

==

bin/scrapy
==================
7d68b084;Mikhail Korobov;2014-09-23 02:59:35 +0600;DOC document download_timeout Request.meta key and download_timeout spider attribute.

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
docs/topics/settings.rst
==================
9af61d5d;Pablo Hoffman;2014-10-03 17:14:00 -0300;Merge pull request #895 from scrapy/we-are-past-0.15
[MRG] drop support for CONCURRENT_REQUESTS_PER_SPIDER
==
==================
5f1bbe2d;Pablo Hoffman;2014-10-03 17:13:17 -0300;Merge pull request #911 from nyov/nyov/dev
Drop old engine code
==
==================
7db6bbce;nyov;2014-10-03 18:41:29 +0000;Drop old engine code
  * remove Downloader import unused since 1fba64
  * remove CONCURRENT_SPIDERS deprecation warning from a1dbc6 (2011)

==

scrapy/core/engine.py
==================
14957ed7;Mikhail Korobov;2014-10-03 16:30:39 +0600;Merge pull request #909 from VKen/master
updated deprecated cgi.parse_qsl to use six's parse_qsl
==
==================
33a7c1d4;VKen;2014-10-03 04:16:21 +0800;updated deprecated cgi.parse_qsl to use six's parse_qsl

==

scrapy/utils/url.py
==================
ea3b372b;Mikhail Korobov;2014-10-02 15:20:13 +0600;DOC typo fix in leaks.rst

==

docs/topics/leaks.rst
==================
993b543e;Pablo Hoffman;2014-10-02 01:17:26 -0300;mark SEP-019 as Final

==

sep/sep-019.rst
==================
e7843d35;Pablo Hoffman;2014-10-02 01:14:54 -0300;Merge pull request #894 from kmike/leaks-docs
Leaks docs
==
==================
5835224e;Pablo Hoffman;2014-10-02 00:58:55 -0300;Merge pull request #896 from scrapy/robotstxt-once
[MRG] process robots.txt once
==
==================
9e2c6043;Pablo Hoffman;2014-10-02 00:33:27 -0300;Merge pull request #902 from scrapy/load_object_full_traceback
[MRG] scrapy.utils.misc.load_object should print full traceback
==
==================
0c23b134;Pablo Hoffman;2014-10-02 00:09:07 -0300;Merge pull request #904 from scrapy/from_crawler_docs
[MRG] DOC document from_crawler method for item pipelines
==
==================
6fcf9dce;Mikhail Korobov;2014-09-25 03:13:51 +0600;DOC document from_crawler method for item pipelines; add an example.

==

docs/topics/item-pipeline.rst
==================
50862629;Mikhail Korobov;2014-09-24 13:27:14 +0600;don't hide original exception in scrapy.utils.misc.load_object

==

scrapy/utils/misc.py
==================
36eec8f4;Mikhail Korobov;2014-09-23 00:10:43 +0600;dont_obey_robotstxt meta key; don't process requests to /robots.txt

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
scrapy/contrib/downloadermiddleware/robotstxt.py
tests/test_downloadermiddleware_robotstxt.py
==================
fe6f3efe;Mikhail Korobov;2014-09-22 22:56:54 +0600;RobotsTxtMiddleware: remove unused attribute

==

scrapy/contrib/downloadermiddleware/robotstxt.py
==================
d11c8595;Mikhail Korobov;2014-09-22 04:29:22 +0600;drop support for CONCURRENT_REQUESTS_PER_SPIDER

==

scrapy/core/downloader/__init__.py
==================
bdbca1e2;Mikhail Korobov;2014-09-21 07:30:44 +0600;DOC request queue memory usage

==

docs/topics/leaks.rst
==================
bc0f481a;Mikhail Korobov;2014-09-21 07:12:01 +0600;DOC bring back notes about multiple spiders per process because it is now documented how to do that

==

docs/topics/leaks.rst
docs/topics/practices.rst
==================
a122fdbf;Mikhail Korobov;2014-01-15 17:39:54 +0600;Update leaks.rst: there is now only a single spider in a process.

==

docs/topics/leaks.rst
==================
7be3479c;Mikhail Korobov;2014-09-21 06:37:32 +0600;CookieJar cleanup

==

scrapy/http/cookies.py
==================
49645d4b;Mikhail Korobov;2014-09-21 05:31:34 +0600;TST small cleanup of a cookie test

==

tests/test_downloadermiddleware_cookies.py
==================
c543fe6e;Mikhail Korobov;2014-09-21 05:24:54 +0600;Merge pull request #878 from andrewshir/master
Fix bug for ".local" host name
==
==================
e435b3e3;Mikhail Korobov;2014-09-21 00:19:24 +0600;DOC simplify extension docs

==

docs/topics/downloader-middleware.rst
docs/topics/extensions.rst
docs/topics/item-pipeline.rst
docs/topics/spider-middleware.rst
==================
a312ebfb;John-Scott Atlakson;2014-09-14 10:54:43 -0400;Update request-response.rst
Fixed minor typo

==

docs/topics/request-response.rst
==================
e583c030;andrewshir;2014-09-14 14:24:16 +0600;Test for local domains (without dots) added

==

tests/test_downloadermiddleware_cookies.py
==================
22da1783;Mikael Åhlén;2014-09-13 03:47:40 +0200;added a test-case for wrong quotechar

==

tests/test_utils_iterators.py
==================
47b6dff9;Mikael Åhlén;2014-09-13 02:14:57 +0200;Allow to specify the quotechar in CSVFeedSpider

==

docs/topics/spiders.rst
scrapy/contrib/spiders/feed.py
scrapy/utils/iterators.py
tests/sample_data/feeds/feed-sample6.csv
tests/test_utils_iterators.py
==================
5bcabfe9;Daniel Graña;2014-09-10 23:25:57 -0300;SPIDER_MODULES can be set as a csv string

==

scrapy/spidermanager.py
tests/test_spidermanager/__init__.py
==================
c05e99a4;Daniel Graña;2014-09-10 12:21:08 -0300;oops, restore Pillow from precise test requirements

==

tox.ini
==================
a823207f;Daniel Graña;2014-09-10 12:09:07 -0300;Stop logobserver only when set

==

scrapy/crawler.py
tox.ini
==================
ec93c0fd;Daniel Graña;2014-09-10 12:05:18 -0300;Add the tests changes for previous commit

==

tests/test_crawler.py
==================
ce180227;Daniel Graña;2014-09-10 12:04:14 -0300;Twisted 11.1.0 (precise) can not deal with generators in DeferredList
Also create a list of the crawlers before iterating them because crawlers are removed from the set once stopped

==

scrapy/crawler.py
==================
99971dc8;Daniel Graña;2014-09-09 20:59:07 +0000;Do not pop the crawler from the managed list

==

tests/test_crawler.py
==================
774aa9ee;Daniel Graña;2014-09-09 17:23:11 -0300;Merge branch 'crawler-api'

==
==================
8ddf0811;Daniel Graña;2014-09-02 18:07:32 -0300;Correctly detect when all managed crawlers are done in CrawlerRunner

==

scrapy/commands/shell.py
scrapy/crawler.py
==================
68954fa5;Daniel Graña;2014-09-08 14:32:06 -0300;Merge pull request #879 from Curita/fix-874-issue
Fix #874 issue
==
==================
51532af6;Julia Medina;2014-09-07 13:03:34 -0300;Erase unneeded flag in CrawlerProcess.start

==

scrapy/commands/shell.py
scrapy/crawler.py
==================
d513b5a5;Julia Medina;2014-09-07 13:02:39 -0300;Run root logger in CrawlerProcess creation instead of in its start method

==

scrapy/crawler.py
==================
dfca7b3c;andrewshir;2014-09-06 18:23:27 +0600;Fix bug for ".local" host name
It's necessary to put new list member in squared brackets (i.e. create new list) to merge lists properly, otherwise we will get result list with character elements instead of string element.
==

scrapy/http/cookies.py
==================
acb0a61c;Pablo Hoffman;2014-09-02 12:55:04 -0300;Merge pull request #871 from eltermann/master
Removed unused 'load=False' parameter from walk_modules()
==
==================
1dff1fbf;eltermann;2014-09-02 08:33:36 -0300;Removed unused 'load=False' parameter from walk_modules()

==

scrapy/utils/misc.py
==================
5daa1477;Daniel Graña;2014-09-01 21:58:13 -0300;Merge branch 'Curita-per-spider-settings'

==
==================
c2592b39;Julia Medina;2014-08-14 14:17:18 -0300;Test verifying that CrawlerRunner populates spider class settings

==

tests/test_crawler.py
==================
77bd26a6;Julia Medina;2014-08-14 14:01:12 -0300;Non mutable default in Spider.custom_settings

==

scrapy/spider.py
==================
16e62e9c;Julia Medina;2014-08-13 01:42:34 -0300;Per-spider settings documentation

==

docs/topics/api.rst
docs/topics/settings.rst
docs/topics/spiders.rst
==================
9ef3972c;Julia Medina;2014-08-13 01:41:50 -0300;Per-spider settings tests

==

tests/test_spider.py
==================
4932ec43;Julia Medina;2014-08-13 01:41:16 -0300;Per-spider settings implementation

==

scrapy/crawler.py
scrapy/settings/__init__.py
scrapy/spider.py
==================
ccde3317;Daniel Graña;2014-09-01 21:55:36 -0300;Merge pull request #816 from Curita/api-cleanup
GSoC API cleanup
==
==================
620dbe71;Pablo Hoffman;2014-08-29 16:18:44 -0300;Merge pull request #865 from yakxxx/master
SgmlLinkExtractor - fix for parsing <area> tag with Unicode present
==
==================
8aa731c8;Mikhail Korobov;2014-08-29 06:59:47 +0600;Merge pull request #866 from adamdonahue/patch-1
Fix typo
==
==================
d92914d2;Adam Donahue;2014-08-28 20:30:50 -0400;Fix typo

==

scrapy/utils/trackref.py
==================
e4689556;yakxxx;2014-08-28 18:47:49 +0200;SgmlLinkExtractor - fix for parsing <area> tag with Unicode present

==

scrapy/contrib/linkextractors/sgml.py
tests/test_contrib_linkextractors.py
==================
774ab74a;Mikhail Korobov;2014-08-28 18:52:51 +0600;Merge pull request #864 from younghz/master
Duplicate comma in request-response.rst
==
==================
d49766a6;Uyounghz;2014-08-28 19:58:58 +0800;Duplicate comma in request-response.rst

==

docs/topics/request-response.rst
==================
2a540206;nramirezuy;2014-08-19 13:57:00 -0300;fix xmliter namespace on selected node

==

scrapy/utils/iterators.py
tests/test_utils_iterators.py
==================
c4f9e9d8;Mikhail Korobov;2014-08-20 00:16:33 +0600;Merge pull request #856 from eliasdorneles/fix-embed-ipython-shell
fix IPython shell scope issue by using IPython.embed()
==
==================
8360380d;Pablo Hoffman;2014-08-19 10:30:25 -0300;removed scrapy-ws.py, moved to scrapy-jsonrpc package

==

extras/scrapy-ws.py
==================
6f50cf55;Elias Dorneles;2014-08-13 21:39:31 -0300;fix IPython shell scope issue and load IPython user config

==

scrapy/utils/console.py
==================
841dd5f1;Daniel Graña;2014-08-18 17:48:01 -0300;Update webservice.rst

==

docs/topics/webservice.rst
==================
d684ecad;Daniel Graña;2014-08-18 13:54:11 -0300;Merge pull request #846 from rocioar/master
fix dont_merge_cookies bad behaviour when set to false on meta
==
==================
94d00b2a;Daniel Graña;2014-08-15 23:28:26 -0300;Merge branch 'jsonrpc-split'

==
==================
a9292cfa;Daniel Graña;2014-08-15 15:32:54 -0300;jsonrpc webservice moved to https://github.com/scrapy/scrapy-jsonrpc repository

==

docs/intro/overview.rst
docs/topics/extensions.rst
docs/topics/settings.rst
docs/topics/webservice.rst
scrapy/contrib/webservice/__init__.py
scrapy/contrib/webservice/crawler.py
scrapy/contrib/webservice/enginestatus.py
scrapy/contrib/webservice/stats.py
scrapy/settings/default_settings.py
scrapy/utils/jsonrpc.py
scrapy/utils/serialize.py
scrapy/utils/txweb.py
scrapy/webservice.py
tests/test_utils_jsonrpc.py
tests/test_utils_serialize.py
==================
51b0bd28;Rocio Aramberri;2014-08-15 13:44:29 -0700;fix dont settings on meta behaviour, add docs and tests

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
tests/test_downloadermiddleware_cookies.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_retry.py
==================
6339864f;Julia Medina;2014-08-14 12:32:37 -0300;Minor refactor in the docs and functions used in the shell command

==

scrapy/commands/shell.py
scrapy/crawler.py
==================
70f2010d;Julia Medina;2014-08-14 11:59:25 -0300;Change error type when updating frozen settings

==

scrapy/settings/__init__.py
tests/test_settings/__init__.py
==================
3547ca6e;Julia Medina;2014-08-14 11:50:33 -0300;Add example on running spiders outside projects

==

docs/topics/practices.rst
==================
41902661;Julia Medina;2014-08-14 09:19:41 -0300;Deprecate Crawler.spiders attribute

==

docs/topics/api.rst
scrapy/crawler.py
tests/py3-ignores.txt
tests/test_crawler.py
==================
c90977ca;Julia Medina;2014-08-08 06:15:20 -0300;Drop support for scrapy.project.crawler (And scrapy.stats consequently)

==

conftest.py
docs/faq.rst
docs/topics/shell.rst
scrapy/crawler.py
scrapy/project.py
scrapy/shell.py
scrapy/spider.py
scrapy/stats.py
tests/test_engine.py
==================
9cbbfd8b;Julia Medina;2014-08-06 08:51:12 -0300;Adjust spiders' utils to new SpiderManager API

==

scrapy/commands/fetch.py
scrapy/commands/parse.py
scrapy/commands/shell.py
scrapy/shell.py
scrapy/utils/spider.py
==================
900a4876;Julia Medina;2014-08-05 21:01:57 -0300;Support multiple simultaneous LogObservers listening different crawlers

==

docs/topics/logging.rst
scrapy/crawler.py
scrapy/log.py
tests/test_log.py
==================
89df18bd;Julia Medina;2014-07-31 10:16:25 -0300;Fix usage of crawler_process in ScrapyCommands

==

scrapy/commands/bench.py
scrapy/commands/check.py
scrapy/commands/crawl.py
scrapy/commands/edit.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/runspider.py
scrapy/contracts/__init__.py
==================
d0edad4b;Julia Medina;2014-07-31 10:10:25 -0300;Drop support for ScrapyCommand.crawler property

==

scrapy/command.py
==================
870438e5;Julia Medina;2014-07-31 04:12:12 -0300;Update tests utils, fixing get_crawler and removing docrawl

==

scrapy/utils/test.py
tests/py3-ignores.txt
tests/test_closespider.py
tests/test_crawl.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware.py
tests/test_downloadermiddleware_ajaxcrawlable.py
tests/test_downloadermiddleware_defaultheaders.py
tests/test_downloadermiddleware_downloadtimeout.py
tests/test_downloadermiddleware_httpcache.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_retry.py
tests/test_downloadermiddleware_stats.py
tests/test_downloadermiddleware_useragent.py
tests/test_engine.py
tests/test_proxy_connect.py
tests/test_spider.py
tests/test_spidermiddleware_depth.py
tests/test_spidermiddleware_httperror.py
tests/test_spidermiddleware_offsite.py
tests/test_stats.py
==================
d4027356;Julia Medina;2014-07-30 05:35:18 -0300;CrawlerProcess cleanup changes

==

docs/topics/api.rst
docs/topics/practices.rst
scrapy/crawler.py
==================
980e30a1;Julia Medina;2014-07-29 17:46:42 -0300;Crawler interface cleanup

==

docs/topics/api.rst
scrapy/crawler.py
==================
d7038b2a;Julia Medina;2014-07-17 10:25:07 -0300;SpiderManager interface cleanup

==

docs/topics/api.rst
docs/topics/settings.rst
scrapy/interfaces.py
scrapy/spidermanager.py
tests/test_spidermanager/__init__.py
tests/test_spidermanager/test_spiders/spider4.py
==================
39c6a80f;Julia Medina;2014-08-01 00:42:25 -0300;Both getdict and getlist return copies of the requested values

==

docs/topics/api.rst
scrapy/settings/__init__.py
==================
3ae97146;Julia Medina;2014-07-29 18:47:49 -0300;Add Settings.copy, freeze and frozencopy method

==

docs/topics/api.rst
scrapy/settings/__init__.py
tests/test_settings/__init__.py
==================
a9957271;Julia Medina;2014-07-17 10:49:15 -0300;Connect spider_closed signal after a crawler is bound to a Spider

==

scrapy/spider.py
tests/test_spider.py
==================
eb0253e5;Julia Medina;2014-06-30 03:20:05 -0300;Update from_crawler method as well as set_crawler on CrawlSpider

==

scrapy/contrib/spiders/crawl.py
tests/test_spider.py
==================
84fa0047;Julia Medina;2014-06-30 01:35:58 -0300;Add from_crawler class method to base Spider

==

docs/topics/spiders.rst
scrapy/spider.py
tests/test_spider.py
==================
8fece4b0;Daniel Graña;2014-08-09 17:19:39 -0300;Add 0.24.4 release notes

==

docs/news.rst
==================
02dd4a56;Daniel Graña;2014-08-09 00:44:48 -0300;fix requirement typo

==

tox.ini
==================
37787081;Daniel Graña;2014-08-09 00:37:08 -0300;precise ships zope.interface 3.6.1

==

tox.ini
==================
4badcc07;Daniel Graña;2014-08-09 00:30:52 -0300;Add 0.24.3 release notes

==

docs/news.rst
==================
0254f587;Daniel Graña;2014-08-08 18:09:43 -0300;Merge branch 'moderm-setuppy'

==
==================
0772201a;Daniel Graña;2014-08-08 18:07:38 -0300;Update installation docs

==

docs/intro/install.rst
==================
029c51ac;Daniel Graña;2014-08-05 14:43:13 -0300;There is a trove classifier for Scrapy framework!
Added by https://bitbucket.org/pypa/pypi/issue/179

==

setup.py
==================
c2497e66;Shane;2014-08-05 12:31:20 +0100;Merge pull request #841 from cyberplant/patch-1
Fixed buildbot tests, after 242c085
==
==================
5e87ed64;Luar Roji;2014-08-05 04:15:25 -0700;Fixed buildbot tests, after 242c085

==

Makefile.buildbot
==================
3e1d157b;Daniel Graña;2014-08-04 15:58:13 -0300;Merge branch 'master' of https://github.com/scrapy/scrapy

==
==================
9fb7b36a;Daniel Graña;2014-08-04 15:57:13 -0300;Merge branch 'w3lib-warnings'

==
==================
3b64b244;Daniel Graña;2014-08-04 15:56:41 -0300;update other places where w3lib version is mentioned

==

debian/control
requirements.txt
tox.ini
==================
69a665eb;Pablo Hoffman;2014-08-04 15:20:51 -0300;Merge pull request #832 from ivannotes/master
Bugfix for leaking Proxy-Authorization header to targeted host
==
==================
511a2697;Daniel Graña;2014-08-04 11:55:35 -0300;Merge pull request #817 from nramirezuy/fix-startproject-project-name
[MRG] Fix startproject project name
==
==================
480cfa19;Paul Tremberth;2014-08-04 16:01:28 +0200;Update w3lib requirement to 1.8.0

==

setup.py
==================
928e7f29;Paul Tremberth;2014-08-03 12:02:25 +0200;Use w3lib.html.replace_entities() (remove_entities() is deprecated)

==

scrapy/contrib/downloadermiddleware/ajaxcrawl.py
scrapy/contrib/linkextractors/regex.py
scrapy/utils/misc.py
==================
fcd34b65;Daniel Graña;2014-08-01 16:26:08 -0300;set zip_safe=False

==

setup.py
==================
1fc4e59c;Daniel Graña;2014-08-01 16:23:37 -0300;do not ship tests package

==

setup.py
==================
f35fac11;Daniel Graña;2014-08-01 16:23:26 -0300;scrapy.bat is not needed anymore

==

extras/scrapy.bat
==================
a8f45dc6;Daniel Graña;2014-08-01 15:29:59 -0300;Modernize setup.py

==

Makefile.buildbot
scrapy/core/downloader/handlers/ftp.py
setup.py
==================
e62bbf07;Mikhail Korobov;2014-08-02 00:24:32 +0600;PY3 top-level shortcuts work

==

scrapy/__init__.py
tests/py3-ignores.txt
==================
ee21eaa6;Daniel Graña;2014-08-01 15:19:36 -0300;Merge pull request #835 from scrapy/modernize-asserts
[MRG] modernize some of the asserts
==
==================
1f59a69a;Mikhail Korobov;2014-08-02 00:16:01 +0600;PY3 port scrapy.link

==

scrapy/link.py
tests/py3-ignores.txt
tests/test_link.py
==================
628a8d8a;Mikhail Korobov;2014-08-01 23:44:23 +0600;TST modernize some of the asserts

==

tests/test_contrib_feedexport.py
tests/test_log.py
tests/test_middleware.py
tests/test_utils_defer.py
tests/test_utils_python.py
tests/test_utils_signal.py
==================
53e74a69;nramirezuy;2014-07-25 15:02:15 -0300;exitcode and prints fixed, some code reworking

==

scrapy/commands/startproject.py
==================
08224c92;Nuno Maximiano;2013-10-18 14:46:55 +0100;add project name validation

==

scrapy/commands/startproject.py
tests/test_commands.py
==================
e2c12268;Mikhail Korobov;2014-08-01 23:28:28 +0600;PY3 port scrapy.contrib.feedexport

==

scrapy/contrib/feedexport.py
tests/py3-ignores.txt
tests/test_contrib_feedexport.py
==================
51bd9f7d;Mikhail Korobov;2014-08-01 23:12:52 +0600;TST enable doctests for Python 3

==

conftest.py
tests/py3-ignores.txt
tox.ini
==================
444052a2;Mikhail Korobov;2014-08-01 22:56:03 +0600;PY3 port scrapy.utils.misc.arg_to_iter; fix scrapy.utils.misc.md5sum doctest

==

scrapy/utils/misc.py
tests/py3-ignores.txt
==================
83432184;Mikhail Korobov;2014-08-01 16:53:18 +0600;PY3 enable more tests

==

tests/py3-ignores.txt
tests/test_spidermiddleware_offsite.py
==================
669b62c7;Mikhail Korobov;2014-08-01 16:43:39 +0600;PY3 port scrapy.utils.spider

==

scrapy/spidermanager.py
scrapy/utils/spider.py
tests/py3-ignores.txt
tests/test_utils_spider.py
==================
560c32d3;Mikhail Korobov;2014-08-01 16:17:40 +0600;PY3 fix test_utils_sitemap.
Sitemap class is only initialized with bytes by Scrapy;
broken tests was only a testing issue.

==

tests/py3-ignores.txt
tests/test_utils_sitemap.py
==================
33074341;Mikhail Korobov;2014-08-01 16:10:34 +0600;PY3 enable more tests

==

tests/py3-ignores.txt
==================
7183a87c;Mikhail Korobov;2014-08-01 15:51:57 +0600;Merge pull request #828 from dangra/string-headers
normalize header values to bytes (and PY3)
==
==================
4161a8c8;Daniel Graña;2014-08-01 02:34:14 -0300;lint scrapy/http/request/*.py

==

scrapy/http/request/__init__.py
scrapy/http/request/form.py
==================
ccae4981;Daniel Graña;2014-08-01 02:33:24 -0300;PY3: port scrapy/utils/httpobj.py

==

scrapy/http/request/__init__.py
tests/py3-ignores.txt
==================
c564334d;Daniel Graña;2014-08-01 02:25:33 -0300;PY3: port scrapy/utils/gz.py

==

tests/py3-ignores.txt
tests/test_utils_gz.py
==================
910d0d36;Daniel Graña;2014-08-01 02:20:34 -0300;PY3: port scrapy/utils/conf.py

==

scrapy/utils/conf.py
tests/py3-ignores.txt
==================
521303e2;Daniel Graña;2014-08-01 02:10:57 -0300;fix ftp test cases

==

tests/test_downloader_handlers.py
==================
f42b44b5;Daniel Graña;2014-07-30 16:54:02 -0300;normalize header values to bytes

==

scrapy/http/headers.py
tests/py3-ignores.txt
tests/test_http_headers.py
==================
484a0159;ivannotes;2014-08-01 09:25:13 +0800;Add test case for tunneling proxy

==

tests/test_proxy_connect.py
==================
c1a108b4;ivannotes;2014-08-01 09:22:58 +0800;Bugfix for leaking Proxy-Authorization header to remote host when using tunneling

==

scrapy/core/downloader/handlers/http11.py
==================
40cc875d;Mikhail Korobov;2014-08-01 03:28:05 +0600;PY3 MimeTypes wants files in text mode.
See http://hg.python.org/cpython/file/2766320bdb10/Lib/mimetypes.py#l202

before: 455 failed, 248 passed, 10 skipped, 8 warnings, 55 error in 88.36 seconds
after:  466 failed, 253 passed, 12 skipped, 8 warnings, 49 error in 90.15 seconds

==

scrapy/responsetypes.py
==================
7cd271eb;Daniel Graña;2014-07-31 17:30:45 -0300;remove more references to runtests.sh

==

tests/__init__.py
tox.ini
==================
d89fc50d;Daniel Graña;2014-07-31 14:24:03 -0300;Merge pull request #830 from dangra/py3-tests
[WIP] Prevent Python 3 port regressions
==
==================
70ee66ba;Daniel Graña;2014-07-30 19:41:12 -0300;Collect the list of packages not working on python3

==

.travis.yml
conftest.py
pytest.ini
tests/py3-ignores.txt
tests/spiders.py
tox.ini
==================
6c402d3c;Daniel Graña;2014-07-31 14:05:19 -0300;The sum up of travis-ci builds are taking like 50min to complete

==

.travis.yml
==================
8d1f2677;Daniel Graña;2014-07-31 13:47:01 -0300;Merge pull request #827 from dangra/tests-on-root
Move Test cases under project root dir 
==
==================
99fb4eb1;Daniel Graña;2014-07-31 12:50:07 -0300;fix requirements.txt for tests under precise

==

tox.ini
==================
1a96cd5a;Daniel Graña;2014-07-31 12:28:00 -0300;update tox usage on contributing.rst

==

docs/contributing.rst
==================
d63d55d9;Daniel Graña;2014-07-31 12:27:44 -0300;remove obsolete shell scripts used to run tests suite

==

bin/runtests.bat
bin/runtests.sh
==================
7a41ef41;Daniel Graña;2014-07-31 12:21:17 -0300;Fix bench command

==

scrapy/commands/bench.py
scrapy/utils/benchserver.py
==================
aaf531c7;Daniel Graña;2014-07-30 17:30:40 -0300;fix Twisted package name

==

tox.ini
==================
eb1cf303;Daniel Graña;2014-07-30 17:30:19 -0300;use pytest.ini to enable twisted plugin

==

pytest.ini
tox.ini
==================
caab9f29;Daniel Graña;2014-07-30 17:29:41 -0300;move tests requirements under tests dir

==

tests/requirements.txt
tox.ini
==================
242c0855;Daniel Graña;2014-07-30 16:53:28 -0300;move tests under root dir

==

MANIFEST.in
conftest.py
docs/contributing.rst
extras/coverage-report.sh
scrapy/commands/bench.py
scrapy/tests/test_cmdline/settings.py
scrapy/utils/url.py
tests/__init__.py
tests/keys/cert.pem
tests/keys/mitmproxy-ca.pem
tests/mocks/__init__.py
tests/mocks/dummydbm.py
tests/mockserver.py
tests/sample_data/compressed/feed-sample1.tar
tests/sample_data/compressed/feed-sample1.xml
tests/sample_data/compressed/feed-sample1.xml.bz2
tests/sample_data/compressed/feed-sample1.xml.gz
tests/sample_data/compressed/feed-sample1.zip
tests/sample_data/compressed/html-gzip.bin
tests/sample_data/compressed/html-rawdeflate.bin
tests/sample_data/compressed/html-zlibdeflate.bin
tests/sample_data/compressed/truncated-crc-error-short.gz
tests/sample_data/compressed/truncated-crc-error.gz
tests/sample_data/feeds/feed-sample1.xml
tests/sample_data/feeds/feed-sample2.xml
tests/sample_data/feeds/feed-sample3.csv
tests/sample_data/feeds/feed-sample4.csv
tests/sample_data/feeds/feed-sample5.csv
tests/sample_data/link_extractor/linkextractor_latin1.html
tests/sample_data/link_extractor/linkextractor_noenc.html
tests/sample_data/link_extractor/sgml_linkextractor.html
tests/sample_data/test_site/index.html
tests/sample_data/test_site/item1.html
tests/sample_data/test_site/item2.html
tests/spiders.py
tests/test_closespider.py
tests/test_cmdline/__init__.py
tests/test_cmdline/extensions.py
tests/test_cmdline/settings.py
tests/test_command_fetch.py
tests/test_command_shell.py
tests/test_command_version.py
tests/test_commands.py
tests/test_contracts.py
tests/test_contrib_exporter.py
tests/test_contrib_feedexport.py
tests/test_contrib_linkextractors.py
tests/test_contrib_loader.py
tests/test_contrib_spiderstate.py
tests/test_crawl.py
tests/test_dependencies.py
tests/test_djangoitem/__init__.py
tests/test_djangoitem/models.py
tests/test_djangoitem/settings.py
tests/test_downloader_handlers.py
tests/test_downloadermiddleware.py
tests/test_downloadermiddleware_ajaxcrawlable.py
tests/test_downloadermiddleware_cookies.py
tests/test_downloadermiddleware_decompression.py
tests/test_downloadermiddleware_defaultheaders.py
tests/test_downloadermiddleware_downloadtimeout.py
tests/test_downloadermiddleware_httpauth.py
tests/test_downloadermiddleware_httpcache.py
tests/test_downloadermiddleware_httpcompression.py
tests/test_downloadermiddleware_httpproxy.py
tests/test_downloadermiddleware_redirect.py
tests/test_downloadermiddleware_retry.py
tests/test_downloadermiddleware_robotstxt.py
tests/test_downloadermiddleware_stats.py
tests/test_downloadermiddleware_useragent.py
tests/test_dupefilter.py
tests/test_engine.py
tests/test_http_cookies.py
tests/test_http_headers.py
tests/test_http_request.py
tests/test_http_response.py
tests/test_item.py
tests/test_link.py
tests/test_log.py
tests/test_logformatter.py
tests/test_mail.py
tests/test_middleware.py
tests/test_pipeline_files.py
tests/test_pipeline_images.py
tests/test_pipeline_media.py
tests/test_proxy_connect.py
tests/test_responsetypes.py
tests/test_selector.py
tests/test_selector_csstranslator.py
tests/test_selector_lxmldocument.py
tests/test_settings/__init__.py
tests/test_settings/default_settings.py
tests/test_spider.py
tests/test_spidermanager/__init__.py
tests/test_spidermanager/test_spiders/__init__.py
tests/test_spidermanager/test_spiders/spider0.py
tests/test_spidermanager/test_spiders/spider1.py
tests/test_spidermanager/test_spiders/spider2.py
tests/test_spidermanager/test_spiders/spider3.py
tests/test_spidermanager/test_spiders/spider4.py
tests/test_spidermiddleware_depth.py
tests/test_spidermiddleware_httperror.py
tests/test_spidermiddleware_offsite.py
tests/test_spidermiddleware_referer.py
tests/test_spidermiddleware_urllength.py
tests/test_squeue.py
tests/test_stats.py
tests/test_toplevel.py
tests/test_urlparse_monkeypatches.py
tests/test_utils_conf.py
tests/test_utils_datatypes.py
tests/test_utils_defer.py
tests/test_utils_deprecate.py
tests/test_utils_gz.py
tests/test_utils_http.py
tests/test_utils_httpobj.py
tests/test_utils_iterators.py
tests/test_utils_jsonrpc.py
tests/test_utils_misc/__init__.py
tests/test_utils_misc/test.egg
tests/test_utils_misc/test_walk_modules/__init__.py
tests/test_utils_misc/test_walk_modules/mod/__init__.py
tests/test_utils_misc/test_walk_modules/mod/mod0.py
tests/test_utils_misc/test_walk_modules/mod1.py
tests/test_utils_python.py
tests/test_utils_reqser.py
tests/test_utils_request.py
tests/test_utils_response.py
tests/test_utils_serialize.py
tests/test_utils_signal.py
tests/test_utils_sitemap.py
tests/test_utils_spider.py
tests/test_utils_template.py
tests/test_utils_url.py
tests/test_webclient.py
tox.ini
==================
51feb4b6;Daniel Graña;2014-07-28 13:33:29 -0300;Merge pull request #820 from lisimia/patch-1
Update shell.rst typo
==
==================
b6b44a33;Lisimia;2014-07-28 12:26:13 -0400;Update shell.rst typo
There was a typo. 
"start" was mistyped as "star"
==

docs/topics/shell.rst
==================
8f4e63cd;Daniel Graña;2014-07-24 15:38:21 -0300;Merge branch 'py3-port'

==
==================
0cf035dc;Daniel Graña;2014-07-24 15:38:04 -0300;Add tox env for python 3.4

==

tox.ini
==================
79aba9e3;Daniel Graña;2014-07-24 15:37:43 -0300;pytest 2.6.0 is on pypi now

==

tox.ini
==================
6d215a1b;Daniel Graña;2014-07-24 15:37:10 -0300;items: Use BaseItem.__hash__ and six.add_metaclass decorator

==

scrapy/item.py
==================
dbc9b373;Felix Yan;2014-07-25 00:32:52 +0800;PY3: use MutableMapping instead of DictMixin

==

scrapy/item.py
scrapy/tests/test_item.py
==================
d7d9f2f9;Mikhail Korobov;2014-07-24 08:04:05 +0600;Merge pull request #814 from eliasdorneles/adding-some-xpath-tips
Adding some xpath tips to selectors docs
==
==================
c298eaf1;Elias Dorneles;2014-07-23 20:42:36 -0300;removes weird indentation in the shell results

==

docs/topics/selectors.rst
==================
514e8582;Elias Dorneles;2014-07-23 19:43:57 -0300;improved explanations, clarified blog post as source, added link for XPath string functions in the spec

==

docs/topics/selectors.rst
==================
16ed92d7;Daniel Graña;2014-07-23 18:28:43 -0300;Merge pull request #815 from nramirezuy/retry_timeout-583
renamed UserTimeoutError and ServerTimeouterror #583
==
==================
ebf76867;nramirezuy;2014-07-23 14:46:43 -0300;renamed UserTimeoutError and ServerTimeouterror #583

==

scrapy/contrib/downloadermiddleware/retry.py
scrapy/tests/test_downloadermiddleware_retry.py
==================
80de43dd;Elias Dorneles;2014-07-22 23:09:26 -0300;adding some xpath tips to selectors docs

==

docs/topics/selectors.rst
==================
4cf6a3b4;Pablo Hoffman;2014-07-22 15:54:42 -0300;Merge pull request #812 from kmike/fix-w3lib-trunk
fix tests to account for https://github.com/scrapy/w3lib/pull/23
==
==================
af0635e2;Mikhail Korobov;2014-07-22 04:15:13 +0600;fix tests to account for https://github.com/scrapy/w3lib/pull/23

==

scrapy/tests/test_downloadermiddleware.py
==================
f6b1e9b7;Daniel Graña;2014-07-21 14:17:42 -0300;Merge pull request #803 from felixonmars/py3-port
[MRG] PY3: use six.BytesIO and six.moves.cStringIO
==
==================
dd3b77ea;Daniel Graña;2014-07-21 13:41:03 -0300;Merge pull request #809 from nramirezuy/get_func_args-728
get_func_args maximum recursion fix #728
==
==================
86f61a99;nramirezuy;2014-07-17 19:07:13 -0300;get_func_args maximum recursion fix #728

==

scrapy/tests/test_utils_python.py
scrapy/utils/python.py
==================
e748ca50;Pablo Hoffman;2014-07-16 17:14:53 -0300;Merge pull request #804 from darkrho/issue-560
Updated input/ouput processor example according to #560.
==
==================
a17d4172;Pablo Hoffman;2014-07-16 17:11:20 -0300;Merge pull request #805 from darkrho/spiderstate-jobdir
For consistency, use `job_dir` helper in `SpiderState` extension.
==
==================
85b52b06;Rolando Espinoza;2014-07-16 10:34:42 -0400;For consistency, use `job_dir` helper in `SpiderState` extension.
The `SpiderState` extension is the only place not using the `job_dir`
helper.

This might cause an error in case JOBDIR is a nested path which does not
exists, although this is least likely by default given the job dir being
set up earlier.

==

scrapy/contrib/spiderstate.py
==================
e441a018;Rolando Espinoza;2014-07-16 09:04:48 -0400;Updated input/ouput processor example according to #560.

==

docs/topics/loaders.rst
==================
1cd9c4d6;Felix Yan;2014-07-15 21:26:01 +0800;fix tests by using a tempfile instead of BytesIO

==

scrapy/tests/test_pipeline_images.py
scrapy/utils/iterators.py
==================
0786e84a;Felix Yan;2014-07-15 20:51:12 +0800;use io.BytesIO and cStringIO instead of six.BytesIO as suggested

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http11.py
scrapy/responsetypes.py
scrapy/tests/test_contrib_exporter.py
scrapy/tests/test_contrib_feedexport.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_log.py
scrapy/tests/test_mail.py
scrapy/tests/test_pipeline_images.py
scrapy/tests/test_spider.py
scrapy/tests/test_utils_jsonrpc.py
scrapy/utils/gz.py
scrapy/utils/iterators.py
==================
ef8872a5;Felix Yan;2014-07-15 16:24:57 +0800;use .seek(0) instead of reset() for compatibility
Since I don't find docs for the .reset() method, I lookup up the source
code, and it should work just the same as .seek(0).

For reference:
https://github.com/python/cpython/blob/8eeb7e9122109f5cc71c22047d5cdd312ca770a0/Modules/cStringIO.c#L281

==

scrapy/core/downloader/handlers/ftp.py
scrapy/tests/test_contrib_exporter.py
==================
2999fc75;Felix Yan;2014-07-15 15:52:10 +0800;PY3: use six.BytesIO and six.moves.cStringIO

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http11.py
scrapy/mail.py
scrapy/responsetypes.py
scrapy/tests/test_contrib_exporter.py
scrapy/tests/test_contrib_feedexport.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_log.py
scrapy/tests/test_mail.py
scrapy/tests/test_pipeline_images.py
scrapy/tests/test_spider.py
scrapy/tests/test_utils_jsonrpc.py
scrapy/tests/test_utils_misc/__init__.py
scrapy/utils/gz.py
scrapy/utils/iterators.py
==================
91387b6e;Mikhail Korobov;2014-07-14 21:49:40 +0600;Merge pull request #801 from felixonmars/py3-port
PY3: fix xmlrpclib and email imports
==
==================
61717ca0;Felix Yan;2014-07-14 23:08:40 +0800;use six.moves version for MIMEMultipart, MIMEText, and MIMEBase

==

scrapy/mail.py
==================
0d758e4b;Felix Yan;2014-07-14 22:18:57 +0800;PY3: fix xmlrpclib and email imports

==

scrapy/http/request/rpc.py
scrapy/mail.py
scrapy/tests/test_http_request.py
==================
5a2f738f;Mikhail Korobov;2014-07-14 19:46:10 +0600;Merge pull request #800 from felixonmars/py3-port
PY3: use six for robotparser and urlparse
==
==================
6f7efa1d;Felix Yan;2014-07-14 21:26:37 +0800;PY3: use six for robotparser and urlparse

==

extras/scrapy-ws.py
scrapy/commands/deploy.py
scrapy/contrib/downloadermiddleware/httpproxy.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/feedexport.py
scrapy/contrib/linkextractors/htmlparser.py
scrapy/contrib/linkextractors/lxmlhtml.py
scrapy/contrib/linkextractors/regex.py
scrapy/contrib/linkextractors/sgml.py
scrapy/contrib/pipeline/files.py
scrapy/core/downloader/handlers/ftp.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/webclient.py
scrapy/http/request/form.py
scrapy/linkextractor.py
scrapy/tests/test_contrib_feedexport.py
scrapy/tests/test_engine.py
scrapy/tests/test_http_cookies.py
scrapy/tests/test_http_request.py
scrapy/tests/test_spidermiddleware_offsite.py
scrapy/tests/test_urlparse_monkeypatches.py
scrapy/tests/test_utils_httpobj.py
scrapy/tests/test_utils_response.py
scrapy/tests/test_webclient.py
scrapy/utils/httpobj.py
scrapy/utils/request.py
scrapy/utils/testsite.py
scrapy/utils/url.py
==================
2de4b8dc;Mikhail Korobov;2014-07-14 18:00:20 +0600;TST clean temporary file explicitly

==

scrapy/tests/test_commands.py
==================
321a7656;Mikhail Korobov;2014-07-14 17:52:25 +0600;Merge pull request #799 from felixonmars/py3-port
PY3: use six.iterkeys, six.iteritems, and tempfile
==
==================
4f24e724;Felix Yan;2014-07-14 18:47:22 +0800;PY3: use six.iterkeys, six.iteritems, and tempfile

==

scrapy/cmdline.py
scrapy/commands/check.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/exporter/__init__.py
scrapy/contrib/loader/__init__.py
scrapy/contrib/memdebug.py
scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/core/downloader/handlers/__init__.py
scrapy/http/request/form.py
scrapy/item.py
scrapy/responsetypes.py
scrapy/shell.py
scrapy/spidermanager.py
scrapy/tests/test_commands.py
scrapy/tests/test_downloadermiddleware_defaultheaders.py
scrapy/utils/datatypes.py
scrapy/utils/python.py
scrapy/utils/trackref.py
scrapy/xlib/pydispatch/dispatcher.py
==================
2f567f94;Mikhail Korobov;2014-07-14 16:17:30 +0600;Merge pull request #798 from felixonmars/py3-port
PY3: fix has_key and use six.moves.configparser
==
==================
3067d6d7;Felix Yan;2014-07-14 18:09:11 +0800;PY3: fix has_key and use six.moves.configparser

==

scrapy/tests/test_utils_datatypes.py
scrapy/utils/conf.py
scrapy/xlib/pydispatch/dispatcher.py
scrapy/xlib/pydispatch/robustapply.py
==================
2cddc2a3;Mikhail Korobov;2014-07-14 15:44:51 +0600;Merge pull request #797 from felixonmars/py3-port
PY3: use six.moves.cPickle
==
==================
389882eb;Felix Yan;2014-07-14 17:15:28 +0800;PY3: use six.moves.cPickle

==

scrapy/contrib/exporter/__init__.py
scrapy/contrib/httpcache.py
scrapy/contrib/spiderstate.py
scrapy/squeue.py
scrapy/tests/test_contrib_exporter.py
scrapy/utils/project.py
==================
e95e1fb7;Daniel Graña;2014-07-12 22:12:09 -0300;Merge pull request #796 from redapple/patch-1
Add PyPI Pin for Wheels compatibility
==
==================
0240ff82;Daniel Graña;2014-07-11 17:07:54 -0300;Merge pull request #791 from redapple/xhtmllinks
Extract links from XHTML documents with MIME-Type "application/xml"
==
==================
41ad55de;Paul Tremberth;2014-07-11 21:53:10 +0200;Add PyPI Pin for Wheels compatibility

==

README.rst
==================
a2dd5e5a;Alexander Chekunkov;2014-07-11 16:21:57 +0300;Added referer to "Spider error processing" log message + fixed some pep8 issues

==

scrapy/core/scraper.py
==================
71685fa2;Mikhail Korobov;2014-07-11 13:29:18 +0600;too much drama

==

scrapy/contrib/linkextractors/sgml.py
==================
54d2b110;Paul Tremberth;2014-07-10 13:04:21 +0200;Extract links from XHTML documents with MIME-Type "application/xml"
"application/xhtml+xml" is already interpreted as HTML
and link extractor is fine with it to extract links.

Only for XML documents can the namespaces in tags be an issue.

Fixes #780

Do both tag and attribute tests in _iter_links() method

==

scrapy/contrib/linkextractors/lxmlhtml.py
scrapy/tests/test_contrib_linkextractors.py
==================
1a950e8f;Roy Crihfield;2014-07-10 11:04:48 -0500;Fix typo in commands.rst

==

docs/topics/commands.rst
==================
ef8b3372;Daniel Graña;2014-07-10 14:41:30 -0300;Merge pull request #792 from redapple/travis-release-cond
Fix Travis CI config for conditional releases
==
==================
6e04c0b3;Paul Tremberth;2014-07-10 14:54:08 +0200;Match dot using character class (avoids escaping headaches)

==

.travis.yml
==================
8d5c2fe3;Paul Tremberth;2014-07-10 13:44:32 +0200;Fix Travis CI config for conditional releases

==

.travis.yml
==================
0fd119df;Daniel Graña;2014-07-09 03:05:39 -0300;Bump version: 0.25.0 → 0.25.1

==

.bumpversion.cfg
scrapy/VERSION
==================
9b8e1836;Daniel Graña;2014-07-09 02:50:12 -0300;deploy to pypi only on even minor version

==

.travis.yml
==================
ea8e444b;Daniel Graña;2014-07-09 01:41:13 -0300;better testcase for settings.overrides.setdefault

==

scrapy/tests/test_settings/__init__.py
==================
4bb09898;Pablo Hoffman;2014-07-08 19:37:01 -0300;Merge pull request #787 from ivannotes/master
Using CRLF as line marker according to http 1.1 definition
==
==================
379f6ee6;Daniel Graña;2014-07-08 05:53:08 -0300;Add 0.24.2 release notes

==

docs/news.rst
==================
acbde40f;Daniel Graña;2014-07-08 05:27:02 -0300;Use a mutable mapping to proxy deprecated settings.overrides and settings.defaults attribute

==

scrapy/settings/__init__.py
scrapy/tests/test_settings/__init__.py
==================
a9c7f8b2;ivan;2014-07-08 14:37:44 +0800;Using CRLF as line marker according to http 1.1 definition

==

scrapy/core/downloader/handlers/http11.py
==================
e29eec9c;Mikhail Korobov;2014-07-04 14:45:45 +0600;Merge pull request #786 from zsiciarz/patch-1
Fixed Python syntax in tutorial.
==
==================
0466e8cb;Zbigniew Siciarz;2014-07-04 10:38:01 +0200;Fixed Python syntax in tutorial.

==

docs/intro/tutorial.rst
==================
f3f3a440;Mikhail Korobov;2014-07-04 04:03:45 +0600;fix a couple of typos in sep-19

==

sep/sep-019.rst
==================
19dc3fa0;Pablo Hoffman;2014-07-03 17:54:21 -0300;fix typo

==

sep/sep-014.rst
==================
a653bf38;Mikhail Korobov;2014-07-03 20:31:15 +0600;Merge pull request #779 from Digenis/master
selector.__repr__ test
==
==================
aacf1d05;Nikolaos-Digenis Karagiannis;2014-07-03 13:05:20 +0300;selector.__repr__ test, unicode query

==

scrapy/tests/test_selector.py
==================
9ac639ab;Nikolaos-Digenis Karagiannis;2014-07-03 13:04:37 +0300;selector.__repr__ test, rename method

==

scrapy/tests/test_selector.py
==================
d2d014a4;Nikolaos-Digenis Karagiannis;2014-07-03 09:32:52 +0300;selector.__repr__ test, repr type is bytesarray

==

scrapy/tests/test_selector.py
==================
36d99a07;Pablo Hoffman;2014-07-02 19:05:49 -0300;Merge pull request #777 from scrapy/deprecate-sgml
Deprecate SgmlLinkExtractor
==
==================
19228c65;Mikhail Korobov;2014-07-03 03:59:28 +0600;Remove FixedSGMLParser: it is both useless and unused.

==

scrapy/utils/python.py
==================
7316a376;Mikhail Korobov;2014-07-03 01:32:33 +0600;FixedSGMLParser is useless.

==

scrapy/contrib/linkextractors/sgml.py
scrapy/utils/python.py
==================
4b17aa22;Pablo Hoffman;2014-07-02 15:58:14 -0300;Merge pull request #776 from kmike/py3-tests-fix
PY3 make it possible to run some tests in Python3
==
==================
00cd4f0f;Mikhail Korobov;2014-07-02 23:15:17 +0600;deprecate SgmlLinkExtractor

==

docs/topics/link-extractors.rst
scrapy/contrib/linkextractors/sgml.py
==================
2b749668;Mikhail Korobov;2014-07-02 22:48:16 +0600;Deprecate scrapy.python.utils.FixedSGMLParser
SGML link extractor that uses it is also going to be deprecated;
sgmllib module is not available in Python 3.

==

scrapy/utils/python.py
==================
e38e3d27;Mikhail Korobov;2014-07-02 22:23:01 +0600;PY3 make it possible to run some tests in Python3
* switch to Twisted 14.0.0 because SVN version broke twisted.log in Python 3;
* skip top-level shortcuts to make at least some tests pass;
* use PY3 compatible import of _monkeypatches.

==

scrapy/__init__.py
tox.ini
==================
e87dc377;Daniel Graña;2014-07-02 11:49:23 -0300;Merge pull request #775 from kmike/rename-sflo
rename "sflo" local variables to less cryptic "log_observer"
==
==================
daabc718;Nikolaos-Digenis Karagiannis;2014-07-02 16:03:21 +0300;selector.__repr__ test

==

scrapy/tests/test_selector.py
==================
9d3aa945;Mikhail Korobov;2014-07-02 18:16:26 +0600;rename "sflo" local variables to less cryptic "log_observer"

==

scrapy/crawler.py
scrapy/log.py
scrapy/tests/test_log.py
==================
e17866aa;Daniel Graña;2014-07-01 17:12:01 +0000;there is not support for python3 yet

==

debian/pyversions
==================
e58c23e4;Daniel Graña;2014-07-01 12:12:31 -0300;Update python compatible version set to debian packages

==

debian/pyversions
==================
173a9dfe;Mikhail Korobov;2014-06-28 13:28:57 +0600;DOC fix formatting in release notes

==

docs/news.rst
==================
284a2a06;Daniel Graña;2014-06-27 12:02:41 -0300;Add 0.24.1 release notes

==

docs/news.rst
==================
d76108c6;Daniel Graña;2014-06-27 11:55:21 -0300;Merge pull request #770 from dangra/769-settings-bugfix
Fix deprecated CrawlerSettings
==
==================
3b6fae1e;Daniel Graña;2014-06-27 11:35:35 -0300;Fix deprecated CrawlerSettings and increase backwards compatibility with .defaults attribute

==

scrapy/settings/__init__.py
scrapy/tests/test_settings/__init__.py
==================
77c8284f;Daniel Graña;2014-06-26 11:45:32 -0300;set 0.24.0 release date

==

docs/news.rst
==================
93f255c0;Daniel Graña;2014-06-26 11:24:52 -0300;Bump version: 0.24.0 → 0.25.0

==

.bumpversion.cfg
scrapy/VERSION
==================
f0facb97;Daniel Graña;2014-06-26 10:30:37 -0300;Bump version: 0.23.0 → 0.24.0

==

.bumpversion.cfg
scrapy/VERSION
==================
ee33efac;Daniel Graña;2014-06-23 19:32:01 -0300;Add 0.24.0 release notes

==

docs/news.rst
==================
eb97d257;Daniel Graña;2014-06-25 16:29:15 -0300;Merge pull request #764 from dangra/763-bugfix
no need to keep links as instance attribute
==
==================
53057728;Daniel Graña;2014-06-25 16:11:01 -0300;No need to keep extracted links as instance attribute. fixes #763

==

scrapy/contrib/linkextractors/lxmlhtml.py
==================
ccec728c;Daniel Graña;2014-06-25 15:56:33 -0300;Merge pull request #762 from kmike/688-spider-templates
add utf8 encoding header to spider templates
==
==================
6fb70931;Mikhail Korobov;2014-06-26 00:30:27 +0600;add utf8 encoding header to spider templates

==

scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
==================
df4ba41c;Mikhail Korobov;2014-06-26 00:26:12 +0600;Merge pull request #688 from stillzhl/master
add encoding utf-8 to the first line
==
==================
436c1c89;Daniel Graña;2014-06-25 14:58:27 -0300;address latest comments

==

docs/topics/link-extractors.rst
==================
2ad8db6a;Daniel Graña;2014-06-25 15:07:02 -0300;Merge pull request #761 from dangra/lxmlextractor
Promote LxmlLinkExtractor as LxmlExtractor
==
==================
a9ecef56;Daniel Graña;2014-06-25 14:34:30 -0300;promote LxmlLinkExtractor as default in docs

==

docs/intro/overview.rst
docs/topics/firebug.rst
docs/topics/link-extractors.rst
docs/topics/spiders.rst
scrapy/contrib/linkextractors/__init__.py
scrapy/templates/spiders/crawl.tmpl
scrapy/tests/spiders.py
scrapy/tests/test_engine.py
scrapy/tests/test_spider.py
==================
ef81127b;Mikhail Korobov;2014-06-25 23:31:48 +0600;Merge pull request #760 from dangra/546-remaining
recognize jl extension as jsonlines exporter and update docs
==
==================
5b2faf61;Daniel Graña;2014-06-25 13:55:15 -0300;recognize jl extension as jsonlines exporter and update docs

==

docs/faq.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
scrapy/settings/default_settings.py
==================
f98bf2c5;Daniel Graña;2014-06-25 13:01:50 -0300;Merge pull request #737 from Curita/settings-cleanup
Settings api cleanup

==
==================
f224ac13;Daniel Graña;2014-06-25 12:51:48 -0300;Restore compatibility with Settings.overrides while still deprecating it

==

scrapy/settings/__init__.py
scrapy/tests/test_settings/__init__.py
==================
f72b1597;Daniel Graña;2014-06-25 09:50:31 -0300;Merge pull request #718 from dangra/twisted-14.0.0
[WIP] does it work with Twisted 14.0.0?
==
==================
d4815842;Daniel Graña;2014-06-25 04:21:56 -0300;hold a reference to backwards compatible _contextFactory

==

scrapy/core/downloader/handlers/http11.py
==================
bfe02b01;Daniel Graña;2014-06-25 03:25:20 -0300;Revert "limit Twisted support to pre-14.0.0 while #718 is fixed"
This reverts commit 65f69e16095799e05de79a3f8f449f7b9edb27aa.

==

requirements.txt
setup.py
==================
559af943;Daniel Graña;2014-06-25 03:19:04 -0300;Add bumpversion config

==

.bumpversion.cfg
==================
1b32ece9;Daniel Graña;2014-06-25 02:55:20 -0300;Merge branch 'settings-cleanup' of https://github.com/Curita/scrapy into Curita-settings-cleanup

==
==================
4300334a;Daniel Graña;2014-06-25 02:53:12 -0300;Upload sdist and wheel packages to pypi using travis-ci deploys

==

.travis-workarounds.sh
.travis.yml
==================
499438ec;Daniel Graña;2014-06-24 10:32:56 -0300;indent parsed-literal as part of ordered list

==

docs/topics/ubuntu.rst
==================
ee5c3209;Pablo Hoffman;2014-06-24 09:52:51 -0300;doc: use |version| substitution in ubuntu packages

==

docs/topics/ubuntu.rst
==================
90e69141;Paul Tremberth;2014-06-21 01:06:04 +0200;Add doc on LxmlLinkExtractor class

==

docs/topics/link-extractors.rst
==================
d34a57a1;Paul Tremberth;2014-01-23 17:22:24 +0100;Add LxmlLinkExtractor class similar to SgmlLinkExtractor (#528)

==

scrapy/contrib/linkextractors/lxmlhtml.py
scrapy/contrib/linkextractors/sgml.py
scrapy/linkextractor.py
scrapy/tests/test_contrib_linkextractors.py
==================
05ffca27;Daniel Graña;2014-06-23 15:30:13 -0300;Merge pull request #626 from dangra/500-leveldb-cache
[WIP] Add a LevelDB cache backend
==
==================
a90fd81c;Daniel Graña;2014-06-23 14:28:55 -0300;add leveldb cache backend docs

==

docs/topics/downloader-middleware.rst
==================
9d57ecfc;Daniel Graña;2014-06-18 03:15:21 -0300;Merge pull request #752 from tpeng/slightly-improve-contract-tests
print spider name even it has no contract tests when -v is specified
==
==================
7449b25b;Daniel Graña;2014-06-18 03:01:21 -0300;Merge pull request #745 from crlane/cl/offsite-middleware-bugfix
Cl/offsite middleware bugfix
==
==================
5fb22ba4;tpeng;2014-06-17 13:39:10 +0200;print spider name even it has no contract tests when -v is specified

==

scrapy/commands/check.py
==================
7fd8a1a3;Pablo Hoffman;2014-06-14 20:51:16 -0300;minor change to request_scheduled signal doc

==

docs/topics/signals.rst
==================
313ff26a;Pablo Hoffman;2014-06-14 20:49:43 -0300;Merge pull request #746 from Digenis/doc
Document signal "request_scheduled"
==
==================
5f799402;Nikolaos-Digenis Karagiannis;2014-06-14 11:08:18 +0300;Document signal "request_scheduled"

==

docs/topics/signals.rst
==================
a069d366;Cameron Lane;2014-06-12 11:43:03 -0400;[#744] Test for allowed domains including NoneTypes

==

scrapy/tests/test_spidermiddleware_offsite.py
==================
eefa878f;Cameron Lane;2014-06-12 11:42:14 -0400;[#744] Ensure domain is not None before building regex

==

scrapy/contrib/spidermiddleware/offsite.py
==================
ad11fc01;Pablo Hoffman;2014-06-10 18:46:45 -0300;crate release notes for 0.24 and #699 to it

==

docs/news.rst
==================
6730e3c9;Julia Medina;2014-06-09 16:51:25 -0300;Fix settings usage across tests

==

scrapy/tests/test_cmdline/extensions.py
scrapy/tests/test_downloadermiddleware_robotstxt.py
==================
43ae69e4;Julia Medina;2014-06-09 12:20:09 -0300;Fix settings usage in runspider and crawl commands
Explicit conversion of FEED_EXPORTERS and FEED_EXPORTERS_BASE values into
dictionaries, and cast of the keys to a list for py3 support.

==

scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
c81b087d;Julia Medina;2014-06-03 04:21:17 -0300;Change how settings are overriden in ScrapyCommands

==

scrapy/command.py
scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
080a28f3;Julia Medina;2014-06-03 04:20:13 -0300;Change command's default_settings population in cmdline.py

==

scrapy/cmdline.py
==================
c496468e;Julia Medina;2014-06-03 03:43:11 -0300;get_project_settings now returns a Settings instance

==

scrapy/utils/project.py
==================
b397f5e9;Julia Medina;2014-05-24 08:06:00 -0300;Update get_crawler method in utils/test.py with new Settings interface
This early adaptation of the new Settings interface is needed for running tests

==

scrapy/utils/test.py
==================
ed033854;Julia Medina;2014-06-03 01:31:34 -0300;setmodule helper method on Settings class

==

docs/topics/api.rst
scrapy/settings/__init__.py
scrapy/tests/test_settings/__init__.py
==================
bdca0624;Julia Medina;2014-06-09 18:48:34 -0300;Fix settings repr on the logs of the shell and tutorial docs topics

==

docs/intro/tutorial.rst
docs/topics/shell.rst
==================
8a3a6236;Julia Medina;2014-06-10 10:59:48 -0300;Settings topic updated

==

docs/topics/settings.rst
==================
00e6470e;Julia Medina;2014-05-30 08:34:42 -0300;Fix and extend the documentation of the new Settings api

==

docs/topics/api.rst
==================
b4b17049;Julia Medina;2014-05-27 05:09:12 -0300;Settings and SettingsAtribute tests

==

scrapy/tests/test_settings.py
scrapy/tests/test_settings/__init__.py
scrapy/tests/test_settings/default_settings.py
==================
22572834;Julia Medina;2014-05-26 23:27:29 -0300;Deprecate CrawlerSettings, as its functionality is replicable by Settings class

==

scrapy/settings/__init__.py
==================
95ba6868;Julia Medina;2014-05-24 00:42:51 -0300;New set and setdict method using SettingsAttribute in Settings

==

scrapy/settings/__init__.py
==================
384efce0;Julia Medina;2014-05-24 00:37:37 -0300;Settings priorities dictionary

==

scrapy/settings/__init__.py
==================
1276b12c;Julia Medina;2014-05-22 05:38:31 -0300;New SettingsAttribute class

==

scrapy/settings/__init__.py
==================
752787e6;Daniel Graña;2014-03-06 02:13:15 -0200;Add a LevelDB cache backend

==

scrapy/contrib/httpcache.py
scrapy/tests/test_downloadermiddleware_httpcache.py
tox.ini
==================
9a4ee209;Pablo Hoffman;2014-06-03 17:34:04 -0300;Merge pull request #742 from dangra/sort-scrapy-list
sort spiders in "scrapy list" cmd.
==
==================
f6d48213;Daniel Graña;2014-06-03 15:36:58 -0300;sort spiders in "scrapy list" cmd. closes #736

==

scrapy/commands/list.py
==================
1c9effd7;Daniel Graña;2014-06-03 15:11:20 -0300;Avoid IPython warning. thanks @bryant1410. closes #623

==

scrapy/utils/console.py
==================
9830efb9;Daniel Graña;2014-06-03 11:13:13 -0300;Merge pull request #697 from allait/master
Add a note about reporting security issues
==
==================
02ac973a;Alex Cepoi;2014-06-03 15:26:01 +0200;fix contracts tests

==

scrapy/tests/test_contracts.py
==================
7752074c;Daniel Graña;2014-06-03 10:01:15 -0300;Merge pull request #719 from Digenis/master
document spider.closed() shortcut
==
==================
791889f5;Daniel Graña;2014-06-03 09:55:48 -0300;Merge pull request #733 from alexcepoi/contracts_tweaks
improvements to scrapy check/contracts
==
==================
7130df2d;Alex Cepoi;2014-05-25 00:03:49 +0200;improvements to scrapy check/contracts
* report number of contracts run and time spent (similar to unittest)
* exit with code 1 if there are failures (similar to unittest)
* capture and report errback errors (twisted or mw errors)
* capture and report callback errors (exceptions raised by spider)

==

scrapy/commands/check.py
scrapy/contracts/__init__.py
==================
0467ad77;Daniel Graña;2014-06-03 09:51:16 -0300;Merge pull request #699 from allait/telnet-port
Bind telnet console and webservice to 127.0.0.1 by default
==
==================
8a1c67fd;Daniel Graña;2014-06-03 09:48:06 -0300;Merge pull request #724 from rafallo/master
item_dropped signal should pass response arg as item_scraped does
==
==================
21df09d8;Daniel Graña;2014-06-03 09:44:09 -0300;Merge pull request #726 from nyov/fix
some cosmetics
==
==================
2a42c1c6;Daniel Graña;2014-06-03 09:36:53 -0300;Merge pull request #738 from chekunkov/downloader_setting
Downloader setting
==
==================
597fac25;Daniel Graña;2014-06-02 20:29:35 +0000;force installation of w3lib and queuelib for trunk env

==

tox.ini
==================
2ba78e71;Daniel Graña;2014-06-02 16:57:59 +0000;fix tests after changes introduced by scrapy/w3lib#21

==

scrapy/tests/test_http_request.py
scrapy/utils/url.py
==================
65f69e16;Daniel Graña;2014-06-02 13:27:20 -0300;limit Twisted support to pre-14.0.0 while #718 is fixed

==

requirements.txt
setup.py
==================
fa5a6772;Alexander Chekunkov;2014-06-02 13:05:22 +0300;DOWNLOADER setting

==

docs/topics/settings.rst
==================
1fba64d3;Alexander Chekunkov;2014-06-02 13:05:22 +0300;DOWNLOADER setting

==

docs/topics/settings.rst
scrapy/core/engine.py
scrapy/settings/default_settings.py
==================
156d347c;Daniel Graña;2014-05-21 09:50:03 -0400;Merge pull request #727 from tpeng/fix-scrapy-check-exitcode
set the exit code to non-zero when contracts fails
==
==================
b2ca3cf7;tpeng;2014-05-20 17:04:40 +0200;set the exit code to non-zero when contracts fails

==

scrapy/commands/check.py
==================
1cd21f97;nyov;2014-05-20 05:19:12 +0000;update a link reference

==

scrapy/contrib/httpcache.py
==================
2899a778;nyov;2014-05-20 04:56:57 +0000;better call to parent class

==

scrapy/item.py
==================
ad6e449c;Rafal Jagoda;2014-05-19 16:18:33 +0100;Merge remote-tracking branch 'upstream/master'

==
==================
24073a26;Nikolaos-Digenis Karagiannis;2014-05-12 22:25:18 +0300;document spider.closed() shortcut

==

docs/topics/spiders.rst
==================
2bf09b8a;Pablo Hoffman;2014-05-07 17:53:38 -0400;Merge pull request #714 from andrewbaxter/master
Elaborated Request priority value in Scrapy docs
==
==================
8bdb6e2e;Rendaw;2014-05-07 18:34:29 +0900;Elaborated request priority value.

==

docs/topics/request-response.rst
==================
6431e70d;Pablo Hoffman;2014-05-06 16:59:04 -0400;Merge pull request #711 from cerivera/master
grammatical issue
==
==================
946b854d;Carlos Rivera;2014-05-06 15:41:59 -0500;grammatical issue

==

docs/intro/overview.rst
==================
c424f370;Pablo Hoffman;2014-05-04 12:02:35 -0300;add Julia to SEP-019 authors

==

sep/sep-019.rst
==================
4bd8eb17;Daniel Graña;2014-05-04 10:13:33 -0400;Merge pull request #705 from Curita/sep19-update
Per-spider settings and api cleanup: sep#19 update
==
==================
9d226e62;Rafal Jagoda;2014-05-02 14:42:01 +0100;add response arg to item_dropped signal handlers #710

==

docs/topics/signals.rst
scrapy/core/scraper.py
==================
197e3607;Daniel Graña;2014-04-28 12:13:40 -0400;Merge pull request #707 from redapple/gh-issue-706-start-requests
[MRG] Fix engine to support filtered start_requests
==
==================
7199555e;Paul Tremberth;2014-04-26 14:04:28 +0200;Check pending start_requests before calling _spider_idle() in engine (fixes #706)

==

scrapy/core/engine.py
==================
ad14cf05;Daniel Graña;2014-04-28 10:37:35 -0400;Merge pull request #597 from chekunkov/dupefilter_request_fingerprint_test_and_docs
Dupefilter request_fingerprint test and docs
==
==================
4aa6179a;Alexander Chekunkov;2014-04-26 15:46:53 +0300;added short RFPDupeFilter.request_fingerprint interface description

==

docs/topics/settings.rst
==================
baaa0777;Alexander Chekunkov;2014-02-15 17:48:32 +0200;added note about RFPDupeFilter.request_fingerprint overriding to the settings documentation

==

docs/topics/settings.rst
==================
6e4c77c6;Alexander Chekunkov;2014-02-15 17:47:07 +0200;test for RFPDupeFilter.request_fingerprint overriding

==

scrapy/tests/test_dupefilter.py
==================
4898d963;Paul Tremberth;2014-04-26 13:47:42 +0200;Add tests for start requests, filtered and non-filtered

==

scrapy/tests/spiders.py
scrapy/tests/test_crawl.py
==================
3932877b;Pablo Hoffman;2014-04-25 16:03:19 -0300;signals doc: make argument order more consistent with code (although it doesn't matter in practice)

==

docs/topics/signals.rst
==================
9cbce910;Julia Medina;2014-04-24 13:23:31 -0300;sep#19 proposed changes

==

sep/sep-019.rst
==================
eb07e091;Pablo Hoffman;2014-04-24 17:59:36 -0400;Merge pull request #663 from pawl/patch-1
fixed typo
==
==================
bdea071a;Mikhail Korobov;2014-04-24 22:54:17 +0600;DOC selectors.rst cleanup

==

docs/topics/selectors.rst
==================
5f188164;ncp1113;2014-03-31 16:14:22 -0400;for loops have to have a : at the end of the line
changed 3 instances

==

docs/topics/selectors.rst
==================
e8f56af9;Mikhail Korobov;2014-04-24 22:43:55 +0600;Merge pull request #698 from allait/pep8templates
Fix PEP8 warnings in project and spider template files
==
==================
5d37e4dc;Alexey Bezhan;2014-04-17 14:18:57 +0100;Fix PEP8 warnings in spider templates

==

scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
==================
1d6cc257;Alexey Bezhan;2014-04-17 14:18:32 +0100;Fix PEP8 warnings in project template files

==

scrapy/templates/project/module/items.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
==================
9acf2be4;Daniel Graña;2014-04-24 12:11:39 -0400;Merge pull request #690 from dangra/kmike-response-selectors
Added docs response selector shortcuts
==
==================
1e7ddc8e;Daniel Graña;2014-04-24 12:47:45 -0300;Restore and deprecate "sel" shortcut

==

scrapy/shell.py
==================
18412d75;Daniel Graña;2014-04-24 10:32:17 -0300;Ammend example nesting selectors

==

docs/topics/selectors.rst
==================
b4593c2a;Daniel Graña;2014-04-24 00:11:42 -0300;document shortcuts in TextResponse class

==

docs/topics/request-response.rst
==================
d37308ad;Daniel Graña;2014-04-14 20:10:28 -0400;Remove "sel" shortcut from scrapy shell$
Use response.xpath(), response.css() or response.selector instead.

==

scrapy/shell.py
scrapy/tests/test_command_shell.py
==================
72f68dcc;Daniel Graña;2014-04-14 20:10:42 -0400;update spider templates

==

scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
==================
1117687c;Daniel Graña;2014-04-14 19:47:26 -0400;update docs

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/firebug.rst
docs/topics/selectors.rst
docs/topics/spiders.rst
==================
681c2985;Daniel Graña;2014-04-14 19:46:58 -0400;remove .re() shortcut

==

scrapy/http/response/text.py
scrapy/tests/test_http_response.py
==================
134bd8a9;Mikhail Korobov;2014-04-10 04:11:23 +0600;response.selector, response.xpath(), response.css() and response.re()

==

scrapy/http/response/text.py
scrapy/tests/test_http_response.py
==================
21d073d0;Daniel Graña;2014-04-23 23:14:09 -0300;Merge top-level-shortcuts

==
==================
5246986d;Daniel Graña;2014-04-21 22:43:38 -0400;Merge pull request #693 from redapple/domain-casesensitivity
Support case-insensitive domains in url_is_from_any_domain()
==
==================
89159779;Alexey Bezhan;2014-04-17 13:46:07 +0100;Bind telnet console and webservice to 127.0.0.1 by default

==

docs/topics/telnetconsole.rst
docs/topics/webservice.rst
scrapy/settings/default_settings.py
==================
e482c6ec;Mikhail Korobov;2014-04-17 20:07:05 +0600;Merge pull request #692 from kmike/version_info_fix
fix scrapy.version_info when SCRAPY_VERSION_FROM_GIT is set
==
==================
6d6282da;Alexey Bezhan;2014-04-17 14:41:21 +0100;Add a note about reporting security issues

==

docs/contributing.rst
==================
a19dfafb;Paul Tremberth;2014-04-16 22:33:30 +0200;Support case-insensitive domains in url_is_from_any_domain()

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
e8e689ac;Mikhail Korobov;2014-04-16 22:59:28 +0600;fix scrapy.version_info when SCRAPY_VERSION_FROM_GIT is set

==

scrapy/__init__.py
==================
c3426e95;Mikhail Korobov;2014-04-15 06:54:14 +0600;TST fix tests that became broken after adding top-level imports and switching to py.test.
py.test replaces AssertionError exception with its own subclass in an import hook.
For some reason when top-level shortcuts were added "except AssertionError" in
contracts.__init__ meant "except py.test AssertionError" while scrapy.exceptions.ContractFail
was still a subclass of a builtin AssertionError, so Contracts reported errors
instead of failures and this made tests in test_contracts.py fail.

For now - just disable fancy py.test asserts.

==

pytest.ini
==================
11e62117;Mikhail Korobov;2014-04-10 03:32:00 +0600;suggest scrapy.Selector in deprecation warnings

==

scrapy/selector/lxmlsel.py
scrapy/tests/test_selector.py
==================
2d380367;Mikhail Korobov;2014-04-09 05:34:14 +0600;DOC use top-level shortcuts in docs

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/commands.rst
docs/topics/debug.rst
docs/topics/djangoitem.rst
docs/topics/downloader-middleware.rst
docs/topics/exporters.rst
docs/topics/firebug.rst
docs/topics/images.rst
docs/topics/items.rst
docs/topics/jobs.rst
docs/topics/loaders.rst
docs/topics/practices.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/shell.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
==================
4ddad88d;Mikhail Korobov;2014-04-09 04:22:35 +0600;use "import scrapy" in templates

==

scrapy/templates/project/module/items.py.tmpl
scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
==================
62c7daf7;Daniel Graña;2014-01-22 20:58:53 -0200;Add basic top-level shortcuts

==

scrapy/__init__.py
scrapy/tests/test_toplevel.py
==================
9a643d68;Daniel Graña;2014-01-22 20:48:21 -0200;cleanup toplevel namespace

==

scrapy/__init__.py
scrapy/_monkeypatches.py
scrapy/tests/test_toplevel.py
==================
7814cbf3;Mikhail Korobov;2014-04-15 00:49:47 +0600;remove unused import

==

scrapy/tests/test_selector.py
==================
2c8eceb5;Daniel Graña;2014-04-14 14:08:05 -0400;Merge pull request #659 from denysbutenko/master
[MRG] Resolved issue #546. Output format parsing from filename extension.
==
==================
0a7e6559;Daniel Graña;2014-04-14 13:39:27 -0400;Merge pull request #681 from kmike/version_info
[MRG] make scrapy.version_info a tuple of integers
==
==================
86a60e2c;Irhine;2014-04-14 18:14:29 +0800;support i18n by using utf-8 coding template files

==

scrapy/templates/project/module/items.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/templates/project/module/settings.py.tmpl
==================
943b6f90;Irhine;2014-04-14 17:05:42 +0800;add encoding utf-8 to the first line

==

scrapy/templates/project/module/items.py.tmpl
==================
21bff7b3;Daniel Graña;2014-04-11 15:36:00 -0400;Merge pull request #687 from Curita/docs-linkcheck
Docs build and linkcheck in tox env
==
==================
80081054;Julia Medina;2014-04-09 18:57:52 -0300;Fix broken links in documentation

==

docs/faq.rst
docs/intro/overview.rst
docs/news.rst
docs/topics/architecture.rst
docs/topics/commands.rst
docs/topics/email.rst
docs/topics/selectors.rst
==================
f0a0d0bc;Julia Medina;2014-04-09 18:46:21 -0300;Ignore known broken links in docs linkcheck

==

docs/conf.py
==================
c7c57178;Julia Medina;2014-04-09 18:46:01 -0300;New tox env: docs

==

.travis.yml
tox.ini
==================
96ef4c60;Daniel Graña;2014-04-08 10:41:03 -0700;Merge pull request #679 from Curita/pytest
Run tests with pytest instead of trial
==
==================
e71b8f26;Daniel Graña;2014-04-08 10:40:04 -0700;Merge pull request #676 from csalazar/fix_xxe_flaw
Fixed XXE flaw in sitemap reader
==
==================
dd9d3af9;Julia Medina;2014-04-04 17:01:42 -0300;Ensure spiders module reload between spider manager tests

==

scrapy/tests/test_spidermanager/__init__.py
==================
c50f088b;Julia Medina;2014-04-04 16:58:08 -0300;Fix httpcache doctest that assumed dictionary order

==

scrapy/contrib/httpcache.py
==================
11869697;Julia Medina;2014-04-03 05:58:15 -0300;Change function name so it does not mess up with pytest autodiscover

==

scrapy/tests/test_squeue.py
==================
81187fea;Julia Medina;2014-04-04 16:55:35 -0300;Ignore files with import errors on pytest test discover

==

scrapy/conftest.py
==================
560a8465;Julia Medina;2014-04-04 16:54:40 -0300;Support doctest and __init__.py test discover in pytest

==

pytest.ini
==================
1779b31e;Julia Medina;2014-04-03 13:14:59 -0300;Add py33 environment to allowed failures in travis-ci

==

.travis.yml
==================
20b4c8f3;Julia Medina;2014-04-04 16:38:09 -0300; Trial functionality for running tests with pytest
  * Change current dir to tmp dir on each test run
  * Log twisted with test.log

==

pytest.ini
scrapy/conftest.py
==================
713aec39;Mikhail Korobov;2014-04-05 05:54:49 +0600;make scrapy.version_info a tuple of integers

==

scrapy/__init__.py
==================
554102fd;Claudio Salazar;2014-04-05 00:40:41 +0800;Added resolve_entities to kwargs in SafeXMLParser

==

scrapy/selector/unified.py
==================
d034df36;Claudio Salazar;2014-04-05 00:22:36 +0800;Added test against XXE attacks for Sitemap

==

scrapy/tests/test_utils_sitemap.py
==================
c2a424da;Claudio Salazar;2014-04-05 00:13:27 +0800;Fixed XML selector against XXE attacks

==

scrapy/selector/unified.py
scrapy/tests/test_selector.py
==================
986be9a3;Daniel Graña;2014-03-28 13:53:53 -0300;Run testsuite with py.test

==

.travis.yml
tests-requirements.txt
tox.ini
==================
f3d15085;Daniel Graña;2014-04-02 19:45:00 -0700;Merge pull request #674 from dangra/pypy
[WIP] try to restore pypy tests
==
==================
43217fd6;Claudio Salazar;2014-04-01 23:54:04 +0800;Fixed XXE flaw in sitemap reader

==

scrapy/utils/sitemap.py
==================
95853b32;Daniel Graña;2014-03-28 15:56:23 -0300;try to restore pypy tests

==

.travis-workarounds.sh
.travis.yml
==================
ade7662f;Daniel Graña;2014-03-27 09:06:43 -0700;Merge pull request #661 from ananana/sgml-attrs-tuple
Fixed default value of attrs argument in SgmlLinkExtractor to be tuple
==
==================
73109bf9;Ana Sabina Uban;2014-03-20 03:13:47 +0200;Fixed SgmlLinkExtractor constructor to properly handle both string and list parameters (attrs, tags, deny_extensions)

==

docs/topics/link-extractors.rst
scrapy/contrib/linkextractors/sgml.py
scrapy/tests/test_contrib_linkextractors.py
==================
7e353761;Denys Butenko;2014-03-26 12:27:52 +0200;Added more verbose error message for unrecognized output format. PEP8.

==

scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
f6874550;Daniel Graña;2014-03-24 06:10:23 -0700;Merge pull request #660 from rubenvereecken/issue193
Added content-type check as per issue #193
==
==================
54434095;Ruben Vereecken;2014-03-21 14:41:07 +0100;Redefined test for #193

==

scrapy/tests/test_downloadermiddleware_httpcompression.py
==================
a1ee3546;Paul Brown;2014-03-20 15:16:48 -0500;fixed typo

==

docs/topics/request-response.rst
==================
92780b70;Ruben Vereecken;2014-03-19 21:48:44 +0100;Added content-type check as per issue #193

==

scrapy/contrib/downloadermiddleware/httpcompression.py
==================
aa79abc5;Denys Butenko;2014-03-20 12:36:05 +0200;Add import os for crawl.

==

scrapy/commands/crawl.py
==================
e64d6e3f;Denys Butenko;2014-03-19 21:32:32 +0200;Fix default value.

==

scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
9822eb78;Denys Butenko;2014-03-19 21:18:01 +0200;Added back `-t` option. If `--output-format` not defined parse from extension `--output`

==

scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
8e0b2bd3;Denys Butenko;2014-03-19 19:00:55 +0200;Resolved issue #546. Output format parsing from filename extension.

==

scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
3df69462;Daniel Graña;2014-03-18 19:46:59 -0700;Merge pull request #656 from kmike/httperror-logging
[MRG] Fix for #612 + small tests cleanup
==
==================
60f9dc7a;Mikhail Korobov;2014-03-19 04:18:04 +0600;TST fix file descriptor leak and a bad variable name in get_testlog

==

scrapy/utils/test.py
==================
75060d14;Mikhail Korobov;2014-03-19 04:04:24 +0600;Fix for #612 + integration-style tests for HttpErrorMiddleware

==

scrapy/contrib/spidermiddleware/httperror.py
scrapy/tests/test_spidermiddleware_httperror.py
==================
364790eb;Mikhail Korobov;2014-03-19 03:30:58 +0600;scrapy.utils.test.docrawl function

==

scrapy/tests/test_closespider.py
scrapy/tests/test_crawl.py
scrapy/tests/test_proxy_connect.py
scrapy/utils/test.py
==================
15454e78;Mikhail Korobov;2014-03-19 01:50:09 +0600;reduce code duplication in test_spidermiddleware_httperror

==

scrapy/tests/test_spidermiddleware_httperror.py
==================
9edbb68b;Mikhail Korobov;2014-03-18 22:30:07 +0500;Merge pull request #612 from deed02392/patch-1
Update httperror.py
==
==================
ff41d545;Mikhail Korobov;2014-03-18 21:33:05 +0500;Merge pull request #654 from tpeng/patch-2
add message when raise IngoreReques; fix item_scraped document
==
==================
fd7b40e8;tpeng;2014-03-18 15:23:25 +0800;add message when raise IngoreReques; fix item_scraped document

==

docs/topics/signals.rst
scrapy/contrib/downloadermiddleware/redirect.py
==================
b8ecbb76;Daniel Graña;2014-03-17 19:39:46 -0700;Merge pull request #650 from Curita/dlhandler-disable
Allow to disable a downloader handler just like any other component
==
==================
f921d2af;Daniel Graña;2014-03-13 12:18:26 -0700;Merge pull request #645 from Curita/formrequest-clickdata-doc
Documentation for FormRequest.from_response clickdata parameter
==
==================
c2fd1f8a;Daniel Graña;2014-03-13 12:17:55 -0700;Merge pull request #646 from Curita/formrequest-clickdata-nr-index-tests
Tests for clickdata's nr index in FormRequest
==
==================
2177d4fe;Julia Medina;2014-03-13 01:29:10 -0300;Minor fixes in LoadTestCase in test_downloader_handlers
 * same __init__ parameters in both download handlers's mocks
 * additional assertion in test_disabled_handler

==

scrapy/tests/test_downloader_handlers.py
==================
b9e2aad8;Julia Medina;2014-03-12 23:21:33 -0300;Doc for disabling download handler

==

docs/topics/settings.rst
==================
65734594;Julia Medina;2014-03-12 22:33:42 -0300;Fix minor typo in DownloaderHandlers comment

==

scrapy/core/downloader/handlers/__init__.py
==================
efb86f96;Julia Medina;2014-03-12 22:32:48 -0300;Tests for loading download handlers

==

scrapy/tests/test_downloader_handlers.py
==================
a1df15b9;Rolando Espinoza La fuente;2013-11-06 21:21:35 -0400;Alow to disable a downloader handler just like any other component.

==

scrapy/core/downloader/handlers/__init__.py
==================
ae4eb90c;Julia Medina;2014-03-12 12:45:46 -0300;More appropriate assert in FormRequest test

==

scrapy/tests/test_http_request.py
==================
ca1c1a82;Julia Medina;2014-03-12 11:39:16 -0300;FormRequest doc improvements
Clickdata doc enhancements:
 * Fix xml attributes mention
 * nr is 0-indexed reference

==

docs/topics/request-response.rst
==================
a63b7e1c;Julia Medina;2014-03-12 07:26:52 -0300;New tests: clickdata's nr in Formrequest.from_response

==

scrapy/tests/test_http_request.py
==================
e29ab4d1;Julia Medina;2014-03-12 06:43:50 -0300;New doc: clickdata in Formrequest.from_response
Documentation about:
 * clickdata parameter in Formrequest.from_response
 * nr attribute in clickdata dict
 * default behaviour when clickdata is None

==

docs/topics/request-response.rst
==================
5bbc20f5;Pablo Hoffman;2014-03-09 08:06:37 -0700;Merge pull request #643 from Digenis/master
ItemLoader doc: missing args in replace_value()
==
==================
8ac9d406;Nikolaos-Digenis Karagiannis;2014-03-09 15:16:57 +0200;ItemLoader doc: missing args in replace_value()

==

docs/topics/loaders.rst
==================
a762834d;Pablo Hoffman;2014-03-07 19:25:25 -0800;Merge pull request #642 from aspidites/sep-014.rst
sep 14 for #629
==
==================
38ea9373;Edwin O Marshall;2014-03-07 10:00:07 -0500;sep 14 for #629

==

sep/sep-014.rst
sep/sep-014.trac
==================
0bc2cbaf;Pablo Hoffman;2014-03-07 10:35:58 -0800;Merge pull request #613 from breno/master
Update scrapy command line doc with additional scrapy parse options
==
==================
75389322;Pablo Hoffman;2014-03-07 10:32:33 -0800;Merge pull request #641 from aspidites/remaining_seps
Converted remaining SEPs...
==
==================
690fbdb9;Pablo Hoffman;2014-03-07 10:32:07 -0800;Merge pull request #633 from aspidites/sep-004.rst
sep 4 for #629
==
==================
138e534b;Edwin O Marshall;2014-03-07 11:52:12 -0500;converted sep017

==

sep/sep-017.rst
sep/sep-017.trac
==================
770e24ae;Edwin O Marshall;2014-03-07 11:44:41 -0500;converted sep 9

==

sep/sep-009.rst
sep/sep-009.trac
==================
f1e0faac;Edwin O Marshall;2014-03-07 11:28:37 -0500;- convertd sep 8

==

sep/sep-008.rst
sep/sep-008.trac
==================
f43c99f3;Edwin O Marshall;2014-03-07 11:18:08 -0500;converted sep 5

==

sep/sep-005.rst
sep/sep-005.trac
==================
5312146f;Edwin O Marshall;2014-03-07 11:07:57 -0500;converted sep 13

==

sep/sep-013.rst
sep/sep-013.trac
==================
05ac4112;Edwin O Marshall;2014-03-07 10:47:54 -0500;converted sep 16

==

sep/sep-016.rst
sep/sep-016.trac
==================
c68798b3;Edwin O Marshall;2014-03-07 10:38:18 -0500;- converted sep 18

==

sep/sep-018.rst
sep/sep-018.trac
==================
c9c43432;Pablo Hoffman;2014-03-07 07:07:40 -0800;Merge pull request #631 from aspidites/sep-002.rst
converted sep 002 to rst
==
==================
61b81b1c;Pablo Hoffman;2014-03-07 07:06:20 -0800;Merge pull request #637 from aspidites/sep-010.rst
sep 10 for #629
==
==================
c1d31bd1;Pablo Hoffman;2014-03-07 07:05:52 -0800;Merge pull request #639 from aspidites/sep-007.rst
converted sep 7 for #629
==
==================
9323b001;Pablo Hoffman;2014-03-07 07:05:34 -0800;Merge pull request #634 from aspidites/sep-011.rst
sep 11 for #629
==
==================
8cf9a97c;Pablo Hoffman;2014-03-07 07:05:11 -0800;Merge pull request #635 from aspidites/sep-015.rst
- sep 15 for #629
==
==================
326d9fb5;Pablo Hoffman;2014-03-07 07:03:46 -0800;Merge pull request #640 from aspidites/sep-012.rst
sep 12 for #629
==
==================
51966f59;Pablo Hoffman;2014-03-07 07:01:29 -0800;Merge pull request #636 from aspidites/sep-006.rst
 sep 6 for #629
==
==================
cf4d91be;Pablo Hoffman;2014-03-07 07:00:54 -0800;Merge pull request #632 from aspidites/sep-003.rst
converted sep 3 for #629
==
==================
b5e359be;Pablo Hoffman;2014-03-07 06:41:55 -0800;Merge pull request #638 from aspidites/sep-001.rst
- removed trac file for #629
==
==================
4b902d2a;Edwin O Marshall;2014-03-07 09:39:55 -0500;sep 12 for #629

==

sep/sep-012.rst
sep/sep-012.trac
==================
358ec6e8;Edwin O Marshall;2014-03-07 09:27:30 -0500;converted sep 7 for #629

==

sep/sep-007.rst
sep/sep-007.trac
==================
06fdb16f;Edwin O Marshall;2014-03-07 09:12:35 -0500;- removed trac file

==

sep/sep-015.trac
==================
2e92400e;Edwin O Marshall;2014-03-07 09:12:21 -0500;removed trac file

==

sep/sep-011.trac
==================
8f0858cb;Edwin O Marshall;2014-03-07 09:11:45 -0500;removed trac file

==

sep/sep-010.trac
==================
2e99045b;Edwin O Marshall;2014-03-07 09:11:19 -0500;- removed track file

==

sep/sep-006.trac
==================
79d10b7e;Edwin O Marshall;2014-03-07 09:10:59 -0500;- removed trac file

==

sep/sep-004.trac
==================
7a63bb4a;Edwin O Marshall;2014-03-07 09:10:37 -0500;- removed trac file

==

sep/sep-003.trac
==================
c407ff81;Edwin O Marshall;2014-03-07 09:08:25 -0500;- removed trac file

==

sep/sep-001.trac
==================
73926002;Edwin O Marshall;2014-03-07 09:04:12 -0500;- removing trac file again to see if merges play well together

==

sep/sep-002.trac
==================
690081b4;Pablo Hoffman;2014-03-07 05:52:44 -0800;Merge pull request #630 from aspidites/sep-001.rst
Converted sep-001 to rst format
==
==================
d8fb4a35;Mikhail Korobov;2014-03-07 12:41:39 +0500;Merge pull request #627 from Digenis/master
SpiderMW doc typo: SWP request, response
==
==================
672b6788;Edwin O Marshall;2014-03-06 17:55:37 -0500;- given that it'sa block quote, quotation marks seem redundant

==

sep/sep-006.rst
==================
96f05efb;Edwin O Marshall;2014-03-06 17:54:16 -0500;- changing indentation so contexts are recognized

==

sep/sep-006.rst
==================
9f0e9e0e;Edwin O Marshall;2014-03-06 17:53:16 -0500;- trying to separate quote context

==

sep/sep-006.rst
==================
3217d1d1;Edwin O Marshall;2014-03-06 17:50:41 -0500;- didn't like the way blockquotes rendered

==

sep/sep-010.rst
==================
acff13d2;Edwin O Marshall;2014-03-06 17:48:39 -0500;- sep 10 for #629

==

sep/sep-010.rst
==================
aa1ab8de;Edwin O Marshall;2014-03-06 17:39:41 -0500; sep 6 for #629

==

sep/sep-006.rst
==================
27ff010a;Edwin O Marshall;2014-03-06 17:18:51 -0500;- sep 15 for #629

==

sep/sep-015.rst
==================
9a52adce;Edwin O Marshall;2014-03-06 17:06:20 -0500;sep 11 for #629

==

sep/sep-011.rst
==================
aef14cbf;Edwin O Marshall;2014-03-06 16:55:37 -0500;sep 4 for #629

==

sep/sep-004.rst
==================
350f26cc;Edwin O Marshall;2014-03-06 16:44:02 -0500;converted sep 3 for #629

==

sep/sep-003.rst
==================
197f1418;Edwin O Marshall;2014-03-06 16:32:14 -0500;- readded file to prevent future merge conflicts

==

sep/sep-002.trac
==================
bc378f4e;Edwin O Marshall;2014-03-06 16:30:53 -0500;- decided that removing files would cause conflicts on merge

==

sep/sep-001.trac
==================
07ef3df2;Edwin O Marshall;2014-03-06 16:26:32 -0500;converted sep 002 to rst

==

sep/sep-002.rst
sep/sep-002.trac
==================
b0833719;Edwin O Marshall;2014-03-06 16:05:42 -0500;Converted sep-001 to rst format

==

sep/sep-001.rst
sep/sep-001.trac
==================
c0a72e9c;Mikhail Korobov;2014-03-06 21:36:17 +0500;Merge pull request #628 from barraponto/codespell
Using lucasdemarchi/codespell to fix typos
==
==================
4de45c94;Capi Etheriel;2014-03-06 12:41:38 -0300;Running lucasdemarchi/codespell to fix typos in code

==

scrapy/contracts/default.py
scrapy/contrib/linkextractors/sgml.py
scrapy/contrib/memusage.py
scrapy/core/scraper.py
scrapy/responsetypes.py
scrapy/xlib/pydispatch/robustapply.py
scrapy/xlib/tx/_newclient.py
scrapy/xlib/tx/interfaces.py
==================
20a82379;Capi Etheriel;2014-03-06 12:41:21 -0300;Running lucasdemarchi/codespell to fix typos in SEPs

==

sep/sep-003.trac
sep/sep-014.trac
sep/sep-016.trac
sep/sep-018.trac
==================
72b6c96d;Capi Etheriel;2014-03-06 12:15:42 -0300;Running lucasdemarchi/codespell to fix typos in docs

==

docs/faq.rst
docs/news.rst
docs/topics/request-response.rst
==================
4335420f;Nikolaos-Digenis Karagiannis;2014-03-06 16:09:37 +0200;SpiderMW doc typo: SWP request, response

==

docs/topics/spider-middleware.rst
==================
262e7599;Pablo Hoffman;2014-03-02 18:25:51 -0800;Merge pull request #622 from ajw0100/generalize-file-pipeline-log-messages
Generalize the file pipeline log messages
==
==================
67aa586a;A.J. Welch;2014-03-02 17:55:04 -0800;Generalize the file pipeline log messages so they are not specific to downloading images.

==

scrapy/contrib/pipeline/files.py
==================
c99f1d23;Pablo Hoffman;2014-02-27 11:22:47 -0800;Merge pull request #618 from allait/master
Fix some small typos and errors in docs
==
==================
210a0a6f;Alexey Bezhan;2014-02-27 18:02:22 +0000;Fix some typos, whitespace and small errors in docs

==

docs/intro/tutorial.rst
docs/topics/commands.rst
docs/topics/items.rst
docs/topics/loaders.rst
docs/topics/spiders.rst
==================
2e59d775;Alexey Bezhan;2014-02-27 17:55:36 +0000;Clarify MapCompose documentation

==

docs/topics/loaders.rst
==================
c532e13d;Cash Costello;2014-02-27 09:53:11 -0500;Added missing word in practices.rst

==

docs/topics/practices.rst
==================
6d8b7b29;Pablo Hoffman;2014-02-27 12:16:01 -0200;remove unused setting: DOWNLOADER_DEBUG

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
551c1c5e;Breno Colom;2014-02-24 18:10:51 -0500;Update scrapy command line doc with additional scrapy parse options

==

docs/topics/commands.rst
==================
341c5962;deed02392;2014-02-24 15:55:04 +0000;Update httperror.py
Log ignored HTTP pages when the response code is not allowed or not configured to be handled.
==

scrapy/contrib/spidermiddleware/httperror.py
==================
822adb1d;Pablo Hoffman;2014-02-20 12:05:14 -0800;Merge pull request #602 from Blender3D/email
Added a mimetype parameter to `MailSender.send`
==
==================
9e62041b;Pablo Hoffman;2014-02-20 12:03:31 -0200;remove no longer used setting: MAIL_DEBUG

==

scrapy/settings/default_settings.py
==================
091c336b;Pablo Hoffman;2014-02-20 12:03:06 -0200;rename attribute to match conventions used for XXX_DEBUG settings (in autothrottle and cookies mw)

==

scrapy/dupefilter.py
==================
5f42dbf9;Pablo Hoffman;2014-02-19 09:41:47 -0800;Merge pull request #603 from barraponto/dynamic-itemclass-docfix
fixes dynamic itemclass example usage of type()
==
==================
1ec1100b;Capi Etheriel;2014-02-18 20:59:05 -0300;fixes dynamic itemclass example usage of type()

==

docs/topics/practices.rst
==================
70a57dc7;Daniel Graña;2014-02-18 05:21:32 -0800;Merge pull request #553 from redapple/dupefilter-verbose
DupeFilter: add settings for verbose logging and filtered requests stats
==
==================
ec48df7f;Daniel Graña;2014-02-18 05:11:04 -0800;Merge pull request #555 from redapple/crawlspider-processlinks
CrawlSpider: support process_links as generator
==
==================
a676017f;Nikita Nikishin;2014-02-18 03:50:43 -0500;Fixed #441.

==

docs/topics/email.rst
scrapy/mail.py
scrapy/tests/test_mail.py
==================
66fb1738;Paul Tremberth;2014-02-04 12:51:08 +0100;Remove _log_level attribute as per comments

==

scrapy/dupefilter.py
==================
41765ca1;Paul Tremberth;2014-01-21 18:25:17 +0100;DupeFilter: add setting for verbose logging + stats counter for filtered requests

==

docs/topics/settings.rst
scrapy/dupefilter.py
==================
42dc34f9;Mikhail Korobov;2014-02-17 17:21:38 +0600;TST Improved twisted installation in tox.ini for Python 3.3
Install twisted trunk because released twisted doesn't install properly,
see https://twistedmatrix.com/trac/ticket/6539.

Also, test-requirements are removed for 3.3 because mitmproxy doesn't
install in Python 3.3, and mock is in Python 3.3 standard library.

Note that trial scrapy is not doing what is expected because twisted doesn't
have trial runner for 3.3 yet, so this command will most likely call "trial"
outside tox virtualenv and will use incorrect interpreter.

==

tox.ini
==================
d24212c8;Pablo Hoffman;2014-02-16 21:44:49 -0200;remove references to deprecated scrapy-developers list

==

docs/contributing.rst
extras/scrapy.1
==================
fcbd7b49;Pablo Hoffman;2014-02-16 14:19:52 -0800;Merge pull request #596 from darkrho/doc-pipeline
DOC Use pipelines module name instead of pipieline following default project files.
==
==================
28f946b0;Rolando Espinoza;2014-02-15 10:59:56 -0400;DOC Use pipelines module name instead of pipieline following default project files.

==

docs/topics/item-pipeline.rst
docs/topics/settings.rst
==================
180fc98c;Daniel Graña;2014-02-14 15:44:57 -0200;Add 0.22.2 release notes

==

docs/news.rst
==================
6ca49ce7;Daniel Graña;2014-02-14 09:39:30 -0800;Merge pull request #594 from dangra/593-engineslots
fix a reference to unexistent engine.slots.
==
==================
b58285b6;Daniel Graña;2014-02-14 15:16:36 -0200;fix a reference to unexistent engine.slots. closes #593

==

docs/topics/telnetconsole.rst
scrapy/tests/spiders.py
scrapy/tests/test_crawl.py
scrapy/utils/engine.py
==================
c886d745;Pablo Hoffman;2014-02-11 20:15:49 -0200;add SEP-021 (Add-ons) - work in progress

==

sep/sep-021.rst
==================
9caf3755;Mikhail Korobov;2014-02-12 02:49:30 +0500;Merge pull request #590 from Digenis/master
downloaderMW doc typo (spiderMW doc copy remnant)
==
==================
43a797e2;Nikolaos-Digenis Karagiannis;2014-02-11 22:30:00 +0200;downloaderMW doc typo (spiderMW doc copy remnant)

==

docs/topics/downloader-middleware.rst
==================
b2f4b296;tracicot;2014-02-08 12:08:24 -0700;Correct typos

==

docs/topics/exporters.rst
==================
783d8e3a;Daniel Graña;2014-02-08 17:08:27 -0200;Add 0.22.1 release notes

==

docs/news.rst
==================
877e345d;Daniel Graña;2014-02-08 16:38:19 -0200;localhost666 can resolve under certain circumstances
localhost666 is resolvable if the host running the tests contains a
"search mydomain.com" in /etc/resolv.conf and a wildcard dns entry
exists for *.mydomain.com

==

scrapy/tests/test_crawl.py
==================
45c9dab1;Daniel Graña;2014-02-06 19:41:32 -0800;Merge pull request #582 from kmike/inspect-workaround
[WIP] Handle cases when inspect.stack() fails
==
==================
9e95b36a;Daniel Graña;2014-02-07 01:36:43 -0200;test inspect.stack failure

==

scrapy/tests/test_utils_deprecate.py
==================
c12e3a58;Daniel Graña;2014-02-05 14:39:56 -0800;Merge pull request #585 from kmike/mitmproxy-reqs-cleanup
[MRG] testing PIL dependency is removed because there is a new mitmproxy version
==
==================
3d4fe60e;Daniel Graña;2014-02-05 13:48:40 -0800;Merge pull request #584 from dangra/581-deprecated-subclass-fix
Fix wrong checks on subclassing of deprecated classes
==
==================
ee896b15;Daniel Graña;2014-02-05 15:42:01 -0200;Fix wrong checks on subclassing of deprecated classes. closes #581

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
8e88fbc2;Mikhail Korobov;2014-02-06 00:49:26 +0600;testing PIL dependency is removed because there is a new mitmproxy version

==

tests-requirements.txt
==================
8a1905e6;Mikhail Korobov;2014-02-05 02:28:51 +0600;Handle cases when inspect.stack() fails

==

scrapy/utils/deprecate.py
==================
45417e6b;Daniel Graña;2014-02-02 19:09:02 -0800;Merge pull request #574 from redapple/htmllx-tests
Fix HtmlParserLinkExtractor and tests after #485 merge
==
==================
b74e7dd3;Mikhail Korobov;2014-02-01 15:07:01 -0800;Merge pull request #575 from redapple/docs-tutorialindent
Docs: 4-space indent for final spider example
==
==================
57f30bcb;Paul Tremberth;2014-02-01 23:31:14 +0100;Docs: 4-space indent for final spider example

==

docs/intro/tutorial.rst
==================
8017d85d;Paul Tremberth;2014-02-01 22:47:30 +0100;Fix HtmlParserLinkExtractor and tests after #485 merge

==

scrapy/contrib/linkextractors/htmlparser.py
scrapy/tests/test_contrib_linkextractors.py
==================
e31fb493;Pablo Hoffman;2014-02-01 17:38:31 -0200;make 'basic' the default template spider in genspider, and added info with next steps to startproject. closes #488

==

scrapy/commands/genspider.py
scrapy/commands/startproject.py
==================
c928eef5;Pablo Hoffman;2014-02-01 10:28:56 -0800;Merge pull request #485 from bblanchon/sgml-extractor-link-text
SgmlLinkExtractor: Fixed link text when there is an inner tag
==
==================
38a96fba;Paul Tremberth;2014-01-23 11:52:40 +0100;CrawSpider: support process_links as generator
Adding tests for CrawlSpider's process_links

==

scrapy/contrib/spiders/crawl.py
scrapy/tests/test_spider.py
==================
e1c6d3ff;Daniel Graña;2014-01-31 10:05:35 -0800;Merge pull request #566 from redapple/offsite-stats
OffsiteMiddleware: add 2 stats counters
==
==================
1e553ec0;Daniel Graña;2014-01-31 09:16:54 -0800;Merge pull request #570 from redapple/travistests
[MRG] Fix tests for Travis-CI build
==
==================
cc157f18;Paul Tremberth;2014-01-30 15:16:31 +0100;Fix tests for Travis-CI build

==

scrapy/contrib/linkextractors/regex.py
scrapy/tests/test_contrib_exporter.py
scrapy/tests/test_contrib_linkextractors.py
scrapy/tests/test_djangoitem/__init__.py
scrapy/tests/test_downloadermiddleware_ajaxcrawlable.py
scrapy/tests/test_downloadermiddleware_cookies.py
scrapy/tests/test_http_headers.py
scrapy/tests/test_http_request.py
scrapy/tests/test_item.py
scrapy/tests/test_webclient.py
==================
05158803;Mikhail Korobov;2014-01-30 08:48:39 -0800;Merge pull request #571 from darkrho/httpcache-storage-doc
DOC Fixed HTTPCACHE_STORAGE typo in the default value which is now Files...
==
==================
a6279fe9;Rolando Espinoza;2014-01-30 11:53:42 -0400;DOC Fixed HTTPCACHE_STORAGE typo in the default value which is now Filesystem instead Dbm.

==

docs/topics/downloader-middleware.rst
==================
fd5b4059;Paul Tremberth;2014-01-29 14:33:12 +0100;Always enable offsite stats + refactor test to initialize crawler

==

scrapy/contrib/spidermiddleware/offsite.py
scrapy/tests/test_spidermiddleware_offsite.py
==================
1a545157;Paul Tremberth;2014-01-28 12:52:28 +0100;Offsite: add 2 stats counters

==

scrapy/contrib/spidermiddleware/offsite.py
==================
21f0e404;Pablo Hoffman;2014-01-27 22:01:39 -0800;Merge pull request #565 from dangra/562-sgmlinkextractor
replace unencodeable codepoints with html entities
==
==================
116a1df4;Pablo Hoffman;2014-01-27 21:08:02 -0800;Merge pull request #557 from darkrho/expose-crawler-in-shell
Expose current crawler in the scrapy shell.
==
==================
66829c96;Daniel Graña;2014-01-27 11:37:09 -0200;replace unencodeable codepoints with html entities. fixes #562 and #285

==

scrapy/contrib/linkextractors/sgml.py
scrapy/tests/test_contrib_linkextractors.py
==================
8ecf0b78;Daniel Graña;2014-01-27 04:21:09 -0800;Merge pull request #556 from darkrho/item-loader-nones
Make `ItemLoader` ignore `None` values from processors.
==
==================
b14dabb2;Daniel Graña;2014-01-24 07:33:23 -0800;Merge pull request #561 from redapple/regexlx-encoding
RegexLinkExtractor: encode URL unicode value when creating Links
==
==================
4255e12b;Rolando Espinoza;2014-01-23 18:18:56 -0400;Updated the tutorial crawl output with latest output.

==

docs/intro/tutorial.rst
==================
9aab9224;Rolando Espinoza;2014-01-23 18:04:57 -0400;Updated shell docs with the crawler reference and fixed the actual shell output.
Also updated the shell example with a reproducible code example.

==

docs/intro/tutorial.rst
docs/topics/shell.rst
==================
f87859a6;Paul Tremberth;2014-01-23 19:36:31 +0100;RegexLinkExtractor: encode URL unicode value when creating Links

==

scrapy/contrib/linkextractors/regex.py
==================
4081ba23;Rolando Espinoza;2014-01-23 11:13:54 -0400;PEP8 minor edits.

==

scrapy/shell.py
==================
240fdde6;Rolando Espinoza;2014-01-23 11:08:56 -0400;Expose current crawler in the scrapy shell.

==

scrapy/shell.py
==================
b9341205;Rolando Espinoza;2014-01-23 10:37:33 -0400;Unused re import and PEP8 minor edits.

==

scrapy/contrib/loader/__init__.py
==================
420efe77;Rolando Espinoza;2014-01-23 10:36:06 -0400;Ignore None's values when using the ItemLoader.

==

scrapy/contrib/loader/__init__.py
scrapy/tests/test_contrib_loader.py
==================
2d60f860;Pablo Hoffman;2014-01-22 07:41:31 -0800;Merge pull request #535 from redapple/xpath-smartstrings
Disable smart strings in lxml XPath evaluations
==
==================
677afe7e;Daniel Graña;2014-01-20 16:22:53 -0200;show ubuntu setup instructions as literal code

==

docs/topics/ubuntu.rst
==================
1c514c5f;Daniel Graña;2014-01-20 09:27:57 -0800;Merge pull request #549 from dangra/509-scrapy-apt-repo
[MRG] update instruction to install using ubuntu packages
==
==================
ebfb5b70;Daniel Graña;2014-01-20 15:18:34 -0200;replace warning about updating package lists by a note on package upgrade

==

docs/topics/ubuntu.rst
==================
52c3ff91;Daniel Graña;2014-01-20 14:39:26 -0200;fix apt-get line

==

docs/topics/ubuntu.rst
==================
a0e25aec;Paul Tremberth;2014-01-20 17:29:16 +0100;Use assertTrue/False

==

scrapy/tests/test_selector.py
==================
eb73ddd3;Daniel Graña;2014-01-19 19:12:07 -0200;Update Ubuntu installation instructions

==

docs/topics/ubuntu.rst
==================
7f30a671;stray-leone;2014-01-20 12:32:09 +0900;modify the version of scrapy ubuntu package
latest version is 0.22.
with scrapy-0.18, tutorial project provides error
relative issue : https://github.com/scrapy/scrapy/issues/511

==

docs/topics/ubuntu.rst
==================
431f2d10;Daniel Graña;2014-01-17 17:54:01 -0200;fix 0.22.0 release date

==

docs/news.rst
==================
dfd13f99;Mikhail Korobov;2014-01-18 01:44:21 +0600;fix typos in news.rst and remove (not released yet) header

==

docs/news.rst
==================
001cf39f;Paul Tremberth;2014-01-17 00:04:20 +0100;Add testcase to check is default Selector doesnt return smart strings

==

scrapy/tests/test_selector.py
==================
5eb33621;Paul Tremberth;2014-01-16 10:44:17 +0100;Make lxml smart strings functionality customizable

==

scrapy/selector/unified.py
==================
1f184ed7;Paul Tremberth;2014-01-15 15:17:18 +0100;Disable smart strings in lxml XPath evaluations

==

scrapy/selector/unified.py
==================
d8164bd5;Daniel Graña;2014-01-17 15:57:10 -0200;bump version to 0.23

==

scrapy/VERSION
==================
d1f1b074;Daniel Graña;2014-01-16 21:16:11 -0200;Merge 0.22.0 release notes

==

docs/news.rst
scrapy/VERSION
==================
3c1e2261;Daniel Graña;2014-01-17 09:10:26 -0800;Merge pull request #541 from kmike/fs-as-default-cache
[MRG] Make Filesystem storage backend default again. 
==
==================
7b7a1d8d;Mikhail Korobov;2014-01-17 04:32:08 +0600;Make Filesystem storage backend default again. See GH-500.

==

docs/topics/downloader-middleware.rst
scrapy/settings/default_settings.py
==================
f0851e41;Daniel Graña;2014-01-16 14:02:26 -0800;Merge pull request #478 from redapple/offsitetests
Add tests for OffsiteMiddleware() + use re.escape() in domains regexp
==
==================
151f9478;Daniel Graña;2014-01-16 10:33:46 -0800;Merge pull request #538 from kmike/ajaxcrawlable-rename
[MRG] Rename AjaxCrawlableMiddleware to AjaxCrawlMiddleware
==
==================
b03fe049;Mikhail Korobov;2014-01-16 23:09:37 +0600;Rename AjaxCrawlableMiddleware to AjaxCrawlMiddleware

==

docs/topics/broad-crawls.rst
docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/ajaxcrawl.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware_ajaxcrawlable.py
==================
ed6fd493;Pablo Hoffman;2014-01-16 06:44:51 -0800;Merge pull request #524 from hobsonlane/master
documentation code example corrections per pablohoffman
==
==================
71ada547;Pablo Hoffman;2014-01-16 06:32:05 -0800;Merge pull request #472 from redapple/exslt
Register EXSLT namespaces by default (resolves #470)
==
==================
b9bb9bed;Daniel Graña;2014-01-16 05:07:39 -0800;Merge pull request #343 from kmike/ajax-crawlable
[MRG] AjaxCrawlableMiddleware
==
==================
e2a5310f;Daniel Graña;2014-01-16 04:14:27 -0800;Merge pull request #537 from dangra/warn-xpathselector-subclass
warn XPathSelector deprecation on subclassing and direct instance
==
==================
5a175ad2;Daniel Graña;2014-01-16 04:07:21 -0800;Merge pull request #519 from dangra/warn-once
Warn BaseSpider deprecation only once
==
==================
b3be6e21;Daniel Graña;2014-01-03 17:32:40 -0200;warn XPathSelector deprecation on subclassing and direct instance

==

scrapy/selector/lxmlsel.py
scrapy/tests/test_selector.py
==================
3e42646c;Daniel Graña;2014-01-16 09:49:51 -0200;do not test multiple instantation warnings

==

scrapy/tests/test_utils_deprecate.py
==================
85a80d07;Hobson Lane;2014-01-15 17:29:23 -0800;remove "for brevity's sake" line and correct "Torrent item"
Torrent item -> TorrentItem class
==

docs/intro/overview.rst
==================
03dab011;Mikhail Korobov;2014-01-15 16:39:33 -0800;Merge pull request #536 from manfre/patch-1
Fix comment typo
==
==================
4a2a45b4;Michael Manfre;2014-01-15 12:35:34 -0500;Fix comment typo

==

scrapy/contrib/spidermiddleware/offsite.py
==================
827c0cf5;Paul Tremberth;2014-01-15 15:00:25 +0100;Rename "regexp" prefix to "re"

==

docs/topics/selectors.rst
scrapy/selector/unified.py
scrapy/tests/test_selector.py
==================
c92f52ce;Mikhail Korobov;2014-01-15 04:05:37 -0800;Merge pull request #525 from alexanderlukanin13/urllib_test_coverage
Improved test coverage
==
==================
af16fa32;Mikhail Korobov;2014-01-15 03:56:45 -0800;Merge pull request #533 from chekunkov/make_dupefilter_easily_subclassable
Make dupefilter easily subclassable
==
==================
88c8a523;Paul Tremberth;2014-01-15 12:52:10 +0100;Add warning in docs on performance when using EXSLT regexp functions

==

docs/topics/selectors.rst
==================
54116959;Alexander Chekunkov;2014-01-15 13:44:46 +0200;removed request_fingerprint method from BaseDupeFilter, removed unnecessary docstring

==

scrapy/dupefilter.py
==================
a3eba68a;Paul Tremberth;2014-01-15 12:28:25 +0100;Drop EXSLT strings and math extensions

==

docs/topics/selectors.rst
scrapy/selector/unified.py
scrapy/tests/test_selector.py
==================
c2421a4b;Alexander Chekunkov;2014-01-15 13:02:05 +0200;Added request_fingerprint method to dupefilter classes so they could be easily subclassed without need to override entire request_seen method.

==

.gitignore
scrapy/dupefilter.py
==================
25759bdf;alexanderlukanin13;2014-01-15 13:09:36 +0600;Removed deploy test (as deploy command is deprecated and moved to scrapyd)

==

scrapy/tests/test_command_deploy.py
scrapy/tests/test_commands.py
==================
ab649664;alexanderlukanin13;2014-01-15 13:05:00 +0600;Added "six>=1.5.2" to requirements

==

debian/control
setup.py
==================
ea2f897b;Pablo Hoffman;2014-01-14 21:07:42 -0800;Merge pull request #502 from scrapy/doc-fixes
DOWNLOAD_DELAY docs clarification
==
==================
a3db9598;Hobson Lane;2014-01-14 21:04:15 -0800;another import name correction by pablo

==

docs/intro/overview.rst
==================
3d308d77;Pablo Hoffman;2014-01-14 21:01:32 -0800;Merge pull request #517 from hoprocker/patch-1
Clarify return value from extract_links
==
==================
622ffd84;Pablo Hoffman;2014-01-14 20:58:07 -0800;Merge pull request #523 from dangra/warn-xpathitemloader-subclass
warn on XPathItemLoader subclassing
==
==================
b377d4c2;Pablo Hoffman;2014-01-14 20:42:19 -0800;Merge pull request #531 from kmike/fix-memdebug
Fix logging of stats collected by MemoryDebugger extension.
==
==================
26538b01;Mikhail Korobov;2014-01-15 04:05:09 +0600;Fix logging of stats collected by MemoryDebugger extension.
Stats are printed on spider_closed event;
engine_stopped signal is called after spider_closed signal,
so stats for MemoryDebugger extension were not printed to user.

==

scrapy/contrib/memdebug.py
==================
553c70a9;Daniel Graña;2014-01-14 13:56:02 -0800;Merge pull request #530 from kmike/memusage-osx
Fix MemoryUsage extension for OS X
==
==================
a83c6f54;Mikhail Korobov;2014-01-15 03:24:48 +0600;Fix MemoryUsage extension for OS X. Fix GH-529.

==

scrapy/contrib/memusage.py
==================
2cc26e6f;Paul Tremberth;2014-01-14 13:09:18 +0100;Fix typo error

==

docs/topics/selectors.rst
==================
29fc9f34;Paul Tremberth;2014-01-09 19:08:34 +0100;Update selectors documentation and tests

==

docs/topics/selectors.rst
scrapy/tests/test_selector.py
==================
5df56a97;Paul Tremberth;2014-01-08 18:48:20 +0100;Applying suggestions from previous comments

==

scrapy/selector/unified.py
==================
d46534cc;Paul Tremberth;2013-11-24 04:41:14 +0100;Register EXSLT namespaces by default (resolves #470)

==

scrapy/selector/unified.py
scrapy/tests/test_selector.py
==================
62a7b6fe;Pablo Hoffman;2014-01-13 07:06:32 -0800;Merge pull request #527 from ferdyrod/master
Torrent url in the "Scrapy at a glance" doc was removed
==
==================
807dd253;Ferdy Rodriguez;2014-01-13 00:03:58 -0600;fixed error on tor's name

==

docs/intro/overview.rst
==================
8b9348cf;Ferdy Rodriguez;2014-01-12 23:46:04 -0600;Changed TOR Info as previous was removed from www.mininova.org

==

docs/intro/overview.rst
==================
4862a7d7;alexanderlukanin13;2014-01-11 17:29:44 +0600;RobotsTxtMiddlewareTest

==

scrapy/tests/test_downloadermiddleware_robotstxt.py
==================
a54e31ce;alexanderlukanin13;2014-01-11 15:12:54 +0600;RegexLinkExtractorTestCase

==

scrapy/tests/test_contrib_linkextractors.py
==================
968141cd;alexanderlukanin13;2014-01-11 14:30:27 +0600;test_command_deploy, test_contrib_linkextractors

==

requirements.txt
scrapy/tests/test_command_deploy.py
scrapy/tests/test_commands.py
scrapy/tests/test_contrib_linkextractors.py
scrapy/tests/test_downloadermiddleware_robotstxt.py
==================
31dd3dc4;Daniel Graña;2014-01-10 17:42:52 -0200;allow deprecation of subclasses of already deprecated classes

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
116f01f2;Daniel Graña;2014-01-10 16:44:54 -0200;allow overriding old and new class paths

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
6313b7ff;Daniel Graña;2014-01-10 17:50:05 -0200;allow deprecation of a class with custom metaclass

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
1e37b64e;Daniel Graña;2014-01-10 13:40:54 -0200;split subclassing tests and default to warning only once per deprecated class

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
a97b4aa6;Daniel Graña;2014-01-10 13:03:40 -0200;only warn on direct subclasses of the deprecated class

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
8c81d6c6;Daniel Graña;2014-01-10 13:02:05 -0200;revert warning filter on deprecated class instantiation

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
23c37dee;Daniel Graña;2014-01-08 15:05:06 -0200;support showing subclassing deprecation warning only once

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
6ba0857a;Hobson Lane;2014-01-10 10:37:27 -0800;documentation code example correction corrections per pablohoffman

==

docs/intro/overview.rst
docs/topics/downloader-middleware.rst
==================
72ff7a48;Daniel Graña;2014-01-10 13:57:04 -0200;warn on XPathItemLoader subclassing

==

scrapy/contrib/loader/__init__.py
==================
9028a06d;Daniel Graña;2014-01-09 10:58:04 -0800;Merge pull request #520 from redapple/startupinfo
Promote startup info on settings and middleware to INFO level
==
==================
9f90c112;Paul Tremberth;2014-01-09 19:37:06 +0100;Promote startup info on settings and middleware to INFO level

==

scrapy/log.py
scrapy/middleware.py
==================
962e5ef7;malcolm m;2014-01-05 14:42:48 -0800;Clarify return value from extract_links

==

docs/topics/link-extractors.rst
==================
21a8a945;Daniel Graña;2014-01-03 15:31:30 -0800;Merge pull request #514 from dangra/mitmproxy-in-pip15
Mitmproxy in pip15
==
==================
02c80ca7;Daniel Graña;2014-01-03 21:02:25 -0200;rename tests requirements to forward looking for /tests/

==

tests-requirements.txt
tox.ini
==================
face0bf4;Daniel Graña;2014-01-03 19:00:47 -0200;Force PIL installation to comply with mitmproxy requirements. closes #513

==

test-requirements.txt
==================
958d0dbf;Daniel Graña;2014-01-03 18:55:38 -0200;move tests requirements to a single place

==

test-requirements.txt
tox.ini
==================
dadaedce;Pablo Hoffman;2014-01-03 06:49:55 -0800;Merge pull request #512 from yprez/patch-1
Item Pipeline docs - remove unused import from code sample
==
==================
060891c0;Yuri Prezument;2014-01-03 15:44:17 +0200;Remove unused import from code sample
Item pipeline docs - removed unused import from code sample
==

docs/topics/item-pipeline.rst
==================
292d21ca;Mikhail Korobov;2014-01-01 11:52:07 +0600;spelling: instanciated -> instantiated

==

scrapy/contrib/loader/__init__.py
scrapy/selector/lxmlsel.py
scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
sep/sep-001.trac
==================
d7fbccdf;Mikhail Korobov;2013-12-31 21:47:26 -0800;Merge pull request #510 from dangra/kmike-reanme-base-spider
Rename BaseSpider to Spider. Fixes #495, fixes #501.
==
==================
e2f09180;Pablo Hoffman;2013-12-31 12:01:13 -0800;Merge pull request #507 from dangra/fromresponse_override_url
[MRG] support overriding url in FormRequest.from_response
==
==================
b41ad38f;Daniel Graña;2013-12-31 15:54:30 -0200;warn when the deprecated class is instanciated

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
8c4e1db5;Daniel Graña;2013-12-31 14:58:37 -0200;Hold the deprecated class reference in the metaclass

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
f6a0ac83;Daniel Graña;2013-12-30 15:13:18 -0200;support overriding url in FormRequest.from_response

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
5af45689;Mikhail Korobov;2013-12-31 00:17:42 +0600;allow caller to customize clsdict

==

scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
1e96063f;Mikhail Korobov;2013-12-30 23:57:27 +0600;simplify deprecation code (@dangra’s idea)

==

scrapy/spider.py
scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
fa82cc67;Mikhail Korobov;2013-12-30 08:45:38 -0800;Merge pull request #506 from dangra/ahbeng-368-get-func-args-partial-support
get func args partial support - based on #504
==
==================
39458b78;Mikhail Korobov;2013-12-30 20:59:10 +0600;Rename warn_when_subclassed to deprecated_base_class; add some magic for issubclass and isinstance checks to work if subclasses of non-deprecated class are checked against deprecated class.

==

scrapy/spider.py
scrapy/tests/test_spider.py
scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
04788673;Mikhail Korobov;2013-12-29 01:54:24 +0600;improved deprecation code; add some test

==

scrapy/spider.py
scrapy/tests/test_spider.py
scrapy/tests/test_utils_deprecate.py
scrapy/utils/deprecate.py
==================
a27d91f0;Mikhail Korobov;2013-12-28 00:47:32 +0600;Rename BaseSpider to Spider. See GH-495.

==

docs/intro/tutorial.rst
docs/topics/commands.rst
docs/topics/debug.rst
docs/topics/downloader-middleware.rst
docs/topics/item-pipeline.rst
docs/topics/leaks.rst
docs/topics/logging.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/shell.rst
docs/topics/signals.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
extras/qpsclient.py
scrapy/commands/fetch.py
scrapy/contrib/spiders/crawl.py
scrapy/contrib/spiders/feed.py
scrapy/contrib/spiders/init.py
scrapy/contrib/spiders/sitemap.py
scrapy/shell.py
scrapy/spider.py
scrapy/templates/spiders/basic.tmpl
scrapy/tests/spiders.py
scrapy/tests/test_commands.py
scrapy/tests/test_contracts.py
scrapy/tests/test_contrib_feedexport.py
scrapy/tests/test_contrib_spiderstate.py
scrapy/tests/test_downloader_handlers.py
scrapy/tests/test_downloadermiddleware.py
scrapy/tests/test_downloadermiddleware_cookies.py
scrapy/tests/test_downloadermiddleware_decompression.py
scrapy/tests/test_downloadermiddleware_defaultheaders.py
scrapy/tests/test_downloadermiddleware_downloadtimeout.py
scrapy/tests/test_downloadermiddleware_httpauth.py
scrapy/tests/test_downloadermiddleware_httpcache.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_downloadermiddleware_httpproxy.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_downloadermiddleware_retry.py
scrapy/tests/test_downloadermiddleware_stats.py
scrapy/tests/test_downloadermiddleware_useragent.py
scrapy/tests/test_engine.py
scrapy/tests/test_log.py
scrapy/tests/test_logformatter.py
scrapy/tests/test_pipeline_media.py
scrapy/tests/test_settings.py
scrapy/tests/test_spider.py
scrapy/tests/test_spidermanager/test_spiders/spider0.py
scrapy/tests/test_spidermanager/test_spiders/spider1.py
scrapy/tests/test_spidermanager/test_spiders/spider2.py
scrapy/tests/test_spidermanager/test_spiders/spider3.py
scrapy/tests/test_spidermanager/test_spiders/spider4.py
scrapy/tests/test_spidermiddleware_depth.py
scrapy/tests/test_spidermiddleware_httperror.py
scrapy/tests/test_spidermiddleware_offsite.py
scrapy/tests/test_spidermiddleware_referer.py
scrapy/tests/test_spidermiddleware_urllength.py
scrapy/tests/test_stats.py
scrapy/tests/test_utils_reqser.py
scrapy/tests/test_utils_serialize.py
scrapy/tests/test_utils_url.py
scrapy/utils/serialize.py
scrapy/utils/spider.py
==================
439a141a;Mikhail Korobov;2013-12-28 00:46:58 +0600;utility for showing a warning when a class is subclassed

==

scrapy/utils/deprecate.py
==================
74433a17;Daniel Graña;2013-12-30 04:08:50 -0800;Merge pull request #505 from kmike/scrapy-shell-docs
[MRG] minor fixes to scrapy shell docs
==
==================
22e10719;Daniel Graña;2013-12-30 09:25:57 -0200;test loader processors using partial functions

==

scrapy/tests/test_contrib_loader.py
==================
589fd037;Daniel Graña;2013-12-30 09:25:11 -0200;do not return applied arguments on partial functions

==

scrapy/tests/test_utils_python.py
scrapy/utils/python.py
==================
e713733e;Mikhail Korobov;2013-12-30 10:27:39 +0600;minor fixes to scrapy shell docs
* better IPython links;
* MDC link instead of w3schools;
* small formatting fixes;
* show quoted URL in example

==

docs/topics/shell.rst
==================
f9dd2986;Daniel Graña;2013-12-29 14:03:29 -0800;Merge pull request #503 from kmike/better-tox-ini
[MRG] allow running individual tests via tox
==
==================
09c3f536;Beng Hee Eu;2013-12-30 03:46:10 +0800;Fixes #368: Support functools.partial in scrapy.utils.python.get_func_args()

==

scrapy/tests/test_utils_python.py
scrapy/utils/python.py
==================
b15df73a;Mikhail Korobov;2013-12-29 01:59:20 +0600;allow running individual tests via tox, e.g. «tox -e trunk -- scrapy.tests.test_spider»

==

tox.ini
==================
f18ac029;Mikhail Korobov;2013-12-28 05:40:10 +0500;remove duplicated link extractors link
Check http://doc.scrapy.org/en/latest/topics/link-extractors.html - two menu items are highlighted at the left.
==

docs/index.rst
==================
9a999daa;Mikhail Korobov;2013-12-28 06:30:34 +0600;DOWNLOAD_DELAY docs clarification:
* delay is enforced per website, not per spider;
* document download_delay attribute (it was previously documented only in FAQ about 999 error codes);
* document how CONCURRENT_REQUESTS_PER_IP affects download delays.

==

docs/topics/autothrottle.rst
docs/topics/settings.rst
==================
99f02b11;Pablo Hoffman;2013-12-24 06:36:06 -0800;Merge pull request #498 from mbacho/master
Removing extra 'doc' extension, adding 'pptx' and 'xlsx' extensions
==
==================
95dc46f2;Chomba Ng'ang'a;2013-12-24 17:29:40 +0300;Removing extra 'doc' extension, adding 'pptx' and 'xlsx' extensions

==

scrapy/linkextractor.py
==================
e42e3743;Pablo Hoffman;2013-12-24 12:19:15 -0200;quick documentation for #475

==

docs/topics/request-response.rst
==================
c4cd0f45;Daniel Graña;2013-12-17 11:58:46 -0200;reindent travis.yml as per travis gem defaults

==

.travis.yml
==================
e9102553;Daniel Graña;2013-12-24 05:20:36 -0800;Merge pull request #475 from dangra/473-do-not-send-header
[MRG] Do not set Referer by default when its value is None
==
==================
2b7fea26;Daniel Graña;2013-11-25 15:34:13 -0200;Do not set Referer by default when its value is None
closes #473

==

scrapy/http/headers.py
scrapy/tests/mockserver.py
scrapy/tests/spiders.py
scrapy/tests/test_crawl.py
scrapy/tests/test_http_headers.py
==================
2c2ce208;Daniel Graña;2013-12-23 15:11:53 -0800;Merge pull request #490 from max-arnold/master
add new pipeline methods to get file/image/thumbnail paths
==
==================
e0cebbfc;Mikhail Korobov;2013-12-20 23:12:37 +0600;add a remark about 1%

==

docs/topics/broad-crawls.rst
==================
ee46ec89;Mikhail Korobov;2013-12-20 19:08:49 +0600;kill AjaxCrawlableMiddlewar.enabled_setting

==

scrapy/contrib/downloadermiddleware/ajaxcrawlable.py
==================
80bb9fb5;Pablo Hoffman;2013-12-19 05:40:34 -0800;Merge pull request #497 from kmike/utils-unique
[MRG] no need to use dict in scrapy.utils.python.unique
==
==================
84aa7599;Mikhail Korobov;2013-12-19 15:06:27 +0600;no need to use dict in scrapy.utils.python.unique

==

scrapy/utils/python.py
==================
93eee9d1;Mikhail Korobov;2013-12-18 12:17:57 -0800;Merge pull request #479 from citizen-stig/unicode_spider_name
fix logging error with unicode spider name
==
==================
943a0bd2;Mikhail Korobov;2013-12-19 01:01:26 +0600;AjaxCrawlableMiddleware in Broad Crawl docs

==

docs/topics/broad-crawls.rst
docs/topics/downloader-middleware.rst
==================
84a3a9da;Mikhail Korobov;2013-12-19 00:35:46 +0600;extra test

==

scrapy/tests/test_downloadermiddleware_ajaxcrawlable.py
==================
503ab58f;Mikhail Korobov;2013-12-19 00:28:47 +0600;Fail-fast path.
For me middleware now can process about 2-3k ajax crawlable pages/sec and 50k+ regular pages/sec (if they don’t contain «fragment» or «content» words).

==

scrapy/contrib/downloadermiddleware/ajaxcrawlable.py
==================
71c59e1c;Mikhail Korobov;2013-12-19 00:23:38 +0600;add an undocumented setting for lookup body size

==

scrapy/contrib/downloadermiddleware/ajaxcrawlable.py
==================
a87b3bd1;Mikhail Korobov;2013-07-10 04:30:05 +0600;AjaxCrawlableMiddleware

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/ajaxcrawlable.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware_ajaxcrawlable.py
==================
51f340e1;Mikhail Korobov;2013-12-18 23:29:07 +0600;add distutils folders to gitignore

==

.gitignore
==================
87559a12;Max Arnold;2013-12-18 23:23:01 +0700;fix missing keyword arguments for file_path in media_downloaded()

==

scrapy/contrib/pipeline/files.py
==================
d8ca8f83;Max Arnold;2013-12-18 23:09:37 +0700;test for new response and info keyword arguments

==

scrapy/tests/test_pipeline_files.py
scrapy/tests/test_pipeline_images.py
==================
2dfeff7e;Max Arnold;2013-12-18 22:46:27 +0700;rename ImagesPipelineTestCase image_path var to file_path for clarity

==

scrapy/tests/test_pipeline_images.py
==================
69595233;Max Arnold;2013-12-18 22:44:04 +0700;implement DeprecatedImagesPipelineTestCase

==

scrapy/tests/test_pipeline_images.py
==================
65c017c5;Max Arnold;2013-12-18 22:25:42 +0700;implement DeprecatedFilesPipelineTestCase

==

scrapy/tests/test_pipeline_files.py
==================
14b68b47;Max Arnold;2013-12-18 22:13:49 +0700;rename FilesPipelineTestCase image_path var to file_path for clarity

==

scrapy/tests/test_pipeline_files.py
==================
23c50bd9;Max Arnold;2013-12-18 10:52:13 +0700;rename key to path in FilesPipelineTestCase

==

scrapy/tests/test_pipeline_files.py
==================
d58a4639;Max Arnold;2013-12-17 23:57:22 +0700;switch existing pipeline tests to use new file_path/image_path methods

==

scrapy/tests/test_pipeline_files.py
scrapy/tests/test_pipeline_images.py
==================
220ced16;Max Arnold;2013-12-17 23:19:40 +0700;simplify porting to Python 3

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
==================
86a6d689;Max Arnold;2013-12-17 22:44:12 +0700;better marker name to detect overridden methods

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
==================
c2993986;Max Arnold;2013-12-17 22:35:31 +0700;add deprecation warnings for old file_key/image_key/thumb_key methods

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
==================
270e9190;Max Arnold;2013-12-17 21:50:40 +0700;add new pipeline methods to get file/image/thumbnail paths
This change allows to pass request, response and spider context to filename
construction methods.

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
==================
462e40ac;Pablo Hoffman;2013-12-16 06:40:59 -0800;Merge pull request #489 from RasPat1/patch-2
Note about selector class import
==
==================
ff21281b;RasPat1;2013-12-15 13:46:42 -0500;Note about selector class import
This is the salient point of this code compared to the last example.  We have a selector now and this is how we use it.  Especially since the user has just come from the shell where the pre-instantiated selector is taken for granted.
==

docs/intro/tutorial.rst
==================
8a7c5b5d;Daniel Graña;2013-12-09 18:28:38 -0200;Add 0.20.2 release notes
Conflicts:
	docs/news.rst

==

docs/news.rst
==================
11359188;Daniel Graña;2013-12-09 12:21:27 -0800;Merge pull request #484 from nyov/nyov/crawl-tmpl-selector
Update CrawlSpider Template with Selector changes
==
==================
022538d3;Benoit Blanchon;2013-12-07 20:43:22 +0100;BaseSgmlLinkExtractor: Fixed the missing space when the link has an inner tag

==

scrapy/contrib/linkextractors/sgml.py
==================
79179f59;Benoit Blanchon;2013-12-07 20:42:21 +0100;BaseSgmlLinkExtractor: Added unit test of a link with an inner tag

==

scrapy/tests/sample_data/link_extractor/sgml_linkextractor.html
scrapy/tests/test_contrib_linkextractors.py
==================
62f71719;Benoit Blanchon;2013-12-07 19:47:50 +0100;BaseSgmlLinkExtractor: Fixed unknown_endtag() so that it only set current_link=None when the end tag match the opening tag

==

scrapy/contrib/linkextractors/sgml.py
==================
b6a200d0;nyov;2013-12-06 20:48:25 +0000;Update CrawlSpider Template with Selector changes

==

scrapy/templates/spiders/crawl.tmpl
==================
72543c9e;Daniel Graña;2013-12-03 14:48:42 -0800;Merge pull request #397 from duendex/duendex/proxyTunnel
Adds the functionality to do HTTPS downloads behind proxies using an
==
==================
8ada8f5f;duendex;2013-12-03 12:55:44 -0200;Added a test case to ensure that passing the noconnect paramenter avoids trigerring the creation of a connect tunnel when downloading from a site with https scheme.

==

scrapy/tests/test_downloader_handlers.py
==================
6427d60f;duendex;2013-12-03 11:45:02 -0200;Fixed the location of the certificate required by libmproxy.

==

scrapy/tests/keys/mitmproxy-ca.pem
scrapy/tests/test_proxy_connect.py
==================
500490ee;duendex;2013-12-03 03:10:16 -0200;Corrected a test that used a dummy URL that unpurposedly had an https scheme and failed with PR 397.

==

scrapy/tests/test_downloader_handlers.py
==================
f8dea749;duendex;2013-12-03 03:09:06 -0200;Added a delay to wait for the proxy to start.

==

scrapy/tests/test_proxy_connect.py
==================
247b330f;duendex;2013-12-02 21:34:35 -0200;Corrected typo in tox.ini

==

tox.ini
==================
02bab270;duendex;2013-12-02 20:25:12 -0200;Added mitmproxy as a requirement.

==

tox.ini
==================
d69ba7c1;duendex;2013-12-02 16:35:35 -0200;Changed the proxy tests to use libmproxy instead of starting mitmdump as a separate process.

==

scrapy/tests/test_proxy_connect.py
==================
88bec496;duendex;2013-10-02 15:03:42 -0300;The response matching re is now compiled once at module load time.

==

scrapy/core/downloader/handlers/http11.py
==================
23c3288a;duendex;2013-09-30 12:55:48 -0300;Adds the option to omit the usage of a CONNECT tunnel by adding the noconnect parameter to the URL of the proxy.

==

scrapy/core/downloader/handlers/http11.py
==================
7f053cc1;duendex;2013-09-30 10:43:25 -0300;Adds support for proxy authentication when openning a CONNECT tunnel.

==

scrapy/core/downloader/handlers/http11.py
==================
628bfbcc;duendex;2013-09-30 10:18:57 -0300;Raises a custom TunnelError when the tunnel cannot be opened. Removed unnecesary comments.

==

scrapy/core/downloader/handlers/http11.py
==================
58a98b0c;duendex;2013-09-26 11:20:41 -0300;Improved error handling.

==

scrapy/core/downloader/handlers/http11.py
==================
36e4fc37;duendex;2013-09-25 12:59:11 -0300;Removed some trailing spaces that I left.

==

scrapy/core/downloader/handlers/http11.py
==================
ae28c7d6;duendex;2013-09-25 12:19:03 -0300;Adds the functionality to do HTTPS downloads behind proxies using an HTTP CONNECT.

==

scrapy/core/downloader/handlers/http11.py
==================
f2741c41;Pablo Hoffman;2013-12-02 13:24:12 -0200;fix method name in tutorial. closes GH-480

==

docs/intro/tutorial.rst
==================
a651a752;Nikolay Golub;2013-11-30 21:08:56 +0400;fix logging error with unicode spider name
Log message fails if spider name is in unicode, because "system" key in eventDict isn't encoded.

==

scrapy/log.py
==================
e34ffc0f;Daniel Graña;2013-11-28 16:18:59 -0200;Add 0.20.1 release notes
Conflicts:
	docs/news.rst

==

docs/news.rst
==================
cfe58810;Daniel Graña;2013-11-28 16:15:10 -0200;include_package_data is required to build wheels from published sources

==

setup.py
==================
13002564;Paul Tremberth;2013-11-28 13:37:01 +0100;Add tests for OffsiteMiddleware() + use re.escape() in domains regexp

==

scrapy/contrib/spidermiddleware/offsite.py
scrapy/tests/test_spidermiddleware_offsite.py
==================
33986136;Pablo Hoffman;2013-11-25 10:33:35 -0800;Merge pull request #425 from audiodude/master
DownloaderMiddleware docs: Update process_request and minor cleanups.
==
==================
aeeba214;Daniel Graña;2013-11-25 13:57:28 -0200;travis-ci updated to pypy 2.2

==

.travis-workarounds.sh
.travis.yml
==================
36c8da2a;Daniel Graña;2013-11-22 12:10:39 -0800;Merge pull request #461 from redapple/selectorloader
Add "unified" SelectorItemLoader (supports .add_css() and .add_xpath())
==
==================
545f2601;Pablo Hoffman;2013-11-21 10:55:07 -0800;Merge pull request #469 from redapple/xgzip
Remove "x-gzip" from Requests' "Accept-Encoding" header
==
==================
0d99babe;Paul Tremberth;2013-11-21 18:58:24 +0100;Remove "x-gzip" from Requests' "Accept-Encoding" header

==

scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
==================
14f5817d;Paul Tremberth;2013-11-16 01:05:39 +0100;Modify ItemLoader to support XPath and CSS selectors
Deprecate XPathItemLoader (now an alias to the new ItemLoader)

==

docs/topics/loaders.rst
scrapy/contrib/loader/__init__.py
scrapy/tests/test_contrib_loader.py
==================
f87be371;Pablo Hoffman;2013-11-21 14:33:17 -0200;better names for HANDLE_* settings, and added doc

==

docs/topics/spider-middleware.rst
scrapy/contrib/spidermiddleware/httperror.py
scrapy/tests/test_spidermiddleware_httperror.py
==================
ab01e9e9;Daniel Graña;2013-11-21 03:55:44 -0800;Merge pull request #466 from kalessin/httperror
allow to use settings for defining http error handling defaults
==
==================
55bee912;Martin Olveyra;2013-11-20 20:12:49 -0200;allow to use settings for defining http error handling defaults

==

scrapy/contrib/spidermiddleware/httperror.py
scrapy/tests/test_spidermiddleware_httperror.py
==================
8416cc75;Mikhail Korobov;2013-11-20 09:40:19 -0800;Merge pull request #465 from bjlange/master
Add note to item-pipeline documentation explaining order 
==
==================
e4c1d8d3;Brian Lange;2013-11-19 17:51:50 -0600;Elaborate on use of order numbers

==

docs/topics/item-pipeline.rst
==================
2564c21d;Daniel Graña;2013-11-19 20:15:15 -0200;add a tox env for Python 3.3

==

tox.ini
==================
526a944e;Daniel Graña;2013-11-19 20:14:48 -0200;lxml is required, no need to skip tests.

==

scrapy/tests/test_utils_iterators.py
==================
3f156ad8;Daniel Graña;2013-11-19 20:13:34 -0200;Do not call body_as_unicode on non text responses. closes #462

==

scrapy/tests/test_utils_iterators.py
scrapy/tests/test_utils_response.py
scrapy/utils/iterators.py
==================
b878f60b;Brian Lange;2013-11-19 16:12:54 -0600;Add note to item-pipeline documentation explaining order in the ITEM_PIPELINES setting.

==

docs/topics/item-pipeline.rst
==================
ec7833a9;Daniel Graña;2013-11-19 19:21:54 -0200;Deprecate body_or_str helper function only used by xml iterators

==

scrapy/utils/decorator.py
scrapy/utils/iterators.py
scrapy/utils/response.py
==================
2d91c713;Pablo Hoffman;2013-11-19 05:22:58 -0800;Merge pull request #464 from kalessin/telnet
telnet client: fix unexisting reference to engine.slots
==
==================
755b9ba5;olveyra;2013-11-19 04:52:24 +0100;telnet client: fix unexisting reference to engine.slots

==

scrapy/telnet.py
==================
afe6eaa2;Pablo Hoffman;2013-11-15 04:10:49 -0800;Merge pull request #460 from tntC4stl3/master
duplicate 'use' in line 87
==
==================
b51d5d81;tntC4stl3;2013-11-15 13:56:44 +0800;duplicate 'use' in line 87

==

docs/topics/commands.rst
==================
c74903f9;Daniel Graña;2013-11-09 02:12:52 -0200;process_parallel was leaking the failures on its internal deferreds.  closes #458
DeferredList implemented cancellation in Twisted 13.2.0 by holding a
reference to the affected deferreds objects, if a deferred errored the
result was propagated to the DeferredList but still referenced by the
original deferred and nobody was consuming it.

The tests started to fail because the reference from DeferredList
prevented the underlining deferred from been collected before the test
finish invalidating the effect of self.flushedLoggedErrors() call.

==

scrapy/utils/defer.py
==================
04ff7ece;Daniel Graña;2013-11-08 17:43:43 -0200;improve 0.20 release notes
Conflicts:
	docs/news.rst

==

docs/news.rst
==================
3d18a3c4;Daniel Graña;2013-11-08 17:09:00 -0200;bumped version to 0.21.0

==

docs/news.rst
scrapy/VERSION
==================
d0980e5c;Daniel Graña;2013-11-08 16:57:42 -0200;Merge 0.20 release notes

==

docs/news.rst
scrapy/VERSION
==================
60516123;Daniel Graña;2013-11-07 11:29:58 -0200;Merge branch 'travix-toxed'
Conflicts:
	requirements.txt

==
==================
d29791d7;Daniel Graña;2013-11-07 09:54:04 -0200;building Pillow with pypy requries dev headers

==

.travis-workarounds.sh
==================
971f60d7;Daniel Graña;2013-11-07 05:01:32 -0200;TOXENV is tox supported env

==

.travis-workarounds.sh
.travis.yml
==================
ecfa7431;Daniel Graña;2013-11-07 04:26:25 -0200;install updated pypy from ppa

==

.travis-install.sh
.travis.yml
==================
fabb3510;Daniel Graña;2013-11-07 04:02:46 -0200;map travis-ci matrix to tox environments

==

.travis.yml
.travis/requirements-latest.txt
.travis/requirements-precise.txt
.travis/requirements-trunk.txt
requirements.txt
tox.ini
==================
bc7fa611;Daniel Graña;2013-11-07 02:32:00 -0200;Django 1.6 form validation errors now include ValidationError exception instances instead of just strings

==

requirements.txt
scrapy/tests/test_djangoitem/__init__.py
==================
6f5423ae;Rolando Espinoza La fuente;2013-10-27 19:10:25 -0400;Replaced remaning __import__(module) calls.
This commit replaces the statements __import__(module) as the previous
replaced the statements __import__(module, {}, {}, ['']).

At first I thought leaving the single-argument calls, but perhaps it's
better to be strict rather than having exceptions to the rule in this
case.

==

scrapy/contrib/memusage.py
scrapy/settings/default_settings.py
scrapy/tests/test_dependencies.py
scrapy/utils/test.py
==================
6b1760d7;Rolando Espinoza La fuente;2013-10-27 18:28:23 -0400;replaced __import__ by importlib.import_module.
Since python 2.7, importlib.import_module is the recommended way to
import modules programmatically.

From __import__'s doc:

    Import a module. Because this function is meant for use by the
Python
    interpreter and not for general use it is better to use
    importlib.import_module() to programmatically import a module.

==

scrapy/commands/genspider.py
scrapy/commands/runspider.py
scrapy/contrib/httpcache.py
scrapy/tests/test_dependencies.py
scrapy/utils/misc.py
scrapy/utils/project.py
==================
b6bed44c;Daniel Graña;2013-11-07 02:32:00 -0200;Django 1.6 form validation errors now include ValidationError exception instances instead of just strings

==

requirements.txt
scrapy/tests/test_djangoitem/__init__.py
==================
b78e7610;Daniel Graña;2013-11-06 20:14:27 -0800;Merge pull request #445 from darkrho/import-module
Use `importlib.import_module` instead of `__import__`
==
==================
2318c56f;Daniel Graña;2013-11-04 23:57:44 -0200;shutdown the active crawler on SIGINT. fixes #450

==

scrapy/crawler.py
==================
f80f10ae;Mikhail Korobov;2013-11-04 00:54:02 -0800;Merge pull request #452 from alexanderlukanin13/python3
PY3: scrapy.__version__, NoneType, urlparse_monkeypatches
==
==================
6c7292a0;alexanderlukanin13;2013-11-03 22:20:33 +0600;python3: scrapy.__version__, NoneType, urlparse_monkeypatches

==

scrapy/__init__.py
scrapy/utils/trackref.py
scrapy/xlib/urlparse_monkeypatches.py
==================
d1b91289;Rolando Espinoza La fuente;2013-10-30 21:07:53 -0400;Merge branch 'master' into import-module

==
==================
fa245af6;Pablo Hoffman;2013-10-30 05:53:06 -0700;Merge pull request #448 from dangra/drop-py26
Drop Python 2.6 support
==
==================
2df81564;Daniel Graña;2013-10-29 13:44:00 -0200;Drop Python 2.6 support

==

.travis.yml
.travis/requirements-lucid.txt
README.rst
debian/control
docs/faq.rst
docs/intro/install.rst
docs/news.rst
docs/topics/ubuntu.rst
scrapy/__init__.py
scrapy/tests/test_downloadermiddleware_httpproxy.py
scrapy/utils/datatypes.py
scrapy/utils/py26.py
scrapy/utils/py27.py
scrapy/xlib/ordereddict.py
setup.py
tox.ini
==================
10e22aa5;Rolando Espinoza La fuente;2013-10-27 19:10:25 -0400;Replaced remaning __import__(module) calls.
This commit replaces the statements __import__(module) as the previous
replaced the statements __import__(module, {}, {}, ['']).

At first I thought leaving the single-argument calls, but perhaps it's
better to be strict rather than having exceptions to the rule in this
case.

==

scrapy/contrib/memusage.py
scrapy/settings/default_settings.py
scrapy/tests/test_dependencies.py
scrapy/utils/test.py
==================
343f997e;Rolando Espinoza La fuente;2013-10-27 18:28:23 -0400;replaced __import__ by importlib.import_module.
Since python 2.7, importlib.import_module is the recommended way to
import modules programmatically.

From __import__'s doc:

    Import a module. Because this function is meant for use by the
Python
    interpreter and not for general use it is better to use
    importlib.import_module() to programmatically import a module.

==

scrapy/commands/genspider.py
scrapy/commands/runspider.py
scrapy/contrib/httpcache.py
scrapy/tests/test_dependencies.py
scrapy/utils/misc.py
scrapy/utils/project.py
==================
bd79b6e1;Daniel Graña;2013-10-24 16:47:36 -0200;debian package requires python-cssselect

==

debian/control
==================
247b2ad5;Mikhail Korobov;2013-10-22 10:38:45 -0700;Merge pull request #431 from alexanderlukanin13/syntax
Python 3 compatible syntax: print, except, raise, octal numbers; removed...
==
==================
6b598476;alexanderlukanin13;2013-10-22 22:49:18 +0600;print_function in xlib

==

scrapy/xlib/lsprofcalltree.py
scrapy/xlib/pydispatch/saferef.py
==================
3d4904be;Mikhail Korobov;2013-10-22 08:35:09 -0700;Merge pull request #436 from alexanderlukanin13/syntax-next
Using next() for Python 3 compatibility; ordereddict.py converted from DOS to Unix
==
==================
bf6ef291;Mikhail Korobov;2013-10-22 07:37:57 -0700;Merge pull request #435 from alexanderlukanin13/syntax-map
Converted map() to list comprehension/generator for Python3 compatibility
==
==================
a958cb2c;alexanderlukanin13;2013-10-22 13:54:22 +0600;Using next() for Python 3 compatibility

==

scrapy/core/engine.py
scrapy/tests/test_utils_iterators.py
scrapy/tests/test_utils_python.py
scrapy/utils/defer.py
scrapy/utils/iterators.py
scrapy/xlib/ordereddict.py
scrapy/xlib/tx/endpoints.py
==================
6b35166d;alexanderlukanin13;2013-10-22 13:18:26 +0600;Converted map() to list comprehension or generator for Python 3 compatibility

==

scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/httpcache.py
scrapy/telnet.py
scrapy/tests/test_contracts.py
scrapy/tests/test_dependencies.py
scrapy/tests/test_pipeline_files.py
scrapy/webservice.py
==================
911c8082;Pablo Hoffman;2013-10-21 14:42:51 -0200;simplified description of crawl command

==

docs/topics/commands.rst
scrapy/commands/crawl.py
==================
e8ee449a;Pablo Hoffman;2013-10-21 09:40:58 -0700;Merge pull request #432 from darkrho/crawl-url
Removed URL reference in crawl command and .tld suffix in docs for spider names
==
==================
ae4a61a2;alexanderlukanin13;2013-10-20 11:55:07 +0600;Added "from __future__ import print_function" in all relevant places except xlib

==

extras/qps-bench-server.py
extras/scrapy-ws.py
scrapy/__init__.py
scrapy/cmdline.py
scrapy/commands/check.py
scrapy/commands/deploy.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/parse.py
scrapy/commands/settings.py
scrapy/commands/startproject.py
scrapy/commands/version.py
scrapy/contrib/httpcache.py
scrapy/contrib/pipeline/media.py
scrapy/dupefilter.py
scrapy/shell.py
scrapy/tests/mockserver.py
scrapy/tests/test_downloadermiddleware_httpcache.py
scrapy/tests/test_engine.py
scrapy/tests/test_pipeline_media.py
scrapy/tests/test_utils_request.py
scrapy/utils/display.py
scrapy/utils/engine.py
scrapy/utils/request.py
scrapy/utils/testsite.py
scrapy/utils/trackref.py
==================
34543c2b;Rolando Espinoza La fuente;2013-10-19 23:03:20 -0400;DOCS removed .tld suffix for spider names for the sake of consistency.

==

docs/intro/overview.rst
docs/topics/settings.rst
==================
c2ced9a2;Rolando Espinoza La fuente;2013-10-19 22:57:37 -0400;Removed reference to URL in crawl command as it's no longer supported.

==

scrapy/commands/crawl.py
==================
d381a357;alexanderlukanin13;2013-10-20 01:59:35 +0600;Python 3 compatible syntax: print, except, raise, octal numbers; removed Python 2.2 boolean compatibility code in xlib/pydispatch/dispatcher.py

==

extras/scrapy-ws.py
scrapy/__init__.py
scrapy/cmdline.py
scrapy/commands/check.py
scrapy/commands/deploy.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/parse.py
scrapy/commands/runspider.py
scrapy/commands/settings.py
scrapy/commands/startproject.py
scrapy/commands/version.py
scrapy/contrib/djangoitem.py
scrapy/contrib/loader/__init__.py
scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/s3.py
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/middleware.py
scrapy/shell.py
scrapy/squeue.py
scrapy/tests/mocks/dummydbm.py
scrapy/tests/mockserver.py
scrapy/tests/test_contrib_loader.py
scrapy/tests/test_dependencies.py
scrapy/tests/test_downloadermiddleware_httpcache.py
scrapy/tests/test_engine.py
scrapy/tests/test_pipeline_images.py
scrapy/tests/test_selector.py
scrapy/tests/test_utils_defer.py
scrapy/tests/test_utils_jsonrpc.py
scrapy/utils/datatypes.py
scrapy/utils/defer.py
scrapy/utils/display.py
scrapy/utils/engine.py
scrapy/utils/jsonrpc.py
scrapy/utils/misc.py
scrapy/utils/python.py
scrapy/utils/test.py
scrapy/utils/testsite.py
scrapy/utils/trackref.py
scrapy/xlib/pydispatch/dispatcher.py
scrapy/xlib/pydispatch/robust.py
scrapy/xlib/pydispatch/saferef.py
scrapy/xlib/tx/_newclient.py
==================
dc666f6e;Rolando Espinoza La fuente;2013-10-19 15:40:42 -0400;PEP8 improvements
* Space lines around classes/functions.
* Space in inline comments.
* Remove redundant backslash between brackets.

==

scrapy/command.py
==================
62fd5b32;Mikhail Korobov;2013-10-18 16:20:04 -0700;Merge pull request #430 from alexanderlukanin13/cleanup
pylint cleanup: unused imports and old-style exceptions
==
==================
105e4620;alexanderlukanin13;2013-10-19 00:48:22 +0600;restored import *, added comment

==

scrapy/utils/url.py
==================
1f17230f;Daniel Graña;2013-10-18 16:08:27 -0200;add testing environment for development versions of w3lib and queuelib

==

.travis.yml
.travis/requirements-trunk.txt
tox.ini
==================
ddcd5710;alexanderlukanin13;2013-10-18 19:23:45 +0600;pylint cleanup: unused imports and old-style exceptions

==

scrapy/crawler.py
scrapy/exceptions.py
scrapy/utils/datatypes.py
scrapy/utils/url.py
==================
2e8cc281;Mikhail Korobov;2013-10-18 02:28:06 -0700;Merge pull request #429 from alexanderlukanin13/bugfix
wrong variable name
==
==================
192c323a;alexanderlukanin13;2013-10-18 11:30:48 +0600;wrong variable name

==

setup.py
==================
757e2622;Daniel Graña;2013-10-16 22:35:15 -0200;update requirement for cssselect >= 0.9

==

setup.py
==================
875b07ae;Daniel Graña;2013-10-16 22:34:08 -0200;fix references to old selector naming in docs

==

docs/topics/selectors.rst
==================
3043a5ba;Travis Briggs;2013-10-10 19:52:33 +0000;DownloaderMiddleware docs: Update process_request, proper explanation of IgnoreRequest.
Also:
* Change terminology to eliminate uses of terms such as "request middleware" to refer to the process_request methods of installed middleware.
* Remove description of "immediate redirection", as it is misleading.

Further changes.

==

docs/topics/downloader-middleware.rst
==================
086b8a20;Mikhail Korobov;2013-10-17 04:50:30 +0600;typo fix in TextResponse docs

==

docs/topics/request-response.rst
==================
951a9f3f;Pablo Hoffman;2013-10-16 13:15:52 -0700;Merge pull request #226 from scraperdragon/patch-1
Parameters to Request() in wrong order
==
==================
289688e3;Daniel Graña;2013-10-16 12:58:12 -0700;Merge pull request #426 from scrapy/selectors-unified
[MRG] Selectors unified API
==
==================
14613638;Daniel Graña;2013-10-16 17:37:22 -0200;Replace `contenttype` references by `type`
The type to choose from is the selector type, not the input type. A
content-type doesn't make sense in this context.

==

docs/topics/selectors.rst
scrapy/contrib/spiders/feed.py
scrapy/contrib_exp/iterators.py
scrapy/selector/lxmlsel.py
scrapy/selector/unified.py
scrapy/tests/test_selector.py
scrapy/utils/iterators.py
==================
155ea08e;Daniel Graña;2013-10-15 15:58:36 -0200;use `sel` name for Selector's instances in docs, internals and shell

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/firebug.rst
docs/topics/selectors.rst
docs/topics/shell.rst
docs/topics/spiders.rst
scrapy/contrib/linkextractors/sgml.py
scrapy/shell.py
scrapy/tests/test_command_shell.py
scrapy/tests/test_selector.py
scrapy/tests/test_selector_csstranslator.py
==================
1abb1af0;Daniel Graña;2013-10-15 10:13:43 -0200;fix typos and wording on selector's introduction

==

docs/intro/tutorial.rst
==================
a3b711bd;Dragon Dave;2013-10-15 12:19:42 +0100;Move callback blob; mention errback

==

docs/topics/request-response.rst
==================
0ba0d856;scraperdragon;2013-01-15 10:37:06 +0000;Parameters to Request() in wrong order
Implied that callback wasn't the first optional unnamed parameter.
==

docs/topics/request-response.rst
==================
28999590;Daniel Graña;2013-10-14 16:41:04 -0200;update release notes

==

docs/news.rst
==================
ab9462a2;Daniel Graña;2013-10-14 16:37:14 -0200;remove more references to libxml2

==

docs/topics/leaks.rst
scrapy/tests/test_selector_lxmldocument.py
==================
4645f9e0;Daniel Graña;2013-10-14 16:31:20 -0200;Updates docs to reflect unified selectors api

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/firebug.rst
docs/topics/leaks.rst
docs/topics/loaders.rst
docs/topics/selectors.rst
docs/topics/shell.rst
docs/topics/spiders.rst
sep/sep-020.rst
==================
add35069;Daniel Graña;2013-10-14 10:51:16 -0200;remove internal references to old selector classes and api

==

scrapy/contrib/linkextractors/sgml.py
scrapy/contrib/loader/__init__.py
scrapy/contrib/spiders/feed.py
scrapy/contrib_exp/iterators.py
scrapy/tests/test_contrib_loader.py
scrapy/tests/test_spider.py
scrapy/tests/test_utils_iterators.py
scrapy/utils/iterators.py
==================
4e94b383;Daniel Graña;2013-10-14 10:35:02 -0200;port tests to new Selector class

==

scrapy/selector/lxmlsel.py
scrapy/tests/test_selector.py
scrapy/tests/test_selector_csstranslator.py
scrapy/tests/test_selector_lxml.py
scrapy/tests/test_selector_lxmldocument.py
==================
e4d6e2eb;Daniel Graña;2013-10-11 19:53:32 -0200;default xpath selector was html

==

scrapy/selector/lxmlsel.py
==================
a9eb0b74;Daniel Graña;2013-10-11 19:53:01 -0200;port scrapy shell to unified selector api

==

scrapy/shell.py
scrapy/tests/test_command_shell.py
==================
681af6b2;Daniel Graña;2013-10-11 18:22:03 -0200;Remove CSS*Selector classes and port its tests

==

scrapy/selector/__init__.py
scrapy/selector/csssel.py
scrapy/selector/unified.py
scrapy/tests/test_selector_cssselect.py
==================
c3d28cc4;Daniel Graña;2013-10-11 18:06:27 -0200;working implementaion of unified api

==

scrapy/selector/__init__.py
scrapy/selector/csssel.py
scrapy/selector/csstranslator.py
scrapy/selector/list.py
scrapy/selector/lxmlsel.py
scrapy/selector/unified.py
scrapy/tests/test_selector_cssselect.py
==================
bf37f785;Daniel Graña;2013-10-10 19:02:55 -0200;Drop libxml2 selectors backend

==

docs/news.rst
docs/topics/extensions.rst
docs/topics/selectors.rst
scrapy/__init__.py
scrapy/commands/version.py
scrapy/contrib/memdebug.py
scrapy/selector/__init__.py
scrapy/selector/libxml2document.py
scrapy/selector/libxml2sel.py
scrapy/tests/test_libxml2.py
scrapy/tests/test_selector.py
scrapy/tests/test_selector_libxml2.py
scrapy/tests/test_selector_lxml.py
scrapy/utils/test.py
==================
6d598f0d;Daniel Graña;2013-09-24 12:34:46 -0300;Update selectors docs

==

docs/topics/selectors.rst
scrapy/selector/list.py
==================
ea579bca;Paul Tremberth;2013-09-16 15:36:35 +0200;Support only ::text and ::attr(name) + add more CSS selector tests

==

scrapy/selector/csssel.py
scrapy/tests/test_selector_cssselect.py
==================
52e2eb6b;Paul Tremberth;2013-09-16 13:26:34 +0200;Adapt to latest cssselect API supporting pseudo-elements

==

scrapy/selector/csssel.py
scrapy/tests/test_selector_cssselect.py
==================
4e6967b8;Daniel Graña;2013-01-09 17:48:20 -0200;extend css selectors with ":text" and :attribute(<name>) #176

==

scrapy/selector/csssel.py
scrapy/tests/test_selector_cssselect.py
==================
b38ac27e;Daniel Graña;2013-01-09 11:09:02 -0200;rename XPathSelectorList as SelectorList #176

==

scrapy/selector/__init__.py
scrapy/selector/csssel.py
scrapy/selector/libxml2sel.py
scrapy/selector/list.py
scrapy/selector/lxmlsel.py
==================
bc17e9d4;Capi Etheriel;2012-09-30 14:55:55 -0300;Adds HtmlCSSSelector and XmlCSSSelector classes, cssselect as optional dependency.
Ported .get() from _Element and .text_content() from HTMLMixin

Add CSS selectors to scrapy shell

Documenting CSS Selectors: Constructing selectors

Documenting CSS Selectors: Using Selectors

Make CSS Selectors a default feature.

Adds XPath powers to CSS Selectors and some syntactic sugar.

Removes methods copied over from lxml.html.HtmlMixin.

Updating docs to use new CSS Selector super powers.

Documenting CSS Selectors: Regular Expressions

Moving section after Nesting section, since it mentions it.

Documenting CSS Selectors: Nesting Selectors

Fix XPath specificity in lxml.selector.CSSSelectorMixin.text

Cleaning up unused stuff from cssel.py

Changing the behavior of lxml.selector.CSSSelectorMixin.text.

Concatenating all of the descendant text nodes is more useful
than returning it in pieces (there's xpath() if you need that).

Documenting CSS Selectors: CSS Selector objects

Documenting CSS Selectors: CSSSelectorList objects

Documenting CSS Selectors: HtmlCSSSelector objects

Documenting CSS Selectors: XmlCSSSelector objects

Fixing some documentations typos and errors

Enforcing the 80-char width lines

Tidying up CSS selectors and CSSSelectorMixin objects

Adding some missing references in documentation.

Fixing lxml.selector.CSSSelectorList.text

==

docs/topics/selectors.rst
scrapy/selector/__init__.py
scrapy/selector/csssel.py
scrapy/shell.py
setup.py
==================
8bf3284e;Daniel Graña;2013-10-10 11:53:08 -0700;Merge pull request #380 from dangra/dont-log-ignorerequest
Dont log IgnoreRequest exception as download failure
==
==================
1a2db089;Pablo Hoffman;2013-10-10 10:31:13 -0700;Merge pull request #418 from nramirezuy/engine-multispider
engine multispider support removed
==
==================
5b5dd679;Daniel Graña;2013-10-10 01:03:04 -0200;Add 0.18.4 release notes
Conflicts:
	docs/news.rst

==

docs/news.rst
==================
aa6fb7da;Daniel Graña;2013-10-10 00:56:52 -0200;IPython refuses to update the namespace. fix #396
IPython embedding code borrowed from https://github.com/mitsuhiko/werkzeug/pull/85

==

scrapy/utils/console.py
==================
7b1288ba;Daniel Graña;2013-10-09 23:50:24 -0200;Fix AlreadyCalledError replacing a request in shell command. closes #407

==

scrapy/shell.py
scrapy/tests/test_command_shell.py
scrapy/utils/request.py
==================
5eb42999;Daniel Graña;2013-10-03 12:48:56 -0300;Fix start_requests lazyness and early hangs
- Removes new public methods added by #330 to Crawler and CrawlerProcess
- Add test for start_requests lazy evaluation
- Fix and test hangs when start_requests erroed before returning the generator
- Add test when start_requests fails while generating requests
- Simplify Crawler and CrawlerProcess implementation taking in count
  that only one spider can be attached per Crawler. As required by SEP-019
- "scrapy settings" command do not require starting a Crawler anymore

==

scrapy/commands/settings.py
scrapy/crawler.py
scrapy/tests/spiders.py
scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_crawl.py
==================
2bd5002f;Pablo Hoffman;2013-10-09 15:34:08 -0700;Merge pull request #416 from redapple/attrnamespaces
.remove_namespaces(): remove namespaces on elements' attributes
==
==================
e1683ddf;Pablo Hoffman;2013-10-09 17:24:12 -0200;fix doc typo

==

docs/intro/tutorial.rst
==================
a84e5f80;nramirezuy;2013-10-08 16:01:27 -0200;engine multispider support removed

==

scrapy/core/engine.py
scrapy/utils/engine.py
==================
ce82d22c;Pablo Hoffman;2013-10-09 09:03:33 -0700;Merge pull request #423 from nramirezuy/defaultheaders-multispider
defaultheaders multi spider support removed
==
==================
332bf3b6;nramirezuy;2013-10-09 13:50:15 -0200;defaultheaders multi spider support removed

==

scrapy/contrib/downloadermiddleware/defaultheaders.py
==================
7ec01799;Pablo Hoffman;2013-10-09 07:43:11 -0700;Merge pull request #419 from nramirezuy/robotstxt-multispider
robotstxt mid multi spider support removed
==
==================
9ad736d7;Pablo Hoffman;2013-10-08 21:06:49 -0700;Merge pull request #420 from nramirezuy/httpauth-multispider
httpauth mid multispider support removed
==
==================
27d3cbb6;Pablo Hoffman;2013-10-08 21:06:13 -0700;Merge pull request #421 from nramirezuy/useragent-multispider
useragent mid multi spider support removed
==
==================
37b01a22;Pablo Hoffman;2013-10-08 21:05:06 -0700;Merge pull request #422 from nramirezuy/downloadtimeout-multispider
downloadtimeout mid multi spider support removed
==
==================
1d09b6e1;nramirezuy;2013-10-08 19:03:26 -0200;downloadtimeout mid multi spider support removed

==

scrapy/contrib/downloadermiddleware/downloadtimeout.py
scrapy/tests/test_downloadermiddleware_downloadtimeout.py
==================
fbb0ad64;nramirezuy;2013-10-08 18:18:49 -0200;useragent mid multi spider support removed

==

scrapy/contrib/downloadermiddleware/useragent.py
scrapy/tests/test_downloadermiddleware_useragent.py
==================
f56f5477;nramirezuy;2013-10-08 17:36:13 -0200;httpauth mid multispider support removed

==

scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/tests/test_downloadermiddleware_httpauth.py
==================
10646f17;nramirezuy;2013-10-08 16:38:08 -0200;robotstxt mid multi spider support removed

==

scrapy/contrib/downloadermiddleware/robotstxt.py
==================
3501c202;Pablo Hoffman;2013-10-08 15:18:45 -0200;remove no longer existent examples from doc_files used in bdist_rpm. closes GH-417

==

setup.cfg
==================
d806184b;Paul Tremberth;2013-10-08 00:01:44 +0200;.remove_namespaces(): remove namespaces on elements' attributes

==

scrapy/selector/lxmlsel.py
scrapy/tests/test_selector_lxml.py
==================
8b9526a8;Pablo Hoffman;2013-10-07 07:57:18 -0700;Merge pull request #400 from irgmedeiros/patch-2
Update the second code example
==
==================
86c6e943;Pablo Hoffman;2013-10-04 14:37:55 -0300;remove minor reference to 'scrapy server' command

==

docs/topics/commands.rst
==================
aad90ec5;Daniel Graña;2013-10-03 12:53:54 -0300;Add 0.18.3 release notes
Conflicts:
	docs/news.rst

==

docs/news.rst
==================
479b4942;Daniel Graña;2013-10-03 12:36:03 -0300;fix regression on lazy evaluation of start requests

==

scrapy/crawler.py
==================
662eac11;Pablo Hoffman;2013-10-03 12:47:22 -0300;added pypi version badge to README

==

README.rst
==================
ba7b75d2;Pablo Hoffman;2013-10-02 14:05:44 -0700;Merge pull request #410 from duendex/httpsMockServer
Adds HTTPS support to the MockServer.
==
==================
2519b303;duendex;2013-10-02 17:35:28 -0300;Adds HTTPS support to the MockServer.

==

scrapy/tests/keys/cert.pem
scrapy/tests/mockserver.py
==================
0c63c953;Daniel Graña;2013-10-02 13:31:26 -0700;Merge pull request #409 from kalessin/imagesfield
allow to set source and destination fields in files and images pipelines, and added tests
==
==================
e81120e6;Martin Olveyra;2013-10-02 18:23:13 -0200;allow to set source and destination fields in files and images pipelines, and added tests

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
scrapy/tests/test_pipeline_files.py
scrapy/tests/test_pipeline_images.py
==================
37c24e01;Pablo Hoffman;2013-10-02 17:13:17 -0300;document bindaddress request meta

==

docs/topics/request-response.rst
==================
a9c35198;Pablo Hoffman;2013-10-01 14:07:38 -0300;updated required twisted version to 10.0

==

docs/topics/images.rst
docs/topics/request-response.rst
requirements.txt
setup.py
==================
fe9ae1d4;Pablo Hoffman;2013-10-01 09:59:00 -0700;Merge pull request #406 from nopper/master
Handling inconsistencies among Twisted releases
==
==================
cc8a93f1;Francesco Piccinno;2013-10-01 14:36:44 +0200;Handling inconsistencies among Twisted releases

==

scrapy/webservice.py
==================
56275b1b;Pablo Hoffman;2013-09-30 11:15:32 -0700;Merge pull request #404 from darkrho/djangoitem-docs
Add a section to DjangoItem docs page regarding setting up Django's settings.
==
==================
d6e3eae5;Rolando Espinoza;2013-09-30 09:47:07 -0400;docs: added section regarding setting up django's settings.

==

docs/topics/djangoitem.rst
==================
0cc1d870;Rolando Espinoza;2013-09-30 08:43:25 -0400;docs: minor tidy up sample code and missing shell prompts.

==

docs/topics/djangoitem.rst
==================
36cb54d3;Mikhail Korobov;2013-09-29 14:21:04 -0700;Merge pull request #402 from LorenDavie/master
Corrected typo.
==
==================
8af0e89e;Loren Davie;2013-09-29 17:06:46 -0400;Corrected typo.

==

docs/topics/practices.rst
==================
1a90ee51;Pablo Hoffman;2013-09-29 07:20:52 -0700;Merge pull request #401 from LorenDavie/master
Added dynamic creation of item classes to practices.rst. Issue
==
==================
f49f5724;Loren Davie;2013-09-28 09:00:48 -0400;Added dynamic creation of item classes to practices.rst.

==

docs/topics/practices.rst
==================
9b504099;irgmedeiros;2013-09-27 18:22:33 -0300;Update the second code example
Update the second code example to reflect the last change in the first example.
==

docs/topics/practices.rst
==================
780ef128;Pablo Hoffman;2013-09-27 14:03:51 -0700;Merge pull request #399 from irgmedeiros/patch-1
Update practices.rst
==
==================
d9e0fdc9;irgmedeiros;2013-09-27 17:56:30 -0300;Update practices.rst
With this modification scrapy runs the spider with project settings. The previous example ran only with default settings resulting in ignoring all user settings as pipelines for example.
==

docs/topics/practices.rst
==================
265910aa;Daniel Graña;2013-09-26 09:15:02 -0700;Merge pull request #363 from taikano/sitemap_alternate
also fetch alternate URLs from sitemaps, see #360
==
==================
12280c2a;Pablo Hoffman;2013-09-25 15:13:17 -0300;fix sphinx references in doc

==

docs/topics/settings.rst
==================
b74e5aa5;Mikhail Korobov;2013-09-25 20:37:06 +0600;fix ITEM_PIPELINES setting handling
* item_pipelines variable was unused so the fallback didn't work;
* added support for fallback in case of ITEM_PIPELINIES defined as set.

==

scrapy/contrib/pipeline/__init__.py
==================
61e89d82;Daniel Graña;2013-09-23 14:12:26 -0700;Merge pull request #393 from scrapy/itempipe-dict
Make ITEM_PIPELINE setting a dict
==
==================
fc388f46;Pablo Hoffman;2013-09-23 16:41:58 -0300;Make ITEM_PIPELINE setting a dict
This is for consistency with how spider and downloader middlewares are
defined. ITEM_PIPELINE_BASE was also added and both remain empty.

Backwards compatibility is kept (with a warning) with list-based
ITEM_PIPELINES.

==

docs/news.rst
docs/topics/images.rst
docs/topics/item-pipeline.rst
docs/topics/settings.rst
scrapy/contrib/pipeline/__init__.py
scrapy/settings/default_settings.py
scrapy/tests/test_commands.py
==================
b1d1a36a;Pablo Hoffman;2013-09-18 18:01:28 -0300;add note about enclosing urls with quotes when running from command-line. closes GH-384

==

docs/intro/tutorial.rst
==================
bb8cb417;Mikhail Korobov;2013-09-18 07:59:46 -0700;Merge pull request #391 from amferraz/patch-2
Update request-response.rst
==
==================
71b32091;cacovsky;2013-09-18 11:45:25 -0300;Update request-response.rst
Fix small doc typo (too many backticks)
==

docs/topics/request-response.rst
==================
ee8464b4;Pablo Hoffman;2013-09-17 15:51:54 -0700;Merge pull request #390 from kmike/mock-in-tox
mock is required for running tests
==
==================
7ffc786f;Mikhail Korobov;2013-09-18 00:02:23 +0600;mock is required for running tests since https://github.com/scrapy/scrapy/commit/45ff6ec28ac44114b1c8b98e151ff3c21cd9b994
This fixes tox test running. Mock is available at Travis, but there is no harm in listing it explicitly.

==

.travis/requirements-latest.txt
.travis/requirements-lucid.txt
.travis/requirements-precise.txt
==================
2a89265b;Pablo Hoffman;2013-09-16 11:36:13 -0700;Merge pull request #387 from ktharmal/patch-1
Fixed directory location for dmoz_spider.py file
==
==================
bbb06030;Kumara Tharmalingam;2013-09-15 21:55:52 -0700;Fixed directory location for dmoz_spider.py file
It should be under 'tutorial/spiders' not 'dmoz/spiders'
==

docs/intro/tutorial.rst
==================
855041eb;Stefan;2013-09-14 12:17:34 +0200;added test case for comments, see #363

==

scrapy/tests/test_utils_sitemap.py
==================
0400b18e;Daniel Graña;2013-09-09 12:44:26 -0300;docs: list lxml as installation prerequisite

==

docs/intro/install.rst
==================
69949591;Stefan;2013-09-08 10:38:28 +0200;renamed to sitemap_alternate_links and added default value, see #360

==

docs/topics/spiders.rst
scrapy/contrib/spiders/sitemap.py
==================
e8be35dc;Daniel Graña;2013-09-08 00:24:34 -0300;Do not log IgnoreRequest exceptions as download failures

==

scrapy/core/scraper.py
==================
684cfc0b;Daniel Graña;2013-09-08 00:15:50 -0300;Do not silence download errors when request errback raises an exception

==

scrapy/core/scraper.py
==================
b326b871;Daniel Graña;2013-09-07 21:53:27 -0300;forms: do not submit reset inputs

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
8ed2d0cd;Stefan;2013-09-07 12:56:30 +0200;improved changes to allow retrieval of alternate links in sitemaps, see #360

==

docs/topics/spiders.rst
scrapy/contrib/spiders/sitemap.py
scrapy/tests/test_utils_sitemap.py
scrapy/utils/sitemap.py
==================
65135db7;Daniel Graña;2013-09-05 21:52:54 -0300;increase unittest timeouts to decrease travis false positive failures

==

scrapy/tests/test_commands.py
==================
801564c2;Daniel Graña;2013-09-05 17:00:16 -0300;exporters linting

==

scrapy/contrib/exporter/__init__.py
==================
2be3f713;Daniel Graña;2013-09-05 16:57:27 -0300;Do not fail on when json exporter are instanciated with extra keywords. closes #379

==

scrapy/contrib/exporter/__init__.py
scrapy/tests/test_contrib_exporter.py
==================
92d14d4a;Daniel Graña;2013-09-03 23:21:29 -0300;Fix permission and set umask before generating sdist tarball

==

Makefile.buildbot
==================
e6b3ca01;Daniel Graña;2013-09-03 14:27:22 -0300;Add 0.18.2 release notes

==

docs/news.rst
==================
9b821df4;Daniel Graña;2013-09-03 11:40:06 -0300;Merge pull request #330 from alexcepoi/contracts_fix

==
==================
f54d5c58;Daniel Graña;2013-09-03 07:29:30 -0700;Merge pull request #370 from loucash/master
FilesPipeline extracted and separated from ImagesPipeline
==
==================
50b653e5;Alex Cepoi;2013-09-02 18:43:25 +0200;don't start reactor if no crawler is scheduled

==

scrapy/crawler.py
==================
0a8bf2c9;Lukasz Biedrycki;2013-08-28 18:00:54 +0200;after additional tests with actual s3: k.set_contents_from_string is working

==

scrapy/contrib/pipeline/files.py
==================
0f00b160;Daniel Graña;2013-08-27 18:45:21 -0300;merge 0.18 release notes

==

docs/news.rst
==================
ac218ed4;Daniel Graña;2013-08-27 17:38:28 -0300;no need to test latest versions of dependencies on python 2.6

==

.travis.yml
==================
c5222b4b;Daniel Graña;2013-08-27 17:19:45 -0300;remove phanton build row from travis matrix due to travis-ci/travis-core#1027

==

.travis.yml
==================
ad140a27;Daniel Graña;2013-08-27 16:53:54 -0300;another try to limit travis build matrix

==

.travis.yml
==================
73949692;Daniel Graña;2013-08-27 15:31:08 -0300;test pypy with travis

==

.travis.yml
==================
401e888c;Daniel Graña;2013-08-27 15:30:10 -0300;test lucid and precise python packages under their respective python versions

==

.travis.yml
==================
588a262b;Daniel Graña;2013-08-27 14:05:37 -0300;fix crawling tests under twisted pre 11.0.0

==

scrapy/core/downloader/webclient.py
scrapy/tests/mockserver.py
==================
92826586;Daniel Graña;2013-08-27 12:12:50 -0300;py26 can not format zero length fields {}

==

scrapy/tests/test_crawl.py
==================
caa0f902;Daniel Graña;2013-08-27 11:53:18 -0300;test PotentiaDataLoss errors on unbound responses

==

scrapy/core/downloader/handlers/http11.py
scrapy/tests/mockserver.py
scrapy/tests/test_crawl.py
==================
6720acc1;Daniel Graña;2013-08-27 11:09:55 -0300;Treat responses without content-length or Transfer-Encoding as good responses
There is not a way to determine if responses without Content-Length or Transfer-Encoding are complete, this change treat them as good responses but flags them as "partial".
This is backout change only for this functionality of 3c64a989

==

scrapy/core/downloader/handlers/http11.py
==================
da1f6d31;Pablo Hoffman;2013-08-23 13:03:28 -0300;remove unused imports and some assorted pylint-ing

==

scrapy/__init__.py
scrapy/commands/crawl.py
scrapy/commands/shell.py
scrapy/contrib/exporter/__init__.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/webclient.py
scrapy/resolver.py
scrapy/spider.py
scrapy/tests/test_http_request.py
scrapy/tests/test_utils_defer.py
scrapy/tests/test_utils_misc/__init__.py
==================
19ff9ac4;Pablo Hoffman;2013-08-23 12:43:22 -0300;url/body attributes of Request/Response objects are now immutable

==

docs/news.rst
scrapy/http/common.py
scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
==================
86230c0a;Pablo Hoffman;2013-08-22 21:49:18 -0300;added quantal & raring to support ubuntu releases

==

docs/topics/ubuntu.rst
==================
83bd151c;Lukasz Biedrycki;2013-08-22 15:13:59 +0200;backwards compatibility: image_key & image_downloaded

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
scrapy/tests/test_pipeline_files.py
==================
2b11e7da;Lukasz Biedrycki;2013-08-22 14:44:04 +0200;backwards compatibility: image_key

==

scrapy/contrib/pipeline/images.py
==================
02d08722;Lukasz Biedrycki;2013-08-22 14:33:28 +0200;typo

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/media.py
==================
4c89d8b2;Lukasz Biedrycki;2013-08-22 12:26:56 +0200;remarks

==

scrapy/contrib/pipeline/files.py
==================
efb4f32d;Daniel Graña;2013-08-21 19:04:12 -0300;do no include ResponseFailed if http11 handler is not enabled

==

scrapy/tests/test_downloadermiddleware_retry.py
==================
3c64a989;Daniel Graña;2013-08-21 15:17:40 -0300;New HTTP client wraps connection losts in ResponseFailed exception. fix #373

==

scrapy/contrib/downloadermiddleware/retry.py
scrapy/core/downloader/handlers/http11.py
scrapy/tests/mockserver.py
scrapy/tests/test_crawl.py
scrapy/tests/test_downloadermiddleware_retry.py
==================
071172cb;Pablo Hoffman;2013-08-21 14:32:22 -0300;fix retry middleware which didn't retry certain connection errors after the upgrade to http1 client, closes GH-373

==

scrapy/contrib/downloadermiddleware/retry.py
scrapy/tests/mockserver.py
scrapy/tests/test_crawl.py
==================
6e4ed8b0;Pablo Hoffman;2013-08-21 09:55:51 -0700;Merge pull request #372 from kmike/xml-exporter-fix-for-2.7.4
fix XmlItemExporter in Python 2.7.4 and 2.7.5
==
==================
a6e6ca06;Mikhail Korobov;2013-08-21 06:05:40 +0600;fix XmlItemExporter in Python 2.7.4 and 2.7.5

==

scrapy/contrib/exporter/__init__.py
==================
9c092536;Alex Cepoi;2013-08-21 01:52:36 +0200;remove redundant kwarg

==

scrapy/log.py
==================
7bdeabc0;Alex Cepoi;2013-08-21 01:42:03 +0200;fix log intermixing in scrapy shell command

==

scrapy/commands/shell.py
scrapy/crawler.py
==================
902208ca;Alex Cepoi;2013-08-20 14:02:55 +0200;fix some missing logs with new crawlerprocess

==

scrapy/commands/settings.py
scrapy/crawler.py
==================
96077ccf;Lukasz Biedrycki;2013-08-20 11:29:55 +0200;typo

==

scrapy/contrib/pipeline/images.py
==================
a812def5;Alex Cepoi;2013-08-19 23:40:23 +0200;port all scrapy commands to new CrawlerProcess

==

scrapy/command.py
scrapy/commands/bench.py
scrapy/commands/crawl.py
scrapy/commands/edit.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/parse.py
scrapy/commands/runspider.py
scrapy/commands/settings.py
scrapy/commands/shell.py
scrapy/crawler.py
==================
a9a911fb;Alex Cepoi;2013-08-19 22:43:29 +0200;default to multi crawler commands
compatibility for old single crawler process
deprecated command's `crawler` property
logs about settings only shown once

==

scrapy/cmdline.py
scrapy/command.py
scrapy/commands/check.py
scrapy/crawler.py
scrapy/log.py
==================
034ffae6;Mikhail Korobov;2013-08-18 00:44:01 +0600;Recommend Pillow instead of PIL. Closes GH-317.

==

docs/topics/images.rst
==================
45ff6ec2;Lukasz Biedrycki;2013-08-16 18:47:56 +0200;Test reorganization and new tests for Files and Images Pipelines, PEP8 changes in MediaPipeline

==

scrapy/contrib/pipeline/media.py
scrapy/tests/test_pipeline_files.py
scrapy/tests/test_pipeline_images.py
==================
76ce8c52;Lukasz Biedrycki;2013-08-16 17:02:31 +0200;FilesPipeline which enalbes to download any files. It has been extracted from ImagesPipelines. ImagesPipeline is built on top of FilesPipeline and consist only with convert image and thumbnail generation logic.

==

scrapy/contrib/pipeline/files.py
scrapy/contrib/pipeline/images.py
scrapy/tests/test_pipeline_images.py
==================
f95b164d;Pablo Hoffman;2013-08-14 07:17:30 -0700;Merge pull request #367 from berendiwema/master
#327 - Support STARTTLS / SSL option in email sender
==
==================
32b6364b;Berend Iwema;2013-08-14 12:59:01 +0200;#327 - Support STARTTLS / SSL option in email sender

==

docs/topics/email.rst
scrapy/mail.py
==================
49952a45;Pablo Hoffman;2013-08-14 02:48:10 -0300;add docstring to PythonItemExporter

==

scrapy/contrib/exporter/__init__.py
==================
c0b26e3d;Pablo Hoffman;2013-08-14 01:39:44 -0300;minor updates to 0.18 release notes

==

docs/news.rst
==================
c6157d37;Daniel Graña;2013-08-13 06:55:27 -0700;Merge pull request #366 from kalessin/exporter
added a python native classes item exporter
==
==================
456b6f2e;olveyra;2013-08-13 13:48:28 +0000;added a python native classes item exporter

==

scrapy/contrib/exporter/__init__.py
scrapy/tests/test_contrib_exporter.py
==================
b43b5f57;Daniel Graña;2013-08-12 22:42:45 -0300;adjust http11 pool size to per-domain concurrency

==

scrapy/core/downloader/handlers/http11.py
==================
892386ee;Pablo Hoffman;2013-08-12 18:59:13 -0300;tox.ini: disable sitepackages on windows, as a compiler is often not available

==

tox.ini
==================
ed5b9068;Daniel Graña;2013-08-11 21:49:56 -0300;fix contributters list format

==

docs/news.rst
==================
80e25c59;Daniel Graña;2013-08-09 19:09:47 -0300;bumped version to 0.19.0

==

scrapy/VERSION
==================
a6693c9a;Daniel Graña;2013-08-09 15:38:21 -0300;updated release notes and bumped version to 0.18.0

==

docs/news.rst
scrapy/VERSION
==================
4dc76e7c;Pablo Hoffman;2013-08-09 18:20:04 -0300;fixed scrapy.utils.gz.gunzip() broken after changes from Python 2.7.3 to 2.7.4

==

requirements.txt
scrapy/utils/gz.py
==================
29a12af1;Daniel Graña;2013-08-05 09:10:22 -0700;Merge pull request #361 from hmsimha/master
Doc fixes: Minor typo (was fixed on 0.16 branch so I figured it could be on master as well) and an error in the overview doc.
==
==================
915d7cf2;Stefan Koch;2013-08-04 16:08:06 +0200;also fetch alternate URLs from sitemaps, see #360

==

scrapy/contrib/spiders/sitemap.py
scrapy/tests/test_utils_sitemap.py
scrapy/utils/sitemap.py
==================
c00c4d71;Hart;2013-08-03 17:08:58 -0700;correction to description of example XPath retrieval in overview doc

==

docs/intro/overview.rst
==================
0ad01c34;Hart;2013-08-03 17:06:10 -0700;fixed typo to parallel fix on 0.16 branch

==

docs/faq.rst
==================
c2a4046f;Nicolás Alejandro Ramírez Quiros;2013-08-01 10:43:47 -0700;Merge pull request #359 from rocioar/master
Added COMPRESSION_ENABLED setting
==
==================
d227d530;Rocio Aramberri;2013-07-31 18:37:46 -0300;Added COMPRESSION_ENABLED setting to enable or disable the HttpCompressionMiddleware
Added COMPRESSION_ENABLE setting to docs

Added COMPRESSION_ENABLED setting to default settings

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/settings/default_settings.py
==================
fb770852;arijitchakraborty;2013-07-22 19:41:01 +0530;Skipping cookie retrieval for non http requests

==

scrapy/http/cookies.py
scrapy/tests/test_downloadermiddleware_cookies.py
==================
e1f0d0d4;Mikhail Korobov;2013-07-18 09:21:13 -0700;Merge pull request #352 from arijitchakraborty/bugfix/cookie_retrieval_for_hosts_with_port
Fixes for bug - Cookie retrieval for hosts with port + unittests for the...
==
==================
66ff34cf;arijitchakraborty;2013-07-18 20:51:56 +0530;improving hostname extraction

==

scrapy/http/cookies.py
==================
ebc136dd;arijitchakraborty;2013-07-18 19:42:58 +0530;Fixes for bug - Cookie retrieval for hosts with port + unittests for the fix

==

scrapy/http/cookies.py
scrapy/tests/test_downloadermiddleware_cookies.py
==================
d7e11082;Daniel Graña;2013-07-18 11:07:42 -0300;it is not possible to enforce an upper limit when latency is out of control

==

scrapy/tests/test_crawl.py
==================
3eb5d5e9;Daniel Graña;2013-07-16 12:42:31 -0700;Merge pull request #330 from nramirezuy/spider-from_crawler
use from_crawler method if available in spiders
==
==================
d14541c5;Daniel Graña;2013-07-16 12:34:17 -0700;Merge pull request #205 from joehillen/master
PyPy support
==
==================
d51f1ff3;Daniel Graña;2013-07-16 12:33:21 -0700;Merge pull request #350 from dellis23/master
This pull request fixes #349
==
==================
d74b6005;Daniel Graña;2013-07-16 16:22:03 -0300;take in count response latencies when testing download delays

==

scrapy/tests/mockserver.py
scrapy/tests/spiders.py
scrapy/tests/test_crawl.py
==================
1ca31244;Dan;2013-07-16 14:50:10 -0400;Fixed ordering of super argument call.

==

docs/topics/spiders.rst
==================
e12b689c;Dan;2013-07-16 14:26:53 -0400;Updated documentation of spider arguments to include required super call.

==

docs/topics/spiders.rst
==================
891fa980;Daniel Graña;2013-07-16 11:16:43 -0700;Merge pull request #341 from kmike/test-running
Improved tox test running & fixed django tests
==
==================
66aa1331;Daniel Graña;2013-07-16 00:49:35 -0300;Twisted pre 10.2 (lucid) can not setup the required ftp server for tests

==

scrapy/tests/test_downloader_handlers.py
==================
26c7ec7d;Daniel Graña;2013-07-15 16:39:46 -0700;Merge pull request #329 from kalessin/ftphandler
added ftp handler
==
==================
f8c105d5;Daniel Graña;2013-07-15 12:28:24 -0300;Merge branch 'gh-347'. thanks @chrisboo

==
==================
9ff82d66;Daniel Graña;2013-07-15 12:26:16 -0300;use lxml parser with recover option to parse invalid sitemaps. closes #347
thanks chrissboo for reporting the issue and proposing a fix.

==

scrapy/tests/test_utils_sitemap.py
scrapy/utils/sitemap.py
==================
1a1c93fa;Mikhail Korobov;2013-07-15 15:47:34 +0600;tiny FormRequest doc fix

==

docs/topics/request-response.rst
==================
aa7b5299;Daniel Graña;2013-07-10 12:32:43 -0300;do not log Starting/Stopping factory messages

==

scrapy/core/downloader/handlers/http11.py
==================
3fe2a326;Mikhail Korobov;2013-07-09 01:58:50 +0600;handle GET parameters for AJAX crawlable URLs:

==

scrapy/utils/url.py
==================
8c555fd4;Mikhail Korobov;2013-07-09 01:50:52 +0600;Enable Travis CI for pull requests and feature branches. Fix GH-340.

==

.travis.yml
==================
0d9f7843;Mikhail Korobov;2013-07-09 00:41:13 +0600;allow passing arguments to runtests script via tox

==

tox.ini
==================
f29e5d0c;Mikhail Korobov;2013-07-09 00:38:00 +0600;reuse runtests.sh and runtests.bat scripts in tox.ini

==

tox.ini
==================
3a6dff30;Mikhail Korobov;2013-07-09 00:30:39 +0600;make tox test running more consistent with bin/runtests.sh script

==

tox.ini
==================
2105ec58;Mikhail Korobov;2013-07-09 00:28:39 +0600;add django to test requirements and fix test_djangoitem for modern django versions

==

.travis/requirements-latest.txt
.travis/requirements-precise.txt
scrapy/tests/test_djangoitem/settings.py
==================
b98e80cb;Mikhail Korobov;2013-07-09 00:26:59 +0600;use tox deps instead of "manual" pip install; add lucid and precise environments to tox.ini

==

.travis.yml
.travis/requirements-latest.txt
.travis/requirements-lucid.txt
.travis/requirements-precise.txt
tox.ini
==================
35fbec2e;Mikhail Korobov;2013-07-08 22:51:03 +0600;allow passing arguments to tox
e.g. "tox -- scrapy.tests.test_contrib_loader" runs test_contrib_loader for Python 2.6 and 2.7

==

tox.ini
==================
f3d8b080;Alex Cepoi;2013-07-08 17:40:03 +0200;disable logging for scrapy check

==

scrapy/commands/check.py
scrapy/crawler.py
==================
919d7c40;Alex Cepoi;2013-07-08 16:57:12 +0200;command with multiple crawlers, fix check command

==

scrapy/cmdline.py
scrapy/command.py
scrapy/commands/check.py
scrapy/crawler.py
scrapy/log.py
==================
45d6d204;Alex Cepoi;2013-07-08 16:54:20 +0200;fix a possible error in contracts post hook

==

scrapy/contracts/__init__.py
==================
6db259c0;Daniel Graña;2013-07-08 07:12:42 -0700;Merge pull request #338 from kmike/patch-3
DownloaderMiddleware docs fix
==
==================
ac2fadf3;Mikhail Korobov;2013-07-08 19:41:58 +0600;DownloaderMiddleware.process_response docs fix
"returns an exception" -> "raises an exception"
==

docs/topics/downloader-middleware.rst
==================
9a13a0fe;Pablo Hoffman;2013-07-08 06:21:49 -0700;Merge pull request #337 from kmike/patch-2
improve docs for DownloaderMiddleware.process_response
==
==================
39e5da5f;Mikhail Korobov;2013-07-08 19:17:29 +0600;improve docs for DownloaderMiddleware.process_response

==

docs/topics/downloader-middleware.rst
==================
163592ee;Pablo Hoffman;2013-07-03 14:26:49 -0700;Merge pull request #334 from nramirezuy/feedexport-remove_multispider
feedexport removed multispider support
==
==================
1fc2bc34;nramirezuy;2013-07-03 18:24:18 -0300;feedexport removed multispider support

==

scrapy/contrib/feedexport.py
==================
42da57c4;Pablo Hoffman;2013-07-03 14:20:41 -0700;Merge pull request #333 from nramirezuy/mediapipe-remove_multispider
pipeline media removed multispider support
==
==================
6533115b;Pablo Hoffman;2013-07-03 14:20:06 -0700;Merge pull request #332 from nramirezuy/offsite-remove_multispider
offsite multispider support removed
==
==================
2abb9d08;nramirezuy;2013-07-03 18:08:15 -0300;pipeline media removed multispider support

==

scrapy/contrib/pipeline/media.py
scrapy/tests/test_pipeline_media.py
==================
07969a9f;nramirezuy;2013-07-03 17:55:20 -0300;offsite multispider support removed

==

scrapy/contrib/spidermiddleware/offsite.py
scrapy/tests/test_spidermiddleware_offsite.py
==================
06b97029;Daniel Graña;2013-06-27 17:09:26 -0300;increase delay in test to avoid small time differences

==

scrapy/tests/test_crawl.py
==================
1af47165;Martin Olveyra;2013-06-27 16:52:59 -0200;added ftp handler

==

scrapy/core/downloader/handlers/ftp.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloader_handlers.py
==================
c70f050b;nramirezuy;2013-06-27 11:45:29 -0300;from_crawler added to spiders

==

scrapy/spidermanager.py
scrapy/tests/test_spidermanager/__init__.py
scrapy/tests/test_spidermanager/test_spiders/spider4.py
==================
0f4b70f5;Pablo Hoffman;2013-06-27 11:23:18 -0300;remove no deprecated request_scheduled signal
It will be replaced by more accurate scheduler signals (proposal will
come soon)

==

docs/topics/signals.rst
==================
a2ddfab4;Pablo Hoffman;2013-06-27 07:21:48 -0700;Merge pull request #328 from nramirezuy/signals-request_scheduled
removed request_received and added request_scheduled
==
==================
bef8ade9;nramirezuy;2013-06-26 16:43:36 -0300;removed request_received and added request_scheduled

==

docs/topics/signals.rst
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/signals.py
scrapy/tests/test_engine.py
==================
819b2776;Pablo Hoffman;2013-06-25 13:30:07 -0700;Merge pull request #326 from berendiwema/master
Include example of how to stop the reactor from script
==
==================
83b27743;nramirezuy;2013-06-25 17:01:29 -0300;remove wrong default httpcache

==

docs/topics/downloader-middleware.rst
==================
e06836ff;Daniel Graña;2013-06-25 14:34:43 -0300;fix import of deprecated http handler for S3 handler

==

scrapy/core/downloader/handlers/s3.py
==================
22da89b7;Daniel Graña;2013-06-25 12:44:01 -0300;callLater must happens before timeout callback is added to avoid AttributeError

==

scrapy/core/downloader/handlers/http11.py
==================
aec314db;Berend Iwema;2013-06-25 09:18:42 +0200;added a bit more documentation on how to close the reactor when running scrapy from a script

==

docs/topics/practices.rst
==================
bbde1d0e;Pablo Hoffman;2013-06-24 11:09:28 -0700;Merge pull request #275 from stav/doc
doc: Response.replace() cannot take meta argument
==
==================
7af94be3;Daniel Graña;2013-06-20 10:56:48 -0300;fix helpers used to sign S3 requests with boto connections

==

scrapy/core/downloader/handlers/s3.py
==================
7a4c012d;Daniel Graña;2013-06-20 10:49:14 -0300;show a meaningful skip message for image tests

==

scrapy/tests/test_pipeline_images.py
==================
de57e27d;Daniel Graña;2013-06-20 10:44:20 -0300;do not skip image tests and set a fixed pyOpenSSL version

==

.travis/requirements-latest.txt
.travis/requirements-lucid.txt
.travis/requirements-precise.txt
==================
26809d22;Daniel Graña;2013-06-20 10:15:23 -0300;fix download_timeout for servers that returns response headers but hangs sending its body

==

scrapy/core/downloader/handlers/http11.py
scrapy/tests/mockserver.py
scrapy/tests/spiders.py
scrapy/tests/test_crawl.py
scrapy/tests/test_downloader_handlers.py
==================
133091af;Daniel Graña;2013-06-19 14:27:11 -0300;rename http11 handler methods and split latency and timeout check

==

scrapy/core/downloader/handlers/http11.py
==================
1e1b1616;Daniel Graña;2013-06-10 06:20:16 -0700;Merge pull request #321 from barraponto/document_crawlspider_parse_start_urls
Document CrawlSpider.parse_start_urls method
==
==================
50fa46d1;Capi Etheriel;2013-06-09 04:03:20 -0300;Document CrawlSpider.parse_start_urls method

==

docs/topics/spiders.rst
==================
5a097cc1;Pablo Hoffman;2013-06-04 19:25:26 -0300;log optional features available on startup

==

scrapy/log.py
==================
8ea04152;Daniel Graña;2013-06-04 14:34:54 -0700;Merge pull request #318 from scrapy/http11
Add HTTP 1.1 download handler
==
==================
e7acc217;Daniel Graña;2013-06-04 17:28:43 -0300;show deprecation warning for HttpDownloadHandler

==

scrapy/core/downloader/handlers/http.py
==================
cf10474b;Daniel Graña;2013-06-04 16:59:35 -0300;improve twisted version tests and enable HTTP11 handler by default if supported

==

scrapy/__init__.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/handlers/http10.py
scrapy/core/downloader/handlers/http11.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloader_handlers.py
scrapy/xlib/tx/__init__.py
==================
bb806fa0;Daniel Graña;2013-06-04 16:36:21 -0300;restore http10 as default handler and skip tests if http1.1 is not supported

==

scrapy/settings/default_settings.py
scrapy/tests/test_downloader_handlers.py
scrapy/xlib/tx/__init__.py
==================
8b0c9466;Daniel Graña;2013-06-04 15:35:31 -0300;add required files to support twisted 11.1 (precise)

==

scrapy/core/downloader/handlers/http11.py
scrapy/xlib/tx/LICENSE
scrapy/xlib/tx/README
scrapy/xlib/tx/__init__.py
scrapy/xlib/tx/_newclient.py
scrapy/xlib/tx/client.py
scrapy/xlib/tx/endpoints.py
scrapy/xlib/tx/interfaces.py
scrapy/xlib/tx/iweb.py
==================
7729f939;Daniel Graña;2013-06-03 19:18:45 -0300;implement download timeouts based on deferred cancellation

==

scrapy/core/downloader/handlers/http11.py
scrapy/tests/test_downloader_handlers.py
==================
4ac0eea5;Pablo Hoffman;2013-05-31 12:20:58 -0700;Merge pull request #316 from nramirezuy/closespider/errorcount
standarizes close_spider to use signals
==
==================
b61a4e71;nramirezuy;2013-05-31 15:54:17 -0300;standarizes close_spider to use signals

==

scrapy/contrib/closespider.py
==================
b4fca90b;Daniel Graña;2013-05-30 18:43:59 -0300;merge 0.16.5 release notes

==

docs/news.rst
==================
58dc16f4;Daniel Graña;2013-05-30 18:32:05 -0300;obey request method when scrapy deploy is redirected to a new endpoint

==

scrapy/commands/deploy.py
==================
0effe139;Pablo Hoffman;2013-05-30 08:47:33 -0700;Merge pull request #311 from nramirezuy/logstats-6017
removed multispider support from logstats
==
==================
14e382ae;nramirezuy;2013-05-30 10:57:06 -0300;test_closespider fixed for python 2.6

==

scrapy/tests/test_closespider.py
==================
461eace4;Pablo Hoffman;2013-05-30 06:34:52 -0700;Merge pull request #313 from nramirezuy/closespider-6017
drop multi-spider support from CloseSpider extension
==
==================
971ef5c7;nramirezuy;2013-05-28 14:05:56 -0300;removed multispider support, test added

==

scrapy/contrib/closespider.py
scrapy/tests/spiders.py
scrapy/tests/test_closespider.py
==================
2bb2ba66;Pablo Hoffman;2013-05-28 15:12:38 -0300;simplify scrapy.tests.mockserver

==

scrapy/tests/mockserver.py
==================
f35266e6;Pablo Hoffman;2013-05-28 15:10:05 -0300;use os.pathsep

==

scrapy/utils/test.py
==================
96b8fb69;nramirezuy;2013-05-27 17:48:49 -0300;removed multispider support from logstats

==

scrapy/contrib/logstats.py
==================
98aa3efe;Pablo Hoffman;2013-05-28 08:46:31 -0700;Merge pull request #312 from nramirezuy/cmd/bech/test
added test for bench command
==
==================
1ed5643e;nramirezuy;2013-05-28 12:42:50 -0300;added test for bench command

==

scrapy/contrib/closespider.py
scrapy/tests/test_commands.py
==================
a4b5bfbb;Pablo Hoffman;2013-05-27 09:07:48 -0700;Merge pull request #309 from amferraz/patch-1
Add FAQ entry referencing Request.meta usage
==
==================
80077628;cacovsky;2013-05-27 13:02:17 -0300;Add FAQ entry referencing Request.meta usage

==

docs/faq.rst
==================
7874eef7;Nicolás Alejandro Ramírez Quiros;2013-05-23 12:50:17 -0700;Merge pull request #307 from DeaconDesperado/raise-format
Raise a usage error when an invalid or unrecognized output format is entered on Command line
==
==================
485a9545;Mark Grey;2013-05-22 14:21:36 -0400;raise on unrecognized format

==

scrapy/commands/crawl.py
scrapy/commands/runspider.py
==================
845c64b8;Pablo Hoffman;2013-05-17 10:38:42 -0300;add benchmarking to 0.18 release notes

==

docs/news.rst
==================
ca12886a;Pablo Hoffman;2013-05-16 15:05:52 -0300;update copyright notes

==

debian/copyright
docs/conf.py
==================
8e49fed9;Pablo Hoffman;2013-05-16 13:23:13 -0300;minor improvements to benchmarking doc

==

docs/topics/benchmarking.rst
==================
76087e33;Pablo Hoffman;2013-05-16 13:15:25 -0300;add scrapy bench command for benchmarking, with documentation

==

docs/index.rst
docs/topics/benchmarking.rst
docs/topics/commands.rst
scrapy/commands/bench.py
==================
5c40741d;Pablo Hoffman;2013-05-16 13:01:02 -0300;added context manager for mock server, moved test spiders into a separate module (scrapy.tests.spiders)

==

scrapy/tests/mockserver.py
scrapy/tests/spiders.py
scrapy/tests/test_crawl.py
==================
214bcdf3;Pablo Hoffman;2013-05-08 07:00:52 -0700;Merge pull request #301 from tpeng/fix_telnet_doc
change manager in telnet variable to crawler
==
==================
edbe525d;tpeng;2013-05-08 11:58:15 +0800;change manager in telnet variable to crawler

==

scrapy/telnet.py
==================
99f8d573;Pablo Hoffman;2013-05-06 20:04:15 -0300;added mock tests for retries (more to come)

==

scrapy/tests/test_crawl.py
scrapy/utils/test.py
==================
a7b7c892;Pablo Hoffman;2013-05-06 20:03:54 -0300;improved logging of downloader errors, when they contain tracebacks

==

scrapy/core/scraper.py
==================
db195ee4;Pablo Hoffman;2013-05-06 20:03:17 -0300;added more methods to mockserver

==

scrapy/tests/mockserver.py
==================
c2561ca1;Pablo Hoffman;2013-05-06 17:35:09 -0300;use get_testenv() shortcut instead of get_pythonpath()

==

scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_commands.py
==================
14e71216;Pablo Hoffman;2013-05-06 17:27:59 -0300;make sure the mockserver forked from tests uses the current installation of scrapy, not the system one

==

scrapy/tests/test_crawl.py
scrapy/utils/test.py
==================
cf4d4bc0;Pablo Hoffman;2013-05-06 14:47:24 -0300;added mock server test for DOWNLOAD_TIMEOUT

==

scrapy/tests/mockserver.py
scrapy/tests/test_crawl.py
==================
495acba2;Daniel Graña;2012-09-12 13:04:42 -0300;agents requires an instance of contextFactory

==

scrapy/core/downloader/handlers/http11.py
==================
3e62ce35;Daniel Graña;2012-09-07 11:12:40 -0300;cleanup http connection pool on engine stop

==

scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/__init__.py
==================
334ad71a;Daniel Graña;2012-09-04 16:18:21 -0300;adapt for singletons removals

==

scrapy/core/downloader/handlers/http11.py
==================
ba654555;Daniel Graña;2012-05-16 12:24:24 -0300;empty bodies does not require a body producer

==

scrapy/core/downloader/handlers/http11.py
==================
db232da0;Daniel Graña;2012-05-16 10:31:03 -0300;close pool connections before finishing tests

==

scrapy/core/downloader/handlers/http11.py
scrapy/tests/test_downloader_handlers.py
==================
b3460603;Daniel Graña;2012-05-15 11:32:52 -0300;remove duplicate context factory handling for non-ssl support in http1.0

==

scrapy/core/downloader/handlers/http.py
==================
0a261700;Daniel Graña;2012-05-15 11:27:04 -0300;move ssl context factory to its own module and implement a non-ssl version that warns about pyopenssl support

==

scrapy/core/downloader/contextfactory.py
scrapy/core/downloader/webclient.py
scrapy/settings/default_settings.py
==================
ab340728;Daniel Graña;2012-05-15 08:36:32 -0300;enable persistent connections

==

scrapy/core/downloader/handlers/http11.py
==================
e4fe7c63;Daniel Graña;2012-05-14 17:04:08 -0300;add http connection pool and custom ssl context factory

==

scrapy/core/downloader/handlers/http11.py
scrapy/core/downloader/webclient.py
==================
a7a354f9;Daniel Graña;2012-04-25 12:45:28 -0300;http11 cleanup

==

scrapy/core/downloader/handlers/http11.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloader_handlers.py
==================
ef036038;paul;2012-04-12 00:16:03 +0200;Restore handling of HTTPS

==

scrapy/core/downloader/handlers/http11.py
==================
46341d52;paul;2012-04-11 23:47:07 +0200;Renamed downloader to Http11DownloadHandler and some refactoring
Only for HTTP, not HTTPS
Test on expected body length instead of request method (HEAD case)

==

scrapy/core/downloader/handlers/http11.py
scrapy/tests/test_downloader_handlers.py
==================
4018d25a;paul;2012-04-07 23:00:21 +0200;Use twisted.web.client.Agent for download requests (use of HTTP/1.1)
Adds http11.HttpDownloadHandler in scrapy.core.downloader.handlers

==

scrapy/core/downloader/handlers/http11.py
scrapy/tests/test_downloader_handlers.py
==================
66311db2;Pablo Hoffman;2013-05-04 18:19:45 -0300;mention crawlera in best practices, as a way to deal with bans

==

docs/topics/practices.rst
==================
e1f41443;Pablo Hoffman;2013-04-29 13:04:40 -0300;removed obsolete (and broken) downloader method: is_idle()

==

scrapy/core/downloader/__init__.py
scrapy/utils/engine.py
==================
2a1a4477;Daniel Graña;2013-04-29 07:38:27 -0700;Merge pull request #297 from scrapy/downloader-gc
Add garbage collector to downloader
==
==================
af5c13fa;Pablo Hoffman;2013-04-26 16:28:31 -0300;Add garbage collector to downloader
This fixes a couple of issues:
- reactor callLater leaks when using download delay (test was
  re-enabled)
- downloader slot leaking on broad crawls (slots were created but never
  removed)

==

scrapy/core/downloader/__init__.py
scrapy/core/engine.py
scrapy/tests/test_crawl.py
==================
36ee3600;Pablo Hoffman;2013-04-27 04:17:19 -0300;bind mockserver to 0.0.0.0, to listen on all 127.* range (useful for testing broad crawls)

==

scrapy/tests/mockserver.py
==================
9361c895;Pablo Hoffman;2013-04-27 04:15:42 -0300;remove scrapyd doc, as it was moved to its own repo

==

docs/news.rst
docs/topics/commands.rst
docs/topics/scrapyd.rst
docs/topics/spiders.rst
==================
5ba2b60a;Daniel Graña;2013-04-25 11:56:56 -0300;fix broken doctests

==

scrapy/contrib/httpcache.py
scrapy/http/cookies.py
==================
32b781a1;Daniel Graña;2013-04-24 16:22:40 -0300;cookies: increase candidate list with dot prefixed domains

==

scrapy/http/cookies.py
==================
31bec08a;Daniel Graña;2013-04-24 15:07:40 -0300;rfc2965 is dead
- It is not enabled by default in python cookielib
- Mozilla rejected implementing it https://bugzilla.mozilla.org/show_bug.cgi?id=208985
- Netscape cookies still rules
- It was superseded by RFC6265 which is the facto protocol formalized

==

scrapy/http/cookies.py
==================
97390615;Daniel Graña;2013-04-24 10:59:36 -0700;Merge pull request #77 from shane42/master
Cookie handling performance improvement
==
==================
d02da2f3;Pablo Hoffman;2013-04-23 17:48:09 -0300;ported code to use queuelib

==

debian/control
docs/news.rst
scrapy/core/scheduler.py
scrapy/squeue.py
scrapy/tests/test_squeue.py
scrapy/tests/test_utils_pqueue.py
scrapy/tests/test_utils_queue.py
scrapy/utils/pqueue.py
scrapy/utils/queue.py
setup.py
==================
5531290d;Daniel Graña;2013-04-19 10:53:20 -0700;Merge pull request #292 from nramirezuy/item-unusedimport
deleted unused import
==
==================
bc592e99;Nicolás Ramírez;2013-04-19 14:51:59 -0300;deleted unused import

==

scrapy/item.py
==================
7a1536f7;Pablo Hoffman;2013-04-19 09:27:44 -0700;Merge pull request #290 from nramirezuy/item-copy
added copy method to item
==
==================
6df274bb;Nicolás Ramírez;2013-04-19 12:28:54 -0300;added copy method to item

==

docs/topics/items.rst
scrapy/item.py
scrapy/tests/test_item.py
==================
98f89d1c;Pablo Hoffman;2013-04-19 09:22:38 -0700;Merge pull request #291 from nramirezuy/cmd-parse-pipelines
parse pipelines test fixed
==
==================
626331b8;Pablo Hoffman;2013-04-19 13:06:30 -0300;test_crawl: make mock server print a line when ready, and wait for that line to start tests, instead of waiting for an arbitrary time

==

scrapy/tests/mockserver.py
scrapy/tests/test_crawl.py
==================
e0c88f2d;Nicolás Ramírez;2013-04-19 12:38:20 -0300;test fixed

==

scrapy/tests/test_commands.py
==================
ce177fa5;Daniel Graña;2013-04-19 14:31:27 +0000;mock server is slow bringing up on busy builders

==

scrapy/tests/test_crawl.py
==================
74e9aecc;Pablo Hoffman;2013-04-17 17:55:45 -0700;Merge pull request #288 from kmike/patch-1
Update faq.rst
==
==================
b245d592;Mikhail Korobov;2013-04-18 02:42:15 +0600;Update faq.rst
spider.DOWNLOAD_DELAY is deprecated
==

docs/faq.rst
==================
9feb6586;Pablo Hoffman;2013-04-09 06:26:24 -0700;Merge pull request #284 from nramirezuy/cmd-parse-pipelines
Command parse, --pipelines argument added
==
==================
adf38a65;Pablo Hoffman;2013-04-08 13:48:05 -0700;Merge pull request #283 from opyate/patch-1
Update overview.rst, Torrent referenced as TorrentItem in spider
==
==================
2b39527f;Nicolás Ramírez;2013-04-08 14:31:10 -0300;pipelines argument added

==

scrapy/commands/parse.py
scrapy/tests/test_commands.py
==================
4de3aa49;Juan M Uys;2013-04-08 14:13:15 +0200;Update overview.rst

==

docs/intro/overview.rst
==================
96c2332e;Pablo Hoffman;2013-04-02 11:35:32 -0300;fix inaccurate downloader middleware documentation. refs #280

==

docs/topics/downloader-middleware.rst
==================
b0ea457c;Pablo Hoffman;2013-03-28 15:38:35 -0700;Merge pull request #277 from nramirezuy/cmd-parse-args
Spider Arguments support for parse command
==
==================
df19693e;Nicolás Ramírez;2013-03-28 16:47:39 -0300;Spider Arguments support for parse command and test

==

scrapy/commands/parse.py
scrapy/tests/test_commands.py
==================
70179c7c;Steven Almeroth;2013-03-21 13:57:39 -0600;doc: remove trailing spaces

==

docs/topics/request-response.rst
==================
0d7747d3;Steven Almeroth;2013-03-21 13:49:55 -0600;doc: Response.replace() cannot take meta argument
>>> response.replace(meta={'foo':1})
Traceback (most recent call last):
  File "<input>", line 1, in <module>
  File "/srv/scrapy/scrapy-fork/scrapy/scrapy/http/response/text.py", line 45, in replace
    return Response.replace(self, *args, **kwargs)
  File "/srv/scrapy/scrapy-fork/scrapy/scrapy/http/response/__init__.py", line 77, in replace
    return cls(*args, **kwargs)
  File "/srv/scrapy/scrapy-fork/scrapy/scrapy/http/response/text.py", line 22, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'meta'

==

docs/topics/request-response.rst
==================
21c8b894;Pablo Hoffman;2013-03-21 12:26:52 -0300;Revert "replaced use of depricated module scrapy.settings with the method get_project_settings()"
This reverts commit 1b4d14c8f635b28d5f72d37f924c4e71d71520ca.

Calling `get_project_settings()` generates a new independent Settings
object that doesn't contain the overrides passed by command line
arguments, for example.

Proper port would require implementing the from_crawler() class method
and making sure the settings object is passed to all internal objects
(probably breaking some minor backwards compatibility).

==

scrapy/contrib/feedexport.py
==================
8c181d87;Pablo Hoffman;2013-03-21 08:25:29 -0700;Merge pull request #274 from brunsgaard/master
Updated settings import in contrib/feedexport.py class S3FeedStorage
==
==================
1b4d14c8;Jonas Brunsgaard;2013-03-21 16:09:14 +0100;replaced use of depricated module scrapy.settings with the method get_project_settings()

==

scrapy/contrib/feedexport.py
==================
d0a81d36;Pablo Hoffman;2013-03-20 14:46:04 -0300;initial version of crawl tests using a mock HTTP server (in separate process). This can also be used to benchmark scrapy performance, although a script (specially suited for that task) would be more convenient

==

scrapy/tests/mockserver.py
scrapy/tests/test_crawl.py
==================
2a5c7ed4;Pablo Hoffman;2013-03-20 14:40:30 -0300;make Crawler.start() return a deferred that is fired when the crawl is finished

==

docs/topics/api.rst
scrapy/core/engine.py
==================
c43931ea;Daniel Graña;2013-03-20 11:27:46 -0300;Use latest pyOpenSSL for all travis tests environments
SSLv2 was removed from OpenSSL 1.0 and above but it is still referenced
by pyOpenSSL < 0.13. Travis workers are precise hosts with OpenSSL 1.0
and pyOpenSSL 0.12 (!) with a debian patch to workaround this problem
that is not present in pyOpenSSL 0.12 shipped by PyPi.

Trying to install pyOpenSSL 0.10 or 0.12 from packages at PyPi under a
system with OpenSSL >= 1.0 will success but fails at import time with a
message similar to:

    ImportError: .../lib/python2.7/site-packages/OpenSSL/SSL.so: undefined symbol: SSLv2_method

==

.travis/requirements-lucid.txt
.travis/requirements-precise.txt
==================
9968f99e;Pablo Hoffman;2013-03-20 09:52:40 -0300;remove ssl from optional_features to simplify code, as it is now required. also deprecate optional_features set

==

scrapy/__init__.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/webclient.py
==================
320bdfe3;Pablo Hoffman;2013-03-19 11:10:54 -0700;Merge pull request #269 from kalessin/settingdict
added support for explicitly interpret a setting value as dict
==
==================
bf480015;Martin Olveyra;2013-03-19 16:02:53 -0200;added support generic python literals in settings, and for explicitly interpret a setting value as dict

==

scrapy/settings/__init__.py
scrapy/tests/test_settings.py
==================
d246b926;Pablo Hoffman;2013-03-19 07:27:56 -0700;Merge pull request #273 from plainas/master
Accept ajax requests from other hosts (CORS support)
==
==================
a80ed769;Pedro;2013-03-19 12:00:49 +0100;allow remote ajax requests to the webservice

==

scrapy/utils/txweb.py
==================
b347c14b;Pablo Hoffman;2013-03-18 19:12:12 -0300;update engine status output on telnet console documentation

==

docs/topics/telnetconsole.rst
scrapy/utils/engine.py
==================
6f9f6f1f;Pablo Hoffman;2013-03-18 15:05:34 -0700;Merge pull request #271 from nramirezuy/scraper-6017
Slots removed, now Scraper can handle just one spider
==
==================
5c2a82f1;Shane Evans;2013-03-17 19:34:55 +0000;fix typo

==

docs/topics/selectors.rst
==================
58975abe;Nicolás Ramírez;2013-03-15 11:11:51 -0300;Slots removed, now Scraper can handle just one spider

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/utils/engine.py
==================
e630126b;Pablo Hoffman;2013-03-14 16:47:35 -0300;scrapy deploy: return non-zero exit code if deploy fails

==

scrapy/commands/deploy.py
==================
bb209072;Pablo Hoffman;2013-03-14 16:43:00 -0300;minor updated to faq

==

docs/faq.rst
==================
098ccff8;Pablo Hoffman;2013-03-14 12:56:30 -0300;added FAQ about error: "cannot import name crawler"

==

docs/faq.rst
==================
a862f233;Pablo Hoffman;2013-03-14 12:44:36 -0300;added Nicolas Ramirez to AUTHORS

==

AUTHORS
==================
46b305ef;Pablo Hoffman;2013-03-14 08:43:53 -0700;Merge pull request #267 from nramirezuy/formrequest
Override Request 'method' in FormRequest
==
==================
f043bba0;Nicolás Ramírez;2013-03-13 13:38:37 -0300;Override request method in FormRequest
Changes proposed in the comments

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
a2e9d031;Pablo Hoffman;2013-03-14 10:32:19 -0300;removed duplicated test

==

scrapy/tests/test_http_request.py
==================
8391b362;Pablo Hoffman;2013-03-13 03:24:25 -0300;minor updates to contributing doc

==

docs/contributing.rst
==================
51c301b3;Pablo Hoffman;2013-03-13 03:18:33 -0300;added link to python binary libs, for windows installation

==

docs/intro/install.rst
==================
8e727307;Pablo Hoffman;2013-03-12 20:44:51 -0700;Merge pull request #261 from stav/allowed_domains
allow spider allowed_domains to be set/tuple, #259
==
==================
296db1dc;Pablo Hoffman;2013-03-12 19:28:43 -0300;log (just once) when duplicate requests are filtered out. closes #105, #249

==

scrapy/core/scheduler.py
scrapy/dupefilter.py
==================
a4507f62;Pablo Hoffman;2013-03-12 18:44:09 -0300;sep-019: fixed typo

==

sep/sep-019.rst
==================
650eda68;Steven Almeroth;2013-03-10 18:51:04 -0600;doc: add comment about commit history cleanliness

==

docs/contributing.rst
==================
5828179c;Steven Almeroth;2013-03-10 18:30:49 -0600;remove over-testing and dict testing for test_utils_url.py

==

scrapy/tests/test_utils_url.py
==================
1514b3b5;Steven Almeroth;2013-03-10 16:47:24 -0600;pylint clean-ups for test_utils_url.py

==

scrapy/tests/test_utils_url.py
==================
a613e151;Steven Almeroth;2013-03-10 16:41:27 -0600;add tests for url_is_from_spider() with allowed_domains

==

scrapy/tests/test_utils_url.py
==================
b2b256dc;Pablo Hoffman;2013-03-10 14:22:08 -0300;added nicolas to sep-019 authors, changed main title formatting for sep-019 and sep-020

==

sep/sep-019.rst
sep/sep-020.rst
==================
b11a1326;Pablo Hoffman;2013-03-08 11:23:15 -0800;Merge pull request #264 from stav/sep
add new sep-20 and update sep-19 with table at the top
==
==================
e66db6fa;Steven Almeroth;2013-03-08 13:04:11 -0600;add new sep-20 and update sep-19 with table at the top

==

sep/sep-019.rst
sep/sep-020.rst
==================
eeb69d2f;Pablo Hoffman;2013-03-08 11:59:38 -0200;added #260 to release notes

==

docs/news.rst
==================
42499c72;Pablo Hoffman;2013-03-08 11:57:54 -0200;updated AUTHORS

==

AUTHORS
==================
b5b37197;Pablo Hoffman;2013-03-08 05:49:08 -0800;Merge pull request #260 from llonchj/entry_point
Commands module
==
==================
b560f4d1;Pablo Hoffman;2013-03-08 09:57:12 -0200;sep-019: remove TODO section (settled down with class method)

==

sep/sep-019.rst
==================
a4475717;Pablo Hoffman;2013-03-07 19:38:12 -0200;sep-019: other minor fixes

==

sep/sep-019.rst
==================
c7add1e5;Pablo Hoffman;2013-03-07 19:24:44 -0200;sep-019: fix typos

==

sep/sep-019.rst
==================
d806acdf;Pablo Hoffman;2013-03-07 12:39:40 -0200;sep-019: minor tide up

==

sep/sep-019.rst
==================
6f24b461;Pablo Hoffman;2013-03-07 12:34:17 -0200;added SEP-019 (per-spider settings) - first draft

==

sep/sep-019.rst
==================
a027da0a;Pablo Hoffman;2013-03-06 11:41:34 -0200;Some changes to scrapy deploy command:
- use branch names when constructing HG/GIT versions
- added -d flag for debugging (keeps build directory)
- improved command output (redirected setup.py stderr)

==

scrapy/commands/deploy.py
==================
b48ec1dc;Steven Almeroth;2013-03-06 00:19:47 -0600;allow spider allowed_domains to be set/tuple, #259

==

scrapy/utils/url.py
==================
5b118ff4;Jordi Llonch;2013-03-06 06:36:23 +1100;added documentation (experimental feature)

==

docs/experimental/index.rst
==================
d9261f6c;Jordi Llonch;2013-03-06 05:25:38 +1100;pluggable sub-commands for scrapy comand-line

==

scrapy/cmdline.py
==================
19d0942c;Pablo Hoffman;2013-03-04 02:14:01 -0200;Merge branch 'shell' of git://github.com/stav/scrapy into stav-shell

==
==================
3c8eef99;Pablo Hoffman;2013-03-04 01:35:17 -0200;docs/contributing: added note explaining what Scrapy contrib is

==

docs/contributing.rst
==================
7dd360f3;Pablo Hoffman;2013-03-03 19:17:46 -0800;Merge pull request #257 from stav/cleanups
doc: fix typo in spider middleware
==
==================
81111dd3;Steven Almeroth;2013-03-02 20:13:14 -0600;fetch command should catch IgnoreRequest exception

==

scrapy/shell.py
==================
f62b6660;Steven Almeroth;2013-03-02 19:46:31 -0600;doc: fix typo in spider middleware

==

docs/topics/spider-middleware.rst
==================
d5d944fa;Pablo Hoffman;2013-02-28 11:35:11 -0200;Log overriden Scrapy settings when Scrapy starts.
This is useful for debugging, to quickly find out which settings where
used for a specific spider run. dict settings are omitted for brevity.
DEBUG level is used for consistency with "Enabled
extensions/middlewares" lines (which share a similar purpose).

==

scrapy/crawler.py
scrapy/settings/__init__.py
==================
8f3a509d;Pablo Hoffman;2013-02-27 03:52:51 -0200;remove debugging code

==

scrapy/core/engine.py
scrapy/signalmanager.py
==================
3a6b8025;Pablo Hoffman;2013-02-27 03:51:23 -0200;arg_to_iter: replaced double call to isinstance with a single one. refs #248

==

scrapy/core/engine.py
scrapy/signalmanager.py
scrapy/utils/misc.py
==================
2bbd9274;Pablo Hoffman;2013-02-27 02:39:31 -0200;arg_to_iter: treat items the same way as dicts (ie. non iterables). fixes #248

==

scrapy/tests/test_utils_misc/__init__.py
scrapy/utils/misc.py
==================
7400ceb1;Pablo Hoffman;2013-02-22 19:12:59 -0200;added 502 to RETRY_HTTP_CODES

==

docs/topics/downloader-middleware.rst
scrapy/settings/default_settings.py
==================
e3f50b97;Pablo Hoffman;2013-02-20 11:38:50 -0200;made scrapy/item.py pep8 compliant

==

scrapy/item.py
==================
a038f468;Pablo Hoffman;2013-02-14 11:11:17 -0200;doc: fixed rst title

==

docs/topics/items.rst
==================
22edc44c;Pablo Hoffman;2013-02-14 11:09:40 -0200;doc: remove links to diveintopython.org, which is no longer available. closes #246

==

docs/intro/tutorial.rst
docs/topics/settings.rst
==================
aeb7fbe2;Pablo Hoffman;2013-02-12 18:13:26 -0800;Merge pull request #240 from llonchj/spider_log
spider.log to pass keyword arguments into twisted log.msg
==
==================
07669947;Pablo Hoffman;2013-02-12 18:11:49 -0800;Merge pull request #244 from morty/master
scrapy genspider allows you to create a spider module with the same name as the project
==
==================
2efd8595;Tom Mortimer-Jones;2013-02-12 12:26:38 +0000;Added check so that genspider cannot create a spider with the same name as the project.

==

scrapy/commands/genspider.py
scrapy/tests/test_commands.py
==================
1ff8b4f8;Pablo Hoffman;2013-02-12 00:59:25 -0200;updated release notes with previous commit

==

docs/news.rst
==================
5971333a;Rolando Espinoza La fuente;2013-02-11 12:34:29 -0400;added --pdb command option to enable pdb debugger on failure.

==

scrapy/command.py
==================
d9043ffa;Pablo Hoffman;2013-02-11 11:43:25 -0200;reverted previous changed as it broke tests

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
2df010a9;Pablo Hoffman;2013-02-11 05:29:14 -0800;Merge pull request #241 from zuhao/master
Fix url_has_any_extension bug
==
==================
27ca2547;Zuhao Wan;2013-02-11 17:19:31 +0800;Fix url_has_any_extension bug

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
6d4b764f;Jordi Llonch;2013-02-11 05:00:06 +1100;spider.log to pass keyword arguments into twisted log.msg

==

scrapy/spider.py
==================
c0a7040f;Daniel Graña;2013-02-08 15:07:00 -0200;add PHONYs so build does not match build/ path

==

Makefile.buildbot
==================
910effd1;Daniel Graña;2013-02-06 11:44:26 -0200;get scrapy version from package data

==

MANIFEST.in
Makefile.buildbot
extras/makedeb.py
scrapy/VERSION
scrapy/__init__.py
setup.py
==================
79cb0318;Daniel Graña;2013-02-06 10:36:08 -0200;update travis-ci conf

==

.travis.yml
==================
5db45b38;Daniel Graña;2013-02-06 05:05:06 +0000;remove scrapyd, it was migrated to its own repository

==

.travis.yml
MANIFEST.in
Makefile.buildbot
bin/runtests.sh
bin/scrapyd
debian/control
debian/rules
debian/scrapy.install
debian/scrapyd-files/000-default
debian/scrapyd.default
debian/scrapyd.dirs
debian/scrapyd.install
debian/scrapyd.lintian-overrides
debian/scrapyd.postinst
debian/scrapyd.postrm
debian/scrapyd.scrapyd.upstart
docs/topics/commands.rst
extras/makedeb.py
extras/scrapyd.tac
extras/test-scrapyd.sh
scrapy/commands/server.py
scrapyd/__init__.py
scrapyd/app.py
scrapyd/config.py
scrapyd/default_scrapyd.conf
scrapyd/eggstorage.py
scrapyd/eggutils.py
scrapyd/environ.py
scrapyd/interfaces.py
scrapyd/launcher.py
scrapyd/poller.py
scrapyd/runner.py
scrapyd/scheduler.py
scrapyd/script.py
scrapyd/spiderqueue.py
scrapyd/sqlite.py
scrapyd/tests/__init__.py
scrapyd/tests/mybot.egg
scrapyd/tests/test_dont_load_settings.py
scrapyd/tests/test_eggstorage.py
scrapyd/tests/test_environ.py
scrapyd/tests/test_poller.py
scrapyd/tests/test_scheduler.py
scrapyd/tests/test_spiderqueue.py
scrapyd/tests/test_sqlite.py
scrapyd/tests/test_utils.py
scrapyd/utils.py
scrapyd/webservice.py
scrapyd/website.py
setup.py
tox.ini
==================
33ca2951;Daniel Graña;2013-02-05 17:27:10 -0800;Merge pull request #235 from whodatninja/patch-1
Fix typo labeling attrs type bool instead of list
==
==================
8e3b5baa;whodatninja;2013-02-05 15:10:41 -0500;Fix typo labeling attrs type bool instead of list

==

docs/topics/link-extractors.rst
==================
f293d08e;Daniel Graña;2013-02-01 09:01:27 -0800;Merge pull request #234 from darkrho/httpcache-dbm-module-fullpath
allow to use full path in HTTPCACHE_DBM_MODULE setting
==
==================
d00e6cf1;Rolando Espinoza La fuente;2013-02-01 12:52:59 -0400;tests: dummydbm.error should be KeyError.

==

scrapy/tests/mocks/dummydbm.py
==================
6ed44a3a;Rolando Espinoza La fuente;2013-02-01 12:41:52 -0400;httpcache: added tests for custom dbm module.
And removed the break in the line to improve readability as there
is no strict 80-chars line width convention.

==

scrapy/contrib/httpcache.py
scrapy/tests/mocks/__init__.py
scrapy/tests/mocks/dummydbm.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
a2602df9;Rolando Espinoza La fuente;2012-11-21 10:44:35 -0400;httpcache: allow to import submodules within packages as HTTPCACHE_DBM_MODULE setting.

==

scrapy/contrib/httpcache.py
==================
e5edb8ec;Daniel Graña;2013-01-30 16:55:53 -0200;Merge branch 'dangra/issue-24'

==
==================
3af240f5;Daniel Graña;2013-01-30 16:55:16 -0200;Merge branch 'dangra/issue-12'

==
==================
0d3e4b4c;Daniel Graña;2013-01-30 11:22:03 -0200;do not unquote slash and question mark in url paths. fix #24

==

scrapy/tests/test_contrib_linkextractors.py
scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
872a22df;Daniel Graña;2013-01-29 18:08:32 -0200;pep8ize sgml link extractors

==

scrapy/contrib/linkextractors/sgml.py
scrapy/tests/test_contrib_linkextractors.py
==================
cc69b3aa;Daniel Graña;2013-01-29 17:56:34 -0200;Fix #199 encoding error concatenating link text

==

scrapy/contrib/linkextractors/sgml.py
scrapy/tests/test_contrib_linkextractors.py
==================
95fde0a4;Daniel Graña;2013-01-29 12:00:13 -0200;register namespaces when XMLFeedSpider uses iternodes mode. fixes #12

==

scrapy/contrib/spiders/feed.py
scrapy/tests/test_spider.py
==================
8e77f278;Daniel Graña;2013-01-24 17:47:36 -0200;Find form nodes in invalid html5 documents
lxml fails to parse invalid html5 documents
This error was reported in scrapy/loginform#3

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
ff044806;Daniel Graña;2013-01-24 14:50:40 -0200;fix exporting nested items as xml. fixes #66

==

scrapy/contrib/exporter/__init__.py
scrapy/tests/test_contrib_exporter.py
==================
71d7df92;Pablo Hoffman;2013-01-23 16:28:41 -0200;simplify InitSpider implementation, fixing one bug (closes #228) and adding support generators return from start_requests() (which the previous version didn't)

==

scrapy/contrib/spiders/init.py
==================
3cf7f497;Daniel Graña;2013-01-23 11:27:04 -0200;Add 0.16.4 to release notes
Conflicts:
	docs/news.rst

==

docs/news.rst
==================
c40f947d;Daniel Graña;2013-01-22 20:27:40 -0800;Merge pull request #229 from christilden/master
fixes spelling errors in documentation
==
==================
aae6aed4;Chris Tilden;2013-01-22 14:52:18 -0800;fixes spelling errors in documentation

==

docs/topics/api.rst
docs/topics/commands.rst
docs/topics/debug.rst
docs/topics/djangoitem.rst
docs/topics/downloader-middleware.rst
docs/topics/email.rst
docs/topics/exporters.rst
docs/topics/feed-exports.rst
docs/topics/images.rst
docs/topics/item-pipeline.rst
docs/topics/items.rst
docs/topics/jobs.rst
docs/topics/link-extractors.rst
docs/topics/loaders.rst
docs/topics/logging.rst
docs/topics/request-response.rst
docs/topics/scrapyd.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
docs/topics/stats.rst
docs/topics/telnetconsole.rst
docs/topics/webservice.rst
==================
27583922;Pablo Hoffman;2013-01-21 14:01:12 -0200;remove unused imports

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
65258e36;Pablo Hoffman;2013-01-21 04:57:19 -0800;Merge pull request #227 from tonal/correct-old-cache
Correct init bag for load FilesystemCacheStorage from old location
==
==================
2c51266a;Alexandr N Zamaraev (aka tonal);2013-01-21 13:54:36 +0700;Correct init bag for load old scrapy.contrib.httpcache.FilesystemCacheStorage

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
6ab8afb9;Pablo Hoffman;2013-01-18 12:35:30 -0200;improve documentation about removing namespaces

==

docs/faq.rst
docs/news.rst
docs/topics/selectors.rst
==================
1ba04b1f;Pablo Hoffman;2013-01-18 12:19:58 -0200;added remove_namespaces() method to XmlXPathSelector objects

==

docs/news.rst
docs/topics/selectors.rst
scrapy/selector/lxmlsel.py
scrapy/tests/test_selector_lxml.py
==================
b7eeeff4;Pablo Hoffman;2013-01-17 13:18:23 -0200;get rid of assertDictEqual (since it's python 2.7+ only)

==

scrapy/tests/test_djangoitem/__init__.py
==================
c31441a2;Pablo Hoffman;2013-01-17 13:08:29 -0200;revert default HTTP cache policy to dummy (instead of RFC2616)

==

docs/topics/downloader-middleware.rst
scrapy/settings/default_settings.py
==================
89719518;Daniel Graña;2013-01-08 18:36:20 -0200;document new FormRequest parameter named `formxpath` that matches forms using xpath

==

docs/topics/request-response.rst
==================
7527ef97;Daniel Graña;2013-01-08 12:34:06 -0800;Merge pull request #185 from notsobad/master
Added xpath support in FormRequest.from_response
==
==================
75563b3f;Daniel Graña;2013-01-08 18:16:44 -0200;Add list of supported and missing RFC2616 caching features

==

docs/topics/downloader-middleware.rst
==================
3cbc4d0b;Daniel Graña;2013-01-08 17:56:46 -0200;django is an optional_features, its imports must not fail

==

scrapy/__init__.py
scrapy/contrib/djangoitem.py
scrapy/tests/test_djangoitem/__init__.py
==================
d8a760bf;Daniel Graña;2013-01-08 17:34:48 -0200;Merge branch 'http-cache-middleware'
Conflicts:
	scrapy/contrib/downloadermiddleware/httpcache.py
	scrapy/contrib/httpcache.py
	scrapy/tests/test_downloadermiddleware_httpcache.py

==
==================
864a7aef;Daniel Graña;2013-01-08 17:26:32 -0200;More httpcache updates
* Change default cache policy to RFC2616
* Update HttpCacheMiddleware documentation
* Move policies to scrapy.contrib.httpcache
* remove a lint error for .has_key() usage in DBM storage backend

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/httpcache.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
487299e0;Daniel Graña;2013-01-08 15:47:33 -0200;TakeFirst doc says it returns first non-null/non-empty value, zero is a valid value. closes #59

==

scrapy/contrib/loader/processor.py
scrapy/tests/test_contrib_loader.py
==================
672d09ea;Daniel Graña;2013-01-08 12:30:36 -0200;add meta-refresh changes to release notes

==

docs/news.rst
==================
9527c581;Daniel Graña;2013-01-08 11:48:36 -0200;pep8ize settings

==

scrapy/settings/default_settings.py
scrapy/settings/deprecated.py
==================
defc4f89;Daniel Graña;2013-01-08 11:41:19 -0200;update metarefresh settings

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/settings/default_settings.py
scrapy/settings/deprecated.py
==================
6a2b2388;Daniel Graña;2013-01-08 11:25:38 -0200;Add MetaRefreshMiddleware docs

==

docs/topics/downloader-middleware.rst
==================
076ba404;Daniel Graña;2013-01-08 10:50:27 -0200;update DOWNLOADER_MIDDLEWARES_BASE setting documentation

==

docs/topics/settings.rst
==================
71db7f1b;Daniel Graña;2013-01-08 09:55:16 -0200;Split redirection into status and metarefresh middlewares, also changes httpcompression priority. closes #78

==

scrapy/contrib/downloadermiddleware/redirect.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware.py
scrapy/tests/test_downloadermiddleware_redirect.py
==================
fe5d0ce2;Rolando Espinoza La fuente;2012-01-31 22:46:42 -0400;tests: added downloader middleware manager integration tests for gzipped redirection.

==

scrapy/tests/test_downloadermiddleware.py
==================
227a1d66;Pablo Hoffman;2013-01-07 13:16:19 -0200;add doc about disabling an extension. refs #132

==

docs/topics/extensions.rst
==================
5d3a4d75;Pedro Faustino;2013-01-06 18:53:14 +0000;Update downloader middleware documentation

==

docs/topics/downloader-middleware.rst
==================
59dc71f3;Pedro Faustino;2013-01-06 17:53:25 +0000;Merge branch 'http-cache-middleware', remote-tracking branch 'dangra/http-cache-middleware' into http-cache-middleware

==
==================
7f990a4a;Pablo Hoffman;2013-01-04 14:17:54 -0800;Merge pull request #221 from emschorsch/patch-1
Proposed Changes to DjangoItem documentation
==
==================
f9b130da;Emanuel Schorsch;2013-01-04 15:59:04 -0500;Proposed Changes
I was very confused as to how you actually import DjangoItem.
I searched extensively on the internet looking for actual code so I could see how it worked.
I finally found http://blog.just2us.com/2012/07/setting-up-django-with-scrapy/. It is much easier to understand with full files instead of code fragments.
I also edited where it says "we can see that the model is already saved" as I don't see how it's already saved.
==

docs/topics/djangoitem.rst
==================
acb7bad1;Pablo Hoffman;2013-01-04 10:35:20 -0800;Merge pull request #218 from Mimino666/django-item-validation
Django item validation
==
==================
3f03a2ca;Daniel Graña;2013-01-04 04:20:45 -0200;requests with no-cache set must force revalidation of cached responses

==

scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
cdecc760;Daniel Graña;2013-01-04 03:43:25 -0200;default httpcache to rfc2616 policy and improve storage and policy tests

==

scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/httpcache.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
0a5586fa;Daniel Graña;2013-01-03 09:16:54 -0200;move FilesystemCacheStorage to scrapy.contrib.httpcache

==

scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/httpcache.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
9f003a73;Pablo Hoffman;2013-01-02 21:04:40 -0800;Merge pull request #217 from Mimino666/item-processing-errormsg
Fixed error message formatting.
==
==================
2cfbd13c;Michal Danilak;2013-01-03 02:01:04 +0100;Added "exclude" parameter testing to unittests.

==

scrapy/tests/test_djangoitem/__init__.py
==================
035d1e99;Michal Danilak;2013-01-03 01:42:04 +0100;Added model validation to DjangoItem.

==

scrapy/contrib/djangoitem.py
scrapy/tests/test_djangoitem/__init__.py
==================
8ea89b27;Michal Danilak;2013-01-02 22:46:28 +0100;Fixed error message formatting. log.err() doesn't support cool formatting and when error occured, the message was: 	"ERROR: Error processing %(item)s"

==

scrapy/core/scraper.py
==================
ea096756;Pablo Hoffman;2013-01-02 09:15:15 -0800;Merge pull request #216 from Mimino666/shell-spider-option
Added --spider option to "shell" command.
==
==================
a6ef76ed;Daniel Graña;2013-01-02 14:13:32 -0200;lint and improve images pipeline error logging

==

scrapy/contrib/pipeline/images.py
==================
ea68250d;Michal Danilak;2013-01-02 17:13:37 +0100;Added --spider option to "shell" command.

==

scrapy/commands/shell.py
==================
e9c5b762;Pablo Hoffman;2013-01-02 06:21:32 -0800;Merge pull request #215 from kuyan/patch-1
Fixed typo
==
==================
d572f894;Natan L;2012-12-31 11:14:01 -0800;Fixed typo
'persitent' --> 'persistent'
==

docs/topics/jobs.rst
==================
1aa25cdf;Pablo Hoffman;2012-12-29 19:21:54 -0800;Merge pull request #214 from tonal/log-level-dropped-item
Make LogFormatter return the log level (and require it)
==
==================
71b071ff;Alexandr N Zamaraev (aka tonal);2012-12-29 11:43:41 +0700;Log level return from LogFormatter methods

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/logformatter.py
==================
cf5f0203;Pedro Faustino;2012-12-28 16:11:47 +0100;Instead of extending from HttpCachePolicy, following the same approach used for storage selection

==

.gitignore
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
ba257db6;Pablo Hoffman;2012-12-28 06:42:40 -0800;Merge pull request #213 from tonal/forget-import
Remove firget imports
==
==================
492831fc;Pedro Faustino;2012-12-28 15:27:45 +0100;Merge branch 'master' of git://github.com/scrapy/scrapy into http-cache-middleware

==
==================
3e31d068;Pedro Faustino;2012-12-28 13:28:35 +0100;Implement single HTTP cache policy

==

scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
63d0b9f8;Pedro Faustino;2012-12-28 11:06:04 +0100;Remove plural from stat key.

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
3d397de0;Alexandr N Zamaraev (aka tonal);2012-12-28 13:40:27 +0700;Possible set log-level in LogFormatter.dropped and LogFormatter.scraped

==

scrapy/core/scraper.py
==================
21de68b7;Alexandr N Zamaraev (aka tonal);2012-12-28 13:01:39 +0700;Remove firget imports

==

scrapyd/app.py
scrapyd/website.py
==================
93a11021;Hasnain Lakhani;2012-12-26 16:29:48 -0800;Implemented policies for HTTP Cache

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
51b8feb4;Pablo Hoffman;2012-12-26 16:16:53 -0200;fixed doc typos

==

docs/topics/broad-crawls.rst
docs/topics/practices.rst
==================
1e2ee76d;Pablo Hoffman;2012-12-26 14:02:13 -0200;add documentation topics: Broad Crawls & Common Practies

==

docs/faq.rst
docs/index.rst
docs/topics/broad-crawls.rst
docs/topics/practices.rst
==================
fdaa35f6;Pedro Faustino;2012-12-24 19:37:53 +0100;Updated the downloader middleware documentation to reflect changes introduced by the support for real HTTP caching.

==

docs/topics/downloader-middleware.rst
==================
b2d3f4dd;Pedro Faustino;2012-12-24 16:15:04 +0100;Add cache storage support for real HTTP caching. Add real HTTP caching unit tests for both middleware and cache storage.

==

scrapy/contrib/httpcache.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
0e435fb5;Pedro Faustino;2012-12-24 13:27:13 +0100;Add middleware support for the 'no-store' Cache-Control directive.

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
bb55f39a;Pedro Faustino;2012-12-24 01:52:45 +0100;Add middleware support for real HTTP caching. Add httpcache setting to allow either real or dummy HTTP caching (for backwards compatibility it's set to use dummy cache by default).

==

scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/settings/default_settings.py
==================
e396509f;Pedro Faustino;2012-12-24 00:24:27 +0100;Removing plural from httpcache stats' value names.

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
dabb0642;Pablo Hoffman;2012-12-20 11:59:07 -0200;fix bug in scrapy parse command when spider is not specified explicitly. closes #209

==

scrapy/commands/parse.py
==================
12475fcc;Pablo Hoffman;2012-12-17 10:11:46 -0800;Merge pull request #206 from dangra/downloader-enhancements
AutoThrottle and Downloader enhancements
==
==================
22559833;Daniel Graña;2012-12-12 17:50:12 -0200;core: drop download inactive slots and get slot key from meta

==

scrapy/contrib/throttle.py
scrapy/core/downloader/__init__.py
==================
eb2d8725;Daniel Graña;2012-12-12 17:24:51 -0200;core: move download slot assignment post middleware evaluation

==

scrapy/core/downloader/__init__.py
scrapy/core/engine.py
==================
d7daf836;Daniel Graña;2012-12-06 10:42:57 -0200;Altering delay is enough to auto throttle downloads

==

docs/topics/autothrottle.rst
scrapy/contrib/throttle.py
scrapy/core/downloader/__init__.py
==================
85c98817;Daniel Graña;2012-12-12 17:09:05 -0200;fix pylint and pep8 warnings

==

scrapy/core/downloader/__init__.py
==================
c505b336;joehillen;2012-12-12 08:53:32 -0800;PEP8 on pydispatch/robustapply.py

==

scrapy/xlib/pydispatch/robustapply.py
==================
8778af5c;joehillen;2012-12-12 08:42:18 -0800;Explicitly check if an object is a class is pydispatch.
* This is to fix a disagreement in between CPython and PyPy.
* https://gist.github.com/4220533

==

scrapy/xlib/pydispatch/robustapply.py
==================
0bc5e4f9;Pablo Hoffman;2012-12-10 16:19:25 -0800;Merge pull request #204 from LuanP/patch-1
Update docs/topics/commands.rst
==
==================
5582ea28;Luan;2012-12-10 15:16:02 -0200;Update docs/topics/commands.rst
A short change.
==

docs/topics/commands.rst
==================
0cc138c0;Daniel Graña;2012-12-07 18:52:42 -0200;Add 0.16.3 release notes

==

docs/news.rst
==================
e676ad31;Daniel Graña;2012-12-05 17:06:38 -0200;Support sending requests trough multiples slots in QPS exmaple spider

==

extras/qps-bench-server.py
extras/qpsclient.py
==================
fd58de49;Daniel Graña;2012-12-05 10:56:42 -0200;Remove concurrency limitation when using download delays and still ensure inter-request delays are enforced

==

scrapy/core/downloader/__init__.py
==================
dcc0a540;Daniel Graña;2012-12-05 11:08:43 -0200;QPS bench server and a useful spider spider to generate requests

==

extras/qps-bench-server.py
extras/qpsclient.py
==================
a958fb11;Daniel Graña;2012-12-03 03:06:47 -0800;Merge pull request #202 from saxicek/master
Image pipeline error improvement
==
==================
5f899aa4;Libor Nenadál;2012-12-02 23:29:26 +0100;add error details when image pipeline fails

==

scrapy/contrib/pipeline/images.py
==================
9c9a18b3;Pablo Hoffman;2012-12-02 07:37:53 -0800;Merge pull request #201 from alexcepoi/test-fixes-mac
improve mac os compatibility
==
==================
fc405e98;Alex Cepoi;2012-12-01 16:39:58 +0100;improve mac os compatibility
Highlights:
* FifoDiskQueue: mixing buffered version of seek with unbuffered version
  of read causes problems
* BSD's find does not default to current directory
* gdbm needs to be closed before it can reopen the same file
* skip PIL tests if jpeg support is not available

==

bin/runtests.sh
scrapy/tests/test_downloadermiddleware_httpcache.py
scrapy/tests/test_pipeline_images.py
scrapy/utils/queue.py
==================
b9a96147;Pablo Hoffman;2012-11-25 22:22:24 -0200;setup.py: use README.rst to populate long_description

==

setup.py
==================
39274a24;Pablo Hoffman;2012-11-23 19:06:47 -0200;doc: removed obsolete references to ClientForm

==

docs/topics/request-response.rst
==================
8ca2ee3d;Pablo Hoffman;2012-11-22 13:02:15 -0800;Merge pull request #196 from stav/master
The default storage backend is now DbmCacheStorage
==
==================
99f164fc;stav;2012-11-22 14:05:47 -0600;correct docs for default storage backend

==

docs/topics/downloader-middleware.rst
==================
1f0d1670;Pablo Hoffman;2012-11-22 15:10:26 -0200;doc: removed broken proxyhub link from FAQ

==

docs/faq.rst
==================
0a00e0fd;Pablo Hoffman;2012-11-15 11:18:45 -0800;Merge pull request #195 from kalessin/floatdelay
download delay in autothrottle was being casted as int, should be float
==
==================
421dba98;Martin Olveyra;2012-11-15 18:41:32 +0000;download delay in autothrottle was being casted as int, should be float

==

scrapy/contrib/throttle.py
==================
3a60d420;Pablo Hoffman;2012-11-15 16:29:07 -0200;removed unused import

==

scrapy/core/downloader/webclient.py
==================
5ebaa40e;Pablo Hoffman;2012-11-15 16:28:39 -0200;changed SSL version to use from SSLv23 to TLSv1. closes #194 but needs more testing against counter-effects

==

scrapy/core/downloader/webclient.py
==================
cba39676;Pablo Hoffman;2012-11-12 13:37:52 -0800;Merge pull request #192 from vkrest/master
Fix broken doc links.
==
==================
ac4c66f3;vkrest;2012-11-12 22:43:42 +0200;Fix broken doc links.
All generated template files contain broken link to doc files.

==

scrapy/templates/project/module/items.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/templates/project/module/settings.py.tmpl
scrapy/templates/project/scrapy.cfg
==================
14179a16;Pablo Hoffman;2012-11-12 10:09:30 -0800;Merge pull request #190 from pedrofaustino/master
Adding support to 'nofollow' in the SGML link extractors
==
==================
3d0e962c;Pedro Faustino;2012-11-10 16:25:41 +0100;The Link object has a 'nofollow' attribute. Adding support in the SGML link extractors.

==

scrapy/contrib/linkextractors/sgml.py
scrapy/tests/test_contrib_linkextractors.py
==================
79a8bb6b;Pablo Hoffman;2012-11-10 06:37:54 -0800;Merge pull request #189 from coagulant/patch-1
Fixed docs typo in SpiderOpenCloseLogging example
==
==================
097aea04;Ilya Baryshev;2012-11-10 12:24:53 +0400;Fixed docs typo in SpiderOpenCloseLogging example

==

docs/topics/extensions.rst
==================
da7e414f;Daniel Graña;2012-11-09 13:01:20 -0200;Add 0.16.2 release notes
Conflicts:

	docs/news.rst

==

docs/news.rst
==================
db21bccf;Pablo Hoffman;2012-11-07 16:02:13 -0200;added 0.18 to release notes and mention spider contracts

==

docs/news.rst
==================
c01f81ab;Pablo Hoffman;2012-11-07 09:40:21 -0800;Merge pull request #177 from alexcepoi/contracts_fixes
Improve feedback on spider contracts run
==
==================
a438be39;notsobad;2012-11-07 02:08:38 +0800;Add xpath suppot for FormRequest.from_response.

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
aa0e02dc;Pablo Hoffman;2012-11-04 19:58:06 -0200;added open_in_browser to debugging doc

==

docs/topics/debug.rst
==================
7a7c5d13;Pablo Hoffman;2012-11-03 17:05:01 -0200;removed reference to global scrapy stats from settings doc

==

docs/topics/settings.rst
==================
626662f0;Pablo Hoffman;2012-11-03 16:57:16 -0200;Fix SpiderState bug in Windows platforms
The spider state file was not opened in binary mode.

==

scrapy/contrib/spiderstate.py
==================
0350920f;Alex Cepoi;2012-10-28 18:18:35 +0100;scrapy contracts: python2.6 compat

==

scrapy/commands/check.py
scrapy/contracts/__init__.py
scrapy/tests/test_contracts.py
==================
c6fad057;Alex Cepoi;2012-10-28 17:53:38 +0100;scrapy contracts verbose option

==

scrapy/commands/check.py
scrapy/contracts/__init__.py
scrapy/tests/test_contracts.py
==================
94629a1f;Alex Cepoi;2012-10-27 23:26:40 +0200;proper unittest-like output for scrapy contracts

==

scrapy/commands/check.py
scrapy/contracts/__init__.py
scrapy/exceptions.py
scrapy/tests/test_contracts.py
==================
c0542838;Daniel Graña;2012-10-26 18:53:59 -0200;update news file with 0.16.1 release notes

==

docs/news.rst
==================
b01be861;Pablo Hoffman;2012-10-25 15:24:53 -0200;fixed LogStats extension, which got broken after a wrong merge before the 0.16 release

==

scrapy/contrib/logstats.py
==================
e8e5a62c;Pablo Hoffman;2012-10-25 11:40:09 -0200;better backwards compatibility for scrapy.conf.settings
Althought this backwards compatibility is more complex, it avoid modules
from failing when importing scrapy.conf, if they are not run through
"scrapy" command (such as when running tests on scrapy projects code).

==

scrapy/cmdline.py
scrapy/conf.py
==================
8f4c879b;Pablo Hoffman;2012-10-25 11:28:23 -0200;extended documentation on how to access crawler stats from extensions

==

docs/topics/stats.rst
==================
17d95846;Pablo Hoffman;2012-10-24 17:19:12 -0200;removed .hgtags (no longer needed now that scrapy uses git)

==

.hgtags
==================
a9616f38;Daniel Graña;2012-10-18 20:14:20 -0200;fix dashes under rst headers

==

docs/news.rst
==================
4852c610;Daniel Graña;2012-10-18 20:07:36 -0200;set release date for 0.16.0 in news

==

docs/news.rst
==================
d4b8e263;Daniel Graña;2012-10-18 17:11:33 -0200;bumped version to 0.17.0

==

scrapy/__init__.py
==================
c3e91ba7;Pablo Hoffman;2012-10-12 20:02:03 -0200;updated scrapy_bash_completion

==

extras/scrapy_bash_completion
==================
e9cef3ae;Pablo Hoffman;2012-10-12 20:01:43 -0200;better description for scrapy check command

==

scrapy/commands/check.py
==================
a0e2b6e3;Pablo Hoffman;2012-10-12 17:28:02 -0200;simplified backwards compatibility of scrapy.conf

==

scrapy/cmdline.py
==================
9d710621;Pablo Hoffman;2012-10-12 17:24:25 -0200;added deprecation warning when importing scrapy.conf module

==

scrapy/conf.py
==================
b038bb85;Pablo Hoffman;2012-10-12 16:53:44 -0200;minor message update: spider stats -> Scrapy stats

==

scrapy/statscol.py
==================
1d5967ce;Artem Bogomyagkov;2012-10-10 12:21:59 +0300;httpcompression middleware improvement

==

scrapy/tests/sample_data/compressed/truncated-crc-error-short.gz
scrapy/tests/test_utils_gz.py
scrapy/utils/gz.py
==================
1a905d62;Pablo Hoffman;2012-10-09 16:05:19 -0200;removed scrapy.log.started attribute, and avoid checking if log has already been started (since it should be called once anyway)

==

docs/news.rst
docs/topics/logging.rst
scrapy/command.py
scrapy/log.py
==================
1f89eb59;Pablo Hoffman;2012-10-09 16:02:12 -0200;fixed doc reference to topics-contracts

==

docs/topics/settings.rst
==================
9e4c6aba;Pablo Hoffman;2012-10-09 12:50:42 -0200;updated release notes with new stats recently added

==

docs/news.rst
==================
bd3a1092;Pablo Hoffman;2012-10-09 12:41:31 -0200;Track number of log messages via Scrapy stats
Log messages count are grouped per LEVEL like:

    'log_count/DEBUG': 8,
    'log_count/ERROR': 1,
    'log_count/INFO': 4,

This required passing the Crawler object to scrapy logging facility, so
the scrapy.log module underwent a few changes which should be backwards
compatible (or as backwards compatible as they could be).

==

scrapy/command.py
scrapy/log.py
==================
1ae1a3ea;Pablo Hoffman;2012-10-09 12:40:51 -0200;don't reset scrapy stats when spider is opened

==

scrapy/statscol.py
==================
ceeea27d;Pablo Hoffman;2012-10-09 12:39:30 -0200;added response_received_count to scrapy stats

==

scrapy/contrib/corestats.py
==================
45259579;Pablo Hoffman;2012-10-08 15:29:57 -0200;fix test-scrapyd.sh after changes made to website

==

extras/test-scrapyd.sh
==================
3c3c0c1f;Daniel Graña;2012-10-06 15:15:35 -0300;notify #scrapy room of travis build results

==

.travis.yml
==================
05ce20da;Daniel Graña;2012-10-05 11:04:43 -0300;more cases where response.meta is prefered

==

scrapy/contrib/spidermiddleware/depth.py
==================
1e1cc76f;Pablo Hoffman;2012-10-06 08:47:26 -0700;Merge pull request #179 from artem-dev/errback_fix
This fixes the case where failure.request wasn't available when the failure was generated in a spider middleware (for example, the HttpError middleware).
==
==================
0256a34f;Artem Bogomyagkov;2012-10-05 19:17:59 +0300;fix for request's errback, allows to get failed requests correctly

==

scrapy/core/engine.py
scrapy/core/scraper.py
==================
eee8e70b;Daniel Graña;2012-10-05 10:57:58 -0300;response.meta exposes resquest.meta for binded responses

==

scrapy/contrib/spidermiddleware/httperror.py
==================
dd13dfe8;Pablo Hoffman;2012-10-03 12:31:19 -0300;Raise error when settings module is missing.
Previously, it failed silently if an ImportError was caught when trying
to import the scrapy settings module. This not only happened when the
scrapy settings module itself was missing, but also when it tried to
import a missing module, which made the whole thing a bad idea.

A side effect of this change (not required, but for simplification) is
that we no longer support the default "scrapy_settings" name for the
scrapy settings module, but this was never used afaik.

==

scrapy/utils/project.py
scrapy/utils/testproc.py
==================
ce80e5c7;Shane Evans;2012-10-02 12:26:14 +0100;fix link to online installation instructions

==

INSTALL
==================
7458092e;Pablo Hoffman;2012-09-29 03:06:30 -0300;added spider contracts to release notes and warn that its API is still subject to change

==

docs/news.rst
docs/topics/contracts.rst
==================
34f14773;Pablo Hoffman;2012-09-28 18:55:12 -0300;make tests code python 2.6 compatible

==

scrapy/tests/test_contracts.py
==================
c380910b;Pablo Hoffman;2012-09-28 13:57:07 -0700;Merge pull request #167 from alexcepoi/sep-017
Spider contracts (SEP-017)
==
==================
a5f8943d;Pablo Hoffman;2012-09-26 13:17:01 -0300;added change introduced in previous commit to release notes

==

docs/news.rst
==================
4ca35dba;Pablo Hoffman;2012-09-26 09:15:40 -0700;Merge pull request #175 from euphoris/master
add options -o and -t to the runspider command
==
==================
e94bd818;Jae-Myoung Yu;2012-09-25 09:38:00 +0900;add options -o and -t to the runspider command
copy the codes from commands/crawl.py to commands/runspider.py

==

scrapy/commands/runspider.py
==================
a6eacf2c;Pablo Hoffman;2012-09-21 07:39:47 -0700;Merge pull request #172 from artem-dev/new_git_version
nicer deploy versions for git repos if tags are available
==
==================
7685cb14;Artem Bogomyagkov;2012-09-12 12:39:04 +0300;nicer deploy versions for git repos if tags are available

==

scrapy/commands/deploy.py
==================
73e6bc1b;Alex Cepoi;2012-09-21 00:54:11 +0200;remove unused import

==

scrapy/utils/misc.py
==================
11d29c70;Alex Cepoi;2012-09-21 00:12:46 +0200;SEP-017 contracts: add tests and minor improvements

==

docs/index.rst
docs/topics/contracts.rst
scrapy/commands/check.py
scrapy/contracts/__init__.py
scrapy/tests/test_contracts.py
scrapy/utils/misc.py
scrapy/utils/python.py
==================
b46b5a6e;Pablo Hoffman;2012-09-20 18:50:59 -0300;Documented AutoThrottle extension and added to extensions available by default. Also deprecated concurrency and delay settings, in favour of using the standard Scrapy ones.

==

docs/index.rst
docs/news.rst
docs/topics/autothrottle.rst
docs/topics/settings.rst
scrapy/contrib/throttle.py
scrapy/settings/default_settings.py
scrapy/settings/deprecated.py
==================
c1cbc5de;Pablo Hoffman;2012-09-19 13:58:58 -0300;renamed CONTRIBUTING to CONTRIBUTING.md so that links are rendered as links in github

==

CONTRIBUTING.md
==================
f3516aed;Pablo Hoffman;2012-09-19 13:54:16 -0300;added CONTRIBUTING file, for github: https://github.com/blog/1184-contributing-guidelines

==

CONTRIBUTING
==================
e8eacd6f;Pablo Hoffman;2012-09-19 13:28:34 -0300;minor code simplification

==

scrapy/commands/crawl.py
==================
7afedb89;Pablo Hoffman;2012-09-19 12:42:22 -0300;backwards compatibility support for scrapy.conf.settings singleton for when scrapy.conf is imported *before* calling scrapy.cmdline.execute(), such as in custom bot runners

==

scrapy/cmdline.py
scrapy/conf.py
==================
768a4839;Pablo Hoffman;2012-09-19 03:19:03 -0300;merge adding missing changes from previous commit

==
==================
c7f82199;Pablo Hoffman;2012-09-19 01:46:46 -0300;- removed scrapy.conf singleton from scrapy.log, scrapy.responsetypes,   scrapy.http.response.text, scrapy.selector - fixed bug with scrapy.conf.settings backwards compatibility support - added facility to notify (and provide some guidelines) about deprecated/obsolete settings

==

docs/topics/settings.rst
scrapy/cmdline.py
scrapy/command.py
scrapy/conf.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/crawler.py
scrapy/http/response/text.py
scrapy/log.py
scrapy/logformatter.py
scrapy/responsetypes.py
scrapy/selector/__init__.py
scrapy/selector/dummysel.py
scrapy/settings/default_settings.py
scrapy/settings/deprecated.py
scrapy/tests/test_log.py
scrapy/tests/test_selector_dummy.py
==================
aadf7ff1;Pablo Hoffman;2012-09-19 01:46:46 -0300;- removed scrapy.conf singleton from scrapy.log, scrapy.responsetypes,   scrapy.http.response.text, scrapy.selector - fixed bug with scrapy.conf.settings backwards compatibility support - added facility to notify (and provide some guidelines) about deprecated/obsolete settings

==

docs/topics/settings.rst
scrapy/cmdline.py
scrapy/command.py
scrapy/conf.py
scrapy/http/response/text.py
scrapy/log.py
scrapy/responsetypes.py
scrapy/selector/dummysel.py
scrapy/settings/default_settings.py
scrapy/settings/deprecated.py
scrapy/tests/test_selector_dummy.py
==================
391cc060;Pablo Hoffman;2012-09-18 11:19:23 -0700;Merge pull request #174 from stav/master
Selector documentation typo fixes
==
==================
303e13f6;stav;2012-09-18 12:56:52 -0500;selector documentation typos

==

docs/topics/selectors.rst
==================
3d736e65;Pablo Hoffman;2012-09-18 10:51:01 -0300;fixed typo in doc

==

docs/topics/spiders.rst
==================
eed6eb49;Pablo Hoffman;2012-09-17 10:11:07 -0300;make DBM the new default storage backend for HTTP cache middleware,  simplified DBM storage backend code to avoid dealing with many spiders at once (not needed), and update httpcache stats names (hit -> hits, miss -> misses)

==

docs/news.rst
docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/httpcache.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware_httpcache.py
scrapy/utils/project.py
==================
8f2dda12;Pablo Hoffman;2012-09-16 21:21:44 -0300;removed another instance of scrapy.conf.settings singleton, this time from scrapy.utils.trackref. From now on, trackrefs functionality will be always enabled as it imposes a very minimal performance overhead

==

docs/news.rst
docs/topics/leaks.rst
scrapy/contrib/debug.py
scrapy/contrib/memdebug.py
scrapy/utils/trackref.py
==================
cd823018;Pablo Hoffman;2012-09-16 20:53:52 -0300;removed another instance of scrapy.conf.settings singleton, this time from scrapy.cmdline (which manages scrapy command line tool), by moving the get_project_settings() function to scrapy.utils.project

==

scrapy/cmdline.py
scrapy/conf.py
scrapy/utils/project.py
==================
9685c240;Pablo Hoffman;2012-09-14 12:32:33 -0300;restored stats_spider_{opened,closing,closed} signals in backwards compatibility mode

==

docs/news.rst
scrapy/core/engine.py
scrapy/signals.py
scrapy/tests/test_engine.py
==================
81ed2d2d;Pablo Hoffman;2012-09-14 02:40:00 -0300;major Stats Collection refactoring: removed separation of global/per-spider stats, removed stats-related signals (stats_spider_opened, etc). Stats are much simpler now, backwards compatibility is kept on the Stats Collector API.

==

docs/news.rst
docs/topics/api.rst
docs/topics/stats.rst
scrapy/contrib/corestats.py
scrapy/core/engine.py
scrapy/signals.py
scrapy/statscol.py
scrapy/tests/test_stats.py
==================
8b484205;Pablo Hoffman;2012-09-13 20:07:11 -0300;better names for scheduler stats

==

scrapy/core/scheduler.py
==================
263e302b;Pablo Hoffman;2012-09-13 19:46:45 -0300;added more scheduler stats

==

scrapy/core/scheduler.py
==================
d6867f79;Pablo Hoffman;2012-09-13 15:26:45 -0300;removed sphinx warnings about duplicate reference names 'this page'

==

docs/intro/install.rst
==================
a874964a;Pablo Hoffman;2012-09-13 15:24:44 -0300;renamed 'XPath Selectors' title to just 'Selectors'

==

docs/index.rst
docs/topics/selectors.rst
==================
acb8895e;Pablo Hoffman;2012-09-13 15:22:59 -0300;changed note in scrapyd doc to use sphinx notes

==

docs/topics/scrapyd.rst
==================
26f1d5cb;Pablo Hoffman;2012-09-13 11:16:01 -0700;Merge pull request #171 from artem-dev/scrapyd_job_times
added start and stop times for scrapyd list jobs web service
==
==================
4d8f2539;Artem Bogomyagkov;2012-09-12 11:12:59 +0300;commited doc file missed from prev commit

==

docs/topics/scrapyd.rst
==================
5dde26d3;Artem Bogomyagkov;2012-09-12 11:10:49 +0300;simplified code for finished jobs times, updated docs for scrapyd

==

scrapyd/webservice.py
==================
7ace23c3;Pablo Hoffman;2012-09-11 16:37:55 -0300;removed another instance of scrapy.conf singleton, this time from test_cmdline

==

scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_cmdline/extensions.py
==================
86426451;Pablo Hoffman;2012-09-11 16:34:58 -0300;removed another instance of scrapy.conf singleton

==

scrapy/tests/test_log.py
==================
7ef593c5;Pablo Hoffman;2012-09-11 16:27:19 -0300;refactored MailSender to get rid of scrapy.conf singleton, also removed ill-designed scrapy.mail.mail_sent signal

==

docs/news.rst
docs/topics/email.rst
scrapy/contrib/memusage.py
scrapy/contrib/statsmailer.py
scrapy/mail.py
scrapy/tests/test_mail.py
==================
a42a8caf;Artem Bogomyagkov;2012-09-11 21:06:36 +0300;added start and stop times for scrapyd list jobs web service

==

scrapyd/webservice.py
==================
bf8dc61f;Alex Cepoi;2012-09-10 23:17:27 +0200;SEP-017 contracts: pretty-printing and docs

==

docs/index.rst
docs/topics/commands.rst
docs/topics/settings.rst
docs/topics/testing.rst
scrapy/contracts/__init__.py
scrapy/exceptions.py
==================
1e2efe56;Pablo Hoffman;2012-09-07 15:40:26 -0300;scrapy deploy: retry setup.py bdist_egg on EINTR. closes #9

==

scrapy/commands/deploy.py
==================
3c05fbb6;Pablo Hoffman;2012-09-05 15:54:23 -0300;removed redundant comment

==

scrapy/utils/python.py
==================
44fe4c6b;Pablo Hoffman;2012-09-05 15:54:13 -0300;set missing 'settings' attribute in FeedExports

==

scrapy/contrib/feedexport.py
==================
0135a536;Pablo Hoffman;2012-09-05 15:53:30 -0300;removed debugging print

==

scrapy/core/scraper.py
==================
7bf0af7a;Pablo Hoffman;2012-09-04 19:00:32 -0300;fixed some bugs in get_func_args() and added more test cases

==

scrapy/tests/test_utils_python.py
scrapy/utils/python.py
==================
251d9a90;Pablo Hoffman;2012-09-04 18:13:27 -0300;backwards compatibility support for FeedExport's that don't receive a settings object in their constructor

==

scrapy/contrib/feedexport.py
==================
caa64908;Pablo Hoffman;2012-09-04 18:07:44 -0300;added tests for get_func_args() and support for more cases

==

scrapy/tests/test_utils_python.py
scrapy/utils/python.py
==================
fff28718;Pablo Hoffman;2012-09-04 14:49:30 -0300;added doc section (and FAQ) about spider arguments

==

docs/faq.rst
docs/topics/scrapyd.rst
docs/topics/spiders.rst
==================
241abcb8;Pablo Hoffman;2012-09-04 14:22:21 -0300;scrapyd: log errors in API calls to the scrapyd log

==

scrapyd/webservice.py
==================
f4a17ec2;Pablo Hoffman;2012-09-03 22:19:15 -0300;removed references to Scrapy Snippets site

==

docs/intro/examples.rst
docs/news.rst
==================
b901e640;Pablo Hoffman;2012-09-03 19:28:16 -0300;replaced memory usage acounting with (more portable) resource module, removed scrapy.utils.memory module. closes #161

==

docs/news.rst
scrapy/contrib/memusage.py
scrapy/tests/test_utils_memory.py
scrapy/utils/memory.py
==================
e2f9daac;Pablo Hoffman;2012-09-03 16:58:49 -0300;fixed formatting in scrapyd release notes

==

docs/news.rst
docs/topics/scrapyd.rst
==================
dd1398b2;Pablo Hoffman;2012-09-03 16:43:51 -0300;removed another instance of scrapy.conf.settings singleton, this time from download handlers

==

docs/news.rst
scrapy/core/downloader/__init__.py
scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/file.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/handlers/s3.py
scrapy/tests/test_downloader_handlers.py
==================
3b768ae9;Daniel Graña;2012-08-31 20:10:32 -0300;oops. remove santas debug line

==

scrapy/core/engine.py
==================
c6435c5a;Pablo Hoffman;2012-08-31 18:49:20 -0300;restored scrapyd log message

==

scrapyd/launcher.py
==================
7c8af831;Pablo Hoffman;2012-08-31 18:39:30 -0300;added issue role to documentation

==

docs/_ext/scrapydocs.py
docs/news.rst
==================
3891c208;Pablo Hoffman;2012-08-31 14:33:41 -0700;Merge pull request #164 from dangra/lazy-log-formatting
format log lines lazily in case they are dropped by loglevels
==
==================
a2d22307;Daniel Graña;2012-08-31 17:33:44 -0300;update news.rst

==

docs/news.rst
==================
dcef7b03;Daniel Graña;2012-08-09 16:55:05 -0300;format log lines lazily in case they are dropped by loglevels

==

scrapy/commands/parse.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/urllength.py
scrapy/contrib/spiders/sitemap.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/core/scraper.py
scrapy/crawler.py
scrapy/log.py
scrapy/logformatter.py
scrapy/mail.py
scrapy/middleware.py
scrapy/telnet.py
scrapy/tests/test_commands.py
scrapy/tests/test_logformatter.py
scrapy/utils/iterators.py
scrapy/utils/signal.py
scrapy/utils/spider.py
scrapy/webservice.py
scrapyd/app.py
scrapyd/launcher.py
==================
be206ca5;Pablo Hoffman;2012-08-31 16:40:46 -0300;added process_start_requests method to spider middlewares

==

docs/news.rst
docs/topics/spider-middleware.rst
scrapy/core/engine.py
scrapy/core/spidermw.py
==================
b9206746;Pablo Hoffman;2012-08-31 16:39:45 -0300;corrected minor issue with doc references

==

docs/topics/djangoitem.rst
==================
a2d5a304;Pablo Hoffman;2012-08-31 09:12:19 -0700;Merge pull request #168 from alexcepoi/parse-fixes
parse command: fix crash in case of bad callback
==
==================
0350bed8;Alex Cepoi;2012-08-31 16:43:04 +0200;parse command: fix crash in case of bad callback

==

scrapy/commands/parse.py
==================
4ec99117;Pablo Hoffman;2012-08-30 11:56:30 -0300;fixed minor doc typo

==

docs/topics/spider-middleware.rst
==================
94b40162;Pablo Hoffman;2012-08-30 11:24:29 -0300;fixed tests to work on windows

==

scrapy/tests/test_downloadermiddleware_decompression.py
scrapy/tests/test_utils_iterators.py
scrapy/utils/test.py
scrapyd/launcher.py
scrapyd/tests/test_utils.py
scrapyd/utils.py
==================
3904f5f5;Pablo Hoffman;2012-08-30 10:09:20 -0300;more reliable way to set subprocess PYTHONPATH in tests

==

scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_commands.py
scrapy/utils/test.py
==================
4a5f7027;Pablo Hoffman;2012-08-29 15:44:24 -0300;minor tidy up to installation guide windows notes

==

docs/intro/install.rst
==================
098d892c;Pablo Hoffman;2012-08-29 15:37:05 -0300;simplified installation guide to only mention pip/easy_install mechanism, and provide hints for Windows users

==

docs/intro/install.rst
extras/rpm-install.sh
extras/scrapy.bat
extras/setup_wininst.bmp
setup.cfg
==================
6f1a5d8d;Alex Cepoi;2012-08-29 18:31:10 +0200;SEP-017 contracts: various minor changes

==

.gitignore
scrapy/commands/check.py
scrapy/contracts/__init__.py
scrapy/contracts/default.py
scrapy/exceptions.py
scrapy/settings/default_settings.py
scrapy/utils/misc.py
==================
6217f108;Pablo Hoffman;2012-08-29 11:44:00 -0300;avoid random "Interrupted system call" errors

==

scrapy/tests/test_commands.py
scrapy/utils/python.py
==================
8aa46a4b;Pablo Hoffman;2012-08-29 11:43:01 -0300;removed another usage of scrapy.conf.settings singleton

==

scrapy/commands/genspider.py
==================
280d9d40;Pablo Hoffman;2012-08-29 11:26:52 -0300;added file missed in previous commit

==

scrapy/contrib/djangoitem.py
==================
70f8e517;Pablo Hoffman;2012-08-29 11:23:11 -0300;promoted DjangoItem to main contrib

==

docs/experimental/index.rst
docs/index.rst
docs/news.rst
docs/topics/djangoitem.rst
scrapy/contrib_exp/djangoitem.py
scrapy/tests/test_djangoitem/__init__.py
==================
52151e87;Pablo Hoffman;2012-08-28 19:32:43 -0300;fixed bug in FeedExports extension, introduced in previous commit

==

extras/test-scrapyd.sh
scrapy/contrib/feedexport.py
==================
da234af4;Pablo Hoffman;2012-08-28 18:42:33 -0300;Merge branch 'singleton_removal'

==
==================
babfc6e7;Pablo Hoffman;2012-08-28 18:31:03 -0300;Updated documentation after singleton removal changes.
Also removed some unused code and made some minor additional
refactoring.

==

docs/experimental/djangoitems.rst
docs/index.rst
docs/news.rst
docs/topics/api.rst
docs/topics/architecture.rst
docs/topics/email.rst
docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/firebug.rst
docs/topics/item-pipeline.rst
docs/topics/request-response.rst
docs/topics/settings.rst
docs/topics/signals.rst
docs/topics/stats.rst
docs/topics/telnetconsole.rst
scrapy/contrib/spidermiddleware/depth.py
scrapy/settings/default_settings.py
scrapy/tests/test_engine.py
==================
90198715;Alex Cepoi;2012-08-24 16:42:13 +0200;SEP-017 contracts
* load contracts from settings
* refactored contracts manager
* fixed callback bug, which caused responses to be evaluated with a
wrong callback sometimes
* "returns" contract

==

scrapy/commands/check.py
scrapy/contracts/__init__.py
scrapy/contracts/base.py
scrapy/contracts/default.py
scrapy/exceptions.py
scrapy/settings/default_settings.py
scrapy/utils/misc.py
==================
c95f717e;Pablo Hoffman;2012-08-22 13:50:23 -0300;fixed typo in tests

==

scrapy/tests/test_contrib_exporter.py
==================
5fa5c454;Pablo Hoffman;2012-08-22 13:46:50 -0300;use ScrapyJSONEncoder JsonItemExporter & JsonLinesItemExporter, to support nested items properly

==

docs/news.rst
scrapy/contrib/exporter/__init__.py
scrapy/tests/test_contrib_exporter.py
scrapy/utils/serialize.py
==================
1e12c92b;Pablo Hoffman;2012-03-06 08:59:20 -0200;Removed signals/stats singletons
This change removes singletons for stats collection and signal
dispatching facilities, by making them a member of the Crawler class.

Here are some examples to illustrates the old and new API:

Signals - before:

    from scrapy import signals
    from scrapy.xlib.pydispatch import dispatcher
    dispatcher.connect(self.spider_opened, signals.spider_opened)

Signals - now:

    from scrapy import signals
    crawler.signals.connect(self.spider.opened, signals.spider_opened)

Stats collection - before:

    from scrapy.stats import stats
    stats.inc_value('foo')

Stats collection - now:

    crawler.stats.inc_value('foo')

Backwards compatibility was retained as much as possible and the old API
has been properly flagged with deprecation warnings.

==

scrapy/contrib/closespider.py
scrapy/contrib/corestats.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/downloadermiddleware/stats.py
scrapy/contrib/feedexport.py
scrapy/contrib/logstats.py
scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spiderstate.py
scrapy/contrib/statsmailer.py
scrapy/contrib/throttle.py
scrapy/contrib/webservice/stats.py
scrapy/core/downloader/__init__.py
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/core/scraper.py
scrapy/crawler.py
scrapy/mail.py
scrapy/signalmanager.py
scrapy/spidermanager.py
scrapy/stats.py
scrapy/statscol.py
scrapy/telnet.py
scrapy/tests/test_downloadermiddleware_httpcache.py
scrapy/tests/test_downloadermiddleware_stats.py
scrapy/tests/test_mail.py
scrapy/tests/test_spidermiddleware_depth.py
scrapy/tests/test_stats.py
scrapy/webservice.py
==================
36f47a4a;Pablo Hoffman;2012-08-21 17:27:45 -0300;Removed per-spider settings concept, and scrapy.conf.settings singleton from many extensions and middlewares. There are some still remaining, that will be removed in future commits

==

docs/news.rst
docs/topics/commands.rst
scrapy/contrib/closespider.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/defaultheaders.py
scrapy/contrib/downloadermiddleware/downloadtimeout.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/contrib/downloadermiddleware/stats.py
scrapy/contrib/downloadermiddleware/useragent.py
scrapy/contrib/feedexport.py
scrapy/contrib/httpcache.py
scrapy/contrib/logstats.py
scrapy/contrib/memdebug.py
scrapy/contrib/spiders/crawl.py
scrapy/contrib/statsmailer.py
scrapy/core/scraper.py
scrapy/settings/__init__.py
scrapy/spider.py
scrapy/tests/test_downloadermiddleware_defaultheaders.py
scrapy/tests/test_downloadermiddleware_downloadtimeout.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_downloadermiddleware_retry.py
scrapy/tests/test_downloadermiddleware_useragent.py
scrapy/tests/test_settings.py
==================
99b76eaa;Alex Cepoi;2012-08-21 02:47:35 +0200;SEP-017 contracts: first draft

==

.gitignore
scrapy/commands/check.py
scrapy/contracts/__init__.py
scrapy/contracts/base.py
scrapy/contracts/default.py
==================
19bcb44c;Daniel Graña;2012-08-10 15:04:30 -0700;Merge pull request #165 from andrix/master
Just a simple refactoring on *MemoryQueue classes that improve the performance
==
==================
ed872105;Andrés Moreira;2012-08-09 23:50:26 -0300;Small improvement on *MemoryQueue performance (mainly on push time)

==

scrapy/utils/queue.py
==================
483a70cb;Daniel Graña;2012-08-09 05:41:50 -0700;Merge pull request #160 from midiotthimble/patch-1
Pass into the model only existing fields

test passing OK and changes makes sense
==
==================
3bdd9b7b;Pablo Hoffman;2012-08-07 14:23:50 -0300;added more extensions to ignore on link extractors

==

scrapy/linkextractor.py
==================
16bee46c;Pablo Hoffman;2012-08-07 14:18:49 -0300;added ppt to scrapy.linkextractor.IGNORED_EXTENSIONS

==

scrapy/linkextractor.py
==================
abcc8c9f;Daniel Graña;2012-08-06 10:21:13 -0300;Recommend pypi as single way to install on Windows

==

docs/intro/install.rst
==================
b7b0c495;Daniel Graña;2012-08-06 09:10:16 -0300;append parse command to example code sections in docs. closes #162

==

docs/topics/debug.rst
==================
0497ac2f;Vladislav Poluhin;2012-07-26 20:55:55 +0800;Simple test for default values of model in DjangoItem

==

scrapy/tests/test_djangoitem/__init__.py
scrapy/tests/test_djangoitem/models.py
==================
e14c4163;Vladislav;2012-07-25 10:10:46 +0800;Pass into the model only existing fields
Model fields has default values and when field doesn't exists in item container, added `None` instead default value. My patch solves this problem.
==

scrapy/contrib_exp/djangoitem.py
==================
832e4507;Pablo Hoffman;2012-07-20 17:13:06 -0300;fixed typo in stats documentation. closes #159

==

docs/topics/stats.rst
==================
831a4500;Pablo Hoffman;2012-07-09 12:39:01 -0700;Merge pull request #155 from warvariuc/import_settings_module_verbose
Spider not found - confusion
==
==================
eb91cad0;Victor Varvariuc;2012-07-09 08:39:14 +0400;if you put in settings.py something like import local_settings and local_settings doesn't exist or contains errors you get:
/usr/local/lib/python2.7/dist-packages/Scrapy-0.15.1-py2.7.egg/scrapy/utils/project.py:17: UserWarning: Cannot import scrapy settings module settings
warnings.warn("Cannot import scrapy settings module %s" % scrapy_module)
...
File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.15.1-py2.7.egg/scrapy/cmdline.py", line 117, in _run_command
cmd.run(args, opts)
File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.15.1-py2.7.egg/scrapy/commands/crawl.py", line 43, in run
spider = self.crawler.spiders.create(spname, **opts.spargs)
File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.15.1-py2.7.egg/scrapy/spidermanager.py", line 43, in create
raise KeyError("Spider not found: %s" % spider_name)
KeyError: 'Spider not found: fb_spider'

Which is not very descriptive.

Now showing details about the exception when ImportError was raises

==

scrapy/utils/project.py
==================
99bfd1e5;Pablo Hoffman;2012-07-04 04:36:16 -0700;Merge pull request #154 from vially/patch-1
Fix typo in tutorial
==
==================
00bfb37e;Valentin-Costel Hăloiu;2012-07-04 06:55:01 +0300;Update master

==

docs/intro/tutorial.rst
==================
a40090a6;Daniel Graña;2012-06-29 05:37:24 -0700;Merge pull request #151 from msabramo/tox
Add support for tox (http://tox.testrun.org/)
==
==================
61952c3b;Marc Abramowitz;2012-06-28 12:43:33 -0700;Add .tox to .gitignore

==

.gitignore
==================
9ae8ea96;Marc Abramowitz;2012-06-28 12:43:12 -0700;Add tox.ini for tox (http://tox.testrun.org/)

==

tox.ini
==================
277ed0ae;Daniel Graña;2012-06-25 11:29:04 -0700;Merge pull request #145 from alexcepoi/cookies-changes
domain and path support for request cookies
==
==================
8b30575d;Pablo Hoffman;2012-06-25 11:27:13 -0700;Merge pull request #147 from tonal/cfg-jsons
Configure json services members
==
==================
177c8174;Alexandru Cepoi;2012-06-18 02:10:43 +0200;domain and path support for request cookies

==

docs/topics/request-response.rst
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/tests/test_downloadermiddleware_cookies.py
==================
cf968c32;Alexandr N Zamaraev (aka tonal);2012-06-25 12:50:48 +0700;Configure json services members

==

scrapyd/config.py
scrapyd/default_scrapyd.conf
scrapyd/website.py
==================
179e3810;Pablo Hoffman;2012-06-24 01:00:33 -0300;fixed links to doc. closes #150

==

docs/topics/selectors.rst
scrapy/telnet.py
scrapyd/website.py
==================
700f20b2;Pablo Hoffman;2012-06-22 17:50:40 -0700;Merge pull request #149 from alexcepoi/parse-changes
documentation for `parse` command, debugging spiders section
==
==================
2e05cf56;Alexandru Cepoi;2012-06-21 20:06:50 +0200;fix small bug with parse command

==

scrapy/commands/parse.py
==================
f4faa19e;Alexandru Cepoi;2012-06-21 20:03:33 +0200;added docs topic debugging spiders

==

docs/index.rst
docs/topics/debug.rst
==================
4eeda53b;Pablo Hoffman;2012-06-19 08:14:58 -0700;Merge pull request #148 from tonal/cfg-launcher
Add launcher class to config
==
==================
3bddedfc;Alexandr N Zamaraev (aka tonal);2012-06-14 12:45:42 +0700;Add launcher class to config

==

scrapyd/app.py
scrapyd/default_scrapyd.conf
==================
27689009;Daniel Graña;2012-06-18 11:50:43 -0300;fix urlparse monkeypatches for python 2.7.4. closes #144

==

scrapy/xlib/urlparse_monkeypatches.py
==================
3e05a2ec;Alexandru Cepoi;2012-06-12 18:28:10 +0200;update docs for parse command

==

docs/topics/commands.rst
==================
e1be9c01;Pablo Hoffman;2012-06-08 18:33:53 -0300;updated FAQ about bot bans

==

docs/faq.rst
==================
3d6edc2f;Daniel Graña;2012-06-07 07:52:27 -0700;Merge pull request #135 from alexcepoi/parse-changes
Add --depth option to parse
==
==================
3b5cf311;Alexandru Cepoi;2012-05-24 16:35:09 +0200;add --verbose option to parse command

==

scrapy/commands/parse.py
==================
8e3c5f1b;Alexandru Cepoi;2012-05-24 15:10:03 +0200;add --depth field to parse command

==

scrapy/commands/parse.py
==================
8d770050;Pablo Hoffman;2012-05-22 19:14:55 -0300;scrapy shell: start shell in main thread and crawler in secondary thread, instead of the other way around. fixes #100

==

scrapy/commands/shell.py
scrapy/shell.py
==================
b3330377;Pablo Hoffman;2012-05-21 14:29:15 -0300;scrapyd.launcher: make SCRAPY_LOG_FILE and SCRAPY_FEED_URI optional

==

scrapyd/launcher.py
==================
35ef7de5;Daniel Graña;2012-05-17 09:07:36 -0300;add travis-ci build status to README

==

README.rst
==================
e77e4b5f;Daniel Graña;2012-05-17 09:03:28 -0300;add precise to travis-ci build enviroments

==

.travis.yml
.travis/requirements-precise.txt
==================
3096e464;Daniel Graña;2012-05-17 08:53:18 -0300;add requirements file per travis env

==

.travis/requirements-latest.txt
.travis/requirements-lucid.txt
==================
7740581f;Daniel Graña;2012-05-17 08:50:28 -0300;Merge remote-tracking branch 'upstream/master'

==
==================
c3a31087;Daniel Graña;2012-05-17 08:49:45 -0300;multiple build enviroments for travis-ci

==

.travis.yml
==================
1bc18434;Pablo Hoffman;2012-05-17 01:09:25 -0300;removed obsolete entries from MANIFEST.in

==

MANIFEST.in
==================
7fc573a2;Daniel Graña;2012-05-16 18:54:02 -0300;fix libxml2 test

==

scrapy/tests/test_libxml2.py
==================
f530b0b3;Daniel Graña;2012-05-16 18:17:51 -0300;make libxml2 optional now that lxml is the default

==

scrapy/__init__.py
scrapy/selector/libxml2document.py
scrapy/selector/libxml2sel.py
scrapy/tests/test_libxml2.py
scrapy/tests/test_selector_libxml2.py
==================
8376d95c;Daniel Graña;2012-05-16 16:54:12 -0300;add travis-ci build configuration file

==

.travis.yml
==================
b4f368c3;Pablo Hoffman;2012-05-16 13:12:25 -0300;warn if Link objects are instantiated with unicode urls

==

scrapy/link.py
scrapy/tests/test_link.py
==================
30b6c77c;Pablo Hoffman;2012-05-16 09:16:46 -0300;fixed typo in previous commit

==

scrapy/commands/version.py
==================
b53bc66c;Pablo Hoffman;2012-05-16 09:12:02 -0300;added lxml/libxml2 versions to 'scrapy version' output

==

scrapy/commands/version.py
==================
d74a0672;Daniel Graña;2012-05-15 17:11:51 -0300;require w3lib 1.2 or greater

==

debian/control
setup.py
==================
ae2ff4d3;Daniel Graña;2012-05-15 16:16:02 -0300;update news file with 0.14.4 release notes

==

docs/news.rst
==================
9686f972;Pablo Hoffman;2012-05-12 19:54:36 -0300;added precise to supported ubuntu distros

==

docs/topics/ubuntu.rst
==================
58e88ed2;Pablo Hoffman;2012-05-08 17:43:00 -0300;scrapyd: do not set SCRAPY_FEED_URI/SCRAPY_LOG_FILE if items_dir/logs_dir settings are not set

==

docs/topics/scrapyd.rst
scrapyd/environ.py
scrapyd/tests/test_environ.py
==================
43732e50;Daniel Graña;2012-05-07 10:38:49 -0700;Merge pull request #129 from saxicek/master
ImagesPipeline should not fail if Item['images'] is not defined.
==
==================
69078368;Daniel Graña;2012-05-07 08:37:36 -0700;Merge pull request #130 from alexcepoi/lxml-fixes
fix `tail` issue when extracting nodes [lxml]
==
==================
045ff8e5;Alexandru Cepoi;2012-05-07 17:23:27 +0200;fix `tail` issue when extracting nodes [lxml]

==

scrapy/selector/lxmlsel.py
scrapy/tests/test_selector.py
==================
2b93b0a9;Libor Nenadl;2012-05-05 14:53:02 +0200;Do not try to set item['images'] if it is not defined in the Item.

==

scrapy/contrib/pipeline/images.py
==================
43028876;Daniel Graña;2012-05-03 10:27:11 -0700;Merge pull request #128 from dangra/cannonicalize-missing-url-path
handle missing paths in urls as /
==
==================
72b1c2e8;Daniel Graña;2012-05-03 13:36:04 -0300;handle missing paths in urls as /

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
9c3b9f29;Pablo Hoffman;2012-05-03 12:05:40 -0300;fixed bug in json-rpc webservice reported in https://groups.google.com/d/topic/scrapy-users/qgVBmFybNAQ/discussion. also removed no longer supported 'run' command from extras/scrapy-ws.py

==

docs/topics/webservice.rst
extras/scrapy-ws.py
scrapy/webservice.py
==================
abcac4fc;Pablo Hoffman;2012-05-02 03:25:35 -0300;updated maintainer to scrapinghub

==

AUTHORS
debian/changelog
debian/control
debian/copyright
docs/conf.py
docs/topics/ubuntu.rst
extras/makedeb.py
==================
2681be59;Daniel Graña;2012-04-30 12:16:45 -0700;Merge pull request #127 from stav/master
scrapy.contrib.spiders.Rule documentation indentation
==
==================
86dba76d;stav;2012-04-30 13:09:34 -0500;documentation indentation

==

docs/topics/spiders.rst
==================
f5b87dbe;Pablo Hoffman;2012-04-28 23:32:51 -0300;added NEWS file pointing to docs/news.rst

==

NEWS
==================
78185921;Pablo Hoffman;2012-04-28 23:03:16 -0300;renamed and improved README to provide a more helpful github landing page

==

MANIFEST.in
README
README.rst
debian/scrapy.docs
setup.cfg
==================
9d66d7cd;Daniel Graña;2012-04-27 00:31:03 -0300;be consistent removing BOM from decoded bodies. #123

==

scrapy/http/response/text.py
scrapy/tests/test_http_response.py
==================
8cae228d;Daniel Graña;2012-04-25 16:12:48 -0300;do not treat input type "image" as form input. #111

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
5b9a7814;Daniel Graña;2012-04-25 16:04:37 -0300;support TextResponse in open_in_browser util

==

scrapy/utils/response.py
==================
7865fbf0;Pablo Hoffman;2012-04-20 19:04:44 -0300;replace "import Image" by more standard "from PIL import Image". closes #88

==

scrapy/contrib/pipeline/images.py
scrapy/tests/test_pipeline_images.py
==================
66de3d17;Daniel Graña;2012-04-20 16:40:55 -0300;return trial status as bin/runtests.sh exit value. #118

==

bin/runtests.sh
==================
db99ae39;Daniel Graña;2012-04-20 16:39:50 -0300;test more border cases for formrequest

==

scrapy/tests/test_http_request.py
==================
28401fd4;Daniel Graña;2012-04-20 09:32:43 -0300;Merge dev.scrapinghub.com:~/src/scrapy

==
==================
29d6bcf0;Daniel Graña;2012-04-20 12:24:30 +0000;Workaround bug in lxml for multiple select options
In lxml version pre 2.3.1 there is a bug that returns
all options elements instead of those selected for select tag

it is mentioned in 2.3.1 release notes
http://lxml.de/2.3/changes-2.3.1.html

and fixed by
https://github.com/lxml/lxml/commit/57f49eed82068a20da3db8f1b18ae00c1bab8b12#L1R1139

==

scrapy/http/request/form.py
==================
c7f33c53;Pablo Hoffman;2012-04-20 09:09:55 -0300;removed redundant lines from release notes

==

docs/news.rst
==================
15c8c018;Daniel Graña;2012-04-19 23:25:15 -0300;add 0.14.3 release notes

==

docs/news.rst
==================
f34dd11c;Daniel Graña;2012-04-19 22:49:47 -0300;forgot to include pydispatch license. #118

==

MANIFEST.in
==================
771abd57;Daniel Graña;2012-04-19 22:38:45 -0300;include egg files used by testsuite in source distribution. #118

==

MANIFEST.in
==================
8b45a00f;Daniel Graña;2012-04-19 17:10:29 -0300;Merge dangra/lxml-formrequest

==
==================
72485128;Daniel Graña;2012-04-19 16:58:01 -0300;Add a test case to cover input elements as not direct child of form element. #111 #121

==

scrapy/tests/test_http_request.py
==================
3b2458db;Daniel Graña;2012-04-19 16:48:02 -0300;cleanup all FormRequest test cases. #111 #121

==

scrapy/tests/test_http_request.py
==================
4340a13d;Daniel Graña;2012-04-19 16:17:34 -0300;More lxml FormRequest fixes. #111 #121
* test textarea elements
* handle odd cases for select elements like chrome and FF browsers does
* Remove test case already covered by per tag test cases

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
84d5f5ea;Daniel Graña;2012-04-19 15:40:07 -0300;test and fix each form input type with border cases. #111 #121

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
63e4355f;Daniel Graña;2012-04-19 14:10:55 -0300;find form input elements using one xpath #111 #121

==

scrapy/http/request/form.py
==================
5c03c1df;Daniel Graña;2012-04-19 08:18:02 -0700;Merge pull request #121 from artem-dev/master
fix FormRequest for case when a form values are missed
==
==================
97f362d6;Pablo Hoffman;2012-04-19 12:07:46 -0300;removed deprecated/undocumented class: HTMLImageLinkExtractor

==

docs/news.rst
scrapy/contrib/linkextractors/image.py
scrapy/tests/sample_data/link_extractor/image_linkextractor.html
scrapy/tests/test_contrib_linkextractors.py
==================
3a7c28f1;Artem Bogomyagkov;2012-04-19 18:07:38 +0300;fixed FormRequest for a form missed values case

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
13ac6f63;Pablo Hoffman;2012-04-19 07:56:38 -0700;Merge pull request #119 from andrix/fix-htmlimagelinkextractor
Fix HTMLImageLinkExtractor to work with libxml2 and lxml selectors
==
==================
1e521a3f;Pablo Hoffman;2012-04-19 02:54:57 -0300;improved command line tool usage help which explains that more commands are available when run from project directory. refs #107

==

scrapy/cmdline.py
==================
2fb5e62c;Pablo Hoffman;2012-04-19 02:37:22 -0300;doc: update overview page to point to the genspider command. refs #107

==

docs/intro/overview.rst
docs/intro/tutorial.rst
==================
1c5294be;Pablo Hoffman;2012-04-19 02:15:30 -0300;update docstring in project template to avoid confusion with genspider command, which may be considered as an advanced feature. refs #107

==

scrapy/templates/project/module/spiders/__init__.py
==================
d567d8ef;Pablo Hoffman;2012-04-19 01:33:02 -0300;added note to docs/topics/firebug.rst about google directory being shut down

==

docs/contributing.rst
docs/topics/firebug.rst
==================
21e03729;Daniel Graña;2012-04-19 00:28:27 -0300;lxml is the new default selector backend. closes #120

==

scrapy/selector/__init__.py
==================
6bb40fe5;Daniel Graña;2012-04-19 00:03:04 -0300;use xpath to match img tags in one shot. #119

==

scrapy/contrib/linkextractors/image.py
==================
e24107fe;Andrés Moreira;2012-04-18 18:05:44 -0300;fix HTMLImageLinkExtractor to work with libxml2 and lxml selectors

==

scrapy/contrib/linkextractors/image.py
scrapy/tests/test_contrib_linkextractors.py
==================
30ddbf62;Pablo Hoffman;2012-04-17 12:31:18 -0300;mention about some scrapy.xlib modules removed in the release notes

==

docs/news.rst
==================
d99ee6de;Pablo Hoffman;2012-04-17 12:29:48 -0300;added some missing entries to release notes

==

docs/news.rst
==================
60ee5d62;Daniel Graña;2012-04-15 00:47:39 -0300;Merge branch 'lxml-formrequest'

==
==================
5b0df465;Daniel Graña;2012-04-15 00:47:30 -0300;SELECT matched as form inputs but hasnot type attribute. #111

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
150e5734;Daniel Graña;2012-04-13 12:29:04 -0700;Merge pull request #111 from LucianU/lxml-formrequest
Lxml formrequest
==
==================
39395eb4;Daniel Graña;2012-04-13 16:22:25 -0300;iteritems returns tuple elements duh!. #111

==

scrapy/http/request/form.py
==================
b88bdd05;Daniel Graña;2012-04-13 16:20:35 -0300;do not add clickable if it is in formdata. #111

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
51e5aadd;Daniel Graña;2012-04-13 16:07:27 -0300;simplify formdata type infering. #111

==

scrapy/http/request/form.py
==================
a11ef7fb;Daniel Graña;2012-04-13 15:41:58 -0300;reuse LxmlDocument in FormRequest. #111

==

scrapy/http/request/form.py
scrapy/selector/lxmldocument.py
==================
9e10abcc;Daniel Graña;2012-04-13 14:50:49 -0300;Merge branch 'master' into lxml-formrequest

==
==================
1789a55f;Daniel Graña;2012-04-13 10:49:35 -0700;Merge pull request #117 from dangra/lxml-document
Lxml document
==
==================
4c7d29b7;Daniel Graña;2012-04-13 14:43:30 -0300;Cache response's element trees using LxmlDocument similar to Libxml2Document

==

scrapy/selector/lxmldocument.py
scrapy/selector/lxmlsel.py
scrapy/tests/test_selector_lxml.py
==================
ac4f6cc1;Daniel Graña;2012-04-13 13:54:48 -0300;unify libxml2 document and factories

==

scrapy/selector/document.py
scrapy/selector/factories.py
scrapy/selector/libxml2document.py
scrapy/selector/libxml2sel.py
scrapy/tests/test_selector_libxml2.py
==================
2904dc2d;Daniel Graña;2012-04-13 13:28:16 -0300;no need for MultipleElementsFound exception. #111

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
ee1f7847;Daniel Graña;2012-04-13 12:12:33 -0300;more lxml form fixes and test cases. #111
* Do not treat "coord" attribute specially, just pass "NN,NN" as clickdata value
* Raise explicit ValueError if not clickable is found
* Fix bug looking for clickeables trough xpath when there is more than one form
* Test from_response with multiple clickdata

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
32b9f788;Daniel Graña;2012-04-13 10:52:39 -0300;lxml form request cleanup. #111
* remove unused _nons function copied from lxml.html
* compute clickables only if dont_click is False
* less _get_clickables function branch nesting

==

scrapy/http/request/form.py
==================
e4d22cb1;Daniel Graña;2012-04-13 10:31:59 -0300;reuse form_values() method from lxml to avoid copying code. #111

==

scrapy/http/request/form.py
==================
18a35a9f;Daniel Graña;2012-04-13 09:32:51 -0300;Merge branch 'lxml-selectors'

==
==================
3dbe211d;Daniel Graña;2012-04-13 09:29:56 -0300;lxml boolean results fix. oops #116

==

scrapy/selector/lxmlsel.py
scrapy/tests/test_selector.py
==================
a338c292;Daniel Graña;2012-04-13 04:38:45 -0700;Merge pull request #116 from dangra/lxml-selectors
more fixes to lxml selector incompatibilities
==
==================
b9efa5ee;Daniel Graña;2012-04-13 00:21:48 -0300;more fixes to lxml selector incompatibilities
* Do not fail parsing empty bodies
* Do not fail parsing bodies with null bytes
* Recode to utf8 using response.body_as_unicode() to avoid decoding bugs
* Return empty results with unevaluable nodes like text or attribute nodes
* Return u'1' and u'0' for boolean xpaths

==

scrapy/selector/lxmlsel.py
scrapy/tests/test_selector.py
==================
d8ebf16f;Daniel Graña;2012-04-11 12:08:45 -0700;Merge pull request #114 from stav/master
Scrapy DOC changes
==
==================
7cca916e;Pablo Hoffman;2012-04-11 15:53:23 -0300;added release notes to official documentation, including all release notes since Scrapy 0.7

==

docs/_ext/scrapydocs.py
docs/index.rst
docs/news.rst
==================
c760cc5c;Lucian Ursu;2012-04-11 21:40:00 +0300;Copied lxml.html._nons to not rely on that module's private interface and took out check out of the for loop because it can be done only once

==

scrapy/http/request/form.py
==================
f13a5472;Lucian Ursu;2012-04-11 21:08:43 +0300;Removed unnecessary iteration of formdata items

==

scrapy/http/request/form.py
==================
f1802289;stav;2012-04-11 12:05:39 -0500;small doc typo change to get the fork rolling

==

docs/topics/spider-middleware.rst
==================
02833e32;Daniel Graña;2012-04-11 10:44:31 -0300;fix typo in module description. closes #112

==

scrapy/utils/signal.py
==================
a0a1a502;Daniel Graña;2012-04-11 10:07:34 -0300;do formdata encoding and serialization in one place. refs #111

==

scrapy/http/request/form.py
==================
4f28ffcb;Pablo Hoffman;2012-04-10 16:01:36 -0300;removed no longer needed dependency on simplejson

==

docs/intro/install.rst
scrapy/utils/serialize.py
setup.py
==================
6e8edbd7;Pablo Hoffman;2012-04-10 15:52:14 -0300;switched default selectors backend to lxml

==

debian/control
docs/intro/install.rst
scrapy/selector/__init__.py
setup.py
==================
af0e1c40;Daniel Graña;2012-04-10 13:36:52 -0300;Avoid logging useless error messages about ignored requests in robots.txt

==

scrapy/core/scraper.py
==================
4be6c22c;Lucian Ursu;2012-04-10 10:24:30 +0300;Removed ClientForm with its patch and tests, and BeautifulSoup

==

scrapy/tests/test_clientform.py
scrapy/xlib/BeautifulSoup.py
scrapy/xlib/ClientForm.patch
scrapy/xlib/ClientForm.py
==================
df2e7952;Lucian Ursu;2012-04-10 10:19:59 +0300;Added test case to make sure that ambiguous clickdata is not allowed

==

scrapy/tests/test_http_request.py
==================
eb47849c;Lucian Ursu;2012-04-10 10:18:54 +0300;Replaced ClientForm-based FormRequest with a lxml-based implementation

==

scrapy/http/request/form.py
==================
97e4003a;Daniel Graña;2012-04-04 16:17:18 -0300;do not fail handling unicode xpaths in libxml2 backed selectors

==

scrapy/selector/libxml2sel.py
scrapy/tests/test_selector.py
==================
ab4dd928;Pablo Hoffman;2012-04-03 17:02:31 -0700;Merge pull request #108 from kalessin/throttleslot
Fix autothrottle in order to modify also inactive downloader slots, so c...
==
==================
e6d7afa1;olveyra;2012-04-03 23:14:00 +0000;Fix autothrottle in order to modify also inactive downloader slots, so cases fixed by inactive slots patch will work ok also when using autothrottle

==

scrapy/contrib/throttle.py
==================
c27f7eb7;Pablo Hoffman;2012-04-02 14:39:38 -0700;Merge pull request #106 from kalessin/downloader2
dont discard slot when empty, just save in another dict in order to recycle if needed again
==
==================
b39cb22d;olveyra;2012-04-02 18:49:04 +0000;dont discard slot when empty, just save in another dict in order to recycle if needed again.
This fix avoids to continuosly create new slot under certain cases, bug that prevents download_delay and max_concurrent_requests to work properly.

The problem arises when the slot for a given domain becomes empty, but further requests for that domain werent still created by the spider. This is typical when spider creates requests one by one, or it makes requests to multiple domains and one or more of them are created in a rate enough slow that makes slot to be empty each time the response is fetched.

The effect is that a new slot is created for each request under such conditions, and so the download_delay and max_concurrent_requests are not taking effect (because in order to apply, depends on an already existing slot for that domain).

==

scrapy/core/downloader/__init__.py
==================
e9184def;Pablo Hoffman;2012-04-01 00:41:03 -0300;make selector re() method use re.UNICODE flag to compile regexes

==

scrapy/tests/test_selector.py
scrapy/utils/misc.py
==================
27018fce;Pablo Hoffman;2012-03-23 13:45:21 -0300;changed default user agent to Scrapy/0.15 (+http://scrapy.org) and removed no longer needed BOT_VERSION setting

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
scrapy/templates/project/module/settings.py.tmpl
==================
731c569b;Pablo Hoffman;2012-03-22 16:38:28 -0300;fixed test-scrapyd.sh script after changed on insophia website

==

extras/test-scrapyd.sh
==================
8933e2f2;Pablo Hoffman;2012-03-22 16:35:14 -0300;added REFERER_ENABLED setting, to control referer middleware

==

docs/topics/spider-middleware.rst
scrapy/contrib/spidermiddleware/referer.py
scrapy/settings/default_settings.py
==================
eed34e88;Pablo Hoffman;2012-03-20 19:49:31 -0700;Merge pull request #103 from jsyeo/patch-1
fixed minor mistake in Request objects documentation
==
==================
da826aa1;Jason Yeo;2012-03-21 10:25:41 +0800;fixed minor mistake in Request objects documentation

==

docs/topics/request-response.rst
==================
175c70ad;Pablo Hoffman;2012-03-20 22:56:45 -0300;fixed minor defect in link extractors documentation

==

docs/topics/link-extractors.rst
==================
056a7c53;Pablo Hoffman;2012-03-20 10:46:45 -0300;added artwork files properly now

==

artwork/qlassik.zip
artwork/scrapy-blog-logo.xcf
artwork/scrapy-logo.jpg
==================
aef70e83;Pablo Hoffman;2012-03-20 10:45:48 -0300;removed wrongly added artwork files

==

artwork/qlassik.zip
artwork/scrapy-blog-logo.xcf
artwork/scrapy-logo.jpg
==================
bcd8520f;Pablo Hoffman;2012-03-20 10:15:00 -0300;added sep directory with Scrapy Enhancement Proposal imported from old Trac site

==

sep/README
sep/sep-001.trac
sep/sep-002.trac
sep/sep-003.trac
sep/sep-004.trac
sep/sep-005.trac
sep/sep-006.trac
sep/sep-007.trac
sep/sep-008.trac
sep/sep-009.trac
sep/sep-010.trac
sep/sep-011.trac
sep/sep-012.trac
sep/sep-013.trac
sep/sep-014.trac
sep/sep-015.trac
sep/sep-016.trac
sep/sep-017.trac
sep/sep-018.trac
==================
c0141d15;Pablo Hoffman;2012-03-20 10:14:11 -0300;added artwork directory (data taken from old Trac)

==

artwork/README
artwork/qlassik.zip
artwork/scrapy-blog-logo.xcf
artwork/scrapy-logo.jpg
==================
35fb0115;Pablo Hoffman;2012-03-16 11:55:55 -0300;removed some obsolete remaining code related to sqlite support in scrapy

==

docs/topics/commands.rst
docs/topics/settings.rst
scrapy/settings/default_settings.py
scrapyd/environ.py
scrapyd/tests/test_environ.py
==================
838e1dcc;Pablo Hoffman;2012-03-15 11:47:02 -0300;updated FormRequest tests to use HtmlResponse instead of Response, as it makes more sense

==

scrapy/tests/test_http_request.py
==================
b6ae2665;Pablo Hoffman;2012-03-15 00:28:13 -0300;Removed (very old and possibly broken) backwards compatibility support for Twisted 2.5

==

docs/intro/install.rst
scrapy/__init__.py
scrapy/xlib/twisted_250_monkeypatches.py
setup.py
==================
9fddc73e;Pablo Hoffman;2012-03-06 05:42:09 -0200;removed backwards compatibility code for old scrapy versions

==

scrapy/cmdline.py
scrapy/contrib/exporter/jsonlines.py
scrapy/log.py
==================
9a508d46;Pablo Hoffman;2012-03-01 09:46:14 -0200;Removed deprecated setting: CLOSESPIDER_ITEMPASSED

==

scrapy/contrib/closespider.py
==================
8b831776;Pablo Hoffman;2012-03-01 09:45:25 -0200;Added CLOSESPIDER_ERRORCOUNT to scrapy/default_settings.py

==

scrapy/settings/default_settings.py
==================
90062273;Pablo Hoffman;2012-03-05 20:25:38 -0200;bumped required python-w3lib version in debian/control

==

debian/control
==================
2909a60e;Daniel Graña;2012-03-05 17:49:57 -0200;test that default start_request return value type is a generator. refs #98

==

scrapy/tests/test_spider.py
==================
45685ea6;Pablo Hoffman;2012-03-05 17:15:49 -0200;Restored scrapy.utils.py26 module for backwards compatibility, with a deprecation message. This is needed because the module was used a lot by users and the change causes too much trouble

==

scrapy/utils/py26.py
==================
cc6e2970;Daniel Graña;2012-03-05 08:51:22 -0800;Merge pull request #98 from kalessin/start_requests
This will break any spider that extends `start_requests` and expect a `list` as return value.

In the other side:

* [Docs](http://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spider.BaseSpider.start_requests) says that return value is **iterable** not list: 
* Scrapy core already support consuming start_requests generator on demand so we can avoid problems like #47
* it allows extensions to change starting requests on `spider_opened` signal
==
==================
f6179a92;Martin Olveyra;2012-03-05 14:25:12 -0200;replace list by generator also in start_requests method of Sitemap spider

==

scrapy/contrib/spiders/sitemap.py
==================
cc7fc338;Martin Olveyra;2012-03-05 12:49:17 -0200;change  start_request to return a generator instead of a list, in order to allow to modify start_urls triggered by spider_opened signal

==

scrapy/spider.py
==================
e521da2e;Pablo Hoffman;2012-03-01 08:18:12 -0200;Dropped support for Python 2.5. See: http://blog.scrapy.org/scrapy-dropping-support-for-python-25

==

docs/faq.rst
docs/intro/install.rst
extras/scrapy-ws.py
scrapy/__init__.py
scrapy/cmdline.py
scrapy/command.py
scrapy/commands/deploy.py
scrapy/commands/startproject.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/exporter/__init__.py
scrapy/contrib/httpcache.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/spiderstate.py
scrapy/core/scheduler.py
scrapy/responsetypes.py
scrapy/tests/test_commands.py
scrapy/tests/test_contrib_exporter.py
scrapy/tests/test_downloadermiddleware_cookies.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_spider.py
scrapy/tests/test_utils_gz.py
scrapy/tests/test_utils_jsonrpc.py
scrapy/tests/test_utils_serialize.py
scrapy/utils/jsonrpc.py
scrapy/utils/memory.py
scrapy/utils/py26.py
scrapy/utils/py27.py
scrapy/utils/python.py
scrapy/utils/queue.py
scrapy/utils/serialize.py
scrapy/utils/template.py
scrapy/utils/txweb.py
scrapyd/config.py
scrapyd/eggstorage.py
scrapyd/launcher.py
scrapyd/runner.py
scrapyd/sqlite.py
scrapyd/tests/test_utils.py
setup.py
==================
8eb0b11f;Pablo Hoffman;2012-02-29 17:40:30 -0200;removed unused import

==

scrapy/contrib/spiderstate.py
==================
5c329b65;Pablo Hoffman;2012-02-29 01:45:59 -0800;Merge pull request #97 from scrapy/w3lib_encoding
Ported scrapy to use w3lib.encoding
==
==================
de3a3b68;Pablo Hoffman;2012-02-29 07:44:22 -0200;bumped required w3lib version to 1.1, after refactoring encoding detection to use the new w3lib.encoding module

==

setup.py
==================
2b16ebdc;Pablo Hoffman;2012-02-29 07:19:01 -0200;added minor clarification on cookiejar request meta key usage

==

docs/topics/downloader-middleware.rst
==================
61df6b46;Pablo Hoffman;2012-02-28 23:49:56 -0800;Merge pull request #51 from lostsnow/master
scrapyd: support bind to a specific ip address
==
==================
5afe4f50;lostsnow;2012-02-29 13:47:40 +0800;scrapyd: support bind to a specific ip address

==

docs/topics/scrapyd.rst
scrapyd/app.py
==================
79816980;Daniel Graña;2012-02-28 14:32:55 -0200;Adapt response encoding detection to pass test cases

==

scrapy/http/response/text.py
scrapy/tests/test_http_response.py
scrapy/utils/encoding.py
==================
81abb450;Pablo Hoffman;2012-02-28 11:08:25 -0200;fixed bug in new cookiejar documentation

==

docs/topics/downloader-middleware.rst
==================
26c80041;Pablo Hoffman;2012-02-27 19:58:58 -0200;added documentation for the new cookiejar Request.meta key

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
==================
44d6da82;Pablo Hoffman;2012-02-27 13:48:43 -0800;Merge pull request #96 from kalessin/cookiesmultijar
allow to work with multiple cookie jars on the same spider
==
==================
c093ac5e;olveyra;2012-02-27 18:03:48 +0000;allow to work with multiple cookie jars on the same spider

==

scrapy/contrib/downloadermiddleware/cookies.py
scrapy/tests/test_downloadermiddleware_cookies.py
==================
4ed1a035;Pablo Hoffman;2012-02-24 10:28:32 -0800;Merge pull request #95 from scrapy/openmobilealliance-mimetype
Handle as html standard mimetype defined by Open Mobile Alliance
==
==================
049f315f;Daniel Graña;2012-02-24 16:16:35 -0200;Handle as html standard mimetype defined by Open Mobile Alliance

==

scrapy/responsetypes.py
scrapy/tests/test_responsetypes.py
==================
b1f011d7;Pablo Hoffman;2012-02-24 02:09:02 -0200;use netloc instead of hostname in url_is_from_any_domain(). closes #50

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
08d2c2b9;Daniel Graña;2012-02-23 19:25:28 -0200;Merge branch 'GH92-image-buf-threading'

==
==================
2dbf2a38;Daniel Graña;2012-02-23 19:23:37 -0200;move buffer pointing to start of file before computing checksum. refs #92

==

scrapy/contrib/pipeline/images.py
==================
e0de5f3e;Pablo Hoffman;2012-02-23 13:21:10 -0800;Merge pull request #93 from dangra/GH92-image-buf-threading
compute image checksum before persisting images
==
==================
3286ce4f;Daniel Graña;2012-02-23 17:47:44 -0200;Compute image checksum before persisting images. closes #92
Avoids threading issue accesing buffer

==

scrapy/contrib/pipeline/images.py
==================
52483c55;Pablo Hoffman;2012-02-23 13:11:29 -0800;Merge pull request #94 from dangra/mediapipeline-cache-failures
remove as much information as possible from cached failure
==
==================
5c73a0b1;Daniel Graña;2012-02-23 17:40:32 -0200;remove leaking references in cached failures

==

scrapy/contrib/pipeline/media.py
==================
e312a885;Pablo Hoffman;2012-02-23 17:42:02 -0200;MemoryUsage: use resident memory size (instead of virtual) for tracking memory usage

==

scrapy/contrib/memusage.py
==================
7fe7c3f3;Pablo Hoffman;2012-02-23 16:55:06 -0200;MemoryUsage extension: close the spiders (instead of stopping the engine) when the limit is exceeded, providing a descriptive reason for the close. Also fixed default value of MEMUSAGE_ENABLED setting to match the documentation.

==

docs/topics/extensions.rst
scrapy/contrib/memusage.py
scrapy/settings/default_settings.py
==================
c476681c;Pablo Hoffman;2012-02-21 21:31:19 -0200;ported to code to use w3lib.encoding (work in progress, many tests failing yet)

==

scrapy/http/response/dammit.py
scrapy/http/response/html.py
scrapy/http/response/text.py
scrapy/http/response/xml.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_http_response.py
scrapy/tests/test_utils_encoding.py
scrapy/utils/encoding.py
==================
6769b924;Pablo Hoffman;2012-02-19 05:59:30 -0200;Merge branch 'master' of github.com:scrapy/scrapy

==
==================
09391068;Pablo Hoffman;2012-02-19 05:59:21 -0200;fixed bug in MemoryUsage extension: get_engine_status() takes exactly 1 argument (0 given)

==

scrapy/contrib/memusage.py
==================
5b0f10e7;Daniel Graña;2012-02-17 11:12:41 -0800;Merge pull request #90 from kalessin/master
identify autothrottle debug mode stats with slot key, in order to allow to track concurrency/delay issues with spiders which crawls more than one site.
==
==================
b094cd4c;Martin Olveyra;2012-02-17 16:53:48 -0200;identify autothrottle debug mode stats with slot key, in order to allow to track concurrency/delay issues with spiders which crawls more than one site.

==

scrapy/contrib/throttle.py
==================
7b8942a6;Pablo Hoffman;2012-02-16 15:14:17 -0200;updated StackTraceDump extension doc

==

docs/topics/extensions.rst
==================
fe2ce938;Pablo Hoffman;2012-02-16 14:57:49 -0200;also dump (scrapy.utils.trackref) live references in StackTraceDump extension

==

scrapy/contrib/debug.py
==================
900bf08f;Pablo Hoffman;2012-02-11 20:28:09 -0200;fixed struct.error on http compression middleware. closes #87

==

scrapy/utils/gz.py
==================
acf69dac;Daniel Graña;2012-02-07 14:44:06 -0200;ajax crawling wasn't expanding for unicode urls

==

scrapy/http/request/__init__.py
scrapy/tests/test_http_request.py
==================
2e18f0db;Daniel Graña;2012-01-27 17:41:38 -0200;Catch start_requests iterator errors. refs #83

==

scrapy/core/engine.py
==================
7201d074;Daniel Graña;2012-01-25 19:17:26 -0200;Merge branch 'issue82'

==
==================
eb8e9846;Daniel Graña;2012-01-25 19:15:59 -0200;Add some comments and references to github issues. closes #82

==

scrapy/core/downloader/webclient.py
==================
28408657;Daniel Graña;2012-01-25 18:29:54 -0200;Allow overriding ClientContextFactory and enable SSL bug workarounds by default. refs #82

==

scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/webclient.py
scrapy/settings/default_settings.py
==================
a0f41f10;Pablo Hoffman;2012-01-16 12:24:04 -0800;Merge pull request #80 from kalessin/master
autothrottle code improvements (download delay + style)
==
==================
1c6a5a93;Martin Olveyra;2012-01-16 18:19:31 -0200;some minor improvements in autothrottle code style

==

scrapy/contrib/throttle.py
==================
59cf9d9b;Martin Olveyra;2012-01-16 18:16:24 -0200;allow to set minimal download delay for autothrottle extension. also limit download delay to a minimal of spider.download_delay if given

==

scrapy/contrib/throttle.py
==================
fc52d8d5;Pablo Hoffman;2012-01-15 19:32:59 -0800;Merge pull request #79 from seriyps/master
~10x speed-up for libxml2 XPathSelector
==
==================
a6a21207;Сергей Прохоров;2012-01-15 03:09:00 +0400;Speed-up libxml2 XPathSelector

==

scrapy/selector/libxml2sel.py
==================
85e2b493;Pablo Hoffman;2012-01-13 10:55:20 -0200;make scrapyd debian package dependent on the same (or higher) version of scrapy package

==

debian/control
==================
2ee523b1;Pablo Hoffman;2012-01-12 17:43:44 -0200;scrapyd: added Items link to completed jobs table

==

scrapyd/website.py
==================
8a45dd12;Pablo Hoffman;2012-01-12 17:17:50 -0200;scrapyd: fixed issue with ubuntu package: /var/lib/scrapyd/items dir not being created by default

==

debian/scrapyd-files/000-default
debian/scrapyd.dirs
debian/scrapyd.postinst
==================
e5bf6bf8;Shane Evans;2012-01-05 16:55:20 +0000;performance improvement to cookie handling when a single spider is crawling a large number of domains

==

scrapy/http/cookies.py
==================
ea77342b;Pablo Hoffman;2012-01-05 11:50:28 -0200;updated versioning doc according to recent changes

==

docs/versioning.rst
==================
0b0bce7f;Pablo Hoffman;2012-01-05 11:20:14 -0200;scrapyd: added cancel.json and listjobs.json api methods to documentation

==

docs/topics/scrapyd.rst
==================
8f42633a;Pablo Hoffman;2012-01-05 11:09:18 -0200;scrapyd: added clarification about how to disable items feeds generation

==

docs/topics/scrapyd.rst
==================
531fa95f;Pablo Hoffman;2012-01-03 23:13:56 -0200;scrapyd: removed redundant .scrapy component from paths when using scrapyd in 'scrapy server' mode

==

scrapyd/script.py
==================
dbda33ef;Pablo Hoffman;2012-01-03 22:56:26 -0200;scrapyd: added support for storing items by default
Items are stored the same way as logs, in jsonlines format.

Also renamed logs_to_keep setting to jobs_to_keep.

==

docs/topics/scrapyd.rst
scrapyd/default_scrapyd.conf
scrapyd/environ.py
scrapyd/launcher.py
scrapyd/script.py
scrapyd/tests/test_environ.py
scrapyd/website.py
==================
0693694b;Pablo Hoffman;2012-01-03 22:22:36 -0200;scrapyd: fixed documentation link

==

scrapyd/website.py
==================
485bc180;Pablo Hoffman;2012-01-03 22:21:26 -0200;scrapyd: improved web interface to also show pending and finished jobs

==

scrapyd/launcher.py
scrapyd/website.py
==================
f07e968a;Pablo Hoffman;2012-01-03 21:59:03 -0200;scrapyd: added new cancel.json api to cancel pending/running jobs

==

scrapyd/interfaces.py
scrapyd/spiderqueue.py
scrapyd/sqlite.py
scrapyd/tests/test_sqlite.py
scrapyd/webservice.py
scrapyd/website.py
==================
10ed28b9;Pablo Hoffman;2012-01-03 12:17:17 -0200;SitemapSpider: added support for sitemap urls ending in .xml and .xml.gz, even if they have a wrong content type

==

scrapy/contrib/spiders/sitemap.py
scrapy/tests/test_spider.py
scrapy/utils/gz.py
==================
fb44f303;Pablo Hoffman;2012-01-02 13:28:24 -0200;extras/makedeb.py: no longer obtaining version from git

==

extras/makedeb.py
==================
db92bc8c;Pablo Hoffman;2012-01-02 13:07:15 -0200;bumped version to 0.15.1, mainly to avoid package upgrade issues with new versioning based on git describe

==

scrapy/__init__.py
==================
b6220b8e;Pablo Hoffman;2012-01-02 13:05:26 -0200;use git describe for building version from git, and removed support for building version from hg

==

setup.py
==================
1f87d7ff;Pablo Hoffman;2012-01-01 09:30:31 -0800;Merge pull request #75 from darkrho/httpcache-stats
tests: fixed httpcache testcase.
==
==================
93eb5b32;Rolando Espinoza La fuente;2011-12-30 23:10:44 -0400;tests: fixed httpcache testcase.

==

scrapy/tests/test_downloadermiddleware_httpcache.py
==================
a36c8691;Pablo Hoffman;2011-12-30 18:15:43 -0800;Merge pull request #74 from darkrho/httpcache-stats
httpcache: keep stats of cache hit/miss/store and don't store already cached response
==
==================
503fdf39;Rolando Espinoza La fuente;2011-12-30 14:21:07 -0400;httpcache: don't store already cached response.

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
f2966eeb;Rolando Espinoza La fuente;2011-12-30 14:04:16 -0400;httpcache: keep stats of cache hit/miss/store.

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
90641880;Pablo Hoffman;2011-12-28 15:21:10 -0200;removed unused import

==

scrapyd/launcher.py
==================
150f82e6;Pablo Hoffman;2011-12-28 15:17:52 -0200;some some changes to scrapyd listjobs.json api:
* the api is now a GET instead of POST (for consistency)
* the api also returns pending and finished jobs, in addition to running
  ones
* only the last 100 finished jobs are kept (can be changed through the
  finished_to_keep setting)

==

scrapyd/default_scrapyd.conf
scrapyd/launcher.py
scrapyd/webservice.py
==================
1dfbe5d7;Pablo Hoffman;2011-12-28 14:36:24 -0200;scrapyd.webservice: relocate ListJobs resource for better consistency

==

scrapyd/webservice.py
==================
f214c949;Pablo Hoffman;2011-12-27 21:22:38 -0200;CrawlSpider: don't follow links from non-HTML responses

==

scrapy/contrib/spiders/crawl.py
==================
bda9c97c;Pablo Hoffman;2011-12-23 13:17:00 -0800;Merge pull request #48 from simonratner/delete-logs-by-mtime
Delete old logs based on file mtime.
==
==================
0be421fb;Pablo Hoffman;2011-12-23 18:57:11 -0200;fixed reference to tutorial directory

==

docs/intro/tutorial.rst
==================
41fd3c4f;Pablo Hoffman;2011-12-23 15:55:46 -0200;doc: removed duplicated callback argument from Request.replace()

==

docs/topics/request-response.rst
==================
0eeff762;Pablo Hoffman;2011-12-20 03:18:37 -0200;fixed formatting of scrapyd doc

==

docs/topics/scrapyd.rst
==================
64ba6e79;Daniel Graña;2011-12-15 17:05:07 -0200;Dump stacks for all running threads and fix engine status dumped by StackTraceDump extension

==

scrapy/contrib/debug.py
==================
023232f7;Pablo Hoffman;2011-12-15 14:23:45 -0200;added comment about why we disable ssl on boto images upload

==

scrapy/contrib/pipeline/images.py
==================
aea060e1;Daniel Graña;2011-12-14 13:09:00 -0200;Merge branch '0.14'

==
==================
63d583d9;Daniel Graña;2011-12-08 13:54:16 -0200;SSL handshaking hangs when doing too many parallel connections to S3

==

scrapy/contrib/pipeline/images.py
==================
bcb31988;Daniel Graña;2011-11-09 09:50:59 -0200;change tutorial to follow changes on dmoz site

==

docs/intro/tutorial.rst
==================
98f3f875;Rolando Espinoza La fuente;2011-12-04 23:42:41 -0400;Avoid _disconnectedDeferred AttributeError exception in Twisted>=11.1.0

==

scrapy/core/downloader/webclient.py
==================
9b849147;Pablo Hoffman;2011-12-12 10:10:08 -0800;Merge pull request #62 from darkrho/issue-58
Avoid _disconnectedDeferred AttributeError exception in Twisted>=11.1.0
==
==================
9c049457;Rolando Espinoza La fuente;2011-12-04 23:42:41 -0400;Avoid _disconnectedDeferred AttributeError exception in Twisted>=11.1.0

==

scrapy/core/downloader/webclient.py
==================
175a4b59;Martin Olveyra;2011-12-01 18:44:26 -0200;allow spider to set autothrottle max concurrency

==

scrapy/contrib/throttle.py
==================
4fe42dc6;Pablo Hoffman;2011-12-01 12:47:14 -0800;Merge pull request #61 from kalessin/master
allow spider to set autothrottle max concurrency
==
==================
7b0184eb;Martin Olveyra;2011-12-01 18:44:26 -0200;allow spider to set autothrottle max concurrency

==

scrapy/contrib/throttle.py
==================
e29f9e5b;Pablo Hoffman;2011-11-17 14:44:34 -0200;bumped version to 0.15

==

scrapy/__init__.py
==================
0f649f0e;Pablo Hoffman;2011-11-17 14:43:40 -0200;bumped version to 0.14

==

scrapy/__init__.py
==================
6d13de43;Pablo Hoffman;2011-11-14 20:03:43 -0200;fixed "No free spider slots" bug when calling fetch() from scrapy shell

==

scrapy/shell.py
==================
d37a788d;Pablo Hoffman;2011-11-14 17:00:25 -0200;improve handling of KeyError exception when creating spiders in spider manager. closes issue 49

==

scrapy/spidermanager.py
==================
36df87b4;Pablo Hoffman;2011-11-14 16:54:13 -0200;ignore meta-refresh redirects embedded in <script> tags. related to issue 18

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
ec1ef023;Pablo Hoffman;2011-11-14 16:25:22 -0200;ignore meta-refresh redirect when embedded inside <noscript> tag. closes issue 18

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
7232c31f;Simon Ratner;2011-11-11 11:53:00 -0800;Delete old logs based on file mtime.

==

scrapyd/environ.py
==================
6cc40dc0;Pablo Hoffman;2011-11-08 11:51:26 -0200;fixed bug in MEMUSAGE_NOTIFY_MAIL setting

==

scrapy/contrib/memusage.py
==================
37ad4f87;Pablo Hoffman;2011-10-28 16:33:12 -0200;added support for ajax crawleable urls

==

scrapy/http/request/__init__.py
scrapy/tests/test_http_request.py
scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
992af8d3;Pablo Hoffman;2011-10-25 14:26:38 -0200;ubuntu repos: added support for oneiric release

==

docs/topics/ubuntu.rst
==================
f4821a12;Pablo Hoffman;2011-10-25 13:04:58 -0200;Do not raise PartialDownloadError if Content-Length doesn't match the body size. This fixes the error reported in: https://groups.google.com/d/topic/scrapy-users/FQ25O3KPQuU/discussion

==

scrapy/contrib/downloadermiddleware/retry.py
scrapy/core/downloader/webclient.py
scrapy/tests/test_downloader_handlers.py
scrapy/tests/test_webclient.py
==================
c085f816;Pablo Hoffman;2011-10-25 04:26:37 -0200;removed deprecation warning for spider.download_timeout attribute

==

scrapy/contrib/downloadermiddleware/downloadtimeout.py
==================
c38c49d5;Pablo Hoffman;2011-10-25 02:36:51 -0200;fixed PickeItemExporter bug, added unittest, and added pickle to suported feed exports formats

==

docs/topics/feed-exports.rst
scrapy/contrib/exporter/__init__.py
scrapy/settings/default_settings.py
scrapy/tests/test_contrib_exporter.py
==================
8bdf2884;Pablo Hoffman;2011-10-23 05:29:54 -0200;made scrapyd doc more version agnostic

==

docs/topics/scrapyd.rst
==================
64b8e264;Pablo Hoffman;2011-10-23 03:06:59 -0200;added support for using '-' in scrapy crawl -o, to dump items to standard output

==

scrapy/commands/crawl.py
==================
028bf338;Pablo Hoffman;2011-10-23 03:05:06 -0200;feed exports: removed dependency on file.tell() method, so that stdout output works

==

scrapy/contrib/feedexport.py
==================
10ced29e;Pablo Hoffman;2011-10-23 02:49:17 -0200;changed feed exports storage api so that file/stdio outputs directly without using a temporary file

==

scrapy/contrib/feedexport.py
scrapy/tests/test_contrib_feedexport.py
==================
ade5efdc;Pablo Hoffman;2011-10-22 20:53:49 -0200;added -o option to scrapy crawl, a convenient shortcut for using feed exports

==

docs/faq.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
scrapy/commands/crawl.py
==================
13cd9a1b;Pablo Hoffman;2011-10-22 19:28:12 -0200;remove deprecation warning for spider.user_agent attribute

==

scrapy/contrib/downloadermiddleware/useragent.py
==================
43b79afc;Pablo Hoffman;2011-09-26 12:21:52 -0300;remove usage of assertLess() which is only available on python 2.7+

==

scrapy/tests/test_utils_queue.py
==================
431441cb;Pablo Hoffman;2011-09-25 13:06:24 -0300;updated documentation to remove references to old issue tracker and mercurial repos

==

docs/_ext/scrapydocs.py
docs/contributing.rst
docs/faq.rst
docs/index.rst
docs/intro/examples.rst
docs/intro/install.rst
docs/topics/commands.rst
docs/topics/link-extractors.rst
docs/topics/scrapyd.rst
docs/topics/ubuntu.rst
docs/versioning.rst
==================
ce03ccd4;Pablo Hoffman;2011-09-23 13:22:25 -0300;updated documentation about DEPTH_PRIORITY and DFO/BFO crawls

==

docs/faq.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
scrapy/contrib/spidermiddleware/depth.py
==================
f850a447;Pablo Hoffman;2011-09-23 13:03:07 -0300;Some changes to persistent scheduler after some initial usage feedback:
* added LIFO queues, in addition to the original FIFO queues
* use LIFO queues (instead of FIFO queues) by default, since they resemble DFO
  better which is a more convenient crawling order for most cases
* do not adjust the priority based on depth by default (DEPTH_PRIORITY = 0)

If someone does need to use strict BFO order, it can be by done by setting:

    DEPTH_PRIORITY = 1
    SCHEDULER_DISK_QUEUE = 'scrapy.squeue.PickleFifoDiskQueue'
    SCHEDULER_MEMORY_QUEUE = 'scrapy.squeue.FifoMemoryQueue'

==

scrapy/core/scheduler.py
scrapy/settings/default_settings.py
scrapy/squeue.py
scrapy/tests/test_squeue.py
scrapy/tests/test_utils_pqueue.py
scrapy/tests/test_utils_queue.py
scrapy/utils/queue.py
==================
cfddc314;Pablo Hoffman;2011-09-23 12:56:44 -0300;make SpiderState extension always available, regardless of whether there is a job dir, and make sure it always set spider.state attribute, for consistency between in-memory and on-disk runs

==

scrapy/contrib/spiderstate.py
scrapy/tests/test_contrib_spiderstate.py
==================
2559f211;Pablo Hoffman;2011-09-22 14:42:41 -0700;Merge pull request #42 from noplay/deploy-git-version
scrapy deploy support git version
==
==================
b7c43634;Julien Duponchelle;2011-09-21 22:17:08 +0200;scrapy deploy support git version

==

docs/topics/scrapyd.rst
scrapy/commands/deploy.py
==================
0f0783e5;Pablo Hoffman;2011-09-21 13:11:28 -0700;Merge pull request #39 from kalessin/master
autothrottle fix
==
==================
dcc50201;Martin Olveyra;2011-09-21 17:07:21 -0300;fix autothrottle extension for working with new downloader

==

scrapy/contrib/throttle.py
==================
b0036873;Pablo Hoffman;2011-09-18 06:08:28 -0300;moved rpm-install.sh to extras/

==

extras/rpm-install.sh
setup.cfg
==================
a5c15004;Daniel Graña;2011-09-18 01:08:04 -0300;Merge branch '0.12'

==
==================
fac5e5ea;Daniel Graña;2011-09-18 01:00:23 -0300;migrate hgignore to gitignore

==

.gitignore
==================
d788ba8a;Pablo Hoffman;2011-09-15 13:27:01 -0300;new mechanism to override settings in scrapy commands before the Crawler object is available

==

scrapy/cmdline.py
scrapy/command.py
==================
77ffaa50;Pablo Hoffman;2011-09-14 07:58:43 -0700;Merge pull request #38 from kalessin/master
_extract_links require extra parameter base_url
==
==================
509b05db;Martin Olveyra;2011-09-14 10:58:09 -0300;_extract_links requires extra parameter base_url in order to avoid exception when called from superclass method

==

scrapy/contrib/linkextractors/regex.py
==================
2fcb7097;Pablo Hoffman;2011-09-14 02:41:01 -0300;removed documentation header notifying about other documentation versions, as that's provided by readthedocs already

==

docs/_static/scrapydoc.css
docs/_templates/page.html
==================
ab1c9cfc;Pablo Hoffman;2011-09-14 02:39:32 -0300;removed documentation header notifying about other documentation versions, as that's provided by readthedocs already

==

docs/_static/scrapydoc.css
docs/_templates/page.html
==================
3b00b9cb;Pablo Hoffman;2011-09-11 11:24:12 -0300;added support for generating version from git revision

==

extras/makedeb.py
setup.py
==================
43ae7bdd;Pablo Hoffman;2011-09-11 08:27:05 -0300;added tests for SpiderState extension

==

scrapy/tests/test_contrib_spiderstate.py
==================
1e43afea;Pablo Hoffman;2011-09-09 03:03:46 -0300;added support for generating version from git revision, and use it in extras/makedeb.py

==

extras/makedeb.py
setup.py
==================
5f1b1c05;Daniel Grana;2011-09-08 15:18:10 -0300;Do not filter requests with dont_filter attribute set in OffsiteMiddleware

==

docs/topics/spider-middleware.rst
scrapy/contrib/spidermiddleware/offsite.py
scrapy/tests/test_spidermiddleware_offsite.py
==================
bff3d314;Pablo Hoffman;2011-09-04 09:29:24 -0300;scrapyd: updated schedule.json response format

==

docs/topics/scrapyd.rst
scrapyd/webservice.py
==================
17cc90e3;Pablo Hoffman;2011-09-04 08:58:23 -0300;added unittest for SpiderState extension

==

scrapy/contrib/spiderstate.py
==================
e0ec2399;Pablo Hoffman;2011-09-04 08:39:57 -0300;restored support for spider.DOWNLOAD_DELAY attribute, with deprecation warning

==

scrapy/core/downloader/__init__.py
==================
c8d30c6f;Pablo Hoffman;2011-09-02 19:09:21 -0300;replaced use of deprecated w3lib.url.urljoin_rfc by stdlib urlparse.urljoin

==

scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/linkextractors/htmlparser.py
scrapy/contrib/linkextractors/image.py
scrapy/contrib/linkextractors/regex.py
scrapy/contrib/linkextractors/sgml.py
==================
a1dbc62b;Pablo Hoffman;2011-09-02 18:27:39 -0300;removed CONCURRENT_SPIDERS setting (use scrapyd maxproc instead)

==

docs/topics/settings.rst
scrapy/core/engine.py
scrapy/settings/default_settings.py
scrapyd/environ.py
scrapyd/tests/test_environ.py
==================
40f7075f;Pablo Hoffman;2011-09-02 13:12:27 -0300;added initial documentation about suspend and resume crawls

==

docs/index.rst
docs/topics/jobs.rst
==================
27dd68a6;Pablo Hoffman;2011-09-02 13:06:59 -0300;added SpiderState extension

==

docs/topics/settings.rst
scrapy/contrib/spiderstate.py
scrapy/settings/default_settings.py
==================
c382f2fc;Pablo Hoffman;2011-09-02 09:40:52 -0300;fixed subtle bug in disk-based priority queues caused by serialization errors, and added tests

==

scrapy/tests/test_utils_pqueue.py
scrapy/utils/pqueue.py
==================
cca0b910;Pablo Hoffman;2011-09-01 19:40:44 -0300;add setting to enable logging when unserializable requests are found

==

scrapy/core/scheduler.py
scrapy/settings/default_settings.py
scrapy/squeue.py
scrapy/tests/test_squeue.py
==================
789e1493;Pablo Hoffman;2011-09-01 15:12:13 -0300;PickleDiskQueue: use pickle protocol 2

==

scrapy/squeue.py
==================
6a31ab66;Pablo Hoffman;2011-09-01 15:08:23 -0300;minor fix to doc

==

docs/topics/request-response.rst
==================
d98b058c;Pablo Hoffman;2011-09-01 15:06:49 -0300;no longer recommend using labmda's in the doc, as they're not friendly with scheduler persistence

==

docs/topics/request-response.rst
==================
725362fd;Pablo Hoffman;2011-09-01 14:58:50 -0300;remove redundant code

==

scrapy/tests/test_squeue.py
==================
76af0cdd;Pablo Hoffman;2011-09-01 14:35:37 -0300;updated documentation and code to use -s instead of --set option

==

debian/scrapy-files/scrapy.1
debian/scrapy.manpages
docs/faq.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/settings.rst
extras/scrapy.1
scrapy/command.py
scrapy/tests/test_cmdline/__init__.py
scrapyd/tests/test_utils.py
scrapyd/utils.py
==================
46edfd4a;Pablo Hoffman;2011-09-01 14:29:11 -0300;remove unneeded code to simplify

==

scrapy/command.py
==================
edefb8ac;Pablo Hoffman;2011-09-01 14:27:47 -0300;scrapy tool: added -s alias for --set option

==

scrapy/command.py
==================
75284015;Pablo Hoffman;2011-09-01 14:27:29 -0300;persistent scheduler: use pickle (instead of marshal) as the default serialization format, to support serializing more objects out of the box. also removed __slots__ from Request/Response objects to make them serializable by default.

==

scrapy/http/headers.py
scrapy/http/request/__init__.py
scrapy/http/request/form.py
scrapy/http/request/rpc.py
scrapy/http/response/__init__.py
scrapy/http/response/html.py
scrapy/http/response/text.py
scrapy/http/response/xml.py
scrapy/settings/default_settings.py
scrapy/squeue.py
scrapy/tests/test_http_headers.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
scrapy/tests/test_squeue.py
==================
f1210aed;Daniel Grana;2011-08-29 15:01:18 -0300;ignore *egg-info added by pip install -e

==

.hgignore
==================
accac332;Pablo Hoffman;2011-08-27 01:43:32 -0300;adapted test-scrapyd.sh to be compatible with older versions of mktemp, and to not hang forever is spider doesn't run for some reason

==

extras/test-scrapyd.sh
==================
98b68ca8;Pablo Hoffman;2011-08-27 01:31:12 -0300;scrapyd: documented support for passing setting to spiders in schedule.json

==

docs/topics/scrapyd.rst
==================
6d6cff33;Pablo Hoffman;2011-08-27 01:23:36 -0300;added scrapyd system test script to extras/test-scrapyd.sh

==

extras/test-scrapyd.sh
==================
91b9d89f;Pablo Hoffman;2011-08-27 01:20:57 -0300;moved scrapy.utils.sqlite to scrapyd.sqlite
--HG--
rename : scrapy/utils/sqlite.py => scrapyd/sqlite.py
rename : scrapy/tests/test_utils_sqlite.py => scrapyd/tests/test_sqlite.py

==

scrapy/utils/project.py
scrapyd/interfaces.py
scrapyd/spiderqueue.py
scrapyd/sqlite.py
scrapyd/tests/test_sqlite.py
==================
e1aff779;Pablo Hoffman;2011-08-27 01:03:56 -0300;removed (barely used) spider context extension, to drop dependencies with sqlite

==

scrapy/contrib/spidercontext.py
scrapy/settings/default_settings.py
scrapy/tests/test_contrib_spidercontext.py
==================
075a2d62;Pablo Hoffman;2011-08-27 01:02:14 -0300;scrapyd: added support for passing custom settings to schedule.json

==

scrapyd/tests/test_utils.py
scrapyd/utils.py
scrapyd/webservice.py
==================
ce085048;Pablo Hoffman;2011-08-26 09:24:01 -0300;removed class method from_settings from ISpiderManager interface

==

scrapy/interfaces.py
==================
47cae5fa;Pablo Hoffman;2011-08-24 11:31:52 -0300;fixed unittest broken by previous commit

==

scrapy/tests/test_dupefilter.py
==================
669b98c4;Pablo Hoffman;2011-08-24 11:26:35 -0300;pass close reason to close() method of new DupeFilter

==

scrapy/core/scheduler.py
scrapy/dupefilter.py
==================
5c6b0631;Pablo Hoffman;2011-08-19 11:42:03 -0300;minor doc fix

==

docs/topics/request-response.rst
==================
9d97e73a;Pablo Hoffman;2011-08-19 08:26:41 -0300;fixed priority handling on the new scheduler so that it's backwards compatible (ie. bigger priorities are higher). also fixed a few documentation bugs related to requests priority

==

docs/topics/request-response.rst
docs/topics/settings.rst
scrapy/contrib/spidermiddleware/depth.py
scrapy/core/scheduler.py
==================
ee40aa12;Pablo Hoffman;2011-08-16 11:16:35 -0300;added from_crawler class method to SpiderManager

==

scrapy/commands/list.py
scrapy/crawler.py
scrapy/spidermanager.py
==================
a3697421;Pablo Hoffman;2011-08-11 09:19:59 -0300;some minor updates to documentation

==

docs/intro/examples.rst
docs/topics/settings.rst
==================
5da6ffb5;Pablo Hoffman;2011-08-11 09:11:19 -0300;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
bc2d2183;Pablo Hoffman;2011-08-11 09:11:08 -0300;fixed import in doc

==

docs/intro/overview.rst
==================
19e6da59;Pablo Hoffman;2011-08-09 03:03:25 -0300;added new downloader middleware: ChunkedTransferMiddleware

==

docs/topics/downloader-middleware.rst
docs/topics/settings.rst
scrapy/contrib/downloadermiddleware/chunked.py
scrapy/settings/default_settings.py
scrapy/tests/test_utils_http.py
scrapy/utils/http.py
==================
4db2a592;Pablo Hoffman;2011-08-09 01:42:11 -0300;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
09af0866;Pablo Hoffman;2011-08-09 01:41:48 -0300;scrapy.utils.python: fixed bug introduced when adding support for new IPython 0.11. refs #335

==

scrapy/utils/console.py
==================
415933a1;Pablo Hoffman;2011-08-09 01:38:31 -0300;scrapy.utils.python: fixed bug introduced when adding support for new IPython 0.11. refs #335

==

scrapy/utils/console.py
==================
061132ce;Pablo Hoffman;2011-08-08 17:16:32 -0300;fixed backwards compability with images/media pipeline, after crawler singleton removal in r2758

==

scrapy/contrib/pipeline/media.py
==================
2108517c;Pablo Hoffman;2011-08-08 15:51:22 -0300;removed support for passing more than a single spider on 'scrapy crawl' command

==

scrapy/commands/crawl.py
==================
436ad639;Daniel Grana;2011-08-08 14:29:28 -0300;support s3 signing on pre and post boto v2.0
--HG--
extra : rebase_source : 1d8cd5dfceeaf63975c46014b100d70f6ed36147

==

scrapy/core/downloader/handlers/s3.py
==================
c64123cc;Pablo Hoffman;2011-08-08 15:09:43 -0300;proper fix to what r2760 is supposed to fix

==

scrapy/core/scheduler.py
scrapy/utils/pqueue.py
==================
984be354;Pablo Hoffman;2011-08-08 15:01:08 -0300;Some telnet console changes: * renamed manager alias to crawler * added aliases: spider, slot * fixed est() function

==

docs/topics/telnetconsole.rst
scrapy/telnet.py
==================
f03af787;Pablo Hoffman;2011-08-08 14:52:54 -0300;fixed bug in scheduler 'has_pending_requests' method which prevented spiders to close properly in some cases

==

scrapy/core/scheduler.py
==================
c35a7519;Daniel Grana;2011-08-08 13:23:45 -0300;Correctly handle query parameters on s3:// urls

==

scrapy/core/downloader/handlers/s3.py
scrapy/tests/test_urlparse_monkeypatches.py
scrapy/xlib/urlparse_monkeypatches.py
==================
5c63b230;Pablo Hoffman;2011-08-08 11:42:44 -0300;Another step towards singleton removal: deprecated crawler singleton import (from scrapy.project import crawler) by a new  class method that extensions can implement to receive the crawler

==

scrapy/contrib/closespider.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/webservice/crawler.py
scrapy/contrib/webservice/enginestatus.py
scrapy/contrib/webservice/stats.py
scrapy/core/downloader/__init__.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/crawler.py
scrapy/middleware.py
scrapy/project.py
scrapy/telnet.py
scrapy/utils/engine.py
scrapy/utils/serialize.py
scrapy/webservice.py
==================
0eaa1d95;Pablo Hoffman;2011-08-08 10:39:53 -0300;replaced DeprecationWarning by a new ScrapyDeprecationWarning category, since the default DeprecationWarning is silenced on Python 2.7+

==

scrapy/cmdline.py
scrapy/contrib/closespider.py
scrapy/contrib/exporter/jsonlines.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/core/downloader/__init__.py
scrapy/exceptions.py
scrapy/http/common.py
scrapy/log.py
scrapy/utils/decorator.py
scrapy/utils/deprecate.py
==================
f7c0aecc;Pablo Hoffman;2011-08-07 03:57:09 -0300;added note about engine_started signal

==

docs/topics/signals.rst
==================
a2b0737a;Pablo Hoffman;2011-08-07 03:24:32 -0300;scrapy.utils.sitemap: added one more case of parsing invalid sitemaps

==

scrapy/tests/test_utils_sitemap.py
scrapy/utils/sitemap.py
==================
cea0dae1;Pablo Hoffman;2011-08-07 03:13:55 -0300;scrapy.utils.sitemap: added support for parsing sitemaps with wrong namespaces, found in some bogus websites

==

scrapy/tests/test_utils_sitemap.py
scrapy/utils/sitemap.py
==================
259dccaf;Pablo Hoffman;2011-08-07 02:49:57 -0300;moved module scrapy.core.downloader.responsetypes to scrapy.responsetypes
--HG--
rename : scrapy/core/downloader/responsetypes/mime.types => scrapy/mime.types
rename : scrapy/core/downloader/responsetypes/__init__.py => scrapy/responsetypes.py

==

MANIFEST.in
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/contrib/httpcache.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/core/downloader/handlers/file.py
scrapy/core/downloader/webclient.py
scrapy/mime.types
scrapy/responsetypes.py
scrapy/tests/test_responsetypes.py
==================
9f60c276;Pablo Hoffman;2011-08-05 20:41:59 -0300;added setting to support disabling DNS cache: DNSCACHE_ENABLED

==

docs/topics/settings.rst
scrapy/crawler.py
scrapy/settings/default_settings.py
==================
bb67cfd9;Pablo Hoffman;2011-08-05 20:32:22 -0300;added MarshalDiskQueue unittests

==

scrapy/tests/test_squeue.py
==================
5c938cc0;Pablo Hoffman;2011-08-05 20:26:24 -0300;removed no longer working tests from get_engine_status()

==

scrapy/utils/engine.py
==================
38e193d4;Pablo Hoffman;2011-08-05 17:06:31 -0300;MarshalDiskQueue bug fix

==

scrapy/squeue.py
==================
1ce84046;Pablo Hoffman;2011-08-05 12:39:29 -0300;scheduler: bug fix to use in-memory queues when request can't be serialized by the disk-queues

==

scrapy/core/scheduler.py
==================
76cbb6a2;Pablo Hoffman;2011-08-03 23:55:59 -0300;removed wrong blocking api usage (socket.gethostbyname()) from downloader when using CONCURRENT_REQUESTS_PER_IP

==

scrapy/core/downloader/__init__.py
scrapy/resolver.py
==================
ebb892e5;Pablo Hoffman;2011-08-03 23:19:22 -0300;updated get_engine_status() after scheduler changes

==

scrapy/utils/engine.py
==================
cd8470b3;Pablo Hoffman;2011-08-03 20:25:14 -0300;fixed crawlspider bug introduced after scheduler refactoring

==

scrapy/contrib/spiders/crawl.py
==================
cb95d7a5;Pablo Hoffman;2011-08-03 16:16:48 -0300;added marshal to formats supported by feed exports

==

docs/topics/feed-exports.rst
scrapy/contrib/exporter/__init__.py
scrapy/settings/default_settings.py
==================
884dc93a;Pablo Hoffman;2011-08-02 22:46:02 -0300;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
3191a085;Pablo Hoffman;2011-08-02 22:45:51 -0300;fix start_python_console() to work with IPython >= 0.11. closes #335

==

scrapy/utils/console.py
==================
888dac86;Pablo Hoffman;2011-08-02 15:56:32 -0300;fixed bug with scheduler.__len__() when disk queues are disabled

==

scrapy/core/scheduler.py
==================
f8c9b403;Pablo Hoffman;2011-08-02 15:46:35 -0300;added __len__() method to scheduler

==

scrapy/core/scheduler.py
==================
fbf0e9ef;Pablo Hoffman;2011-08-02 15:10:25 -0300;cleaned up lxml-based link extractors, and left one of them
--HG--
rename : scrapy/contrib/linkextractors/lxmlparser.py => scrapy/contrib/linkextractors/lxmlhtml.py

==

scrapy/contrib/linkextractors/lxmlhtml.py
scrapy/contrib/linkextractors/lxmlparser.py
==================
c6f29f02;Pablo Hoffman;2011-08-02 12:02:08 -0300;tie request to downloader failures, so that they can be accessed from request errbacks

==

scrapy/core/engine.py
==================
54972521;Pablo Hoffman;2011-08-02 11:57:55 -0300;Initial support for a persistent scheduler, to support pausing and resuming crawls.
* requests are serialized (using marshal by default) and stored on disk, using
  one queue per priority
* request priorities must be integers now
* breadh-first and depth-first crawling orders can now be configured
  through a new DEPTH_PRIORITY setting (see doc). backwards compatilibty with
  SCHEDULER_ORDER was kept.
* requests that can't be serialized (for example, non serializable callbacks)
  are always kept in memory queues
* adapted crawl spider to work with persitent scheduler

==

docs/faq.rst
docs/topics/settings.rst
docs/topics/spider-middleware.rst
scrapy/contrib/dupefilter.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spiders/crawl.py
scrapy/core/scheduler.py
scrapy/dupefilter.py
scrapy/http/request/__init__.py
scrapy/settings/default_settings.py
scrapy/squeue.py
scrapy/tests/test_dupefilter.py
scrapy/tests/test_utils_datatypes.py
scrapy/tests/test_utils_pqueue.py
scrapy/tests/test_utils_queue.py
scrapy/tests/test_utils_reqser.py
scrapy/utils/datatypes.py
scrapy/utils/engine.py
scrapy/utils/job.py
scrapy/utils/pqueue.py
scrapy/utils/queue.py
scrapy/utils/reqser.py
==================
6d989e3f;Pablo Hoffman;2011-07-31 03:32:25 -0300;imported patch scheduler_single_spider.patch

==

scrapy/contrib/dupefilter.py
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/utils/engine.py
==================
4d1e01a4;Pablo Hoffman;2011-07-31 02:47:14 -0300;removed obsolete profiling/ dir

==

profiling/priorityqueue/pq_classes.py
profiling/priorityqueue/run.py
profiling/priorityqueue/test_cases.py
==================
f354a49d;Pablo Hoffman;2011-07-28 00:40:30 -0300;added FAQ about preventing bots getting banned

==

docs/faq.rst
==================
ce380226;Pablo Hoffman;2011-07-27 15:14:27 -0300;restored support for download delays after downlaoder refactoring, also restored support for spider attributes: max_concurrent_requests and download_delay

==

scrapy/core/downloader/__init__.py
==================
ce7a7879;Pablo Hoffman;2011-07-27 13:38:09 -0300;Big downloader refactoring to support real concurrency limits per domain/ip, instead of global limits per spider which were a bit useless.
This removes the setting CONCURRENT_REQUESTS_PER_SPIDER and adds thre new
settings:

* CONCURRENT_REQUESTS
* CONCURRENT_REQUESTS_PER_DOMAIN
* CONCURRENT_REQUESTS_PER_IP (overrides per domain)

The AutoThrottle extension had to be disabled, but will be ported and
re-enabled soon.

==

docs/topics/settings.rst
scrapy/contrib/throttle.py
scrapy/core/downloader/__init__.py
scrapy/core/engine.py
scrapy/settings/default_settings.py
scrapy/utils/engine.py
==================
a45dca32;Pablo Hoffman;2011-07-27 13:21:58 -0300;removed deprecation warning (scheduled to be removed on Scrapy 0.11)

==

scrapy/contrib/pipeline/__init__.py
==================
b47f5330;Pablo Hoffman;2011-07-27 12:28:36 -0300;added fragment attribute ot Link object

==

scrapy/link.py
scrapy/tests/test_link.py
==================
e9ca309b;Pablo Hoffman;2011-07-27 03:48:38 -0300;minor comments adjustments

==

scrapy/resolver.py
==================
c5934015;Pablo Hoffman;2011-07-27 03:45:15 -0300;Added cached DNS resolver based on old caching resolver extension from scrapy.contrib.resolver. This new one is *not* an extension, it comes builtin and always enabled.

==

docs/intro/overview.rst
scrapy/contrib/resolver.py
scrapy/crawler.py
scrapy/resolver.py
scrapy/utils/datatypes.py
scrapy/utils/py27.py
scrapy/xlib/ordereddict.py
==================
90b716f7;Pablo Hoffman;2011-07-26 19:06:52 -0300;downloader: removed unneeded code, and some minor refactoring

==

scrapy/core/downloader/__init__.py
==================
549298e3;Pablo Hoffman;2011-07-26 19:05:29 -0300;spidermanager: more detailed error message now that scrapy crawl command will raise the exception directly

==

scrapy/spidermanager.py
==================
cb9c937f;Pablo Hoffman;2011-07-26 18:49:01 -0300;minor code rearrangement for consistency

==

scrapy/core/downloader/__init__.py
scrapy/core/engine.py
==================
dd020e18;Pablo Hoffman;2011-07-26 18:45:51 -0300;removed rather useless (and some deprecated) docstrings

==

scrapy/core/downloader/__init__.py
==================
70493c75;Pablo Hoffman;2011-07-25 14:52:24 -0300;retry middleware: added TCPTimedOutError to exceptions to retry

==

scrapy/contrib/downloadermiddleware/retry.py
==================
6f0e4923;Pablo Hoffman;2011-07-25 12:24:26 -0300;fixed bug with scraper KeyError's on some ConnectionLost errors. closes #334

==

scrapy/core/scraper.py
==================
6e50f944;Pablo Hoffman;2011-07-25 10:47:54 -0300;engine: make it more explicit that we don't need to return the value of nextcall.schedule()

==

scrapy/core/engine.py
==================
ea3bf6d9;Pablo Hoffman;2011-07-25 10:46:00 -0300;more core refactoring including moving engine next request call logic to a separate class

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/utils/engine.py
scrapy/utils/reactor.py
==================
209ecdf4;Pablo Hoffman;2011-07-25 00:49:54 -0300;updated settings.py for djangoitem tests to new django multi-db format

==

scrapy/tests/test_djangoitem/settings.py
==================
2ac08a71;Pablo Hoffman;2011-07-22 02:06:10 -0300;downloader: renamed SpiderInfo to Slot, for consistency with engine and scraper names

==

docs/topics/telnetconsole.rst
scrapy/core/downloader/__init__.py
scrapy/core/engine.py
scrapy/utils/engine.py
==================
d6b83fee;Pablo Hoffman;2011-07-22 02:01:05 -0300;scraper: renamed SpiderInfo to Slot, for consistency with engine names

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/utils/engine.py
==================
f1944242;Pablo Hoffman;2011-07-20 17:41:53 -0300;forked UnicodeDammit from BeautifulSoup to explicitly disable usage of chardet library

==

scrapy/http/response/dammit.py
scrapy/http/response/text.py
scrapy/tests/test_utils_response.py
scrapy/utils/response.py
scrapy/xlib/BeautifulSoup.py
==================
7d18fe18;Pablo Hoffman;2011-07-20 17:05:21 -0300;added missing import

==

scrapy/contrib/downloadermiddleware/redirect.py
==================
0e008268;Pablo Hoffman;2011-07-20 10:38:16 -0300;removed SimpledbStatsCollector from scrapy code, it was moved to https://github.com/scrapinghub/scaws

==

docs/topics/stats.rst
scrapy/contrib/statscol.py
scrapy/settings/default_settings.py
scrapy/tests/test_utils_simpledb.py
scrapy/utils/simpledb.py
==================
b6b0a54d;Pablo Hoffman;2011-07-20 01:31:36 -0300;removed FAQ entry

==

docs/faq.rst
==================
cc6ef3be;Pablo Hoffman;2011-07-20 01:18:34 -0300;engine: renamed slot.requests to slot.start_requests

==

scrapy/core/engine.py
==================
de0bf220;Pablo Hoffman;2011-07-20 01:18:00 -0300;speed up consumption of spider start requests, while the engine has capacity to process them

==

scrapy/core/engine.py
==================
9f742fc9;Pablo Hoffman;2011-07-20 01:04:16 -0300;removed unused import from 'crawl' spider template

==

scrapy/templates/spiders/crawl.tmpl
==================
e3f640c7;Pablo Hoffman;2011-07-19 19:53:32 -0300;added FAQ entry about scrapy deploy issue on Mac + Python 2.5

==

docs/faq.rst
==================
75e2c3eb;Pablo Hoffman;2011-07-19 19:39:27 -0300;moved spider queues to scrapyd
--HG--
rename : scrapy/spiderqueue.py => scrapyd/spiderqueue.py
rename : scrapy/tests/test_spiderqueue.py => scrapyd/tests/test_spiderqueue.py

==

scrapy/interfaces.py
scrapy/settings/default_settings.py
scrapyd/interfaces.py
scrapyd/spiderqueue.py
scrapyd/tests/test_spiderqueue.py
scrapyd/utils.py
==================
d97d6d20;Pablo Hoffman;2011-07-19 19:31:19 -0300;removed no longer used settings

==

scrapy/settings/default_settings.py
==================
442c0bdc;Pablo Hoffman;2011-07-19 14:11:55 -0300;removed SQSSpiderQueue from base scrapy code, it was moved to https://github.com/scrapinghub/scaws

==

scrapy/contrib/spiderqueue.py
scrapy/tests/test_contrib_spiderqueue.py
==================
bdd627fe;Daniel Grana;2011-07-15 15:17:38 -0300;allow overriding store_uri by extending ImagePipeline
--HG--
extra : rebase_source : 5c561b8282f733ab0f26607059dd96d858154426

==

scrapy/contrib/pipeline/images.py
==================
84f518fc;Pablo Hoffman;2011-07-15 15:18:39 -0300;More core changes:
* removed execution queue (replaced by newer spider queues)
* added real support for returning iterators in Spider.start_requests()
* removed support for passing urls to 'scrapy crawl' command

==

docs/topics/commands.rst
scrapy/commands/crawl.py
scrapy/commands/fetch.py
scrapy/commands/parse.py
scrapy/commands/runspider.py
scrapy/commands/shell.py
scrapy/core/engine.py
scrapy/crawler.py
scrapy/queue.py
scrapy/settings/default_settings.py
scrapy/shell.py
scrapy/tests/test_commands.py
scrapy/tests/test_engine.py
scrapy/tests/test_queue.py
==================
4dadeb7c;Daniel Grana;2011-07-15 13:57:24 -0300;fix issue with responses preventing spiders to be idle in engine counts

==

scrapy/core/engine.py
==================
d207c0af;Pablo Hoffman;2011-07-15 12:55:07 -0300;fixed bug in engine.download() method

==

scrapy/core/engine.py
==================
830255ee;Pablo Hoffman;2011-07-14 01:41:24 -0300;removed deprecated commands: queue, runserver

==

scrapy/commands/queue.py
scrapy/commands/runserver.py
==================
359129ad;Pablo Hoffman;2011-07-14 01:40:31 -0300;fixed python pass handling in cmdline/commands tests so that it works with new w3lib library

==

scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_commands.py
==================
dbad1373;Pablo Hoffman;2011-07-13 18:44:54 -0300;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
18cb4ff1;Pablo Hoffman;2011-07-13 18:43:52 -0300;added natty to list of supporte ubuntu distros

==

docs/topics/ubuntu.rst
==================
39a2ea97;Pablo Hoffman;2011-07-13 14:18:15 -0300;redirect mw: added REDIRECT_ENABLED setting and documented the other settings

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/settings/default_settings.py
==================
0b6c7ce9;Pablo Hoffman;2011-07-13 14:10:05 -0300;improved download errors propagation to the spiders, and removed no longer needed code to simplify

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/logformatter.py
==================
804c0279;Pablo Hoffman;2011-07-13 13:04:42 -0300;setup.py: only add lxml requirement if libxml2 is not available

==

setup.py
==================
541ed391;Pablo Hoffman;2011-07-13 11:55:05 -0300;retry middleware: added RETRY_ENABLED setting and documented the other settings more properly, also improved messages when no longer retrying requests

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/retry.py
scrapy/settings/default_settings.py
==================
763f3dc6;Pablo Hoffman;2011-07-12 19:56:39 -0300;minor update to doc

==

docs/faq.rst
==================
bfda9ec3;Pablo Hoffman;2011-07-12 19:53:23 -0300;added clarification about scrapy versioning including the recently adopted odd/even versioning scheme
--HG--
rename : docs/api-stability.rst => docs/versioning.rst

==

docs/api-stability.rst
docs/index.rst
docs/versioning.rst
==================
4fde1ef9;Pablo Hoffman;2011-07-12 14:24:10 -0300;added CloseSpider exception, to manually close spiders

==

docs/faq.rst
docs/topics/exceptions.rst
scrapy/core/scraper.py
scrapy/exceptions.py
==================
4bb40992;Pablo Hoffman;2011-07-12 09:52:50 -0300;improved encoding detection by adding support for HTML5 meta charset

==

scrapy/http/response/html.py
scrapy/tests/test_http_response.py
==================
67213ce6;Pablo Hoffman;2011-07-12 01:16:06 -0300;logformatter: support non-ascii characters in custom implementations of Item.__str__()

==

scrapy/logformatter.py
scrapy/tests/test_logformatter.py
==================
31a375bd;Pablo Hoffman;2011-07-10 04:18:50 -0300;Close the scheduler after closing the scraper and downloader. This shouldn't have any real effect in practice, but it feels more appropiate to close the components in this order

==

scrapy/core/engine.py
==================
90b1ae69;Pablo Hoffman;2011-07-10 04:10:20 -0300;get_engine_status(): preserve test order defined in code

==

scrapy/utils/engine.py
==================
409aaade;Pablo Hoffman;2011-07-08 11:40:19 -0300;Refactored close spider behaviour so that the engine now waits for all downloading (and enqueued for download) requests to finish and their responses to be processed in the scraper/spiders, before closing the spider.
This will be required in the future to avoid loosing requests when we add
scheduler persistence and it's also a more correct behaviour overall.

The closing process has also been refactored to remove unneeded closing state
from downloader and leave it only in the engine.

Finally, some unused methods has been removed too, like spider_is_open() for
engine and scheduler.

==

scrapy/core/downloader/__init__.py
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/utils/engine.py
==================
574b070b;Pablo Hoffman;2011-07-08 09:33:56 -0300;fixed minor bug in sitemap parser

==

scrapy/tests/test_utils_sitemap.py
scrapy/utils/sitemap.py
==================
ab9b7867;Pablo Hoffman;2011-07-06 20:11:11 -0300;Updated CAMELCASE_EXCLUDE_CHARS to also exclude digits (patch by Adam Wentz)

==

scrapy/utils/template.py
==================
7abc4b4c;Pablo Hoffman;2011-07-06 01:35:21 -0300;fixed typo

==

scrapy/contrib/spiders/sitemap.py
==================
949e11ee;Pablo Hoffman;2011-07-06 01:33:46 -0300;SitemapSpider: added support for parsing gzipped sitemaps (patch contributed by Rolando Espinoza)

==

scrapy/contrib/spiders/sitemap.py
==================
57070513;Pablo Hoffman;2011-07-04 21:31:05 -0300;fixed httpcompression middleware tests

==

scrapy/tests/test_downloadermiddleware_httpcompression.py
==================
81fbe8c9;Pablo Hoffman;2011-07-04 21:27:24 -0300;added x-gzip to supported encoding declarations in httpcompression middleware

==

scrapy/contrib/downloadermiddleware/httpcompression.py
==================
a5223881;Pablo Hoffman;2011-06-30 02:28:53 -0300;removed debugging code

==

scrapy/contrib/downloadermiddleware/httpcompression.py
==================
5275343f;Pablo Hoffman;2011-06-28 17:27:40 -0300;use handle_httpstatus_all=True in scrapy shell

==

scrapy/shell.py
==================
7cd559ec;Pablo Hoffman;2011-06-27 10:02:16 -0300;SitemapSpider: ignore non-xml responses. fixes #331

==

scrapy/contrib/spiders/sitemap.py
==================
db5cae7c;Pablo Hoffman;2011-06-23 18:18:29 -0300;SitemapSpider: added support for filtering which sitemaps to follow (patch contributed by Rolando Espinoza). closes #330

==

docs/topics/spiders.rst
scrapy/contrib/spiders/sitemap.py
==================
d97a9d87;Pablo Hoffman;2011-06-23 12:39:51 -0300;improved errors of ItemLoader.load_item() so that it shows the field name and value of the output processor that failed

==

scrapy/contrib/loader/__init__.py
scrapy/tests/test_contrib_loader.py
==================
fbafb295;Pablo Hoffman;2011-06-23 11:34:28 -0300;removed DEFAULT_ITEM_CLASS setting from settings in new project template

==

scrapy/templates/project/module/settings.py.tmpl
==================
d197895d;Pablo Hoffman;2011-06-21 18:06:04 -0300;removed deprecated code

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
d8775a75;Pablo Hoffman;2011-06-21 18:01:05 -0300;removed old deprecated FileExportPipeline

==

scrapy/contrib/pipeline/fileexport.py
==================
0305ffdd;Pablo Hoffman;2011-06-20 21:22:16 -0300;sitemaps: support trailing spaces in <loc> elements

==

scrapy/tests/test_utils_sitemap.py
scrapy/utils/sitemap.py
==================
2e74ccaa;Pablo Hoffman;2011-06-20 13:10:13 -0300;dropped InitSpider super class from CrawlSpider and Feed spiders, to avoid potentially confusing code, as it's also not needed

==

scrapy/contrib/spiders/crawl.py
scrapy/contrib/spiders/feed.py
==================
03bc2189;Pablo Hoffman;2011-06-20 11:09:01 -0300;fixed bug in get_engine_status() function

==

scrapy/utils/engine.py
==================
03a92a8b;Pablo Hoffman;2011-06-20 11:04:38 -0300;slightly improved version of scrapyd script

==

bin/scrapyd
==================
5de5cac4;Pablo Hoffman;2011-06-20 10:48:34 -0300;added quick script script to launch scrapyd

==

bin/scrapyd
==================
841007b5;Pablo Hoffman;2011-06-18 03:31:47 -0300;added envvar SCRAPY_VERSION_FROM_HG=1 to extras/makedeb.py script

==

extras/makedeb.py
==================
7e5e00ce;Pablo Hoffman;2011-06-18 02:52:21 -0300;Added public engine.download() method to use the downloader bypassing the scheduler. Changed media pipeline to use engine.download() to prevent deadlocks.

==

scrapy/contrib/pipeline/media.py
scrapy/core/engine.py
==================
dd90e83e;Pablo Hoffman;2011-06-18 02:48:01 -0300;get_engine_status(): also look up open spiders in scraper component

==

scrapy/utils/engine.py
==================
e575e015;Pablo Hoffman;2011-06-17 16:50:02 -0300;LogStats extension: fixed KeyError bug caused with spiders that don't scrape any items

==

scrapy/contrib/logstats.py
==================
cfc93ba9;Pablo Hoffman;2011-06-16 10:20:28 -0300;added SitemapSpider to basic spider assertion tests

==

scrapy/tests/test_spider.py
==================
25b0ca31;Pablo Hoffman;2011-06-16 10:19:27 -0300;minor imports sort out

==

scrapy/tests/test_spider.py
==================
59acb129;Pablo Hoffman;2011-06-15 19:35:03 -0300;scrapyd activate_egg(): don't override SCRAPY_SETTINGS_MODULE envvar if already set

==

scrapyd/eggutils.py
==================
cd52a7c8;Pablo Hoffman;2011-06-15 12:35:54 -0300;removed debugging print

==

scrapy/contrib/spiders/sitemap.py
==================
57c43fdc;Pablo Hoffman;2011-06-15 11:54:34 -0300;added SitemapSpider, with tests and doc

==

docs/intro/overview.rst
docs/topics/spiders.rst
scrapy/contrib/spiders/__init__.py
scrapy/contrib/spiders/sitemap.py
scrapy/tests/test_utils_sitemap.py
scrapy/utils/sitemap.py
==================
91dc4653;Pablo Hoffman;2011-06-14 00:50:05 -0300;added LogStats extension for periodically logging basic stats (like crawled pages and scraped items)

==

docs/topics/extensions.rst
docs/topics/settings.rst
scrapy/contrib/logstats.py
scrapy/settings/default_settings.py
==================
d2a9c0fd;Pablo Hoffman;2011-06-13 22:34:01 -0300;issue deprecation warning when using CLOSESPIDER_ITEMPASSED setting

==

scrapy/contrib/closespider.py
==================
841e9913;Pablo Hoffman;2011-06-13 16:58:51 -0300;renamed CLOSESPIDER_ITEMPASSED setting to CLOSESPIDER_ITEMCOUNT, to follow the refactoring done in r2630

==

docs/topics/extensions.rst
scrapy/contrib/closespider.py
scrapy/settings/default_settings.py
==================
5dea6be5;Pablo Hoffman;2011-06-13 14:28:03 -0300;use log for dumping stack trace and engine status, in StackTraceDump extension

==

scrapy/contrib/debug.py
==================
72cf5a97;Pablo Hoffman;2011-06-13 09:54:06 -0300;added -e|--edit option to genspider command

==

scrapy/commands/genspider.py
==================
80b55784;Pablo Hoffman;2011-06-12 02:55:21 -0300;fixed test broken in previous commit

==

scrapyd/tests/test_environ.py
==================
0d5399d0;Pablo Hoffman;2011-06-12 02:46:41 -0300;fixed scrapyd tests on win32. closes #295

==

scrapy/commands/list.py
scrapyd/tests/test_eggstorage.py
scrapyd/tests/test_environ.py
==================
c434d11f;Pablo Hoffman;2011-06-12 01:42:30 -0300;added Darian Moody to AUTHORS

==

AUTHORS
==================
6873d5b9;Darian Moody;2011-06-12 01:41:10 -0300;Added to tests for last commit; now tests to make sure  custom primary keys are editable from the Scrapy Item. ---  scrapy/tests/test_djangoitem/__init__.py |   15 ++++++++++++++-  scrapy/tests/test_djangoitem/models.py   |    7 +++++++  2 files changed, 21 insertions(+), 1 deletions(-)

==

scrapy/tests/test_djangoitem/__init__.py
scrapy/tests/test_djangoitem/models.py
==================
05101c7b;Darian Moody;2011-06-12 01:41:09 -0300;Fixed DjangoItem to work properly with auto-generated  fields (such as the primary key); it will now ignore  those that have had the auto_created flag set - this  now allows us to work with custom primary keys as the  previous way ignored a custom primary key field. ---  scrapy/contrib_exp/djangoitem.py |    4 +---  1 files changed, 1 insertions(+), 3 deletions(-)

==

scrapy/contrib_exp/djangoitem.py
==================
37830da1;Pablo Hoffman;2011-06-10 18:27:39 -0300;fixed wrong code in test

==

scrapy/tests/test_downloadermiddleware_stats.py
scrapy/tests/test_http_request.py
scrapy/tests/test_pipeline_media.py
==================
c4a607fc;Pablo Hoffman;2011-06-10 18:22:36 -0300;Raise ValueError if url has no scheme in Request constructor

==

scrapy/http/request/__init__.py
scrapy/tests/test_http_request.py
==================
88e33ad0;Pablo Hoffman;2011-06-09 00:15:53 -0300;Simplified Request/Response __repr__ to be the same as __str__. This improves legibility and shouldn't affect any functionality, since we never use __repr__ for reconstructing a response AFAIK. Also fixes #318

==

scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
==================
07df0edf;Pablo Hoffman;2011-06-08 14:17:04 -0300;scrapyd.webservice: use twisted.web multipart data parsing, to simplify code. closes #324

==

scrapyd/webservice.py
==================
7643f14c;Pablo Hoffman;2011-06-06 18:25:14 -0300;fixed bug handling truncated gzipped responses. closes #319

==

scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/tests/sample_data/compressed/truncated-crc-error.gz
scrapy/tests/test_utils_gz.py
scrapy/utils/gz.py
==================
48509b03;Pablo Hoffman;2011-06-06 16:11:43 -0300;fixed some tests accidentally broken in previous commit

==

scrapy/tests/test_command_fetch.py
==================
f7935155;Pablo Hoffman;2011-06-06 15:21:50 -0300;make --headers output of fetch command resemble curl format, and also show request headers

==

scrapy/commands/fetch.py
==================
03751749;Pablo Hoffman;2011-06-06 03:16:56 -0300;Scheduler refactoring which introduces the following changes:
* dropped deferred stored along with requests in scheduler queues, which will
  add the ability to support persistent schedulers in the future
* moved duplicates filter into the scheduler itself, using the same
  dupe fltering class as before (DUPEFILTER_CLASS setting)
* removed scheduler middleware component to simplify, as it was only used for
  duplicates filtering and that is now done in the scheduler itself
* adapted media pipeline to work with new scheduler
* cleanup old docstrings

==

scrapy/contrib/pipeline/media.py
scrapy/contrib/schedulermiddleware/__init__.py
scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/contrib/spidermiddleware/httperror.py
scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/core/schedulermw.py
scrapy/settings/default_settings.py
scrapy/shell.py
scrapy/tests/test_pipeline_media.py
scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
scrapy/utils/request.py
==================
474cba51;Pablo Hoffman;2011-06-06 03:13:28 -0300;simplified MemoryDebugger extension to use stats for dumping memory debugging info

==

docs/topics/extensions.rst
scrapy/contrib/memdebug.py
==================
5fbc32c0;Pablo Hoffman;2011-06-06 03:12:40 -0300;call stats collector engine_stopped() after the engine is closed (to make sure all data from extensions has been collected), and added that method to documented api

==

docs/topics/stats.rst
scrapy/core/engine.py
scrapy/statscol.py
==================
35b52fcd;Pablo Hoffman;2011-06-06 01:02:58 -0300;removed deprecated stat 'envinfo/request_depth_limit'. we should instead support dumping settings, for these cases

==

scrapy/contrib/spidermiddleware/depth.py
scrapy/tests/test_spidermiddleware_depth.py
==================
9d9c8877;Pablo Hoffman;2011-06-05 22:02:56 -0300;added 'scrapy edit' command

==

docs/topics/commands.rst
docs/topics/settings.rst
extras/scrapy_bash_completion
scrapy/commands/edit.py
scrapy/settings/default_settings.py
==================
ffbc9295;Pablo Hoffman;2011-06-05 20:03:09 -0300;simplified DownloaderStats middleware

==

scrapy/contrib/downloadermiddleware/stats.py
==================
3d823d6f;Pablo Hoffman;2011-06-05 19:57:38 -0300;simplified CoreStats extension

==

scrapy/contrib/corestats.py
==================
61cc95df;Pablo Hoffman;2011-06-03 18:26:17 -0300;removed crawlspider v2 tests

==

scrapy/tests/test_contrib_exp_crawlspider_matchers.py
scrapy/tests/test_contrib_exp_crawlspider_reqext.py
scrapy/tests/test_contrib_exp_crawlspider_reqgen.py
scrapy/tests/test_contrib_exp_crawlspider_reqproc.py
scrapy/tests/test_contrib_exp_crawlspider_rules.py
scrapy/tests/test_contrib_exp_crawlspider_spider.py
==================
03ae481c;Pablo Hoffman;2011-06-03 18:23:23 -0300;removed experimental crawlspider v2

==

docs/experimental/crawlspider-v2.rst
docs/experimental/index.rst
scrapy/contrib_exp/crawlspider/__init__.py
scrapy/contrib_exp/crawlspider/matchers.py
scrapy/contrib_exp/crawlspider/reqext.py
scrapy/contrib_exp/crawlspider/reqgen.py
scrapy/contrib_exp/crawlspider/reqproc.py
scrapy/contrib_exp/crawlspider/rules.py
scrapy/contrib_exp/crawlspider/spider.py
==================
5bf733b6;Pablo Hoffman;2011-06-03 01:13:01 -0300;Changed default representation of items to pretty-printed dicts. This improves default logging by making log more readable in the default case, for both Scraped and Dropped lines.
Projects can still customize how items are represented by overriding the item's __str__ method, as usual.

==

docs/intro/tutorial.rst
scrapy/item.py
scrapy/logformatter.py
scrapy/tests/test_command_shell.py
scrapy/tests/test_item.py
scrapy/tests/test_logformatter.py
==================
1bc2339b;Pablo Hoffman;2011-06-03 01:13:00 -0300;Merged item passed and item scraped concepts, as they have often proved confusing in the past.
This means:

* original item_scraped signal was removed
* original item_passed signal was renamed to item_scraped
* old log lines "Scraped Item..." removed
* old log lines "Passed Item..." renamed to "Scraped Item..."

==

docs/topics/signals.rst
scrapy/contrib/closespider.py
scrapy/contrib/corestats.py
scrapy/contrib/feedexport.py
scrapy/core/scraper.py
scrapy/logformatter.py
scrapy/signals.py
scrapy/tests/test_logformatter.py
==================
e6091df5;Pablo Hoffman;2011-05-30 09:04:31 -0300;fixed doc typo

==

docs/topics/spider-middleware.rst
==================
1d98fc8f;Pablo Hoffman;2011-05-29 22:38:17 -0300;added spider_error signal

==

docs/topics/signals.rst
scrapy/core/scraper.py
scrapy/signals.py
==================
13d80667;Pablo Hoffman;2011-05-27 11:52:33 -0300;removed undocumented (and untested) extension: SpiderCloseDelay

==

scrapy/contrib/spiderclosedelay.py
==================
6c369c50;Pablo Hoffman;2011-05-27 09:09:28 -0300;removed support for spider.dont_throttle attribute

==

scrapy/contrib/throttle.py
==================
2fa0f75f;Pablo Hoffman;2011-05-27 00:35:34 -0300;added COOKIES_ENABLED setting to support disabling the cookies middleware

==

docs/topics/downloader-middleware.rst
docs/topics/settings.rst
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/settings/default_settings.py
==================
756bf0cc;Pablo Hoffman;2011-05-27 00:22:13 -0300;register AutoThrottle extension by default, and made AUTOTHROTTLE_ENABLED disabled by default

==

scrapy/contrib/throttle.py
scrapy/settings/default_settings.py
==================
dcc28b71;Pablo Hoffman;2011-05-22 18:31:36 -0300;added setting: AUTOTHROTTLE_ENABLED

==

scrapy/contrib/throttle.py
==================
110cd052;Pablo Hoffman;2011-05-22 18:26:38 -0300;added Spider.dont_throttle attribute to disable AutoThrottle extension per spider

==

scrapy/contrib/throttle.py
==================
88dbe2ae;Shane Evans;2011-05-20 14:35:37 +0100;fix error messages due to fetching pages during shutdown process
This version keeps the faster approach of not processing request callbacks when engine is shutting down

==

scrapy/core/scheduler.py
scrapy/utils/datatypes.py
==================
3897e336;Pablo Hoffman;2011-05-20 03:52:41 -0300;fixed stupid bug in scheduler introduced in previous change

==

scrapy/core/scheduler.py
==================
70b0e42c;Pablo Hoffman;2011-05-20 03:26:07 -0300;removed unused imports

==

scrapy/core/scheduler.py
==================
d72d3f46;Pablo Hoffman;2011-05-20 03:25:00 -0300;stack trace dump extension: also dump engine status, and support triggering it with SIGQUIT, besides SIGUSR2

==

docs/topics/extensions.rst
scrapy/contrib/debug.py
==================
6069b0e5;Pablo Hoffman;2011-05-20 03:21:36 -0300;Fixed 100% cpu loop that ocurred in some cases where Scrapy was shutting donw

==

scrapy/core/scheduler.py
==================
951ba507;Pablo Hoffman;2011-05-19 21:42:46 -0300;Removed support for default values in Scrapy items, which have proven confusing in the past

==

docs/intro/tutorial.rst
docs/topics/items.rst
scrapy/item.py
scrapy/tests/test_djangoitem/__init__.py
scrapy/tests/test_item.py
==================
503f3020;Pablo Hoffman;2011-05-18 19:48:48 -0300;removed remaining references to scheduler middleware from doc, as it will be removed on next release

==

docs/intro/tutorial.rst
docs/topics/_images/scrapy_architecture.odg
docs/topics/_images/scrapy_architecture.png
docs/topics/architecture.rst
docs/topics/settings.rst
==================
3fd17432;Pablo Hoffman;2011-05-18 14:46:20 -0300;fixed outdated documentation

==

docs/topics/settings.rst
==================
9016e7e9;Pablo Hoffman;2011-05-18 14:43:34 -0300;added role to link to scrapy source code (not yet used)

==

docs/_ext/scrapydocs.py
==================
a98e9e05;Pablo Hoffman;2011-05-18 12:45:19 -0300;minor fix to spider closed count stat

==

scrapy/contrib/corestats.py
==================
cd85c12c;Pablo Hoffman;2011-05-18 12:32:34 -0300;Some Link extractor improvements:
* added support for ignoring common file extensions that are not followed if
  they occur in links
* fixed link extractor documentation issues
* slighly improved performance of applying filters
* added link to link extractors doc from documentation index

==

docs/index.rst
docs/topics/link-extractors.rst
scrapy/contrib/linkextractors/sgml.py
scrapy/linkextractor.py
scrapy/tests/test_contrib_linkextractors.py
scrapy/utils/url.py
==================
495152bd;Pablo Hoffman;2011-05-18 11:04:48 -0300;disabled verbose depth stats collection by default, added DEPTH_STATS_VERBOSE setting to enable it

==

docs/topics/settings.rst
scrapy/contrib/spidermiddleware/depth.py
scrapy/tests/test_spidermiddleware_depth.py
==================
accb6ed8;Pablo Hoffman;2011-05-17 22:42:05 -0300;dump stats to log by default (ie. change default value of STATS_DUMP to True)

==

docs/topics/settings.rst
scrapy/settings/default_settings.py
==================
315457c2;Pablo Hoffman;2011-05-17 22:07:49 -0300;added support for -a option to runspider command (like it works with crawl command)

==

scrapy/commands/runspider.py
==================
ab6a4d05;Pablo Hoffman;2011-05-16 09:56:32 -0300;minor code improvement

==

scrapy/contrib/throttle.py
==================
d29eccba;Pablo Hoffman;2011-05-16 09:42:44 -0300;AutoThrottle: added missing line to connect spider_closed hanlder

==

scrapy/contrib/throttle.py
==================
403dc536;Pablo Hoffman;2011-05-15 06:07:26 -0300;improved documentation of AutoThrottle extension

==

scrapy/contrib/throttle.py
==================
2b933a4a;Pablo Hoffman;2011-05-15 05:39:58 -0300;added AutoThrottle extension (still under testing, not yet enabled by default)

==

scrapy/contrib/throttle.py
==================
bd8d7f5c;Pablo Hoffman;2011-05-15 05:24:01 -0300;collect download latencies in 'download_latency' request/response meta key

==

scrapy/core/downloader/webclient.py
==================
668dfcab;Pablo Hoffman;2011-05-15 05:20:14 -0300;send the response_received signal from the engine, after tying it with the corresponding request

==

scrapy/core/downloader/__init__.py
scrapy/core/engine.py
==================
f9aa819b;Pablo Hoffman;2011-05-14 21:50:14 -0300;scraper: minor performance improvement by using collections.deque() as in downloader (see previous commit)

==

scrapy/core/scraper.py
==================
079de677;Pablo Hoffman;2011-05-14 21:47:25 -0300;downloader: minor performance improvement by using collections.deque() to avoid the list.pop(0) call which is O(n)

==

scrapy/core/downloader/__init__.py
==================
7e62a0a1;Pablo Hoffman;2011-05-14 21:35:46 -0300;Downloader: Added support for dynamically adjusting download delay and maximum concurrent requests

==

scrapy/core/downloader/__init__.py
scrapy/utils/python.py
==================
bac46ba4;Pablo Hoffman;2011-05-02 01:11:19 -0300;make sure Request.method is always str

==

scrapy/http/request/__init__.py
scrapy/tests/test_http_request.py
==================
afa23688;Pablo Hoffman;2011-05-01 19:39:13 -0300;fixed bug in scrapy.http.Headers: values weren't being encoded to str when passed as lists

==

scrapy/http/headers.py
scrapy/tests/test_http_headers.py
==================
7f97259b;Pablo Hoffman;2011-05-01 11:14:57 -0300;added w3lib to requirements, in installation guide

==

docs/intro/install.rst
setup.py
==================
718428c0;Pablo Hoffman;2011-05-01 11:00:02 -0300;debian/control: added python-setuptools to Recommends, because it's need by 'scrapy deploy' command

==

debian/control
==================
d08281a4;Pablo Hoffman;2011-04-30 01:35:43 -0300;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
4a831676;Pablo Hoffman;2011-04-30 01:35:30 -0300;fixed small doc typo

==

docs/faq.rst
==================
cf572bb6;Pablo Hoffman;2011-04-28 18:07:23 -0300;removed experimental examples

==

examples/experimental/googledir/googledir/__init__.py
examples/experimental/googledir/googledir/items.py
examples/experimental/googledir/googledir/pipelines.py
examples/experimental/googledir/googledir/settings.py
examples/experimental/googledir/googledir/spiders/__init__.py
examples/experimental/googledir/googledir/spiders/google_directory.py
examples/experimental/googledir/scrapy.cfg
examples/experimental/imdb/imdb/__init__.py
examples/experimental/imdb/imdb/items.py
examples/experimental/imdb/imdb/pipelines.py
examples/experimental/imdb/imdb/settings.py
examples/experimental/imdb/imdb/spiders/__init__.py
examples/experimental/imdb/imdb/spiders/imdb_site.py
examples/experimental/imdb/scrapy.cfg
==================
bb2b67c8;Pablo Hoffman;2011-04-28 09:31:57 -0300;updated tutorial to use 'dmoz' as the name of the spider instead of 'dmoz.org', so that it's more similar to the dirbot example project

==

docs/intro/tutorial.rst
==================
bf730024;Pablo Hoffman;2011-04-28 02:28:39 -0300;removed googledir example, replaced by dirbot project on github. updated docs accordingly

==

debian/scrapy.examples
docs/faq.rst
docs/index.rst
docs/intro/examples.rst
docs/intro/tutorial.rst
examples/googledir/googledir/__init__.py
examples/googledir/googledir/items.py
examples/googledir/googledir/pipelines.py
examples/googledir/googledir/settings.py
examples/googledir/googledir/spiders/__init__.py
examples/googledir/googledir/spiders/google_directory.py
examples/googledir/scrapy.cfg
==================
b12dd76b;Pablo Hoffman;2011-04-25 09:31:18 -0300;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
678f08bc;Pablo Hoffman;2011-04-25 09:30:42 -0300;added warning about using 'parse' as callback in crawl spider rules

==

docs/topics/spiders.rst
==================
18d303b5;Pablo Hoffman;2011-04-19 01:33:52 -0300;ported internal scrapy.utils imports to w3lib

==

scrapy/commands/crawl.py
scrapy/commands/deploy.py
scrapy/commands/fetch.py
scrapy/commands/parse.py
scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/feedexport.py
scrapy/contrib/linkextractors/htmlparser.py
scrapy/contrib/linkextractors/image.py
scrapy/contrib/linkextractors/lxmlparser.py
scrapy/contrib/linkextractors/regex.py
scrapy/contrib/linkextractors/sgml.py
scrapy/contrib_exp/crawlspider/reqext.py
scrapy/core/downloader/handlers/file.py
scrapy/http/headers.py
scrapy/http/request/__init__.py
scrapy/shell.py
scrapy/tests/test_contrib_feedexport.py
scrapy/tests/test_downloader_handlers.py
scrapy/utils/misc.py
scrapy/utils/request.py
==================
fcc8d738;Pablo Hoffman;2011-04-19 01:04:22 -0300;Removed scrapy.contrib.ibl module (and submodules). They have been moved to a new library "scrapely". See https://github.com/scrapy/scrapely

==

scrapy/contrib/ibl/__init__.py
scrapy/contrib/ibl/descriptor.py
scrapy/contrib/ibl/extraction/__init__.py
scrapy/contrib/ibl/extraction/pageobjects.py
scrapy/contrib/ibl/extraction/pageparsing.py
scrapy/contrib/ibl/extraction/regionextract.py
scrapy/contrib/ibl/extraction/similarity.py
scrapy/contrib/ibl/extractors.py
scrapy/contrib/ibl/htmlpage.py
scrapy/tests/test_contrib_ibl/__init__.py
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_0.html
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_0.json
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_1.html
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_1.json
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_2.html
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_2.json
scrapy/tests/test_contrib_ibl/samples/samples_pageparsing_0.html
scrapy/tests/test_contrib_ibl/samples/samples_pageparsing_0.json
scrapy/tests/test_contrib_ibl/test_extraction.py
scrapy/tests/test_contrib_ibl/test_extractors.py
scrapy/tests/test_contrib_ibl/test_htmlpage.py
scrapy/tests/test_contrib_ibl/test_htmlpage_data.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
==================
ebcbb9f4;Pablo Hoffman;2011-04-19 00:55:08 -0300;debian: added python-w3lib package to dependencies

==

debian/control
==================
b10f4fae;Pablo Hoffman;2011-04-18 22:37:19 -0300;Moved several functions from scrapy.utils.{http,markup,multipart,response,url} (and their tests) to a new library called 'w3lib'. Scrapy will now depend on w3lib.

==

debian/control
scrapy/tests/test_utils_http.py
scrapy/tests/test_utils_markup.py
scrapy/tests/test_utils_response.py
scrapy/tests/test_utils_url.py
scrapy/utils/http.py
scrapy/utils/markup.py
scrapy/utils/multipart.py
scrapy/utils/response.py
scrapy/utils/url.py
setup.py
==================
ad496eb3;Pablo Hoffman;2011-04-14 12:36:27 -0300;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
ecb4f44c;Pablo Hoffman;2011-04-14 12:36:09 -0300;Added clarification on how to work with local settings and scrapy deploy

==

docs/topics/scrapyd.rst
==================
6f262a19;Pablo Hoffman;2011-04-12 18:12:36 -0300;Added IOError to the list of exceptions to retry in the RetryMiddleware

==

scrapy/contrib/downloadermiddleware/retry.py
==================
7c49e867;Pablo Hoffman;2011-04-07 02:04:42 -0300;fixed typo

==

README
==================
3ee2c94e;Pablo Hoffman;2011-04-06 14:54:48 -0300;Improved cookies middleware by making COOKIES_DEBUG nicer and documenting it

==

docs/faq.rst
docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
scrapy/contrib/downloadermiddleware/cookies.py
==================
8a5c08a6;Pablo Hoffman;2011-03-24 13:15:52 -0300;added join_multivalued parameter to CsvItemExporter

==

docs/topics/exporters.rst
scrapy/contrib/exporter/__init__.py
scrapy/tests/test_contrib_exporter.py
==================
84dee1f7;Pablo Hoffman;2011-03-24 09:03:57 -0300;removed unused function

==

scrapy/utils/request.py
==================
3954e600;Pablo Hoffman;2011-03-23 21:32:02 -0300;added DBM storage backend for HTTP cache

==

docs/topics/downloader-middleware.rst
scrapy/contrib/httpcache.py
scrapy/settings/default_settings.py
==================
60f6a9b0;Pablo Hoffman;2011-03-23 15:45:40 -0300;moved scrapyd python module to scrapy debian package. left scrapyd package only for installing service (upstart script) and scrapy user

==

debian/scrapy.install
debian/scrapyd.install
==================
407f7f2d;Shane Evans;2011-03-11 21:58:47 +0000;fix minor error in IBL tests and post-processing nested annoations

==

scrapy/contrib/ibl/extractors.py
scrapy/tests/test_contrib_ibl/test_extraction.py
==================
bc6eee71;Shane Evans;2011-03-11 20:02:29 +0000;refactor IBL extraction to allow processing parsed data
--HG--
extra : rebase_source : 1a0ec4322702288f6e996d384d45a36deede3868

==

scrapy/contrib/ibl/descriptor.py
scrapy/contrib/ibl/extraction/pageobjects.py
scrapy/contrib/ibl/extraction/pageparsing.py
scrapy/contrib/ibl/extraction/regionextract.py
scrapy/contrib/ibl/extractors.py
scrapy/contrib/ibl/htmlpage.py
scrapy/tests/test_contrib_ibl/test_extraction.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
==================
9591413d;Pablo Hoffman;2011-03-09 14:24:17 -0200;added Jochen Maes to AUTHORS

==

AUTHORS
==================
47a7f154;Jochen Maes;2011-03-09 14:22:10 -0200;Add listjobs.json to Scrapyd API You can use listjobs.json with project=<projectname> to get a list of projects that are running currently. It returns a list of jobs with spidername and job-id.
Signed-off-by: Jochen Maes <jochen.maes@sejo.be>
---
 scrapyd/webservice.py |    9 +++++++++
 scrapyd/website.py    |    1 +
 2 files changed, 10 insertions(+), 0 deletions(-)

==

scrapyd/webservice.py
scrapyd/website.py
==================
99033d91;Pablo Hoffman;2011-03-09 12:41:26 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
36431a14;Pablo Hoffman;2011-03-09 12:39:24 -0200;Silenced confusing sqlite3.ProgrammingError exception. For more info see: http://twistedmatrix.com/trac/ticket/4040

==

scrapy/utils/sqlite.py
==================
5cae22b6;Shane Evans;2011-02-25 12:55:51 -0200;add nofollow to Link object

==

scrapy/link.py
==================
cfd11df5;Pablo Hoffman;2011-02-24 15:28:57 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
8f7e163b;Pablo Hoffman;2011-02-24 15:26:32 -0200;Fixed wrong method name in downloader middleware documentation

==

docs/topics/downloader-middleware.rst
==================
32fa2add;Shane Evans;2011-02-24 14:21:23 -0200;style fix to ibl contrib

==

scrapy/contrib/ibl/extraction/regionextract.py
==================
fe9febe2;Pablo Hoffman;2011-02-23 18:10:16 -0200;added --build-only option to deploy command, to build the egg without deploying it

==

scrapy/commands/deploy.py
==================
af4db276;Shane Evans;2011-02-16 18:31:49 -0200;Automated merge with ssh://hg.scrapy.org/scrapy-0.12

==
==================
74413ff9;Shane Evans;2011-02-16 18:30:50 -0200;prevent incorrect assertion error possible when spiders are closing

==

scrapy/core/engine.py
==================
c5535564;Daniel Grana;2011-02-16 08:57:42 -0200;fix FAQ typos reported by marlun_ at #scrapy IRC channel

==

docs/faq.rst
==================
a1c3fa5d;Shane Evans;2011-02-15 15:42:10 -0200;small refactor of image extraction

==

scrapy/contrib/ibl/extractors.py
==================
1fb55bda;Pablo Hoffman;2011-02-15 07:25:12 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
16d9a339;Pablo Hoffman;2011-02-15 07:24:52 -0200;added FAQ entry about working with big data feeds

==

docs/faq.rst
==================
9b07b0ab;Ismael Carnales;2011-02-11 11:41:44 -0200;Fix xmliter_lxml

==

scrapy/contrib_exp/iterators.py
scrapy/tests/test_utils_iterators.py
==================
874bfa02;Pablo Hoffman;2011-02-10 17:41:13 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
3dc67772;Pablo Hoffman;2011-02-10 17:27:40 -0200;Fixed scrapy.utils.python unittests

==

scrapy/tests/test_utils_python.py
==================
e9f3724f;Pablo Hoffman;2011-02-10 17:12:37 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
ce8137b7;Pablo Hoffman;2011-02-10 17:12:03 -0200;Replace unknown characters in sgml link extractor, to deal more gracefully with encoding errors in the page. Closes #309

==

scrapy/contrib/linkextractors/lxmlparser.py
scrapy/contrib/linkextractors/sgml.py
scrapy/tests/test_contrib_linkextractors.py
scrapy/tests/test_utils_python.py
scrapy/utils/python.py
==================
bfc6c380;Ismael Carnales;2011-02-09 16:20:48 -0200;Add namespace support to xmliter_lxml

==

scrapy/contrib_exp/iterators.py
scrapy/tests/test_utils_iterators.py
==================
936353d5;Pablo Hoffman;2011-02-09 11:20:46 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
181d1c09;Pablo Hoffman;2011-02-09 11:19:46 -0200;Fixed typo and code indentation in the doc. Closes #307 and #308

==

docs/intro/tutorial.rst
==================
c91f0d9e;Pablo Hoffman;2011-02-04 13:39:54 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
c5499ead;Pablo Hoffman;2011-02-04 13:39:12 -0200;Clarified behaviour when multiple rules match the same link in CrawlSpider

==

docs/topics/spiders.rst
==================
dde4ccf6;Pablo Hoffman;2011-02-04 13:30:37 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
65fc2fbd;Pablo Hoffman;2011-02-04 13:30:01 -0200;Set CONCURRENT_SPIDERS=1 in Scrapyd to force one spider per process

==

scrapyd/environ.py
scrapyd/tests/test_environ.py
==================
c4fd7174;Pablo Hoffman;2011-01-28 16:24:18 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
b1c89508;Pablo Hoffman;2011-01-28 16:22:39 -0200;fixed wrong changes commited in previous changeset

==

debian/changelog
debian/control
==================
43611504;Pablo Hoffman;2011-01-28 16:21:00 -0200;added missing scrapyd/default_scrapyd.conf file to MANIFEST.in

==

MANIFEST.in
debian/changelog
debian/control
==================
632bc27d;Pablo Hoffman;2011-01-25 19:51:17 -0200;added tests for Link object

==

scrapy/tests/test_link.py
==================
c5351d2f;Shane Evans;2011-01-25 19:23:50 -0200;add __hash__ method to Link object to be compatible with the __eq__ method

==

scrapy/link.py
==================
32adbea5;Martin Olveyra;2011-01-24 18:40:42 -0200;handle case when attributes are not separated by space (still recognizable because of quotes)

==

scrapy/contrib/ibl/htmlpage.py
scrapy/tests/test_contrib_ibl/test_htmlpage.py
scrapy/tests/test_contrib_ibl/test_htmlpage_data.py
==================
18e097d4;Pablo Hoffman;2011-01-13 13:14:57 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
09f084c2;Pablo Hoffman;2011-01-13 13:11:39 -0200;simplified scrapy shell code after recent changes. refs #306

==

scrapy/shell.py
==================
0aac226b;Pablo Hoffman;2011-01-13 13:08:11 -0200;Fixed bug in Scrapy shell's fetch() which wasn't updating local variables properly. Closes #306

==

scrapy/shell.py
==================
c87fef9c;Pablo Hoffman;2011-01-11 17:24:33 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
0c5f605b;LucianU;2011-01-11 17:23:46 -0200;The xmlfeed.tmpl file didn't use the naming convention specific of the XMLFeedSpider. Namely, it used parse_item (which has been deprecated) instead of parse_node and it didn't show the iterator and itertag attributes.

==

scrapy/templates/spiders/xmlfeed.tmpl
==================
1b319a94;Pablo Hoffman;2011-01-11 17:04:21 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
7dc521c5;Pablo Hoffman;2011-01-11 17:03:51 -0200;make scrapyd package depend on specific scrapy version

==

debian/control
==================
7f7a9523;Pablo Hoffman;2011-01-05 16:04:33 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
048044c1;Pablo Hoffman;2011-01-05 15:59:43 -0200;A couple of changes to fix #303:
* improved detection of inside-project environments
* make list command faster (by only instantiating the spider manger)
* print a warning when extensions (middlewares, etc) are disabled with a message on NotConfigured exception
* assert that scrapy configuration hasn't been loaded in scrapyd.runner
* simplified IgnoreRequest exception, to avoid loading settings when importing scrapy.exceptions
* added test to make sure certain modules don't cause scrapy.conf module to be
  loaded, to ensure the scrapyd runner bootstraping performs properly

==

scrapy/cmdline.py
scrapy/commands/list.py
scrapy/core/engine.py
scrapy/exceptions.py
scrapy/middleware.py
scrapy/utils/project.py
scrapyd/runner.py
scrapyd/tests/test_dont_load_settings.py
scrapyd/tests/test_utils.py
==================
48b30ba9;Pablo Hoffman;2011-01-05 12:03:54 -0200;fixed compatibility with python 2.5 and removed unused code

==

scrapy/utils/memory.py
==================
ebf5ad93;Pablo Hoffman;2011-01-05 11:59:19 -0200;fixed compatibility with python 2.5 and removed unused code

==

scrapy/utils/memory.py
==================
0ba9999c;Martin Olveyra;2011-01-05 11:02:05 -0200;Handle badformed tags with no trailing >

==

scrapy/contrib/ibl/htmlpage.py
scrapy/tests/test_contrib_ibl/test_extraction.py
scrapy/tests/test_contrib_ibl/test_htmlpage.py
scrapy/tests/test_contrib_ibl/test_htmlpage_data.py
==================
579463af;Pablo Hoffman;2011-01-04 13:57:32 -0200;make scrapy*-0.13 packages conflict with scrapy*-0.12 packages

==

debian/control
==================
744b146a;Pablo Hoffman;2011-01-04 13:57:10 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
ac816625;Pablo Hoffman;2011-01-04 13:56:28 -0200;make scrapy*-0.12 packages conflict with scrapy*-0.11 packages

==

debian/control
==================
d7f193cb;Pablo Hoffman;2011-01-02 17:29:43 -0200;bumped version to 0.13 in documentation

==

docs/topics/scrapyd.rst
docs/topics/ubuntu.rst
==================
a7c80d0a;Pablo Hoffman;2011-01-02 17:28:57 -0200;Automated merge with ssh://hg.scrapy.org:2222/scrapy-0.12

==
==================
b56e933b;Pablo Hoffman;2011-01-02 17:28:33 -0200;bumped version to 0.12 in documentation

==

docs/topics/scrapyd.rst
docs/topics/ubuntu.rst
==================
cd42bd7d;Pablo Hoffman;2011-01-02 17:21:31 -0200;Bumped version to 0.13

==

scrapy/__init__.py
==================
5879389a;Pablo Hoffman;2011-01-02 16:16:40 -0200;Bumped version to 0.12

==

docs/_templates/page.html
scrapy/__init__.py
==================
fe218abb;Vikas Dhiman;2011-01-02 15:46:11 -0200;scrapy.utils.memory.get_vmvalue_from_procfs() causes test case failure on SunOS 5.10 i86pc. Modified it to support SunOS 5.10

==

AUTHORS
scrapy/utils/memory.py
==================
aebe5d50;Shane Evans;2010-12-28 15:34:39 -0200;make inside_project work with SCRAPY_SETTINGS_MODULE. Closes #300

==

scrapy/utils/project.py
==================
3d8b368f;Pablo Hoffman;2010-12-28 11:16:58 -0200;scrapyd: use runner from config (if not specified) on get_spider_list()

==

scrapyd/utils.py
==================
fa644f7a;Pablo Hoffman;2010-12-27 16:22:32 -0200;Some simplifications to Scrapyd architecture and internals:
- launcher no longer knows about egg storage
- removed get_spider_list_from_eggifile() file and replaced by simpler
  get_spider_list() which doesn't receive en egg file as argument
- changed "egg runner" name to just "runner" to reflect the fact that it
  doesn't necesarilly run eggs (though it does in the default case)

--HG--
rename : scrapyd/eggrunner.py => scrapyd/runner.py

==

docs/topics/scrapyd.rst
scrapyd/default_scrapyd.conf
scrapyd/eggrunner.py
scrapyd/eggutils.py
scrapyd/environ.py
scrapyd/interfaces.py
scrapyd/launcher.py
scrapyd/runner.py
scrapyd/tests/test_eggutils.py
scrapyd/tests/test_environ.py
scrapyd/tests/test_utils.py
scrapyd/utils.py
scrapyd/webservice.py
scrapyd/website.py
==================
9cd649b3;Pablo Hoffman;2010-12-26 19:32:56 -0200;scrapyd: populate SCRAPY_SPIDER and SCRAPY_JOB environment variables

==

scrapyd/environ.py
scrapyd/tests/test_environ.py
==================
1c8d74eb;Pablo Hoffman;2010-12-24 12:47:59 -0200;scrapyd: populate SCRAPY_SLOT environment variable with the scrapyd slot number

==

scrapyd/environ.py
scrapyd/tests/test_environ.py
==================
d9a3df45;Martin Olveyra;2010-12-23 14:40:22 -0200;Remove deprecated match common prefix feature from IBL code

==

scrapy/contrib/ibl/extraction/__init__.py
scrapy/contrib/ibl/extraction/pageobjects.py
scrapy/contrib/ibl/extraction/pageparsing.py
scrapy/contrib/ibl/extraction/regionextract.py
scrapy/tests/test_contrib_ibl/test_extraction.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
==================
633ebc4c;Pablo Hoffman;2010-12-23 13:04:49 -0200;minor indentation improvement

==

docs/_templates/page.html
==================
db07a9a9;Pablo Hoffman;2010-12-23 13:03:40 -0200;Added notice to documentation, pointing dev to stable versions and viceversa

==

docs/_static/scrapydoc.css
docs/_templates/page.html
docs/conf.py
==================
544308d6;Pablo Hoffman;2010-12-21 11:02:56 -0200;updated ubuntu repos doc, in preparation for the 0.11 release

==

docs/topics/ubuntu.rst
==================
fff22c26;Pablo Hoffman;2010-12-20 15:16:21 -0200;Added test to make sure custom mime.types shipped with Scrapy is loaded, and made Scrapy more egg-friendly by using pkutil.get_data()

==

scrapy/core/downloader/responsetypes/__init__.py
scrapy/core/downloader/responsetypes/mime.types
scrapy/tests/test_responsetypes.py
==================
87aa63da;Pablo Hoffman;2010-12-15 12:08:59 -0200;moved coverage report script to extras/

==

Makefile.buildbot
extras/coverage-report.sh
==================
432251be;Pablo Hoffman;2010-12-15 11:13:45 -0200;Added rules to Makefile.buildbot for generating coverage reports

==

.coveragerc
Makefile.buildbot
==================
63c97f65;Pablo Hoffman;2010-12-14 18:21:07 -0200;fixed csviter bug when called with a Response, not TextResponse

==

scrapy/tests/test_utils_iterators.py
scrapy/utils/iterators.py
==================
55ec7a05;Pablo Hoffman;2010-12-14 17:20:31 -0200;deploy command: cleanup temporary files before doing a new build

==

scrapy/commands/deploy.py
==================
3df9070f;Pablo Hoffman;2010-12-14 12:20:38 -0200;fixed bin\runtests.bat windows script

==

bin/runtests.bat
==================
002abf20;Pablo Hoffman;2010-12-13 14:05:47 -0200;Updated item_passed signal to send passed item in 'item' argument, instead of 'output' argument, keeping backwards compatibility for the 'output' argument. Closes #273

==

docs/topics/signals.rst
scrapy/core/scraper.py
==================
f984d438;Pablo Hoffman;2010-12-13 14:02:42 -0200;updated docs to use scrapy version on aptitude install lines

==

docs/topics/scrapyd.rst
docs/topics/ubuntu.rst
==================
60bdb7dc;Pablo Hoffman;2010-12-13 10:34:07 -0200;Removed some deprecated code and modules

==

scrapy/__init__.py
scrapy/core/exceptions.py
scrapy/core/manager.py
scrapy/core/queue.py
scrapy/core/signals.py
==================
97a790d6;Pablo Hoffman;2010-12-13 10:21:39 -0200;improved mechanism for tagging version with hg revision

==

scrapy/__init__.py
setup.py
==================
119fd20e;Pablo Hoffman;2010-12-13 00:32:44 -0200;Added verbose option to 'version' command. Closes #298

==

docs/contributing.rst
docs/topics/commands.rst
scrapy/commands/version.py
==================
6f2cea47;Pablo Hoffman;2010-12-12 20:04:35 -0200;added deprecation messages to queue and runserver commands

==

scrapy/commands/queue.py
scrapy/commands/runserver.py
==================
b19ff21a;Pablo Hoffman;2010-12-10 15:55:40 -0200;scrapyd: added support for deferred spider queues

==

scrapyd/poller.py
==================
02ccca01;Martin Olveyra;2010-12-08 16:28:38 -0200;use safe_url_string in canonicalize_url, to avoid to convert safe characters into percent representation. Lead to errors with many sites (RFC3986). closes #297

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
6a1b69c9;Pablo Hoffman;2010-11-30 20:23:27 -0200;renamed command 'scrapyd' to 'server', and deprecated 'runserver' and 'queue' commands
--HG--
rename : scrapy/commands/scrapyd.py => scrapy/commands/server.py

==

docs/topics/commands.rst
docs/topics/scrapyd.rst
scrapy/commands/queue.py
scrapy/commands/runserver.py
scrapy/commands/server.py
==================
831dc818;Pablo Hoffman;2010-11-30 18:43:59 -0200;scrapyd: added more information webui homepage

==

scrapyd/website.py
==================
a3d30c35;Pablo Hoffman;2010-11-30 17:58:34 -0200;scrapyd: log url where web console can be accesed

==

scrapyd/app.py
==================
823fd982;Pablo Hoffman;2010-11-30 16:19:17 -0200;scrapyd: fixed bug discovering the current project scrapy.cfg file

==

scrapyd/config.py
==================
7b84591e;Pablo Hoffman;2010-11-30 15:52:15 -0200;added command for starting a scrapyd server for the current project

==

scrapy/commands/scrapyd.py
scrapyd/script.py
==================
5a46ce47;Pablo Hoffman;2010-11-30 15:47:05 -0200;scrapyd: add extra_sources consturctor argument, and also read scrapyd configuratoin from current project's scrapy.cfg file

==

scrapyd/config.py
==================
c02d6db6;Pablo Hoffman;2010-11-30 15:46:24 -0200;scrapyd: force application to receive config as argument

==

scrapyd/__init__.py
scrapyd/app.py
==================
85890a50;Pablo Hoffman;2010-11-30 15:45:42 -0200;scrapyd: log process logfile when process starts/finishes

==

scrapyd/launcher.py
==================
5c4f562e;Pablo Hoffman;2010-11-30 13:03:20 -0200;scrapyd: changed keys used in poller message to _project, _spider, _job, and added link to log file in web ui

==

scrapyd/environ.py
scrapyd/interfaces.py
scrapyd/launcher.py
scrapyd/poller.py
scrapyd/tests/test_environ.py
scrapyd/tests/test_poller.py
scrapyd/tests/test_utils.py
scrapyd/utils.py
scrapyd/webservice.py
scrapyd/website.py
==================
df54ed00;Pablo Hoffman;2010-11-30 02:26:31 -0200;Some Scrapyd enhancements:
* added minimal web ui
* return unique id per job (spider scheduled)
* store one log per spider run (job) and rotate them, keeping the last N logs (where N is configurable through settings)

==

docs/topics/scrapyd.rst
scrapyd/app.py
scrapyd/default_scrapyd.conf
scrapyd/environ.py
scrapyd/interfaces.py
scrapyd/launcher.py
scrapyd/tests/test_environ.py
scrapyd/tests/test_utils.py
scrapyd/utils.py
scrapyd/webservice.py
scrapyd/website.py
==================
46e5d694;Pablo Hoffman;2010-11-29 17:22:28 -0200;Scrapyd: return project and version in addversion.json

==

scrapyd/webservice.py
==================
bbffa594;Pablo Hoffman;2010-11-29 17:19:05 -0200;Some changes to Scrapyd:
* Always start one process per spider
* Added max_proc_per_cpu option (defaults to 4)
* Return the number of spiders (instead of a list of them) in schedule.json

==

docs/topics/scrapyd.rst
scrapyd/default_scrapyd.conf
scrapyd/launcher.py
scrapyd/poller.py
scrapyd/tests/test_poller.py
scrapyd/tests/test_utils.py
scrapyd/utils.py
scrapyd/webservice.py
==================
42e8346d;Pablo Hoffman;2010-11-29 10:27:12 -0200;fixed failing test on win32

==

scrapy/tests/test_command_fetch.py
==================
3cda6817;Pablo Hoffman;2010-11-29 09:56:14 -0200;utils.testproc: make spawned process use the original CWD, instead of the temporary one created by twisted trial

==

scrapy/utils/testproc.py
==================
1d726063;Pablo Hoffman;2010-11-28 18:14:45 -0200;* Added tests for shell/fetch/version commands (closes #255) * Fixed bug causing Scrapy shell to fail if started without any argument (closes #294)

==

scrapy/shell.py
scrapy/tests/test_command_fetch.py
scrapy/tests/test_command_shell.py
scrapy/tests/test_command_version.py
scrapy/utils/testproc.py
scrapy/utils/testsite.py
==================
6f82ea19;Pablo Hoffman;2010-11-25 12:12:42 -0200;Fixed bug in addversion.json with old Twisted versions. Closes #293

==

scrapy/webservice.py
==================
2557777c;Pablo Hoffman;2010-11-24 13:27:44 -0200;Updated doc referring to HTTP cache middleware

==

docs/topics/extensions.rst
==================
d59ef482;Pablo Hoffman;2010-11-23 17:28:29 -0200;Fixed SgmlLinkExtractor bug which failed to recognize <base> tags when using restrict_xpaths

==

scrapy/contrib/linkextractors/sgml.py
scrapy/tests/test_contrib_linkextractors.py
==================
426b6fa1;Pablo Hoffman;2010-11-22 13:50:19 -0200;docs/intro/install.rst: added -U flag to easy_install command

==

docs/intro/install.rst
==================
91e67530;Pablo Hoffman;2010-11-22 00:39:45 -0200;scrapy.bat: minor fix to support spaces in python installation dir (windows)

==

extras/scrapy.bat
==================
91a7c257;Pablo Hoffman;2010-11-18 12:51:54 -0200;* Made Response.meta attribute map to Request.meta attribute. Closes #290 * Record redirected URLs in redirect middleware. Closes #291

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/http/response/__init__.py
scrapy/http/response/text.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_http_response.py
==================
ac007802;Pablo Hoffman;2010-11-17 21:32:23 -0200;Simplified installation guide, including lxml as alternative dependency to libxml2. Closes #280

==

docs/faq.rst
docs/intro/install.rst
==================
2897061b;Pablo Hoffman;2010-11-17 17:30:22 -0200;Make scrapy conflict with previous versionsof the debian package

==

debian/control
==================
3926ca45;Pablo Hoffman;2010-11-17 17:08:21 -0200;debian/control: Added scrapy/scrapyd to Provides

==

debian/control
==================
a034d078;Pablo Hoffman;2010-11-17 17:03:00 -0200;Changed Debian packaging to use the scrapy version in the package name, so we can have multiple Scrapy versions in the same apt repo
--HG--
rename : debian/scrapy.1 => debian/scrapy-files/scrapy.1
rename : debian/000-default => debian/scrapyd-files/000-default
rename : debian/scrapyd.upstart => debian/scrapyd.scrapyd.upstart
rename : debian/scrapy.1 => extras/scrapy.1

==

Makefile.buildbot
debian/changelog
debian/control
debian/rules
debian/scrapy-files/scrapy.1
debian/scrapy.manpages
debian/scrapyd-files/000-default
debian/scrapyd.install
debian/scrapyd.scrapyd.upstart
extras/makedeb.py
extras/scrapy.1
==================
67adb2a0;Pablo Hoffman;2010-11-17 00:09:14 -0200;Always use micro versions in Scrapy from now on

==

scrapy/__init__.py
==================
5a5364d0;Pablo Hoffman;2010-11-16 03:31:04 -0200;Updated documentation to point out that simplejson is now required if using Python 2.5, and to recommended switching to Python 2.6

==

docs/faq.rst
docs/intro/install.rst
==================
7c712eed;Pablo Hoffman;2010-11-16 03:11:12 -0200;Removed scrapy.xlib.simplejson module. Scrapy now requires simplejson if running on Python 2.5. Closes #289

==

scrapy/utils/py26.py
scrapy/xlib/simplejson/__init__.py
scrapy/xlib/simplejson/decoder.py
scrapy/xlib/simplejson/encoder.py
scrapy/xlib/simplejson/ordered_dict.py
scrapy/xlib/simplejson/scanner.py
scrapy/xlib/simplejson/tool.py
setup.py
==================
28cf8625;Pablo Hoffman;2010-11-16 02:37:19 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
5ded8251;Pablo Hoffman;2010-11-16 02:36:18 -0200;Fixed bug with deferred spider queues. Closes #288

==

scrapy/queue.py
==================
b3c96c69;Pablo Hoffman;2010-11-13 16:38:30 -0200;Fixed bug with deploy command if ~/.netrc doesn't exist. Closes #286

==

scrapy/commands/deploy.py
==================
e1f419e9;Pablo Hoffman;2010-11-12 16:47:36 -0200;canonicalize_url(): ignore case in domain names

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
b4cc2d91;Martin Olveyra;2010-11-12 13:30:39 -0200;Allow to reapply a labelled region so to allow to use ignored regions inside repeated variants

==

scrapy/contrib/ibl/extraction/regionextract.py
scrapy/tests/test_contrib_ibl/test_extraction.py
==================
08bbbc2f;Pablo Hoffman;2010-11-11 18:05:36 -0200;shell: properly refresh all vars when fetching a new request

==

scrapy/shell.py
==================
5c18f02a;Pablo Hoffman;2010-11-11 18:00:02 -0200;Only instantiate XPath selectors if the response is of the proper type. Closes #285

==

scrapy/shell.py
==================
4e800e90;Pablo Hoffman;2010-11-10 13:36:05 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
7698ff2a;Pablo Hoffman;2010-11-10 13:35:36 -0200;Disabled help() in telnet console. Closes #284

==

scrapy/telnet.py
==================
d988ca1e;Pablo Hoffman;2010-11-08 17:01:06 -0200;Some changes to scrapy deploy command:
* changed deploy section names to [deploy:target]
* project is now passed through a -p|--project option
* version can now be set in the target configuration
* switched meaning of -l and -L options

* updated documentation accordingly

==

docs/topics/scrapyd.rst
scrapy/commands/deploy.py
scrapy/templates/project/scrapy.cfg
==================
37c9d5fe;Pablo Hoffman;2010-11-08 02:19:54 -0200;minor update to queue command doc

==

scrapy/commands/queue.py
==================
5bdffadb;Pablo Hoffman;2010-11-05 11:48:12 -0200;Simplified get_spider_list_from_eggfile() function now that it doesn't need to chdir to a custom directory (Scrapy now works when it's unable to create the SQLite database)

==

scrapyd/eggutils.py
==================
31bbcc94;Pablo Hoffman;2010-11-05 11:24:33 -0200;Raise error when egg is corrupt in activate_egg(). Use a more descriptive name for temporary dirs in get_spider_list_from_eggfile(). Make scrapyd webservice pass egg_runner to get_spider_list_from_eggfile()

==

scrapyd/eggutils.py
scrapyd/webservice.py
==================
de4909fa;Pablo Hoffman;2010-11-04 18:56:11 -0200;get_spider_list_from_eggfile(): more improvements to error messages, and support passing eggruner module as argument

==

scrapyd/eggutils.py
==================
7ba972d8;Pablo Hoffman;2010-11-04 16:27:47 -0200;get_spider_list_from_eggfile(): fail if unable to extract spider list

==

scrapyd/eggutils.py
==================
369a149d;Pablo Hoffman;2010-11-03 17:16:08 -0200;fixed bug with deploy command in windows environments: WindowsError: [Error 32] The process cannot access the file because it is being used by another process

==

scrapy/commands/deploy.py
==================
a6c6dfe9;Pablo Hoffman;2010-11-01 16:10:40 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
1a2146d1;Pablo Hoffman;2010-11-01 16:09:33 -0200;Fixed bug detecting response types for some urls. Closes #281

==

scrapy/core/downloader/responsetypes/__init__.py
==================
0f69e7a1;Pablo Hoffman;2010-11-01 02:38:15 -0200;Some changes to HTTP Cache middleware:
* made it use the project data storage by default (closes #279)
* added HTTPCACHE_ENABLED setting (False by default) to enable it
* made HTTPCACHE_DIR = 'httpcache' by default (inside the project data storage)
* simplified HTTPCACHE_EXPIRATION_SECS semantics: zero means don't expire,
  dropped support for negative numbers
* other minor doc improvements

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/settings/default_settings.py
scrapy/tests/test_downloadermiddleware_httpcache.py
scrapy/utils/project.py
==================
3c94c6cb;Pablo Hoffman;2010-11-01 02:31:20 -0200;fixed sphinx doc id

==

docs/topics/telnetconsole.rst
==================
0b7e8158;Pablo Hoffman;2010-11-01 01:25:30 -0200;Added Didier to AUTHORS

==

AUTHORS
==================
13027660;dfdeshom;2010-11-01 00:59:04 -0200;Bind the web server and telnet server to a configurable interface (WEBSERVICE_HOST). The default is to bind to all interfaces. Also add documentation for WEBSERVICE_HOST and TELNETCONSOLE_HOST.

==

docs/topics/telnetconsole.rst
docs/topics/webservice.rst
scrapy/settings/default_settings.py
scrapy/telnet.py
scrapy/utils/reactor.py
scrapy/webservice.py
==================
b76c5c59;Pablo Hoffman;2010-10-31 03:25:37 -0200;* Added support for project data storage (closes #276) * Documented project file structure * Moved default location of SQLite database to project data storage dir (closes #277)

==

docs/topics/commands.rst
docs/topics/settings.rst
scrapy/contrib/spidercontext.py
scrapy/spiderqueue.py
scrapy/utils/project.py
scrapy/utils/python.py
==================
dfa6745e;Pablo Hoffman;2010-10-30 16:05:53 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
a0d9b430;Pablo Hoffman;2010-10-30 16:05:32 -0200;fixed typo in scrapyd doc

==

docs/topics/scrapyd.rst
==================
3d96016d;Pablo Hoffman;2010-10-30 16:03:00 -0200;runtests.sh: switched to 'text' repoter in trial

==

bin/runtests.sh
==================
f73449fe;Pablo Hoffman;2010-10-30 16:02:14 -0200;removed LxmlItemLoader, as it has been obsoleted by the new lxml selector backend

==

scrapy/contrib_exp/loader/__init__.py
scrapy/contrib_exp/loader/lxmlloader.py
scrapy/tests/test_contrib_exp_loader_lxmlloader.py
==================
d67152ab;Pablo Hoffman;2010-10-30 01:56:12 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
75451cbe;Pablo Hoffman;2010-10-30 01:56:00 -0200;scrapyd doc: fixed delversion.json example

==

docs/topics/scrapyd.rst
==================
20efdc02;Pablo Hoffman;2010-10-29 16:21:36 -0200;added --egg argument to scrapy deploy command, and log message when building the egg

==

scrapy/commands/deploy.py
==================
85dec826;Pablo Hoffman;2010-10-29 03:42:54 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
1cc5cba6;Pablo Hoffman;2010-10-29 03:42:21 -0200;Fixed bug logging Passed items. Closes #274

==

scrapy/core/scraper.py
==================
836e4089;Pablo Hoffman;2010-10-29 02:23:10 -0200;minor fixes for python 2.5 compatibility

==

scrapy/commands/deploy.py
==================
22283854;Pablo Hoffman;2010-10-27 21:39:28 -0200;avoid stripping trailing spaces on lxml-based selectors. closes #270

==

scrapy/selector/lxmlsel.py
scrapy/tests/test_selector.py
==================
7f646541;Pablo Hoffman;2010-10-27 21:18:58 -0200;added trackref stats to memory debugger report. closes #272

==

scrapy/contrib/memdebug.py
scrapy/utils/trackref.py
==================
1d5c5608;Pablo Hoffman;2010-10-27 14:42:47 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
c3e5b4bb;Pablo Hoffman;2010-10-27 14:42:22 -0200;changed pid file name to scrapyd

==

debian/scrapyd.upstart
==================
2bba87f6;Pablo Hoffman;2010-10-27 14:20:21 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
f47b9f60;Pablo Hoffman;2010-10-27 14:18:40 -0200;simplified lockfile used by scrapyd (/var/run/scrapyd.pid instead of /var/run/scrapyd/scrapyd.pid). closes #271

==

debian/scrapyd.postinst
debian/scrapyd.postrm
debian/scrapyd.upstart
==================
bc2d7840;Daniel Grana;2010-10-27 12:36:24 -0200;MediaPipeline fails to assign crawler.engine.download as download function because crawler is configured after pipelines are loaded

==

scrapy/contrib/pipeline/media.py
==================
158f7545;Pablo Hoffman;2010-10-27 09:18:48 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
6f4be21d;Pablo Hoffman;2010-10-27 09:17:58 -0200;changed robots.txt forbidden log level to DEBUG. closes #268

==

scrapy/contrib/downloadermiddleware/robotstxt.py
==================
e625a8d5;Pablo Hoffman;2010-10-27 08:54:32 -0200;moved all similar selector tests to common selector tests, to reuse them among all backends

==

scrapy/tests/test_selector.py
scrapy/tests/test_selector_libxml2.py
scrapy/tests/test_selector_lxml.py
==================
d1f63237;Pablo Hoffman;2010-10-27 08:37:02 -0200;refactored selectors tests, by splitting tests in: common tests, lxml-specific tests and libxml2-specific tests. refs #147

==

scrapy/contrib/linkextractors/image.py
scrapy/tests/test_selector.py
scrapy/tests/test_selector_libxml2.py
scrapy/tests/test_selector_lxml.py
==================
665578bf;Pablo Hoffman;2010-10-27 08:05:08 -0200;fixed imports in scrapy.xlib.simplejson

==

scrapy/xlib/simplejson/__init__.py
scrapy/xlib/simplejson/decoder.py
scrapy/xlib/simplejson/encoder.py
scrapy/xlib/simplejson/scanner.py
==================
9b9ab378;Pablo Hoffman;2010-10-27 08:03:37 -0200;fixed bug with boolean results in lxml-based selectors

==

scrapy/selector/lxmlsel.py
scrapy/tests/test_selector_lxml.py
==================
a8be54a8;Pablo Hoffman;2010-10-27 06:49:15 -0200;scrapyd: make Environment tests independent of the current OS environment
--HG--
rename : scrapyd/tests/test_envion.py => scrapyd/tests/test_environ.py

==

scrapyd/environ.py
scrapyd/tests/test_environ.py
==================
17a6adde;Pablo Hoffman;2010-10-27 06:19:49 -0200;some refactoring to selectors code, to reuse more code between lxml and libxml2 backends (refs #147). also added tests for dummy backend

==

scrapy/selector/dummysel.py
scrapy/selector/libxml2sel.py
scrapy/selector/list.py
scrapy/selector/lxmlsel.py
scrapy/tests/test_selector_dummy.py
==================
9c9a655c;Pablo Hoffman;2010-10-27 05:53:46 -0200;selectors: no need to pass encoding on re() method

==

scrapy/selector/libxml2sel.py
scrapy/selector/lxmlsel.py
==================
bd7def8f;Pablo Hoffman;2010-10-27 05:51:30 -0200;lxml selectors: cache and reuse XPathEvaluator object, for performance. refs #147

==

scrapy/selector/lxmlsel.py
==================
1ead888d;Pablo Hoffman;2010-10-26 20:50:41 -0200;make trial run doctests

==

scrapy/tests/test_contrib_ibl/test_extraction.py
scrapy/tests/test_contrib_ibl/test_extractors.py
scrapy/tests/test_utils_datatypes.py
scrapy/tests/test_utils_http.py
scrapy/tests/test_utils_misc/__init__.py
scrapy/tests/test_utils_python.py
scrapy/tests/test_utils_response.py
scrapy/tests/test_utils_template.py
scrapy/utils/response.py
==================
a3a108dc;Pablo Hoffman;2010-10-26 17:21:43 -0200;fixed some compatibility issues with python 2.5 in scrapyd

==

scrapy/utils/py26.py
scrapyd/config.py
scrapyd/tests/test_eggutils.py
==================
b7c9503d;Pablo Hoffman;2010-10-26 16:50:34 -0200;disable lxml selectors tests which was failing on certain versions of lxml-libxml2

==

scrapy/tests/test_selector_lxml.py
==================
a09dd18b;Pablo Hoffman;2010-10-26 16:37:16 -0200;use absolute imports for compatibility with python 2.5

==

scrapy/selector/__init__.py
==================
41a85f9d;Martin Olveyra;2010-10-26 16:11:04 -0200;Added support for variants when applied to tag attributes. fixed handling of variants with single attribute. Removed unneeded object attribute surrounds_variant. Added  new tests cases for fixes.

==

scrapy/contrib/ibl/extraction/pageobjects.py
scrapy/contrib/ibl/extraction/pageparsing.py
scrapy/contrib/ibl/extraction/regionextract.py
scrapy/tests/test_contrib_ibl/test_extraction.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
==================
a5a6c2ae;Daniel Grana;2010-10-25 15:57:56 -0200;Automated merge with ssh://hg.scrapy.org/scrapy-0.10

==
==================
99096cda;Daniel Grana;2010-10-25 15:56:07 -0200;Image pipeline should upload images with image/jpeg content type. closes #257

==

scrapy/contrib/pipeline/images.py
==================
df635772;Pablo Hoffman;2010-10-25 14:57:50 -0200;added lxml to setup.py install_requires, if using setuptools. refs #147

==

setup.py
==================
f7283ad1;Pablo Hoffman;2010-10-25 14:56:33 -0200;skip lxml selector tests if lxml is not available. refs #147

==

scrapy/tests/test_selector_lxml.py
==================
a59bfb53;Pablo Hoffman;2010-10-25 14:47:10 -0200;* Added lxml backend for XPath selectors. Closes #147 * Added new setting (SELECTORS_BACKEND) to choose which backend to use * Deprecated the extract_unquoted() function from selectors * Made libxml2 optional by adding a dummy selector backend. Closes #260
--HG--
rename : scrapy/tests/test_selector.py => scrapy/tests/test_selector_libxml2.py

==

docs/topics/selectors.rst
scrapy/contrib/memdebug.py
scrapy/selector/__init__.py
scrapy/selector/dummysel.py
scrapy/selector/libxml2sel.py
scrapy/selector/lxmlsel.py
scrapy/settings/default_settings.py
scrapy/tests/test_libxml2.py
scrapy/tests/test_selector_libxml2.py
scrapy/tests/test_selector_lxml.py
scrapy/tests/test_utils_iterators.py
scrapy/utils/test.py
==================
7640e999;Daniel Grana;2010-10-25 13:16:11 -0200;test media_to_download mediapipeline hook. ref #269

==

scrapy/tests/test_pipeline_media.py
==================
fe1dd3a9;Daniel Grana;2010-10-23 05:10:52 -0200;disconnect signals before uninstalling crawler in image tests

==

scrapy/contrib/pipeline/images.py
scrapy/tests/test_pipeline_images.py
scrapy/tests/test_pipeline_media.py
==================
ad439173;Daniel Grana;2010-10-23 04:44:55 -0200;Add tests to MediaPipeline. closes #269
--HG--
extra : rebase_source : ccf726e147b5c97f7cba60d20ce2fca58c687a3e

==

scrapy/contrib/pipeline/media.py
scrapy/tests/test_pipeline_media.py
==================
d17edd4a;Martin Olveyra;2010-10-22 14:21:52 -0200;Fix wrong slice of tokens in recursive extraction of follow region

==

scrapy/contrib/ibl/extraction/regionextract.py
scrapy/tests/test_contrib_ibl/test_extraction.py
==================
72d08383;Daniel Grana;2010-10-22 00:28:35 -0200;Automated merge with ssh://hg.scrapy.org/scrapy-0.10

==
==================
2873c4d9;Daniel Grana;2010-10-22 00:21:54 -0200;SimpleDB stats doesn't use AWS auth from settings.py (thanks geoffwatts). closes #264

==

scrapy/contrib/statscol.py
==================
992683ac;Pablo Hoffman;2010-10-21 13:24:02 -0200;Deploy command requires project

==

scrapy/commands/deploy.py
==================
f8b4d1dc;Pablo Hoffman;2010-10-21 12:53:40 -0200;Fixed compatibility with Python 2.5

==

scrapy/commands/deploy.py
==================
6c921896;Pablo Hoffman;2010-10-19 00:11:45 -0200;Expanded documentation on deploy command and versions. Refs #261

==

docs/topics/scrapyd.rst
==================
1d567cdc;Pablo Hoffman;2010-10-18 22:38:46 -0200;Added new 'deploy' command. Closes #261

==

docs/topics/commands.rst
docs/topics/scrapyd.rst
extras/scrapy_bash_completion
scrapy/commands/deploy.py
scrapy/utils/multipart.py
==================
7d8f922d;Pablo Hoffman;2010-10-18 22:36:30 -0200;Added documentation for CLOSESPIDER_ERRORCOUNT setting. Refs #254

==

docs/topics/extensions.rst
==================
c96f17c4;Pablo Hoffman;2010-10-18 03:21:21 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
deb9c7ef;Pablo Hoffman;2010-10-18 03:18:54 -0200;Reversed scrapy.cfg lookup order so that the one in the current project has more precedence. Also added alternative system-wide location for windows.

==

scrapy/utils/conf.py
==================
98662e53;Pablo Hoffman;2010-10-17 03:20:23 -0200;Formatting fix in Scrapyd doc

==

docs/topics/scrapyd.rst
==================
a3d85da9;Pablo Hoffman;2010-10-16 19:54:24 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
5f65c260;Pablo Hoffman;2010-10-16 19:02:08 -0200;Some minor improvements to feature list in Scrapy at a Glance documentation page

==

docs/intro/overview.rst
==================
9d16ff09;Pablo Hoffman;2010-10-11 21:29:52 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10/

==
==================
f5b188b1;Pablo Hoffman;2010-10-11 21:28:42 -0200;Make RetryMiddleware obey Request.meta 'dont_retry' key when processing exceptions. Closes #259

==

scrapy/contrib/downloadermiddleware/retry.py
scrapy/tests/test_downloadermiddleware_retry.py
==================
d5c8caf0;Pablo Hoffman;2010-10-10 20:31:38 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
b4fbc6c5;Pablo Hoffman;2010-10-10 20:31:05 -0200;Updated Scrapy Tutorial to reference feed exports, instead a custom written pipeline, and extended item pipeline documentation to include a JSON writer.

==

docs/intro/tutorial.rst
docs/topics/item-pipeline.rst
==================
5267772d;Pablo Hoffman;2010-10-09 20:43:47 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
0b91c040;Pablo Hoffman;2010-10-09 20:43:05 -0200;Fixed issue with non-standard line ending in HTTP headers. Closes #258

==

scrapy/core/downloader/webclient.py
scrapy/tests/test_webclient.py
==================
a99bb0de;Martin Olveyra;2010-10-08 11:28:44 -0200;Use binary flag in read/write operations, to fix tests in windows

==

scrapy/tests/test_contrib_ibl/test_htmlpage.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
==================
aa4142e4;Pablo Hoffman;2010-10-07 18:23:48 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
f4accb6c;Pablo Hoffman;2010-10-07 18:22:01 -0200;Updated dmoz xpaths of Scrapy tutorial

==

docs/intro/tutorial.rst
==================
a67a981c;Martin Olveyra;2010-10-07 14:55:29 -0200;Simplification of html parsing algorithm, fixed some tests (with new algorithm, comments inside bigger text region are generated separated from the text). Added test for a case not correctly handled by previous algorithm. Fixed test checking

==

scrapy/contrib/ibl/htmlpage.py
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_0.json
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_1.json
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_2.json
scrapy/tests/test_contrib_ibl/test_htmlpage_data.py
==================
fafaee51;Martin Olveyra;2010-10-07 14:55:00 -0200;htmlpage tests reorganization and fixes: improved how differences between expected and result are shown, and check also correct parsing of tag_type

==

scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_0.html
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_0.json
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_1.html
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_1.json
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_2.html
scrapy/tests/test_contrib_ibl/samples/samples_htmlpage_2.json
scrapy/tests/test_contrib_ibl/samples/samples_pageparsing_0.html
scrapy/tests/test_contrib_ibl/samples/samples_pageparsing_0.json
scrapy/tests/test_contrib_ibl/samples_htmlpage.json.gz
scrapy/tests/test_contrib_ibl/samples_pageparsing.json.gz
scrapy/tests/test_contrib_ibl/test_htmlpage.py
scrapy/tests/test_contrib_ibl/test_htmlpage_data.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
==================
571aeb55;Pablo Hoffman;2010-10-05 12:44:41 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
4bbcbd7b;Pablo Hoffman;2010-10-05 12:43:34 -0200;Don't fail if twisted is not available on scrapy/__init__.py, to avoid making setup.py depend on Twisted. Closes #256

==

scrapy/__init__.py
==================
2d40705e;Pablo Hoffman;2010-09-30 20:17:44 -0300;CloseSpider extension: Added support for closing spider after N errors have been raised. Closes #254

==

scrapy/contrib/closespider.py
==================
b6e7a38a;Pablo Hoffman;2010-09-29 13:37:33 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
61ab9b86;Pablo Hoffman;2010-09-29 13:36:36 -0300;Bumped version to 0.10.4

==

scrapy/__init__.py
==================
ad0f180d;Pablo Hoffman;2010-09-29 13:34:56 -0300;Added tag 0.10.3 for changeset 803efdb19e0b

==

.hgtags
==================
d15a97ff;Pablo Hoffman;2010-09-28 16:45:05 -0300;Updated Scrapy version in debian/changelog

==

debian/changelog
==================
7826869c;Pablo Hoffman;2010-09-28 16:44:53 -0300;Added missing colon

==

docs/topics/extensions.rst
==================
0bf9e462;Martin Santos;2010-09-28 16:29:37 -0300;added support to CloseSpider extension, for close the spider after N pages have been crawled. Using the CLOSESPIDER_PAGECOUNT setting. closes #253

==

docs/topics/extensions.rst
scrapy/contrib/closespider.py
scrapy/settings/default_settings.py
==================
0976e078;Pablo Hoffman;2010-09-27 12:27:58 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
49ffe528;Pablo Hoffman;2010-09-27 12:27:32 -0300;Fixed listen_tcp function when receiving None or 0 in portrange argument. Closes #252

==

scrapy/utils/reactor.py
==================
50e57b08;Pablo Hoffman;2010-09-27 08:20:05 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
92068067;Pablo Hoffman;2010-09-27 08:19:32 -0300;setup.py: added support for generating version from hg revision

==

setup.py
==================
51325fc9;Pablo Hoffman;2010-09-27 07:57:23 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
52d198af;Pablo Hoffman;2010-09-27 07:55:27 -0300;Removed forked cookielib tests, because Python cookielib has been suffering several changes and maintaining a fork of the tests has become a pain. Instead, we've added specific tests for the urllib2 request/response wrappers

==

scrapy/http/cookies.py
scrapy/tests/test_http_cookies.py
==================
3db8d367;Pablo Hoffman;2010-09-26 21:09:14 -0300;Another fix to tests, broken by recent Python changes

==

scrapy/tests/test_utils_url.py
==================
e55ae718;Pablo Hoffman;2010-09-26 17:00:10 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
5d4e0655;Pablo Hoffman;2010-09-26 16:57:42 -0300;Fixed test_utils_url, broken on Windows after recent Python urllib change. Closes #251

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
279dcc24;Pablo Hoffman;2010-09-26 01:01:06 -0300;Fixed role name in Sphinx doc

==

docs/topics/commands.rst
==================
fd84d8d5;Pablo Hoffman;2010-09-25 21:20:15 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
1ef2cd40;Pablo Hoffman;2010-09-25 21:17:36 -0300;Fixed issue with unicode keyword arguments bug in earlier Python versions (see http://bugs.python.org/issue2646). Closes #250

==

scrapy/queue.py
scrapy/tests/test_queue.py
scrapy/tests/test_utils_python.py
scrapy/utils/python.py
==================
622834bc;Pablo Hoffman;2010-09-23 14:01:22 -0300;Removed unused imports, and use crawler.settings instead of scrapy.conf.settings in Scrapy Shell

==

scrapy/shell.py
==================
b78284b6;Pablo Hoffman;2010-09-23 13:59:41 -0300;Fixed spider variable not properly populated in the Scrapy shell

==

scrapy/shell.py
==================
318f7f4c;Pablo Hoffman;2010-09-23 13:49:29 -0300;Added support for passing code to evaluate in Scrapy shell command (closes #249) and simplified handling of shell errors

==

scrapy/commands/shell.py
scrapy/shell.py
==================
a5ee05e8;Pablo Hoffman;2010-09-23 13:43:21 -0300;Added support for setting exit code in Scrapy commands. Closes #248

==

scrapy/cmdline.py
scrapy/command.py
==================
79c0e349;Pablo Hoffman;2010-09-23 12:50:46 -0300;Simplified CrawlerSettings.__str__()

==

scrapy/settings/__init__.py
==================
754d0f53;Pablo Hoffman;2010-09-23 12:33:24 -0300;Fixed unbounded spider error in shell, and enclosed fetch() method in a try/except block for logging errors more reliably

==

scrapy/shell.py
==================
37c25fe9;Pablo Hoffman;2010-09-23 12:32:49 -0300;Fixed CrawlerSettings.__str__() method when settings_module is None

==

scrapy/settings/__init__.py
==================
f29b346f;Pablo Hoffman;2010-09-22 22:21:29 -0300;Fixed access to settings module name, broken after recent changes to Settings classes

==

scrapy/cmdline.py
==================
9599bde3;Pablo Hoffman;2010-09-22 16:09:13 -0300;Removed RequestLimitMiddleware

==

docs/topics/settings.rst
docs/topics/spider-middleware.rst
scrapy/contrib/spidermiddleware/requestlimit.py
scrapy/settings/default_settings.py
==================
97d77c79;Pablo Hoffman;2010-09-22 16:09:13 -0300;Added tests for CrawlerSettings and SpiderSettings classes

==

scrapy/tests/test_settings.py
==================
ed4aec18;Pablo Hoffman;2010-09-22 16:09:13 -0300;Ported code to use new unified access to spider settings, keeping backwards compatibility for old spider attributes. Refs #245

==

docs/faq.rst
docs/topics/commands.rst
docs/topics/downloader-middleware.rst
docs/topics/settings.rst
scrapy/contrib/downloadermiddleware/defaultheaders.py
scrapy/contrib/downloadermiddleware/downloadtimeout.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/downloadermiddleware/useragent.py
scrapy/core/downloader/__init__.py
scrapy/core/downloader/webclient.py
scrapy/tests/test_downloadermiddleware_defaultheaders.py
scrapy/tests/test_downloadermiddleware_downloadtimeout.py
scrapy/tests/test_downloadermiddleware_useragent.py
scrapy/tests/test_engine.py
scrapy/utils/deprecate.py
scrapy/utils/test.py
==================
2459d20c;Pablo Hoffman;2010-09-22 16:09:13 -0300;Added support for unifying access to per-spider settings. Refs #245

==

scrapy/crawler.py
scrapy/settings/__init__.py
scrapy/spider.py
==================
a4639ffb;Pablo Hoffman;2010-09-22 16:08:18 -0300;Removed hacky SCRAPY_SETTINGS_DISABLED environment variable

==

bin/runtests.sh
scrapy/conf.py
scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_commands.py
scrapyd/eggutils.py
==================
b6c2b55e;Pablo Hoffman;2010-09-22 15:47:33 -0300;Splitted settings classes from settings singleton. Closes #244
--HG--
rename : scrapy/conf/__init__.py => scrapy/conf.py
rename : scrapy/conf/default_settings.py => scrapy/settings/default_settings.py
rename : scrapy/tests/test_conf.py => scrapy/tests/test_settings.py

==

docs/topics/settings.rst
examples/experimental/googledir/googledir/settings.py
examples/experimental/imdb/imdb/settings.py
scrapy/conf.py
scrapy/conf/__init__.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/settings/__init__.py
scrapy/settings/default_settings.py
scrapy/shell.py
scrapy/templates/project/module/settings.py.tmpl
scrapy/tests/test_downloadermiddleware_httpcache.py
scrapy/tests/test_engine.py
scrapy/tests/test_middleware.py
scrapy/tests/test_pipeline_media.py
scrapy/tests/test_settings.py
==================
1c20a5e5;Pablo Hoffman;2010-09-22 15:44:11 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
b11e1103;Pablo Hoffman;2010-09-22 15:42:31 -0300;Make custom project commands discovery work with eggified projects. Fixes #247

==

scrapy/cmdline.py
==================
2ebfa7e6;Pablo Hoffman;2010-09-22 10:52:02 -0300;Removed unneeded code (since autodoc is not used in Sphinx doc)

==

docs/Makefile
docs/conf.py
==================
f3769651;Pablo Hoffman;2010-09-22 01:04:15 -0300;Refactored Scrapyd code to fix a couple of bugs that ocurred when running projects without eggs

==

scrapyd/poller.py
scrapyd/scheduler.py
scrapyd/tests/test_poller.py
scrapyd/tests/test_scheduler.py
scrapyd/utils.py
==================
0ffc8d29;Pablo Hoffman;2010-09-22 01:00:34 -0300;Don't silence warnings after log is started. Closes #246

==

scrapy/log.py
==================
be3293df;Pablo Hoffman;2010-09-20 08:48:42 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
4c61df7a;Pablo Hoffman;2010-09-20 08:47:55 -0300;get_spider_list_from_eggfile(): fixed bug when SCRAPY_SETTINGS_DISABLED is set

==

scrapyd/eggutils.py
==================
83294912;Pablo Hoffman;2010-09-20 08:34:22 -0300;Added Shuaib Khan to AUTHORS

==

AUTHORS
==================
9288f622;Shuaib;2010-09-20 08:33:24 -0300;Added formname parameter for FormRequest.from_response

==

docs/topics/request-response.rst
scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
400c4134;Pablo Hoffman;2010-09-19 21:08:27 -0300;Make scrapyd.eggutils compatible with Python 2.5 and added tests for get_spider_list_from_eggfile() function (closes #242)

==

scrapyd/eggutils.py
scrapyd/tests/mybot.egg
scrapyd/tests/test_eggutils.py
==================
b6a95f94;Pablo Hoffman;2010-09-19 19:54:17 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
aa86f180;Ping Yin;2010-09-19 19:28:35 -0300;BaseSgmlLinkExtractor: Fix extract '>>' as '>' The anchor text is extracted as '>' in <a href="/">&gt;&gt;</a>
Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/contrib/linkextractors/sgml.py
scrapy/tests/test_contrib_linkextractors.py
==================
f41fd321;Ping Yin;2010-09-19 19:28:13 -0300;test_engine.py: fix typo brwoser => browser Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/tests/test_engine.py
==================
a8325a30;Pablo Hoffman;2010-09-17 17:21:32 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
08952562;Pablo Hoffman;2010-09-17 16:25:02 -0300;Make Ubuntu package conflict with standard Scrapy Debian/Ubuntu package

==

debian/control
==================
627bc3e7;Daniel Grana;2010-09-16 14:30:27 -0300;Automated merge with ssh://hg.scrapy.org/scrapy-0.10

==
==================
cad07757;Daniel Grana;2010-09-16 14:19:32 -0300;Fix black shapes appearing round transparent images

==

scrapy/contrib/pipeline/images.py
scrapy/tests/test_pipeline_images.py
==================
8d24547e;Pablo Hoffman;2010-09-15 21:05:48 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
4cecbcdc;Pablo Hoffman;2010-09-15 21:03:43 -0300;Fixed bug in Scrapyd launcher when running projects without eggs. Refs #238

==

scrapyd/launcher.py
==================
a5908f05;Pablo Hoffman;2010-09-15 21:03:21 -0300;Bumped version to 0.10.3

==

scrapy/__init__.py
==================
34fc36ff;Pablo Hoffman;2010-09-15 14:49:21 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.10

==
==================
b33c8e49;Pablo Hoffman;2010-09-15 14:48:47 -0300;Added tag 0.10.2 for changeset 68d08e757571

==

.hgtags
==================
edfba29d;Pablo Hoffman;2010-09-15 14:27:27 -0300;Re-bumped version to 0.11

==

scrapy/__init__.py
==================
c01b8651;Pablo Hoffman;2010-09-15 14:04:33 -0300;Bumped version to 0.10.2

==

scrapy/__init__.py
==================
5fe9a49e;Pablo Hoffman;2010-09-15 13:57:17 -0300;Force recalculating the encoding on HTTPCompression middleware until we are sure the responsetypes guessing is reliable. Refs #239, #240

==

scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
==================
28f6bdf7;Pablo Hoffman;2010-09-15 02:44:41 -0300;Added tag 0.10.1 for changeset bb80107f959d

==

.hgtags
==================
beee7e4f;Pablo Hoffman;2010-09-15 01:50:42 -0300;Merge with trunk

==
==================
39499a24;Pablo Hoffman;2010-09-14 20:22:25 -0300;Fixed bug in HTTP Compression middleware which was failing to properly discover the encoding when the encoding was declared inside the response body. Closes #239. Also changed responsetypes to return Response class (instead of HtmlResponse) when the response has a Content-Encoding header

==

scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/core/downloader/responsetypes/__init__.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_responsetypes.py
==================
9acc99e7;Pablo Hoffman;2010-09-14 14:36:35 -0300;Added 'inthread' decorator

==

scrapy/utils/decorator.py
==================
c559b06a;Pablo Hoffman;2010-09-14 01:53:05 -0300;Removed unused import

==

scrapyd/eggrunner.py
==================
833baa60;Pablo Hoffman;2010-09-14 01:44:25 -0300;Support running projects without eggs in Scrapyd. Closes #238

==

scrapyd/eggrunner.py
scrapyd/eggstorage.py
scrapyd/eggutils.py
scrapyd/environ.py
scrapyd/interfaces.py
scrapyd/launcher.py
scrapyd/tests/test_envion.py
==================
b76cd426;Pablo Hoffman;2010-09-14 01:44:10 -0300;Added tests for Scrapyd components. Closes #237

==

bin/runtests.bat
bin/runtests.sh
scrapyd/config.py
scrapyd/eggstorage.py
scrapyd/interfaces.py
scrapyd/tests/__init__.py
scrapyd/tests/test_eggstorage.py
scrapyd/tests/test_envion.py
scrapyd/tests/test_poller.py
scrapyd/tests/test_scheduler.py
==================
d0c7a946;Pablo Hoffman;2010-09-13 19:02:21 -0300;Bumped version to 0.10.1

==

scrapy/__init__.py
==================
1fa96dbc;Pablo Hoffman;2010-09-13 19:02:15 -0300;Bumped version to 0.11

==

scrapy/__init__.py
==================
e2a3ab51;Pablo Hoffman;2010-09-13 18:49:33 -0300;Added tag 0.10 for changeset 3b32720c96a3

==

.hgtags
==================
a3fc60cf;Pablo Hoffman;2010-09-11 04:30:08 -0300;Added missing mime.types files to MANIFEST.in

==

MANIFEST.in
==================
bf467fc3;Pablo Hoffman;2010-09-10 15:29:15 -0300;Check 'dont_merge_cookies' membership in request.meta, instead of getting its value

==

docs/topics/request-response.rst
scrapy/contrib/downloadermiddleware/cookies.py
==================
e7a958a0;Pablo Hoffman;2010-09-10 15:17:36 -0300;Fixed exception thrown when in FreeBSD when /proc exists but it's not mounted. Closes #235

==

scrapy/contrib/memusage.py
scrapy/tests/test_utils_memory.py
scrapy/utils/memory.py
==================
b16eff22;Pablo Hoffman;2010-09-10 01:48:45 -0300;Bumped version to 0.10

==

scrapy/__init__.py
setup.py
==================
9b9b3a2b;Pablo Hoffman;2010-09-09 23:35:51 -0300;Removed unused import

==

scrapy/contrib/downloadermiddleware/retry.py
==================
7d14a522;Pablo Hoffman;2010-09-09 21:54:26 -0300;Reference dont_merge_cookies in list of special Request.meta keys

==

docs/topics/request-response.rst
==================
7f21a638;Pablo Hoffman;2010-09-09 21:50:40 -0300;Documented handle_httpstatus_list request.meta key

==

docs/topics/request-response.rst
docs/topics/spider-middleware.rst
==================
f1c94354;Pablo Hoffman;2010-09-09 21:43:44 -0300;Added dont_retry request.meta key to make RetryMiddleware ignore requests. Closes #234

==

docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
scrapy/contrib/downloadermiddleware/retry.py
scrapy/tests/test_downloadermiddleware_retry.py
==================
9f01e3e7;Pablo Hoffman;2010-09-09 21:37:35 -0300;Added dont_redirect request.meta key to make RedirectMiddleware ignore requests. Closes #233

==

docs/_ext/scrapydocs.py
docs/topics/downloader-middleware.rst
docs/topics/request-response.rst
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/tests/test_downloadermiddleware_redirect.py
==================
ad2b979e;Pablo Hoffman;2010-09-09 18:01:00 -0300;Changed TextResponse.replace() behaviour by keeping previous encoding when not specified

==

scrapy/http/response/text.py
scrapy/tests/test_http_response.py
==================
b9ea9dcf;Pablo Hoffman;2010-09-09 17:42:54 -0300;Restored wrongly removed import

==

scrapy/utils/engine.py
==================
c041328b;Pablo Hoffman;2010-09-09 15:26:46 -0300;Fixed bug with thread unsafety calls from Scrapy shell

==

scrapy/shell.py
==================
24c0088b;Pablo Hoffman;2010-09-09 00:41:18 -0300;Added tag 0.10-rc1 for changeset 131f8e906f75

==

.hgtags
==================
38bbec8d;Pablo Hoffman;2010-09-09 00:40:58 -0300;Bumped version to 0.10-rc1

==

scrapy/__init__.py
==================
fe77794f;Pablo Hoffman;2010-09-08 15:52:35 -0300;Added SpiderContext extension. Closes #203

==

scrapy/conf/default_settings.py
scrapy/contrib/spidercontext.py
scrapy/tests/test_contrib_spidercontext.py
==================
1d5a7df1;Pablo Hoffman;2010-09-08 15:34:13 -0300;Fixed encoding error with some item dropped messages. Closes #232

==

scrapy/logformatter.py
scrapy/tests/test_logformatter.py
==================
cb7cc7c8;Pablo Hoffman;2010-09-08 14:32:28 -0300;Fixed bugs with SQLiteDict and added tests

==

scrapy/tests/test_utils_sqlite.py
scrapy/utils/sqlite.py
==================
7da79b90;Pablo Hoffman;2010-09-08 00:15:11 -0300;Make url/body attributes of Request/Response objects read-only - use replace() to change them. Deprecation warning left for backwards compatibilty.

==

docs/topics/request-response.rst
scrapy/contrib_exp/crawlspider/reqext.py
scrapy/contrib_exp/crawlspider/reqproc.py
scrapy/http/common.py
scrapy/http/request/__init__.py
scrapy/http/request/form.py
scrapy/http/response/__init__.py
scrapy/http/response/text.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
scrapy/tests/test_utils_request.py
==================
c1aab2f5;Pablo Hoffman;2010-09-08 00:15:09 -0300;Copy callback/errback attributes when copying Requests

==

docs/topics/request-response.rst
scrapy/core/engine.py
scrapy/http/request/__init__.py
scrapy/tests/test_http_request.py
==================
e9ebebb2;Pablo Hoffman;2010-09-07 17:51:02 -0300;Removed UrlFilterMiddleware from scrapy.contrib - see this snippet for an alternative: http://snippets.scrapy.org/snippets/12/

==

docs/topics/spider-middleware.rst
scrapy/contrib/spidermiddleware/urlfilter.py
scrapy/tests/test_spidermiddleware_urlfilter.py
==================
8ba6fa20;Pablo Hoffman;2010-09-07 17:47:47 -0300;Fixed bugs introduced by previous scheduler middleware change

==

scrapy/core/engine.py
scrapy/core/scheduler.py
scrapy/core/schedulermw.py
==================
dbc0ba72;Pablo Hoffman;2010-09-07 14:26:50 -0300;Added class constructors scrapy.contrib.ibl FieldDescriptor and ItemDescriptor

==

scrapy/contrib/ibl/descriptor.py
==================
23b13f0c;Pablo Hoffman;2010-09-07 13:10:49 -0300;Simplified SchedulerMiddlewareManager (to be removed in Scrapy 0.11) by making it inherit from MiddlewareManager

==

scrapy/core/schedulermw.py
==================
5918d016;Pablo Hoffman;2010-09-07 13:03:16 -0300;Automated merge with ssh://hg.scrapy.org:2222/scrapy

==
==================
c40e5a74;Pablo Hoffman;2010-09-07 13:02:15 -0300;Moved module: scrapy.core.downloader.manager to scrapy.core.downloader
--HG--
rename : scrapy/core/downloader/manager.py => scrapy/core/downloader/__init__.py

==

scrapy/core/downloader/__init__.py
scrapy/core/downloader/manager.py
==================
12b04b06;Daniel Grana;2010-09-07 13:01:40 -0300;make download_timeout configurable by request. closes #229
--HG--
extra : rebase_source : e57dfd4aeb98d48b04fc4d0c6469e9a85e4b33a8

==

docs/topics/downloader-middleware.rst
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/downloadtimeout.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/webclient.py
scrapy/tests/test_downloader_handlers.py
scrapy/tests/test_downloadermiddleware_downloadtimeout.py
==================
a23b6981;Pablo Hoffman;2010-09-07 13:00:36 -0300;Simplified DownloaderMiddlewareManager by making it inherit from MiddlewareManager

==

scrapy/core/downloader/manager.py
scrapy/core/downloader/middleware.py
==================
37f4ce24;Pablo Hoffman;2010-09-07 12:59:02 -0300;Fixed spider middleware order for methods: process_spider_output, process_spider_exception

==

scrapy/core/spidermw.py
==================
d0081290;Pablo Hoffman;2010-09-07 10:07:47 -0300;Improve error logging when failing to create a spider in the execution queue

==

scrapy/queue.py
==================
9158e9d6;Pablo Hoffman;2010-09-07 09:17:25 -0300;Some changes to Scrapyd to support multiple configuration files, to make it easier to deploy Scrapyd applications. Also documented 'egg_runner' and 'application' options
--HG--
rename : debian/scrapyd.cfg => debian/000-default
rename : scrapyd/default_scrapyd.cfg => scrapyd/default_scrapyd.conf

==

debian/000-default
debian/scrapyd.install
docs/topics/scrapyd.rst
extras/scrapyd.tac
scrapyd/__init__.py
scrapyd/app.py
scrapyd/config.py
scrapyd/default_scrapyd.cfg
scrapyd/default_scrapyd.conf
scrapyd/launcher.py
==================
3414bf13;Daniel Grana;2010-09-06 23:23:14 -0300;remove request_uploaded signal and move response_received and response_downloaded to downloader manager. closes #228
--HG--
extra : rebase_source : 4af0d2a01b34de8a21048bb7f4a66bfc484b3b8f

==

docs/topics/signals.rst
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/manager.py
scrapy/core/downloader/middleware.py
scrapy/core/signals.py
scrapy/signals.py
==================
3c5ab106;Pablo Hoffman;2010-09-06 13:17:08 -0300;Added FAQ entry about __VIEWSTATE parameter

==

docs/faq.rst
==================
3a72e5c0;Pablo Hoffman;2010-09-06 11:04:27 -0300;Removed settings.disabled hack used in some tests. Closes #143

==

scrapy/contrib/pipeline/images.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/urllength.py
scrapy/tests/test_pipeline_images.py
scrapy/tests/test_spidermiddleware_depth.py
scrapy/tests/test_spidermiddleware_urllength.py
==================
5f58af20;Pablo Hoffman;2010-09-06 10:40:33 -0300;Simplified SpiderMiddlewareManager by making it inherit from MiddlewareManager

==

scrapy/core/scraper.py
scrapy/core/spidermw.py
==================
cc72f03e;Pablo Hoffman;2010-09-06 10:22:28 -0300;Added IFeedStorage interface and test all Feed Storages conform to it. Also added test for StdoutFeedStorage

==

scrapy/contrib/feedexport.py
scrapy/tests/test_contrib_feedexport.py
==================
e3d67d74;Pablo Hoffman;2010-09-06 10:04:00 -0300;docs/intro/overview.rst: add example of scraped data and introduce loaders

==

docs/intro/overview.rst
==================
ff9de424;Pablo Hoffman;2010-09-06 09:47:45 -0300;Added SpiderQueue tests. SQS spider queue not tested because operations take too long to complete and it's not easy to know when they have. Closes #227

==

scrapy/tests/test_contrib_feedexport.py
scrapy/tests/test_contrib_spiderqueue.py
scrapy/tests/test_spiderqueue.py
scrapy/utils/test.py
==================
8d1d3493;Daniel Grana;2010-09-06 00:50:56 -0300;Added a weak key factory based cache
--HG--
extra : rebase_source : 2bc7cb5fdb0fd3adb63cf7fe3aedd2f1d15e49f0

==

scrapy/contrib/downloadermiddleware/defaultheaders.py
scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/contrib/downloadermiddleware/useragent.py
scrapy/tests/test_downloadermiddleware_defaultheaders.py
scrapy/tests/test_downloadermiddleware_httpauth.py
scrapy/tests/test_utils_http.py
scrapy/tests/test_utils_python.py
scrapy/utils/http.py
scrapy/utils/python.py
scrapy/utils/request.py
==================
00d55fbb;Pablo Hoffman;2010-09-05 23:38:37 -0300;Updated 'Scrapy at a glance' document replacing item pipeline example by a simpler usage of feed exports

==

docs/intro/overview.rst
==================
5ffc7650;Pablo Hoffman;2010-09-05 20:08:59 -0300;Removed code no longer needed

==

scrapy/core/scraper.py
==================
766f2d91;Pablo Hoffman;2010-09-05 19:35:53 -0300;Renamed Request Handlers to Download Handlers

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/file.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/handlers/s3.py
scrapy/core/downloader/manager.py
scrapy/tests/test_downloader_handlers.py
==================
067ec65d;Pablo Hoffman;2010-09-05 19:09:42 -0300;Removed download_any singleton

==

scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/manager.py
==================
a5cf71cb;Pablo Hoffman;2010-09-05 19:04:15 -0300;Updated Ubuntu package signing key location

==

docs/topics/ubuntu.rst
==================
6bf52fb5;Pablo Hoffman;2010-09-05 06:48:08 -0300;Make telnet console and web service try a range of ports for binding, instead of just one. Closes #226

==

docs/topics/settings.rst
docs/topics/webservice.rst
scrapy/conf/default_settings.py
scrapy/telnet.py
scrapy/utils/reactor.py
scrapy/webservice.py
==================
ce884192;Pablo Hoffman;2010-09-05 06:05:34 -0300;Fixed test broken by previous commit

==

scrapy/tests/test_downloader_handlers.py
==================
630db4fe;Pablo Hoffman;2010-09-05 05:59:40 -0300;Simplified file:// download handler, adding support for reading binary files

==

scrapy/core/downloader/handlers/file.py
scrapy/utils/decorator.py
==================
14e985b0;Pablo Hoffman;2010-09-05 05:29:58 -0300;Updated Command line tool documentation

==

docs/topics/commands.rst
docs/topics/settings.rst
==================
1190f979;Pablo Hoffman;2010-09-05 04:58:14 -0300;Updated settings documentation

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
==================
ebdb733e;Pablo Hoffman;2010-09-05 04:45:43 -0300;Updated some old messages in Scrapy shell doc

==

docs/topics/shell.rst
==================
2f126188;Pablo Hoffman;2010-09-05 04:35:27 -0300;Post reference to Scrapyd in FAQ

==

docs/faq.rst
==================
a66bef79;Pablo Hoffman;2010-09-05 02:23:08 -0300;Make execution queue poll interval configurable through a new QUEUE_POLL_INTERVAL setting

==

scrapy/conf/default_settings.py
scrapy/contrib/spiderqueue.py
scrapy/crawler.py
scrapy/queue.py
scrapy/tests/test_queue.py
==================
b800fdcb;Pablo Hoffman;2010-09-04 03:49:46 -0300;SqliteSpiderQueue: failback to in-memory SQLite if database cannot be opened (typically due to missing write permissions)

==

scrapy/spiderqueue.py
==================
bf34094e;Pablo Hoffman;2010-09-04 03:30:45 -0300;Added versionadded:: notice to new documentation topics

==

docs/topics/commands.rst
docs/topics/feed-exports.rst
docs/topics/scrapyd.rst
docs/topics/ubuntu.rst
==================
e3921ab0;Pablo Hoffman;2010-09-04 03:20:05 -0300;Don't set allowed_domains attribute in BaseSpider constructor

==

scrapy/spider.py
scrapy/tests/test_spider.py
==================
9f4b1e47;Daniel Grana;2010-09-04 03:26:41 -0300;damn, really fix httpcache docs

==

docs/topics/downloader-middleware.rst
==================
7ad90164;Daniel Grana;2010-09-04 03:23:08 -0300;fix httpcache docs

==

docs/topics/downloader-middleware.rst
==================
1abaa794;Daniel Grana;2010-09-04 02:58:43 -0300;Make ignored schemes configurable in HttpCacheMiddleware. closes #224
--HG--
extra : rebase_source : 2e6e8b93c642290f9bd6eb634eb4c8cd6da07c75

==

docs/topics/downloader-middleware.rst
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
5a6284ce;Pablo Hoffman;2010-09-04 02:56:50 -0300;Added TODO:

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
58feb155;Daniel Grana;2010-09-04 02:53:09 -0300;httpcache must restore responses using response.url instead of request.url
--HG--
extra : rebase_source : 08fa2c3862bb35db2234e0f9bb9cb9ce4a8f4d8d

==

scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
7b9fa7fb;Pablo Hoffman;2010-09-04 02:23:04 -0300;Don't filter out requests coming from spiders that don't define allowed_domains. Closes #225

==

docs/topics/spider-middleware.rst
scrapy/contrib/spidermiddleware/offsite.py
scrapy/tests/test_spidermiddleware_offsite.py
==================
1b115633;Daniel Grana;2010-09-04 01:02:52 -0300;monkeypatch urlparse if s3 netloc parsing fails (python issue7904). closes #223

==

scrapy/__init__.py
scrapy/tests/test_urlparse_monkeypatches.py
scrapy/xlib/urlparse_monkeypatches.py
==================
9cfa8edd;Pablo Hoffman;2010-09-03 17:46:36 -0300;Automatic merge

==
==================
9b68c3c1;Daniel Grana;2010-09-03 16:19:47 -0300;Add S3 scheme request handler. closes #222

==

scrapy/__init__.py
scrapy/conf/default_settings.py
scrapy/core/downloader/handlers/s3.py
scrapy/tests/test_downloader_handlers.py
==================
30d94b5b;Daniel Grana;2010-09-03 16:18:46 -0300;Convert request handlers to classes and support NotConfigured. closes #221

==

scrapy/conf/default_settings.py
scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/file.py
scrapy/core/downloader/handlers/http.py
scrapy/tests/test_downloader_handlers.py
==================
37e9c5d7;Pablo Hoffman;2010-09-03 15:54:42 -0300;Added new Scrapy service with support for:
* multiple projects
* uploading scrapy projects as Python eggs
* scheduling spiders using a JSON API

Documentation is added along with the code.

Closes #218.

--HG--
rename : debian/scrapy-service.default => debian/scrapyd.default
rename : debian/scrapy-service.dirs => debian/scrapyd.dirs
rename : debian/scrapy-service.install => debian/scrapyd.install
rename : debian/scrapy-service.lintian-overrides => debian/scrapyd.lintian-overrides
rename : debian/scrapy-service.postinst => debian/scrapyd.postinst
rename : debian/scrapy-service.postrm => debian/scrapyd.postrm
rename : debian/scrapy-service.upstart => debian/scrapyd.upstart
rename : extras/scrapy.tac => extras/scrapyd.tac

==

MANIFEST.in
debian/control
debian/scrapy-service.default
debian/scrapy-service.dirs
debian/scrapy-service.install
debian/scrapy-service.prerm
debian/scrapy-service.upstart
debian/scrapy.1
debian/scrapy.install
debian/scrapyd.cfg
debian/scrapyd.default
debian/scrapyd.dirs
debian/scrapyd.install
debian/scrapyd.lintian-overrides
debian/scrapyd.postinst
debian/scrapyd.postrm
debian/scrapyd.upstart
debian/service_conf.py
docs/index.rst
docs/topics/scrapyd.rst
extras/scrapy.tac
extras/scrapyd.tac
scrapy/__init__.py
scrapy/service.py
scrapy/utils/conf.py
scrapy/utils/txweb.py
scrapy/webservice.py
scrapyd/__init__.py
scrapyd/app.py
scrapyd/config.py
scrapyd/default_scrapyd.cfg
scrapyd/eggrunner.py
scrapyd/eggstorage.py
scrapyd/eggutils.py
scrapyd/environ.py
scrapyd/interfaces.py
scrapyd/launcher.py
scrapyd/poller.py
scrapyd/scheduler.py
scrapyd/utils.py
scrapyd/webservice.py
setup.py
==================
1b766877;Pablo Hoffman;2010-09-03 14:29:27 -0300;Added ISpiderManager interface and a test to verify the default SpiderManager comforms to it

==

scrapy/commands/parse.py
scrapy/interfaces.py
scrapy/queue.py
scrapy/shell.py
scrapy/spidermanager.py
scrapy/spiderqueue.py
scrapy/tests/test_queue.py
scrapy/tests/test_spidermanager/__init__.py
scrapy/utils/spider.py
==================
7cfc3792;Pablo Hoffman;2010-09-03 14:29:27 -0300;Execution Queue refactoring by taking out the queue backend to a new Spider Queue API. Also ported SQS Execution Queue to Spider Queue API, and make the scrapy queue command use the Spider Queue directly, with deferreds support.
Closes #220.

==

scrapy/commands/queue.py
scrapy/commands/runserver.py
scrapy/commands/shell.py
scrapy/commands/startproject.py
scrapy/conf/default_settings.py
scrapy/contrib/queue/__init__.py
scrapy/contrib/queue/sqs.py
scrapy/contrib/spiderqueue.py
scrapy/crawler.py
scrapy/interfaces.py
scrapy/queue.py
scrapy/spiderqueue.py
scrapy/tests/test_contrib_spiderqueue.py
scrapy/tests/test_queue.py
scrapy/tests/test_spiderqueue.py
scrapy/utils/sqlite.py
==================
37776618;Pablo Hoffman;2010-09-02 21:22:17 -0300;Changed format of scrapy.cfg file to contain a [settings] section and a 'default' key inside it, instead of the other way around

==

examples/experimental/googledir/scrapy.cfg
examples/experimental/imdb/scrapy.cfg
examples/googledir/scrapy.cfg
scrapy/cmdline.py
scrapy/conf/__init__.py
scrapy/templates/project/scrapy.cfg
scrapy/utils/conf.py
==================
fb69655a;Pablo Hoffman;2010-08-31 21:40:05 -0300;Removed unused imports

==

scrapy/contrib/downloadermiddleware/cookies.py
==================
758d21b2;Pablo Hoffman;2010-08-31 16:03:08 -0300;Simplified images pipeline by allowing it to be used without having to override it in your project. Closes #217

==

docs/topics/images.rst
scrapy/contrib/pipeline/images.py
==================
59f09c50;Pablo Hoffman;2010-08-28 18:06:51 -0300;Yet another scrapy.cmdline code refactoring by removing --settings and --version options, adding a version command and adding a UsageError exception for signaling usage errors. Updated all commands accordingly

==

scrapy/cmdline.py
scrapy/command.py
scrapy/commands/crawl.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/parse.py
scrapy/commands/queue.py
scrapy/commands/runspider.py
scrapy/commands/startproject.py
scrapy/commands/version.py
scrapy/exceptions.py
scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_cmdline/settings2.py
scrapy/tests/test_commands.py
==================
7394aa92;Pablo Hoffman;2010-08-28 14:47:19 -0300;Fixed typo

==

scrapy/commands/crawl.py
==================
616ecc5a;Pablo Hoffman;2010-08-28 14:43:28 -0300;Support passing spider arguments in crawl command with -a option. Closes #216

==

scrapy/command.py
scrapy/commands/crawl.py
scrapy/tests/test_utils_conf.py
scrapy/utils/conf.py
==================
d4941a06;Pablo Hoffman;2010-08-28 14:07:03 -0300;Minor change to --pidfile argument

==

scrapy/command.py
==================
0ae4c3aa;Pablo Hoffman;2010-08-27 18:36:00 -0300;call Spider.closed() method (if it exists) on SpiderManager.close_spider()

==

scrapy/spidermanager.py
==================
35fd1a26;Pablo Hoffman;2010-08-27 17:21:30 -0300;Fixed typo

==

scrapy/spidermanager.py
==================
3234d76b;Pablo Hoffman;2010-08-27 16:19:51 -0300;Restored SpiderManager.close_spider() method but using signals instead of calling it from the engine

==

scrapy/spidermanager.py
==================
78388745;Pablo Hoffman;2010-08-27 15:50:12 -0300;Moved tests to reflect new module location
--HG--
rename : scrapy/tests/test_core_queue.py => scrapy/tests/test_queue.py

==

scrapy/tests/test_queue.py
==================
88c99e0b;Pablo Hoffman;2010-08-27 13:45:52 -0300;Check that arguments and keyword arguments are not passed simultaneously in jsonrpc_client_call()

==

scrapy/tests/test_utils_jsonrpc.py
scrapy/utils/jsonrpc.py
==================
ffad8e08;Pablo Hoffman;2010-08-27 13:45:14 -0300;Support passing all keyword arguments to ExecutionQueue append_spider_name and append_url

==

scrapy/queue.py
scrapy/tests/test_core_queue.py
==================
4eb0383d;Pablo Hoffman;2010-08-27 11:15:37 -0300;Added Scrapy to scrapy --version

==

scrapy/command.py
==================
e7b3247a;Pablo Hoffman;2010-08-27 01:05:59 -0300;Updated some missing references to scrapy-ws script

==

docs/topics/webservice.rst
setup.py
==================
aab38be4;Pablo Hoffman;2010-08-27 00:53:26 -0300;Print Scrapy on first log line

==

scrapy/log.py
==================
e14cc2c1;Pablo Hoffman;2010-08-27 00:33:08 -0300;Moved scrapy-ws script to extras/ and fixed broken methods due to changes in web service API
--HG--
rename : bin/scrapy-ws.py => extras/scrapy-ws.py

==

debian/rules
debian/scrapy.lintian-overrides
extras/scrapy-ws.py
==================
648f700e;Pablo Hoffman;2010-08-26 23:23:58 -0300;Fixed log formatter tests
--HG--
rename : scrapy/tests/test_contrib_logformatter.py => scrapy/tests/test_logformatter.py

==

scrapy/tests/test_logformatter.py
==================
ad18d4a7;Pablo Hoffman;2010-08-26 23:19:35 -0300;Added pluggable log formatter

==

scrapy/conf/default_settings.py
scrapy/contrib/logformatter.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/log.py
scrapy/logformatter.py
==================
d1e260a8;Pablo Hoffman;2010-08-26 22:20:04 -0300;Simplified engine by removing the configure() and kill() methods. Also simplified the Spider Manager by removing the close_spider() method

==

scrapy/core/engine.py
scrapy/crawler.py
scrapy/spidermanager.py
==================
f6c11af4;Pablo Hoffman;2010-08-26 21:15:32 -0300;Moved module: scrapy.core.queue to scrapy.queue
--HG--
rename : scrapy/core/queue.py => scrapy/queue.py

==

scrapy/commands/shell.py
scrapy/conf/default_settings.py
scrapy/contrib/queue/__init__.py
scrapy/contrib/queue/sqs.py
scrapy/core/queue.py
scrapy/queue.py
scrapy/tests/test_core_queue.py
==================
747f090f;Pablo Hoffman;2010-08-26 20:32:26 -0300;Improved Twisted version detection (wasn't working for Twisted 10.0.0)

==

scrapy/xlib/twisted_250_monkeypatches.py
==================
e95f7f63;Pablo Hoffman;2010-08-25 21:06:10 -0300;Fixed typo

==

scrapy/tests/test_engine.py
==================
a82a4be3;Pablo Hoffman;2010-08-25 21:04:47 -0300;Added docstring to test_engine.py

==

scrapy/tests/test_engine.py
==================
59d18cf9;Pablo Hoffman;2010-08-25 19:59:51 -0300;Fixed crawler reference

==

scrapy/contrib/pipeline/media.py
==================
40b590ca;Pablo Hoffman;2010-08-25 19:59:30 -0300;Moved scrapy.cfg auto-discovery to scrapy.conf.EnvironmentSettings class

==

bin/scrapy
scrapy/conf/__init__.py
scrapy/tool.py
scrapy/utils/conf.py
==================
ef7a0972;Pablo Hoffman;2010-08-25 19:31:04 -0300;Replaced old manager references with crawler

==

scrapy/contrib/webservice/enginestatus.py
scrapy/tests/test_utils_jsonrpc.py
scrapy/tests/test_utils_serialize.py
scrapy/utils/serialize.py
==================
8fc78c4d;Pablo Hoffman;2010-08-25 19:24:36 -0300;Refactoring of Crawler, Commands, Execution Queue and Spider Manager:
Commands changes:

* removed (somewhat hacky) --init argument from settings command
* added set_crawler method to Commands, and a ``crawler`` property that returns
  a configured crawler. This way, commands that don't require a crawler (such
  as startproject) won't need to configure one.

Execution Queue changes:

* changed SERVICE_QUEUE_FILE setting to SQLITE_DB
* removed SERVICE_QUEUE setting
* added QUEUE_CLASS setting for defining the class to use for the execution queue
* added SERVER_QUEUE_CLASS setting for defining the class to use for the
  execution queue in server mode (runserver command)

Spider Manager changes:

* simplified SpiderManager API by removing the load() method
* added from_settings classmethod to SpiderManager
* added spider_modules constructor argument to SpiderManager

Crawler changes:

* added install() method to Crawler (to install it in scrapy.project) and
  uninstall() to remove it
* use CrawlerProcess.install() in scrapy.cmdline
* use crawler.install() and crawler.uninstall() in tests that a crawler in
  scrapy.project
* make telnet console and webservice play nicer with twisted by stopping
  listening when then engine goes down
* refactored Scrapy engine tests - it no longer uses the crawler singleton.
  Closes #215.

==

scrapy/cmdline.py
scrapy/command.py
scrapy/commands/crawl.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/parse.py
scrapy/commands/queue.py
scrapy/commands/runserver.py
scrapy/commands/runspider.py
scrapy/commands/settings.py
scrapy/commands/shell.py
scrapy/conf/default_settings.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/queue/__init__.py
scrapy/core/engine.py
scrapy/core/queue.py
scrapy/core/scraper.py
scrapy/crawler.py
scrapy/project.py
scrapy/spidermanager.py
scrapy/telnet.py
scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_engine.py
scrapy/tests/test_pipeline_images.py
scrapy/tests/test_pipeline_media.py
scrapy/tests/test_spidermanager/__init__.py
scrapy/tests/test_utils_jsonrpc.py
scrapy/utils/serialize.py
scrapy/webservice.py
==================
eb51b9f7;Pablo Hoffman;2010-08-25 06:41:19 -0300;Removed obsolete setting

==

scrapy/conf/default_settings.py
==================
bea2f943;Pablo Hoffman;2010-08-25 05:33:08 -0300;Instantiate SpiderManager in Crawler constructor

==

scrapy/crawler.py
scrapy/project.py
==================
8d24175c;Pablo Hoffman;2010-08-25 05:24:02 -0300;Added CrawlerProcess class, isolating all (Twisted) reactor-controlling code into this class and leaving the Crawler class free of any reactor control.
This allows embedding the Scrapy crawler in other Twisted applications, or any
Twisted asynchronous code.

The "scrapy" command will use the new CrawlerProcess class, which resembles the
behaviour of the old (all-in-one) Crawler class.

Closes #214.

Also moved log.start() call from Crawler class to scrapy.cmdline module.

==

scrapy/cmdline.py
scrapy/crawler.py
scrapy/project.py
==================
54024d1d;Pablo Hoffman;2010-08-25 05:06:45 -0300;Removed unneeded line

==

scrapy/commands/fetch.py
==================
8e83f527;Pablo Hoffman;2010-08-23 22:04:49 -0300;Removed scrapy-sqs script, as it has been superseded by the new scrapy 'queue' command

==

bin/scrapy-sqs.py
debian/rules
debian/scrapy.lintian-overrides
setup.py
==================
e2ed27e4;Pablo Hoffman;2010-08-23 21:28:32 -0300;Added documentation for Ubuntu packages. Refs #211

==

docs/index.rst
docs/intro/install.rst
docs/topics/ubuntu.rst
==================
9ee92686;Pablo Hoffman;2010-08-23 00:25:03 -0300;Moved spidermanager tests module according to policies
--HG--
rename : scrapy/tests/test_contrib_spidermanager/__init__.py => scrapy/tests/test_spidermanager/__init__.py
rename : scrapy/tests/test_contrib_spidermanager/test_spiders/__init__.py => scrapy/tests/test_spidermanager/test_spiders/__init__.py
rename : scrapy/tests/test_contrib_spidermanager/test_spiders/spider0.py => scrapy/tests/test_spidermanager/test_spiders/spider0.py
rename : scrapy/tests/test_contrib_spidermanager/test_spiders/spider1.py => scrapy/tests/test_spidermanager/test_spiders/spider1.py
rename : scrapy/tests/test_contrib_spidermanager/test_spiders/spider2.py => scrapy/tests/test_spidermanager/test_spiders/spider2.py
rename : scrapy/tests/test_contrib_spidermanager/test_spiders/spider3.py => scrapy/tests/test_spidermanager/test_spiders/spider3.py

==

scrapy/tests/test_spidermanager/__init__.py
scrapy/tests/test_spidermanager/test_spiders/__init__.py
scrapy/tests/test_spidermanager/test_spiders/spider0.py
scrapy/tests/test_spidermanager/test_spiders/spider1.py
scrapy/tests/test_spidermanager/test_spiders/spider2.py
scrapy/tests/test_spidermanager/test_spiders/spider3.py
==================
58b4cc2c;Pablo Hoffman;2010-08-23 00:23:14 -0300;Some minor fixes to contribution Contributing documentation

==

docs/contributing.rst
==================
6585c1a2;Pablo Hoffman;2010-08-22 22:42:00 -0300;removed (somewhat hacky) MAIL_DEBUG setting

==

docs/topics/email.rst
scrapy/mail.py
scrapy/tests/test_mail.py
==================
e189861b;Pablo Hoffman;2010-08-22 22:07:44 -0300;Fixed Item Loader bug that was preventing values that evaluate to False from being loaded. Patch contributed by Anibal Pacheco. Closes #174

==

scrapy/contrib/loader/__init__.py
scrapy/tests/test_contrib_loader.py
==================
254d517d;Pablo Hoffman;2010-08-22 21:53:47 -0300;Moved module: scrapy.contrib.spidermanager to scrapy.spidermanager
--HG--
rename : scrapy/contrib/spidermanager.py => scrapy/spidermanager.py

==

scrapy/conf/default_settings.py
scrapy/spidermanager.py
scrapy/tests/test_contrib_spidermanager/__init__.py
==================
cf8a085f;Pablo Hoffman;2010-08-22 20:10:11 -0300;Minor improvement to bash autocompletion

==

extras/scrapy_bash_completion
==================
fd784cd1;Pablo Hoffman;2010-08-22 19:37:20 -0300;Fixed tests on Windows

==

scrapy/contrib/feedexport.py
scrapy/tests/test_contrib_feedexport.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
scrapy/utils/url.py
==================
33686fa5;Pablo Hoffman;2010-08-22 19:08:52 -0300;better skip test message

==

scrapy/tests/test_utils_iterators.py
==================
6da11628;Pablo Hoffman;2010-08-22 19:08:45 -0300;minor fixes to FAQ

==

docs/faq.rst
==================
b3753d34;Pablo Hoffman;2010-08-22 05:59:30 -0300;Added FAQ entry about feed exports

==

docs/faq.rst
==================
cbfec4bb;Pablo Hoffman;2010-08-22 05:48:03 -0300;Renamed webservice ManagerResource to CrawlerResource
--HG--
rename : scrapy/contrib/webservice/manager.py => scrapy/contrib/webservice/crawler.py

==

docs/topics/webservice.rst
scrapy/conf/default_settings.py
scrapy/contrib/webservice/crawler.py
scrapy/contrib/webservice/manager.py
==================
7546a080;Pablo Hoffman;2010-08-22 05:38:46 -0300;Removed webservice Spiders and Extensions resources since they can now be accessed through the Execution Manager (aka. Crawler) resource

==

docs/topics/webservice.rst
scrapy/conf/default_settings.py
scrapy/contrib/webservice/extensions.py
scrapy/contrib/webservice/spiders.py
==================
e5474d8c;Pablo Hoffman;2010-08-22 05:33:08 -0300;Made ExtensionManager a subclass of MiddlewareManager

==

scrapy/crawler.py
scrapy/extension.py
scrapy/middleware.py
scrapy/project.py
==================
c1225e0f;Pablo Hoffman;2010-08-22 05:04:17 -0300;"parse" command refactoring. This fixes #173 and renders #106 invalid.

==

docs/topics/commands.rst
scrapy/commands/parse.py
scrapy/utils/display.py
==================
9fccc113;Pablo Hoffman;2010-08-22 02:15:11 -0300;Moved scrapy.extension.extensions singleton to a "extensions" attribute of the scrapy.project.crawler singleton. Refs #189

==

docs/topics/extensions.rst
docs/topics/telnetconsole.rst
scrapy/contrib/webservice/extensions.py
scrapy/crawler.py
scrapy/extension.py
scrapy/project.py
scrapy/telnet.py
==================
52c1e137;Pablo Hoffman;2010-08-22 02:15:10 -0300;Moved scrapy.spider.spiders singleton to a "spiders" attribute of the scrapy.project.crawler singleton. Refs #189
Warning: this is a backwards incompatible change.

--HG--
rename : scrapy/spider/models.py => scrapy/spider.py

==

scrapy/commands/crawl.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/parse.py
scrapy/contrib/webservice/spiders.py
scrapy/core/engine.py
scrapy/core/queue.py
scrapy/crawler.py
scrapy/project.py
scrapy/shell.py
scrapy/spider.py
scrapy/spider/__init__.py
scrapy/telnet.py
==================
faf7a7da;Pablo Hoffman;2010-08-22 02:10:53 -0300;Moved scrapymanager singleton to scrapy.project module. Refs #189
Detail of changes:

* Moved scrapy.core.manager.ExecutionManager class to scrapy.crawler.Crawler
* Added scrapy.project.crawler singleton to reference a singleton instance of
  Crawler class (previously known as scrapymanager)
* Left an alias scrapy.core.manager.scrapymanager to scrapy.project.crawler for
  backwards compatibility (to be removed in Scrapy 0.11)

==

docs/topics/telnetconsole.rst
scrapy/cmdline.py
scrapy/commands/crawl.py
scrapy/commands/fetch.py
scrapy/commands/parse.py
scrapy/commands/runserver.py
scrapy/commands/runspider.py
scrapy/commands/shell.py
scrapy/contrib/closespider.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/spiderclosedelay.py
scrapy/contrib/spidermiddleware/requestlimit.py
scrapy/contrib/webservice/enginestatus.py
scrapy/contrib/webservice/manager.py
scrapy/core/engine.py
scrapy/core/manager.py
scrapy/crawler.py
scrapy/project.py
scrapy/shell.py
scrapy/telnet.py
scrapy/tests/test_engine.py
scrapy/utils/engine.py
scrapy/utils/serialize.py
==================
053d45e7;Pablo Hoffman;2010-08-22 01:24:07 -0300;Splitted stats collector classes from stats collection facility (#204)
* moved scrapy.stats.collector.__init__ module to scrapy.statscol
* moved scrapy.stats.collector.simpledb module to scrapy.contrib.statscol
* moved signals from scrapy.stats.signals to scrapy.signals
* moved scrapy/stats/__init__.py to scrapy/stats.py
* updated documentation and tests accordingly

--HG--
rename : scrapy/stats/collector/simpledb.py => scrapy/contrib/statscol.py
rename : scrapy/stats/__init__.py => scrapy/stats.py
rename : scrapy/stats/collector/__init__.py => scrapy/statscol.py

==

docs/topics/settings.rst
docs/topics/stats.rst
scrapy/conf/default_settings.py
scrapy/contrib/corestats.py
scrapy/contrib/statscol.py
scrapy/contrib/statsmailer.py
scrapy/signals.py
scrapy/stats.py
scrapy/stats/signals.py
scrapy/statscol.py
scrapy/tests/test_engine.py
scrapy/tests/test_stats.py
==================
c276c48c;Pablo Hoffman;2010-08-21 05:10:06 -0300;Added settings to Scrapy shell variables

==

docs/topics/shell.rst
scrapy/shell.py
==================
b8b7b5ad;Pablo Hoffman;2010-08-21 05:03:38 -0300;Improved some commands descriptions

==

scrapy/commands/genspider.py
scrapy/commands/parse.py
scrapy/commands/runspider.py
scrapy/commands/settings.py
scrapy/commands/startproject.py
scrapy/commands/view.py
==================
e6d2a308;Pablo Hoffman;2010-08-21 04:56:19 -0300;example projects: added scrapy.cfg and removed scrapy-ctl.py

==

examples/experimental/googledir/scrapy-ctl.py
examples/experimental/googledir/scrapy.cfg
examples/experimental/imdb/scrapy-ctl.py
examples/experimental/imdb/scrapy.cfg
examples/googledir/scrapy-ctl.py
examples/googledir/scrapy.cfg
==================
68f9fcff;Pablo Hoffman;2010-08-21 04:46:48 -0300;genspider command refactoring. Also updated tests and doc

==

docs/topics/commands.rst
scrapy/commands/genspider.py
scrapy/tests/test_commands.py
==================
0da61321;Pablo Hoffman;2010-08-21 03:37:59 -0300;Made command-line too output more concise

==

docs/topics/commands.rst
scrapy/cmdline.py
==================
0d9e75c6;Pablo Hoffman;2010-08-21 03:23:45 -0300;Added bash completion for the Scrapy command-line tool. Closes #210

==

debian/scrapy.install
extras/scrapy_bash_completion
==================
f80ae9af;Pablo Hoffman;2010-08-21 01:44:08 -0300;Fixed missing reference to old 'start' command. Refs #209

==

scrapy/service.py
==================
50621b7e;Pablo Hoffman;2010-08-21 01:42:55 -0300;Renamed command "start" to "runserver". Closes #209
--HG--
rename : scrapy/commands/start.py => scrapy/commands/runserver.py

==

docs/topics/commands.rst
scrapy/commands/runserver.py
==================
9aefa242;Pablo Hoffman;2010-08-21 01:26:35 -0300;Applied documentation patch provided by Lucian Ursu (closes #207)

==

AUTHORS
docs/intro/install.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/item-pipeline.rst
docs/topics/items.rst
docs/topics/leaks.rst
docs/topics/link-extractors.rst
docs/topics/loaders.rst
docs/topics/logging.rst
docs/topics/request-response.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/shell.rst
docs/topics/signals.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
docs/topics/stats.rst
docs/topics/telnetconsole.rst
==================
f782245c;Pablo Hoffman;2010-08-21 01:24:39 -0300;Removed obsolete files

==

docs/topics/_images/adaptors_diagram.png
docs/topics/_images/adaptors_diagram.svg
==================
1d3b9e2c;Pablo Hoffman;2010-08-20 11:26:14 -0300;Scrapy shell refactoring

==

docs/faq.rst
docs/intro/tutorial.rst
docs/topics/logging.rst
docs/topics/shell.rst
scrapy/commands/shell.py
scrapy/shell.py
scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
7858244d;Pablo Hoffman;2010-08-20 01:33:02 -0300;Scrapy shell: moved python console starting code to scrapy.utils.console and get rid of noisy console banners

==

docs/intro/tutorial.rst
docs/topics/shell.rst
scrapy/shell.py
scrapy/utils/console.py
==================
136b0e74;Pablo Hoffman;2010-08-19 21:14:27 -0300;Minor change to log message

==

scrapy/core/engine.py
==================
6dd76ab5;Pablo Hoffman;2010-08-19 21:11:39 -0300;Fixed bug in Scrapy shell which hanged if requests failed to download (#205), added dont_filter=True to requests generated when calling the shell with a url argument, and changed formatting of messages

==

scrapy/commands/shell.py
scrapy/shell.py
==================
30e2404d;Pablo Hoffman;2010-08-19 17:59:52 -0300;updated FAQ entry to recommend using higher download delays

==

docs/faq.rst
==================
66525e77;Pablo Hoffman;2010-08-19 17:57:34 -0300;Improved support for scrapy-ctl -> scrapy migration by generating the scrapy.cfg file automatically if it doensn't exist

==

scrapy/cmdline.py
==================
3d8151bb;Pablo Hoffman;2010-08-19 16:51:51 -0300;Added FAQ entry about response code 999

==

docs/faq.rst
==================
2ff5a83b;Pablo Hoffman;2010-08-19 02:55:52 -0300;Added persistent execution queue (based on SQLite), and a new 'queue' command to control it. Closes #198

==

docs/topics/commands.rst
scrapy/commands/queue.py
scrapy/conf/default_settings.py
scrapy/contrib/queue/__init__.py
scrapy/tests/test_utils_sqlite.py
scrapy/utils/sqlite.py
==================
9740ad62;Pablo Hoffman;2010-08-19 02:30:15 -0300;Added tests for runspider command

==

scrapy/tests/test_commands.py
==================
abd7a5e2;Pablo Hoffman;2010-08-19 01:58:10 -0300;Fixed bug with runspider command that appeared after the introduction of new spider manager in r2121. Also factored out common code shared by new spider manager and runspider command, with tests included.

==

scrapy/commands/runspider.py
scrapy/contrib/spidermanager.py
scrapy/tests/test_utils_spider.py
scrapy/utils/spider.py
==================
85f3a4a6;Pablo Hoffman;2010-08-19 00:07:14 -0300;removed obsolete setting

==

scrapy/conf/default_settings.py
==================
94ead94b;Pablo Hoffman;2010-08-19 00:04:52 -0300;Improved documentation of Scrapy command-line tool
--HG--
rename : docs/topics/cmdline.rst => docs/topics/commands.rst

==

docs/_ext/scrapydocs.py
docs/index.rst
docs/topics/cmdline.rst
docs/topics/commands.rst
docs/topics/settings.rst
==================
34554da2;Pablo Hoffman;2010-08-18 19:48:32 -0300;Deprecated scrapy-ctl.py command in favour of simpler "scrapy" command. Closes #199. Also updated documenation accordingly and added convenient scrapy.bat script for running from Windows.
--HG--
rename : debian/scrapy-ctl.1 => debian/scrapy.1
rename : docs/topics/scrapy-ctl.rst => docs/topics/cmdline.rst

==

bin/scrapy-ctl.py
debian/rules
debian/scrapy.1
debian/scrapy.manpages
docs/faq.rst
docs/index.rst
docs/intro/install.rst
docs/intro/tutorial.rst
docs/topics/cmdline.rst
docs/topics/scrapy-ctl.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/shell.rst
examples/experimental/googledir/googledir/spiders/__init__.py
examples/experimental/imdb/imdb/spiders/__init__.py
extras/scrapy.bat
scrapy/cmdline.py
scrapy/commands/startproject.py
scrapy/templates/project/module/spiders/__init__.py
scrapy/templates/project/scrapy-ctl.py
scrapy/tests/test_commands.py
setup.py
==================
5522afca;Daniel Grana;2010-08-18 13:05:50 -0300;pipeline process_item methods decorated with inlineCallbacks fails because of backwards compatible change to support inverted arguments

==

scrapy/contrib/pipeline/__init__.py
==================
50f2236d;Pablo Hoffman;2010-08-17 18:31:16 -0300;removed hacky command_executed signal

==

scrapy/cmdline.py
==================
a71521bf;Pablo Hoffman;2010-08-17 18:30:13 -0300;Default per-command settings are now specified in the default_settings attribute of the command object. Closes #201

==

docs/topics/settings.rst
scrapy/cmdline.py
scrapy/command.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/settings.py
scrapy/commands/shell.py
scrapy/commands/startproject.py
scrapy/conf/commands/__init__.py
scrapy/conf/commands/genspider.py
scrapy/conf/commands/help.py
scrapy/conf/commands/list.py
scrapy/conf/commands/settings.py
scrapy/conf/commands/shell.py
scrapy/conf/commands/startproject.py
scrapy/conf/default_settings.py
==================
76e19baa;Pablo Hoffman;2010-08-17 14:48:38 -0300;minor setting fix

==

scrapy/conf/default_settings.py
==================
ad3fd0af;Pablo Hoffman;2010-08-17 14:37:59 -0300;fixed minor formatting issue with new feed exports doc

==

docs/topics/feed-exports.rst
==================
e741a807;Pablo Hoffman;2010-08-17 14:27:48 -0300;Added new Feed exports extension with documentation and storage tests. Closes #197.
Also deprecated File export pipeline (to be removed in Scrapy 0.11).

Still need to add tests for FeedExport main extension code.

==

bin/runtests.sh
docs/index.rst
docs/intro/overview.rst
docs/topics/exporters.rst
docs/topics/feed-exports.rst
docs/topics/item-pipeline.rst
docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/feedexport.py
scrapy/contrib/pipeline/fileexport.py
scrapy/tests/test_contrib_feedexport.py
scrapy/utils/ftp.py
==================
d17695ee;Pablo Hoffman;2010-08-17 00:59:24 -0300;Added "scrapy" command with project settings auto-discovery. Refs #199

==

bin/scrapy
scrapy/commands/startproject.py
scrapy/templates/project/scrapy.cfg
scrapy/tool.py
setup.py
==================
b563e563;Pablo Hoffman;2010-08-16 12:25:51 -0300;fixed bug in url_is_from_spider() when no allowed_domains class attribute is present

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
a28cf290;Pablo Hoffman;2010-08-16 10:10:57 -0300;Simplified BaseSpider code by removing backwards compatibility code

==

scrapy/spider/models.py
scrapy/tests/test_spider.py
==================
3e3a6662;Pablo Hoffman;2010-08-14 21:10:37 -0300;Added support for returning deferreds from (some) signal handlers. Closes #193

==

docs/faq.rst
docs/topics/signals.rst
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/tests/test_utils_signal.py
scrapy/utils/signal.py
==================
5755bdcd;Pablo Hoffman;2010-08-13 01:45:47 -0300;Improve spider errors logging which were previously logged as confusing "Unhandled errors" - closes #196

==

scrapy/core/scraper.py
scrapy/tests/test_utils_defer.py
scrapy/utils/defer.py
==================
1df2c17b;Pablo Hoffman;2010-08-12 20:45:11 -0300;updated old documentation references

==

docs/topics/settings.rst
docs/topics/telnetconsole.rst
==================
43d47e5d;Pablo Hoffman;2010-08-12 10:48:37 -0300;Some improvements to Item Pipeline (closes #195):
* Made Item Pipeline Manager a subclass of scrapy.middleware.MiddlewareManager
* Added open_spider/close_spider methods with support for returning deferreds from them
* Inverted the process_item() arguments to be more friendly with deferred
  callbacks (backwards compatibility kept through arguments introspection)
* Updated documentation with new methods and process_item() arguments change

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/exporters.rst
docs/topics/item-pipeline.rst
examples/experimental/googledir/googledir/pipelines.py
examples/experimental/imdb/imdb/pipelines.py
examples/googledir/googledir/pipelines.py
scrapy/contrib/pipeline/__init__.py
scrapy/contrib/pipeline/fileexport.py
scrapy/contrib/pipeline/media.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/tests/test_pipeline_media.py
==================
2167bfb2;Pablo Hoffman;2010-08-12 10:26:50 -0300;added prepend_level argument to log._adapt_eventdict()

==

scrapy/log.py
==================
ae692c05;Pablo Hoffman;2010-08-12 03:04:19 -0300;made MiddlewareManager an abstract class, and minor change to log message

==

scrapy/middleware.py
==================
192ec5e3;Pablo Hoffman;2010-08-12 00:33:40 -0300;Error logging improvements

==

scrapy/core/scraper.py
==================
6d21f2f2;Pablo Hoffman;2010-08-10 18:27:58 -0300;removed reference to old middleware

==

scrapy/conf/default_settings.py
==================
68ae1da0;Pablo Hoffman;2010-08-10 18:26:40 -0300;removed unused import

==

scrapy/tests/test_downloadermiddleware_httpproxy.py
==================
6a0ef0e4;Pablo Hoffman;2010-08-10 18:22:05 -0300;removed unused import

==

scrapy/tests/test_downloadermiddleware_useragent.py
==================
0f342417;Pablo Hoffman;2010-08-10 18:15:28 -0300;remove old unsupported item sampler middleware

==

scrapy/contrib/itemsampler.py
==================
2822db73;Pablo Hoffman;2010-08-10 18:03:47 -0300;added new MiddlewareManager class that will be used as base class for pipeline and middlewares

==

scrapy/middleware.py
scrapy/tests/test_middleware.py
scrapy/tests/test_utils_defer.py
scrapy/utils/defer.py
==================
9d38a99a;Pablo Hoffman;2010-08-10 17:47:04 -0300;updated missing doc reference from previous commit

==

docs/topics/signals.rst
==================
dedd6b22;Pablo Hoffman;2010-08-10 17:42:05 -0300;added more information to deprecation notice

==

scrapy/core/exceptions.py
scrapy/core/signals.py
==================
78472277;Pablo Hoffman;2010-08-10 17:40:53 -0300;moved scrapy.core.signals to scrapy.signals, keeping backwards compatibility

==

docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/item-pipeline.rst
scrapy/commands/runspider.py
scrapy/contrib/closespider.py
scrapy/contrib/corestats.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/defaultheaders.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/itemsampler.py
scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/fileexport.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/resolver.py
scrapy/contrib/spiderclosedelay.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/requestlimit.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/middleware.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/core/signals.py
scrapy/signals.py
scrapy/stats/collector/__init__.py
scrapy/tests/test_engine.py
==================
c359a34d;Pablo Hoffman;2010-08-10 17:36:48 -0300;moved scrapy.core.exceptions to scrapy.exceptions, keeping backwards compatibility
--HG--
rename : scrapy/core/exceptions.py => scrapy/exceptions.py

==

docs/topics/downloader-middleware.rst
docs/topics/exceptions.rst
docs/topics/extensions.rst
docs/topics/images.rst
docs/topics/item-pipeline.rst
docs/topics/signals.rst
examples/experimental/googledir/googledir/pipelines.py
examples/googledir/googledir/pipelines.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/httpproxy.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/downloadermiddleware/stats.py
scrapy/contrib/itemsampler.py
scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/__init__.py
scrapy/contrib/pipeline/fileexport.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/contrib/spiderclosedelay.py
scrapy/contrib/spidermiddleware/httperror.py
scrapy/contrib/spidermiddleware/requestlimit.py
scrapy/contrib/spidermiddleware/urllength.py
scrapy/contrib/spiders/feed.py
scrapy/contrib/statsmailer.py
scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/manager.py
scrapy/core/downloader/middleware.py
scrapy/core/engine.py
scrapy/core/exceptions.py
scrapy/core/scheduler.py
scrapy/core/schedulermw.py
scrapy/core/scraper.py
scrapy/core/spidermw.py
scrapy/exceptions.py
scrapy/extension.py
scrapy/mail.py
scrapy/telnet.py
scrapy/tests/test_downloadermiddleware_httpcache.py
scrapy/tests/test_downloadermiddleware_httpproxy.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
scrapy/utils/defer.py
scrapy/webservice.py
==================
355c615c;Pablo Hoffman;2010-08-10 17:23:22 -0300;removed old unsupported SpiderProfiler extension

==

scrapy/contrib_exp/spiderprofiler.py
==================
b1c02806;Pablo Hoffman;2010-08-10 16:59:49 -0300;removed scheduler middleware doc, as scheduler middleware will be removed soon

==

docs/experimental/index.rst
docs/experimental/scheduler-middleware.rst
==================
5aa8e639;Pablo Hoffman;2010-08-09 14:41:54 -0300;Removed 'sender' argument when sending signals, as we're not sending it consistently, and it's not being used by receivers either

==

scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/middleware.py
scrapy/core/engine.py
scrapy/core/scraper.py
==================
3d121898;Pablo Hoffman;2010-08-09 13:32:44 -0300;add signal handler name when logging errors

==

scrapy/utils/signal.py
==================
a08e62a2;Pablo Hoffman;2010-08-09 13:24:22 -0300;silence irrelevant (and confusing) errors generated in tests by signals left active after engine tests run - we should really rewrite engine tests asap

==

scrapy/tests/test_engine.py
scrapy/utils/signal.py
==================
bb2e0de7;Pablo Hoffman;2010-08-09 13:22:57 -0300;fixed utils.signal tests broken in previous commit

==

scrapy/tests/test_utils_signal.py
==================
8de0dc36;Pablo Hoffman;2010-08-09 12:05:03 -0300;Log full traceback of signal handler errors in send_catch_log() - closes #194. Also made engine use send_catch_log for spider_idle signal

==

scrapy/core/engine.py
scrapy/utils/signal.py
==================
2aa84073;Pablo Hoffman;2010-08-09 11:09:07 -0300;moved scrapy log observer logic into a separate function

==

scrapy/log.py
==================
5139843c;Pablo Hoffman;2010-08-09 11:07:45 -0300;avoid noisy KeyError in enqueue_scrape, when closing spiders manually

==

scrapy/core/scraper.py
==================
67e42d1b;Pablo Hoffman;2010-08-08 07:30:03 -0300;Moved scrapy/command/__init__.py to scrapy/command.py
--HG--
rename : scrapy/command/__init__.py => scrapy/command.py

==

scrapy/command.py
scrapy/command/cmdline.py
==================
c7d9f6e2;Pablo Hoffman;2010-08-07 15:52:59 -0300;Added JSON item exporter with doc and unittests (closes #192), and also:
* put all json exporters in scrapy.contrib.exporters and deprecated
  scrapy.contrib.exporters.jsonlines to reduce module nesting
* use JSON exporter with EXPORT_FORMAT=json in file export pipeline

==

docs/faq.rst
docs/topics/exporters.rst
docs/topics/item-pipeline.rst
scrapy/contrib/exporter/__init__.py
scrapy/contrib/exporter/jsonlines.py
scrapy/contrib/pipeline/fileexport.py
scrapy/tests/test_contrib_exporter.py
==================
ba2369bf;Pablo Hoffman;2010-08-06 15:05:58 -0300;changed variable names for clarity

==

scrapy/contrib/spidermanager.py
==================
35e6c872;Pablo Hoffman;2010-08-06 14:59:18 -0300;Added handles_request() class method to BaseSpider - closes #191

==

scrapy/commands/crawl.py
scrapy/contrib/spidermanager.py
scrapy/spider/models.py
scrapy/tests/test_contrib_spidermanager/__init__.py
scrapy/tests/test_contrib_spidermanager/test_spiders/spider3.py
==================
4d66f4c6;Pablo Hoffman;2010-08-05 20:46:54 -0300;Added support for logging twisted errors generated outside of Scrapy - refs #188

==

scrapy/log.py
scrapy/tests/test_log.py
==================
c82260f5;Pablo Hoffman;2010-08-05 13:31:19 -0300;make runtests.sh more virtualenv-friendly

==

bin/runtests.sh
==================
daa9506b;Pablo Hoffman;2010-08-04 14:20:45 -0300;Fixed bug with non-keepalive execution queues (closes #190)

==

scrapy/core/manager.py
==================
49851d7f;Pablo Hoffman;2010-08-02 17:20:55 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
6c68e4ce;Pablo Hoffman;2010-08-02 17:20:13 -0300;fixed documentation typo

==

docs/topics/link-extractors.rst
==================
b2878fbb;Pablo Hoffman;2010-08-02 12:16:36 -0300;scrapy.utils.url_is_from_spider() - Consider spider name as possible domain for matching in scrapy.utils.url_is_from_spider()

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
453e7bf3;Pablo Hoffman;2010-08-02 08:49:14 -0300;Scrapy logging refactoring (closes #188):
 * added Twisted log observer for Scrapy, with unittests
 * use numeric values from Python logging module for log levels
 * removed scrapy.log.exc() function - use scrapy.log.err() instead
 * removed logmessage_received signal - write a (twisted) log observer instead
 * dropped support for obsolete `domain` argument
 * dropped support for old setting names: LOGLEVEL, LOGFILE (replaced by LOG_LEVEL, LOG_FILE)
 * deprecated `component` argument

==

docs/topics/logging.rst
scrapy/log.py
scrapy/tests/test_log.py
scrapy/tests/test_utils_signal.py
==================
c5fd113c;Pablo Hoffman;2010-07-31 16:02:59 -0300;minor fix to path name

==

debian/scrapy-service.prerm
==================
f6eac8e3;Pablo Hoffman;2010-07-31 15:50:12 -0300;Splitted single Debian package into two packages (closes #187):
- scrapy: which provides only the library and scrapy-ctl command
- scrapy-service: which provides the service, upstart script, system user, etc

This allows a clean install of just the library for those which are not
interested in the Scrapy service.

--HG--
rename : debian/scrapy.dirs => debian/scrapy-service.dirs
rename : debian/scrapy.install => debian/scrapy-service.install
rename : debian/scrapy.postinst => debian/scrapy-service.postinst
rename : debian/scrapy.postrm => debian/scrapy-service.postrm
rename : debian/scrapy.upstart => debian/scrapy-service.upstart
rename : debian/conf/service_conf.py => debian/service_conf.py

==

debian/changelog
debian/conf/environment
debian/control
debian/copyright
debian/pycompat
debian/pyversions
debian/rules
debian/scrapy-service.default
debian/scrapy-service.dirs
debian/scrapy-service.install
debian/scrapy-service.lintian-overrides
debian/scrapy-service.postinst
debian/scrapy-service.postrm
debian/scrapy-service.prerm
debian/scrapy-service.upstart
debian/scrapy.install
debian/scrapy.lintian-overrides
debian/scrapy.postinst
debian/scrapy.upstart
debian/service_conf.py
debian/watch
==================
e145ec68;Ismael Carnales;2010-07-30 17:30:32 -0300;Replaced default spider manager (TwistedPluginSpiderManger) with a simpler one that doesn't depend on Twisted Plugins infrastructure.

==

docs/intro/tutorial.rst
docs/topics/firebug.rst
docs/topics/spiders.rst
examples/experimental/googledir/googledir/spiders/google_directory.py
examples/experimental/imdb/imdb/spiders/imdb_site.py
examples/googledir/googledir/spiders/google_directory.py
scrapy/conf/default_settings.py
scrapy/contrib/spidermanager.py
scrapy/spider/models.py
scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
scrapy/tests/test_contrib_spidermanager/__init__.py
scrapy/tests/test_contrib_spidermanager/test_spiders/spider0.py
scrapy/tests/test_contrib_spidermanager/test_spiders/spider1.py
scrapy/tests/test_contrib_spidermanager/test_spiders/spider2.py
==================
65c3de8e;Pablo Hoffman;2010-07-30 17:05:55 -0300;Rewritten walk_modules function to support eggs, and added tests

==

scrapy/tests/test_utils_misc/__init__.py
scrapy/tests/test_utils_misc/test.egg
scrapy/utils/misc.py
==================
6d068244;Ismael Carnales;2010-07-30 15:53:24 -0300;utils: Add walk_packages utility function
--HG--
rename : scrapy/tests/test_utils_misc.py => scrapy/tests/test_utils_misc/__init__.py

==

scrapy/tests/test_utils_misc.py
scrapy/tests/test_utils_misc/__init__.py
scrapy/tests/test_utils_misc/test_walk_modules/__init__.py
scrapy/tests/test_utils_misc/test_walk_modules/mod/__init__.py
scrapy/tests/test_utils_misc/test_walk_modules/mod/mod0.py
scrapy/tests/test_utils_misc/test_walk_modules/mod1.py
scrapy/utils/misc.py
==================
9511a315;Ismael Carnales;2010-07-30 14:49:07 -0300;Fix error message when spider not found in parse command

==

scrapy/commands/parse.py
==================
e112def7;Pablo Hoffman;2010-07-29 12:11:07 -0300;removed old untested module: scrapy.utils.mysql

==

scrapy/utils/mysql.py
==================
63128262;Pablo Hoffman;2010-07-29 12:03:02 -0300;removed (no longer supported) webconsole code

==

scrapy/conf/default_settings.py
scrapy/contrib/webconsole/__init__.py
scrapy/contrib/webconsole/enginestatus.py
scrapy/contrib/webconsole/livestats.py
scrapy/contrib/webconsole/scheduler.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/contrib/webconsole/stats.py
scrapy/management/__init__.py
scrapy/management/web.py
==================
936ffe5e;molveyra;2010-07-28 11:28:52 -0300;Automated merge with ssh://hg@hg.scrapy.org:2222/scrapy

==
==================
8781ef39;molveyra;2010-07-28 11:16:42 -0300;Remove restriction of marking ignore-beneath only for img unpaired tags

==

scrapy/contrib/ibl/extraction/pageparsing.py
==================
2349d241;Pablo Hoffman;2010-07-24 17:02:08 -0300;removed custom Makefile and version based on mercurial revision

==

Makefile
setup.py
==================
e2290a53;Pablo Hoffman;2010-07-22 18:40:35 -0300;Some changes to Crawl spider:
* added process_request attribute to rules
* removed docstrings, since it duplicates documentation

==

docs/topics/spiders.rst
scrapy/contrib/spiders/crawl.py
==================
4e2859e5;Daniel Grana;2010-07-20 15:47:46 -0300;Automated merge with ssh://hg.scrapy.org/scrapy-0.9

==
==================
68c7ef7d;Daniel Grana;2010-07-20 15:47:07 -0300;fix scraper leak closing spider. closes #182

==

scrapy/core/scraper.py
==================
3e013f56;Daniel Grana;2010-07-16 16:17:08 -0300;update docs for defaultheaders middleware and change spider attribute to match global setting name

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/defaultheaders.py
scrapy/tests/test_downloadermiddleware_defaultheaders.py
==================
6883a99c;Daniel Grana;2010-07-16 14:56:00 -0300;Automated merge with ssh://hg.scrapy.org/scrapy-0.9

==
==================
b799e5ee;Daniel Grana;2010-07-16 14:51:14 -0300;Support default headers per spider. closes #181
--HG--
extra : rebase_source : 60162dffa4fbab525501e46b479dc272b8998942

==

scrapy/contrib/downloadermiddleware/defaultheaders.py
scrapy/tests/test_downloadermiddleware_defaultheaders.py
==================
b91d40ba;Pablo Hoffman;2010-07-16 11:34:18 -0300;Fixed grammar error in doc (patch by stav) - closes #176

==

docs/topics/loaders.rst
==================
b8aa74ee;Pablo Hoffman;2010-07-15 12:04:55 -0300;bugfix in request_httprepr() function

==

scrapy/tests/test_utils_request.py
scrapy/utils/request.py
==================
ec850b9f;Martin Olveyra;2010-07-14 18:47:09 -0300;Fix memusage report concatenation

==

scrapy/contrib/memusage.py
==================
90a04f05;Pablo Hoffman;2010-07-13 19:47:55 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
cc32f6ec;Pablo Hoffman;2010-07-13 19:46:53 -0300;Applied patch to ClientForm to fix bug with wrong entities. Also added tests and left patch in repo in case we upgrade ClientForm in the future and need to re-apply it

==

scrapy/tests/test_clientform.py
scrapy/xlib/ClientForm.patch
scrapy/xlib/ClientForm.py
==================
9e37ec42;Pablo Hoffman;2010-07-13 19:03:02 -0300;fixed documentation typo (closes #151)

==

docs/intro/tutorial.rst
==================
b3a65d33;Ping Yin;2010-07-09 13:14:25 -0300;HTTPCACHE: Don't cache response with codes in HTTPCACHE_IGNORE_HTTP_CODES

==

docs/topics/downloader-middleware.rst
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
2067bcd8;Pablo Hoffman;2010-07-08 14:03:58 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
2ddbbc81;Juan Picca;2010-07-08 14:02:28 -0300;allow passing custom headers in FormRequest.from_response()

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
a6a86d9b;Pablo Hoffman;2010-07-01 11:48:36 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
b258fc33;Martin Olveyra;2010-07-01 11:46:06 -0300;Fixed bug with float values in meta refresh

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
3e976e50;Pablo Hoffman;2010-06-28 00:55:35 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
b23af5cc;Pablo Hoffman;2010-06-28 00:54:47 -0300;Added tag 0.9 for changeset 5caf3dc10a92

==

.hgtags
==================
6525d3fe;Pablo Hoffman;2010-06-28 00:54:43 -0300;bumped version to 0.9 final

==

scrapy/__init__.py
==================
66053291;Pablo Hoffman;2010-06-27 19:57:54 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
861c04fb;Pablo Hoffman;2010-06-27 19:55:39 -0300;made encoding explicit in test_get_meta_refresh, to avoid depending on unreliable UnicodeDammit criteria.

==

scrapy/tests/test_utils_response.py
==================
696bb63a;Pablo Hoffman;2010-06-27 19:32:47 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
22555df5;Pablo Hoffman;2010-06-27 19:32:26 -0300;response_httprepr: fixed error with unknown response codes (closes #169)

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
54082026;Pablo Hoffman;2010-06-27 19:23:41 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
2571e1b7;Ismael Carnales;2010-06-27 09:09:54 -0300;docs: Some DjangoItem docs improvements, closes #134. Thanks tn!

==

docs/experimental/djangoitems.rst
==================
7b80cce1;Daniel Grana;2010-06-25 13:06:14 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
91483217;Daniel Grana;2010-06-25 12:57:15 -0300;do not redirect when there is a commented meta refresh header. closes #170

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
a61df93a;Pablo Hoffman;2010-06-22 14:00:51 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
3bbad369;Pablo Hoffman;2010-06-22 14:00:31 -0300;Raise when trying to set an item field value using setattr api, and added tests.

==

scrapy/item.py
scrapy/tests/test_item.py
==================
504f90c6;Pablo Hoffman;2010-06-22 13:39:29 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.9

==
==================
baa52305;Pablo Hoffman;2010-06-22 13:38:32 -0300;removed nltk dependency from IBL code

==

scrapy/contrib/ibl/__init__.py
scrapy/contrib/ibl/extraction/regionextract.py
scrapy/tests/test_contrib_ibl/test_extraction.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
==================
e665e5ab;Pablo Hoffman;2010-06-14 22:00:54 -0300;bumped version to 0.10-dev

==

scrapy/__init__.py
==================
8815de94;Pablo Hoffman;2010-06-14 18:37:55 -0300;Added tag 0.9-rc1 for changeset 8b9c31e18c08

==

.hgtags
==================
61e374eb;Pablo Hoffman;2010-06-14 18:37:52 -0300;bumped version to 0.9-rc1

==

scrapy/__init__.py
==================
115e9f21;Pablo Hoffman;2010-06-14 18:21:12 -0300;Added FAQ entry about running Scrapy deployment.

==

docs/faq.rst
==================
f3d2ee41;Daniel Grana;2010-06-14 12:34:52 -0300;mediapipeline: bugfix error raised when media requests has not callbacks, remove item_media_{downloaded,failed} hooks in favour or request.{errback,calback}, and add tests
--HG--
extra : rebase_source : 72172406ab4ffc748e1648b46fe976e403b87c29

==

scrapy/contrib/pipeline/media.py
scrapy/tests/test_pipeline_media.py
==================
0731c42e;Pablo Hoffman;2010-06-14 09:58:17 -0300;added "hg purge" to make tarball

==

Makefile
==================
4262a0af;Pablo Hoffman;2010-06-14 09:49:07 -0300;moved sign_release.sh code to Makefile

==

Makefile
extras/sign_release.sh
==================
d8ac4857;Pablo Hoffman;2010-06-14 09:11:35 -0300;a couple of fixes to make tests pass on win32

==

scrapy/tests/test_utils_response.py
scrapy/utils/jsonrpc.py
==================
2d3d5b6a;Pablo Hoffman;2010-06-14 08:59:20 -0300;use mercurial revision to construct version, when building a non-final version

==

setup.py
==================
68e8e6ac;Pablo Hoffman;2010-06-14 08:28:48 -0300;removed unused code

==

setup.py
==================
ede1df4b;Pablo Hoffman;2010-06-14 07:16:51 -0300;updated copyright year, and indentation space

==

debian/conf/service_conf.py
docs/conf.py
==================
247fc265;Pablo Hoffman;2010-06-13 23:09:08 -0300;moved scrapy.tac to extras/
--HG--
rename : bin/scrapy.tac => extras/scrapy.tac

==

debian/scrapy.install
extras/scrapy.tac
==================
09182efa;Pablo Hoffman;2010-06-13 19:17:17 -0300;added scrapy-sqs.py to deployed scripts

==

README
debian/rules
setup.py
==================
37f71a99;Pablo Hoffman;2010-06-13 18:59:52 -0300;upstart script: exec twistd and use pidfile

==

debian/scrapy.upstart
==================
91e1e0af;Pablo Hoffman;2010-06-13 17:31:33 -0300;fixed bug and updated old code in googledir example project

==

examples/googledir/googledir/pipelines.py
examples/googledir/googledir/spiders/google_directory.py
==================
bd16d1cd;Pablo Hoffman;2010-06-13 17:14:46 -0300;Added SMTP-AUTH support to scrapy.mail (closes #149)

==

docs/topics/email.rst
docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/mail.py
==================
495f23de;Pablo Hoffman;2010-06-11 18:16:09 -0300;utils.serialize: added support for encoding Deferreds, and to refer spiders by name using 'spider::name'

==

scrapy/tests/test_utils_serialize.py
scrapy/utils/serialize.py
==================
1b083911;Pablo Hoffman;2010-06-11 18:14:01 -0300;scrapy-ws.py: added stop command

==

bin/scrapy-ws.py
==================
ed5d7561;Pablo Hoffman;2010-06-11 17:22:14 -0300;Added SQS Execution Queue, and example script to add spiders to the queue

==

bin/scrapy-sqs.py
scrapy/commands/start.py
scrapy/conf/default_settings.py
scrapy/contrib/queue/__init__.py
scrapy/contrib/queue/sqs.py
scrapy/core/queue.py
==================
efe9811d;olveyra;2010-06-11 13:09:56 -0300;Populate annotation metadata with data not used by IBL extractor.

==

scrapy/contrib/ibl/extraction/__init__.py
scrapy/contrib/ibl/extraction/pageobjects.py
scrapy/contrib/ibl/extraction/pageparsing.py
scrapy/tests/test_contrib_ibl/samples_pageparsing.json.gz
==================
ea8b5ddf;Pablo Hoffman;2010-06-11 12:48:35 -0300;debian package: fix dh_auto_build confusing with Makefile, added scrapy-ws.py to deployed scripts

==

Makefile
debian/rules
setup.py
==================
03912a65;Pablo Hoffman;2010-06-11 11:33:02 -0300;Added Ping Yin to AUTHORS

==

AUTHORS
==================
d13b50a2;Pablo Hoffman;2010-06-11 01:18:16 -0300;Added sources and Makefile for building Debian package

==

Makefile
debian/changelog
debian/compat
debian/conf/environment
debian/conf/service_conf.py
debian/control
debian/copyright
debian/pycompat
debian/pyversions
debian/rules
debian/scrapy-ctl.1
debian/scrapy.dirs
debian/scrapy.docs
debian/scrapy.examples
debian/scrapy.install
debian/scrapy.manpages
debian/scrapy.postinst
debian/scrapy.postrm
debian/scrapy.upstart
debian/watch
==================
d7627640;Pablo Hoffman;2010-06-10 14:50:06 -0300;scrapy.service: fixed minor logging bug on win32 platform with different line endings

==

scrapy/service.py
==================
a8b80f3e;Pablo Hoffman;2010-06-10 14:08:54 -0300;scrapy.service: added support for logging stdout/stderr tails of finished processes

==

scrapy/service.py
==================
a33e8b50;Pablo Hoffman;2010-06-10 13:39:45 -0300;scrapy.service: fixed bug with process respawning

==

scrapy/service.py
==================
075b59f4;Pablo Hoffman;2010-06-10 11:51:46 -0300;some improvements and fixes to scrapy.service

==

scrapy/service.py
==================
6a33d6c4;Pablo Hoffman;2010-06-09 13:46:22 -0300;* Added Scrapy Web Service with documentation and tests. * Marked Web Console as deprecated. * Removed Web Console documentation to discourage its use.

==

bin/scrapy-ws.py
docs/index.rst
docs/intro/overview.rst
docs/topics/extensions.rst
docs/topics/settings.rst
docs/topics/webconsole.rst
docs/topics/webservice.rst
scrapy/conf/default_settings.py
scrapy/contrib/webconsole/__init__.py
scrapy/contrib/webservice/__init__.py
scrapy/contrib/webservice/enginestatus.py
scrapy/contrib/webservice/extensions.py
scrapy/contrib/webservice/manager.py
scrapy/contrib/webservice/spiders.py
scrapy/contrib/webservice/stats.py
scrapy/management/web.py
scrapy/spider/models.py
scrapy/tests/test_utils_jsonrpc.py
scrapy/tests/test_utils_serialize.py
scrapy/utils/engine.py
scrapy/utils/jsonrpc.py
scrapy/utils/serialize.py
scrapy/webservice.py
==================
2499dfee;Pablo Hoffman;2010-06-09 13:06:05 -0300;removed obsolete test

==

scrapy/tests/test_contrib_exp_crawlspider_reqgen.py
==================
62f5c61a;Daniel Grana;2010-06-09 00:44:18 -0300;fix broken request tests. refs #166

==

scrapy/tests/test_http_request.py
==================
73305b1e;Pablo Hoffman;2010-06-08 18:18:02 -0300;Added support for Requests without callbacks (#166) - the Spider.parse() method is used in those cases.
Also removed Request.deferred attribute.

==

docs/topics/request-response.rst
docs/topics/spiders.rst
scrapy/contrib/pipeline/media.py
scrapy/contrib/spiders/crawl.py
scrapy/contrib_exp/spiderprofiler.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/http/request/__init__.py
scrapy/spider/models.py
==================
76ed9d44;Pablo Hoffman;2010-06-07 15:11:25 -0300;Relocated some modules: * scrapy.spider.middelware moved to scrapy.core.spidermw * scrapy.core.scheduler.schedulers to scrapy.core.scheduler * scrapy.core.scheduler.middleware to scrapy.core.schedulermw
Also removed dir: scrapy/core/scheduler/

--HG--
rename : scrapy/core/scheduler/schedulers.py => scrapy/core/scheduler.py
rename : scrapy/core/scheduler/middleware.py => scrapy/core/schedulermw.py
rename : scrapy/spider/middleware.py => scrapy/core/spidermw.py

==

scrapy/core/scheduler.py
scrapy/core/scheduler/__init__.py
scrapy/core/schedulermw.py
scrapy/core/scraper.py
scrapy/core/spidermw.py
==================
72df5cb7;Pablo Hoffman;2010-06-03 01:07:40 -0300;removed unused code

==

scrapy/shell.py
==================
38b57931;Pablo Hoffman;2010-06-02 17:49:18 -0300;Some changes to telnet console:
* moved module from scrapy.management.telnet to scrapy.telnet (to minimize
  nested modules)
* added signal for updating telnet console variables (fixes #165)

--HG--
rename : scrapy/management/telnet.py => scrapy/telnet.py

==

docs/topics/telnetconsole.rst
scrapy/conf/default_settings.py
scrapy/telnet.py
==================
4595c92c;Pablo Hoffman;2010-06-01 13:49:01 -0300;Core logic improvement: wait for Downloader and Scraper to close the spiders before going on and finish closing them

==

scrapy/core/downloader/manager.py
scrapy/core/engine.py
scrapy/core/scraper.py
==================
9523cab2;Pablo Hoffman;2010-06-01 11:07:04 -0300;Fixed bug that was causing the engine to notify the manager of spider closes too early

==

scrapy/core/engine.py
scrapy/core/manager.py
==================
fcdc4ee7;Ping Yin;2010-05-04 16:11:45 +0800;downloadermiddleware/redirect: always do "HEAD" if origin request method is HEAD
Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/contrib/downloadermiddleware/redirect.py
scrapy/tests/test_downloadermiddleware_redirect.py
==================
031eb1e5;Pablo Hoffman;2010-05-28 17:27:15 -0300;removed no longer used SpiderScheduler (obsoleted by ExecutionQueue)

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/spiderscheduler.py
==================
e995c5c7;Rolando Espinoza La fuente;2010-05-28 16:53:17 -0300;Skipped IBL tests if nltk/numpy are not available.

==

scrapy/tests/test_contrib_ibl/test_extraction.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
==================
a71dc295;Ismael Carnales;2010-05-28 16:51:47 -0300;Some mail improvements and tests.
* Add mail_sent signal and use it in MailSender
* Add MAIL_DEBUG setting to not send mails when testing
* Add MailSender tests

==

docs/topics/email.rst
docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/mail.py
scrapy/tests/test_mail.py
==================
dfa7b239;Pablo Hoffman;2010-05-26 11:58:31 -0300;Fixed SpiderManager tests that failed with dropin.cache write permissions errors in some cases
--HG--
rename : scrapy/tests/test_contrib_spidermanager/spider1.py => scrapy/tests/test_contrib_spidermanager/test_spiders/spider1.py
rename : scrapy/tests/test_contrib_spidermanager/spider2.py => scrapy/tests/test_contrib_spidermanager/test_spiders/spider2.py

==

scrapy/tests/test_contrib_spidermanager/__init__.py
scrapy/tests/test_contrib_spidermanager/dropin.cache
scrapy/tests/test_contrib_spidermanager/test_spiders/__init__.py
scrapy/tests/test_contrib_spidermanager/test_spiders/spider1.py
scrapy/tests/test_contrib_spidermanager/test_spiders/spider2.py
==================
dff763c6;Pablo Hoffman;2010-05-26 10:29:32 -0300;Removed Scrapy engine singleton from scrapy.core.engine.scrapyengine. Now engine can only be accesed through Scrapy Manager 'engine' attribute - ie. scrapy.core.manager.engine.

==

scrapy/contrib/closespider.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/itemsampler.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/spiderclosedelay.py
scrapy/contrib/spidermiddleware/requestlimit.py
scrapy/contrib/webconsole/livestats.py
scrapy/contrib/webconsole/scheduler.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/core/engine.py
scrapy/core/manager.py
scrapy/management/telnet.py
scrapy/management/web.py
scrapy/shell.py
scrapy/utils/engine.py
==================
2d313560;Pablo Hoffman;2010-05-26 10:29:32 -0300;added scrapy-ctl view command

==

scrapy/commands/view.py
==================
2905a208;Pablo Hoffman;2010-05-26 10:29:32 -0300;moved scrapy.command.models module to scrapy.command

==

scrapy/cmdline.py
scrapy/command/__init__.py
scrapy/command/models.py
==================
14bfeabe;Pablo Hoffman;2010-05-26 10:29:32 -0300;moved scrapy.command.cmdline module to scrapy.cmdline (keeping backwards compatibility until 0.10)
--HG--
rename : scrapy/command/cmdline.py => scrapy/cmdline.py

==

bin/scrapy-ctl.py
examples/experimental/googledir/scrapy-ctl.py
examples/experimental/imdb/scrapy-ctl.py
examples/googledir/scrapy-ctl.py
scrapy/cmdline.py
scrapy/command/cmdline.py
scrapy/templates/project/scrapy-ctl.py
scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_commands.py
==================
56abafec;Pablo Hoffman;2010-05-26 10:29:32 -0300;moved scrapy.command.commands module to scrapy.commands
--HG--
rename : scrapy/command/commands/__init__.py => scrapy/commands/__init__.py
rename : scrapy/command/commands/crawl.py => scrapy/commands/crawl.py
rename : scrapy/command/commands/fetch.py => scrapy/commands/fetch.py
rename : scrapy/command/commands/genspider.py => scrapy/commands/genspider.py
rename : scrapy/command/commands/list.py => scrapy/commands/list.py
rename : scrapy/command/commands/parse.py => scrapy/commands/parse.py
rename : scrapy/command/commands/runspider.py => scrapy/commands/runspider.py
rename : scrapy/command/commands/settings.py => scrapy/commands/settings.py
rename : scrapy/command/commands/shell.py => scrapy/commands/shell.py
rename : scrapy/command/commands/start.py => scrapy/commands/start.py
rename : scrapy/command/commands/startproject.py => scrapy/commands/startproject.py

==

scrapy/command/cmdline.py
scrapy/commands/__init__.py
scrapy/commands/crawl.py
scrapy/commands/fetch.py
scrapy/commands/genspider.py
scrapy/commands/list.py
scrapy/commands/parse.py
scrapy/commands/runspider.py
scrapy/commands/settings.py
scrapy/commands/shell.py
scrapy/commands/start.py
scrapy/commands/startproject.py
==================
cae22930;Pablo Hoffman;2010-05-26 10:29:32 -0300;Added ExecutionQueue class for feeding spiders and requests to scrape. This class can (and is meant to) be subclassed by projects that want to use a custom mechanism for feeding spiders to crawl. For example, a queue that pulls spiders to scrape from Amazon SQS (an example will be added soon).
Also introduced a rather big core refactoring of Scrapy manager and Scrapy
engine.

==

scrapy/command/commands/crawl.py
scrapy/command/commands/fetch.py
scrapy/command/commands/parse.py
scrapy/command/commands/runspider.py
scrapy/command/commands/start.py
scrapy/contrib/spidermanager.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/core/downloader/manager.py
scrapy/core/engine.py
scrapy/core/manager.py
scrapy/core/queue.py
scrapy/shell.py
scrapy/tests/test_core_queue.py
scrapy/tests/test_engine.py
scrapy/utils/engine.py
==================
8c1feb7a;Pablo Hoffman;2010-05-26 10:29:32 -0300;Ported S3ImagesStore to use boto threads. This simplifies the code and makes the following things no longer needed:
1. custom spider for S3 requests (ex. _S3AmazonAWSSpider)
2. scrapy.contrib.aws.AWSMiddleware
3. scrapy.utils.aws

==

scrapy/contrib/aws.py
scrapy/contrib/pipeline/images.py
scrapy/tests/test_utils_aws.py
scrapy/utils/aws.py
==================
c8c19a8e;Daniel Grana;2010-05-21 17:54:41 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
cce9c4da;Daniel Grana;2010-05-21 17:54:32 -0300;silence HttpError exceptions raised by httperror spidermiddleware if not handled by spider

==

scrapy/contrib/spidermiddleware/httperror.py
scrapy/tests/test_spidermiddleware_httperror.py
==================
f2363afe;Ping Yin;2010-04-27 14:58:11 +0800;LinkExtractor: split _process_links from _extract_links
Separate the extraction and process logic, so we can override in subclass easier.

Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/contrib/linkextractors/sgml.py
==================
60592217;Ping Yin;2010-04-08 10:59:47 +0800;Compose: stop process on None value by default
By doing this, we can use str.lower as a processor safely without
checking whether the given value is None.

By passing stop_on_none=False as keyword argument, this behaviour can be changed.

Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

docs/topics/loaders.rst
scrapy/contrib/loader/processor.py
scrapy/tests/test_contrib_loader.py
==================
15b879f8;Ping Yin;2010-05-18 17:54:25 +0800;ItemLoader: Update docs for {add,replace,get}_{value,xpath}
Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

docs/topics/loaders.rst
==================
8f53a723;Ping Yin;2010-04-24 21:21:12 +0800;ItemLoader: add test for adding a dict value
After arg_to_iter is changed to return [arg] if arg is a dict,
the added test will pass.

Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/tests/test_contrib_loader.py
==================
84973017;Ping Yin;2010-04-24 21:20:23 +0800;arg_to_iter: return [arg] if arg is a dict
Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/tests/test_utils_misc.py
scrapy/utils/misc.py
==================
bd844f69;Ping Yin;2010-04-23 01:34:55 +0800;{add,replace}_xpath: add processors, kw args and allow field_name to be None
Also add method get_xpath.

Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/contrib/loader/__init__.py
scrapy/tests/test_contrib_loader.py
==================
a6c31555;Ping Yin;2010-04-23 01:49:25 +0800;ItemLoader: Update tests for {add,replace,get}_value
Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/tests/test_contrib_loader.py
==================
913b5db2;Ping Yin;2010-04-23 01:45:01 +0800;{add,replace,get}_value: accept keyword args, now only 're'
if re given, extract data from the given value by this regex

Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/contrib/loader/__init__.py
==================
ddfaf604;Ping Yin;2010-04-23 01:42:55 +0800;{add,replace}_value: add processors args and allow field_name to be None
  * value is first proccessed by processors before passing to input
    processor
  * if field_name is None, values for multiple fields may be
    added/replaced. The keys of the processed value are as the field names
  * add get_value function for the processor logic

Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/contrib/loader/__init__.py
==================
cf35e09d;Ping Yin;2010-04-23 01:28:57 +0800;ItemLoader: don't limit item to Item object
Now, for example, item can be a dict

Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/contrib/loader/__init__.py
==================
bfd9cb42;Pablo Hoffman;2010-05-17 20:11:27 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
076cdfd5;Pablo Hoffman;2010-05-17 20:10:46 -0300;Added documentation about contributing to Scrapy

==

docs/contributing.rst
docs/index.rst
==================
7a55158f;Pablo Hoffman;2010-05-11 11:25:03 -0300;fixed documentation bug (thanks rhill for reporting)

==

docs/topics/item-pipeline.rst
==================
5d03405c;Steven Almeroth;2010-04-26 22:28:07 -0300;FormRequest.from_response doc fix. closes #155
--HG--
extra : rebase_source : d54979f6a15e5e997072dcbbc6d43b426189312b

==

docs/topics/request-response.rst
==================
2121a30c;Pablo Hoffman;2010-04-24 18:19:52 -0300;added note about installing Zope.Interface in windows platforms

==

docs/intro/install.rst
==================
6c121068;Daniel Grana;2010-04-18 23:42:56 -0300;Remove shpinx warning introduced by shorter title overline

==

docs/topics/email.rst
==================
2f8c0524;Lucian Ursu;2010-04-18 23:39:54 -0300;#154: Language fixes to the documentation

==

docs/topics/architecture.rst
docs/topics/downloader-middleware.rst
docs/topics/email.rst
docs/topics/exceptions.rst
docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/firebug.rst
docs/topics/firefox.rst
docs/topics/images.rst
==================
d42e5fdb;Ping Yin;2010-04-02 19:45:30 +0800;linkextractor: unique after urljoin_rfc
Now, '/foo.html' and 'http://example.org/foo.html' are considered
as the same and only one is kept.

Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/contrib/linkextractors/sgml.py
scrapy/tests/sample_data/link_extractor/sgml_linkextractor.html
scrapy/tests/test_contrib_linkextractors.py
==================
1868ede5;Pablo Hoffman;2010-05-14 16:38:04 -0300;bumped embedded pydispatch to 2.0.1

==

scrapy/xlib/pydispatch/dispatcher.py
scrapy/xlib/pydispatch/saferef.py
==================
02b7ca7e;Pablo Hoffman;2010-05-14 16:30:50 -0300;bumped embedded BeautifulSoup to 3.0.8.1

==

scrapy/xlib/BeautifulSoup.py
==================
e528a77f;Daniel Grana;2010-05-14 20:09:29 +0100;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
b2f58207;Daniel Grana;2010-05-14 20:09:07 +0100;avoid different behaviour in urljoin between pytho2.5 and python2.6+. see http://bugs.python.org/issue1432

==

scrapy/utils/url.py
==================
c87a29eb;Pablo Hoffman;2010-05-14 14:48:34 -0300;improved docstring

==

scrapy/contrib/ibl/__init__.py
==================
31843316;Pablo Hoffman;2010-05-14 14:33:26 -0300;Added new instance based learning extraction library in scrapy.contrib.ibl. Documentation and tools will be added later.

==

scrapy/contrib/ibl/__init__.py
scrapy/contrib/ibl/descriptor.py
scrapy/contrib/ibl/extraction/__init__.py
scrapy/contrib/ibl/extraction/pageobjects.py
scrapy/contrib/ibl/extraction/pageparsing.py
scrapy/contrib/ibl/extraction/regionextract.py
scrapy/contrib/ibl/extraction/similarity.py
scrapy/contrib/ibl/extractors.py
scrapy/contrib/ibl/htmlpage.py
scrapy/tests/test_contrib_ibl/__init__.py
scrapy/tests/test_contrib_ibl/samples_htmlpage.json.gz
scrapy/tests/test_contrib_ibl/samples_pageparsing.json.gz
scrapy/tests/test_contrib_ibl/test_extraction.py
scrapy/tests/test_contrib_ibl/test_htmlpage.py
scrapy/tests/test_contrib_ibl/test_htmlpage_data.py
scrapy/tests/test_contrib_ibl/test_pageparsing.py
==================
0b3bf5c6;Ping Yin;2010-05-04 15:50:26 +0800;downloader_handler: test HEAD method

==

scrapy/tests/test_downloader_handlers.py
==================
0aaa74d2;Ping Yin;2010-04-22 23:43:34 +0800;extract_regex: encoding arg defaults to 'utf-8'
Sometimes it is not neccessary to pass the encoding argument. For
example, when the text argument is unicode. So set a default encoding.

Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/utils/misc.py
==================
dfdac356;Pablo Hoffman;2010-04-02 02:49:18 -0300;added missing default values to file xporter doc

==

docs/topics/item-pipeline.rst
==================
2f75839e;Pablo Hoffman;2010-03-27 13:23:13 -0300;Ignore noisy Twisted deprecation warnings

==

scrapy/__init__.py
==================
f19c9399;Pablo Hoffman;2010-03-26 08:28:32 -0300;fixed doc typo

==

docs/topics/extensions.rst
==================
99a87675;Pablo Hoffman;2010-03-20 20:24:18 -0300;Improved "What else?" section of "Scrapy at a glance" overview

==

docs/index.rst
docs/intro/overview.rst
==================
234fd709;Pablo Hoffman;2010-03-19 10:32:17 -0300;fixed doc typo (thanks Victor)

==

docs/topics/exporters.rst
==================
184cf668;Daniel Grana;2010-03-18 10:05:33 -0300;Remove HttpException references from docs. Since 0.7, scrapy returns non-200 as Response objects and does not raise HttpException anymore

==

docs/topics/exceptions.rst
==================
17091902;Daniel Grana;2010-03-12 14:12:49 -0200;Explicity say where to save item class in "Defining our item" section of tutorial

==

docs/intro/tutorial.rst
==================
c5cd8b9d;Pablo Hoffman;2010-03-12 09:31:05 -0200;Fixed bug in open_in_browser() function with Python 2.5 (closes #145).

==

scrapy/utils/response.py
==================
90fef3cb;Ping Yin;2010-02-27 18:09:50 +0800;ImagePipeline: show http code when failing to download
Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/contrib/pipeline/images.py
==================
5c60ef69;Ping Yin;2010-04-24 19:08:01 +0800;remove_tags: add keep argument
Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/tests/test_utils_markup.py
scrapy/utils/markup.py
==================
94e6aceb;Ping Yin;2010-04-24 18:18:43 +0800;Fix remove_tags like functions can't remove empty tag such as <br/>
Signed-off-by: Ping Yin <pkufranky@gmail.com>

==

scrapy/tests/test_utils_markup.py
scrapy/utils/markup.py
==================
c925c9e9;Daniel Grana;2010-05-12 16:41:06 -0300;Notify spider when requests are ignored by HttpErrorMiddleware, and generally when any call to process_spider_input raises an exception

==

docs/topics/spider-middleware.rst
scrapy/contrib/spidermiddleware/httperror.py
scrapy/spider/middleware.py
scrapy/tests/test_spidermiddleware_httperror.py
==================
d3ab3cf8;Daniel Grana;2010-05-12 14:09:37 -0300;url_query_cleaner: cleanup and avoid rejoining key-sep-value to build the query again
--HG--
extra : rebase_source : 7c2648b6dd1c2253f1ec0f11d5e1f2ee25bd1273

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
3fb80580;Pablo Hoffman;2010-05-11 11:25:24 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
1750e233;Pablo Hoffman;2010-05-11 11:23:56 -0300;moved import to top

==

scrapy/contrib/pipeline/fileexport.py
==================
ac646a3b;Daniel Grana;2010-04-30 16:19:59 -0300;url_query_cleaner: do not append ? if query is empty

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
3d731ba6;Daniel Grana;2010-04-30 09:41:11 -0300;url_query_cleaner: add exclude and non-unique parameters support, also remove untested exception catching code and add missing tests

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
c0d45846;Daniel Grana;2010-04-26 22:29:45 -0300;Automated merge with ssh://hg.scrapy.org/scrapy-0.8

==
==================
81f6502e;Pablo Hoffman;2010-04-24 18:22:13 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.8/

==
==================
658e6f15;Daniel Grana;2010-04-18 23:44:59 -0300;Automated merge with ssh://hg.scrapy.org/scrapy-0.8

==
==================
b94abf36;Pablo Hoffman;2010-04-12 10:44:07 -0300;Added scrapy.utils.py26.json to use python2.6 json module when available, otherwise failback to simplejson module or scrapy.xlib.simplejson. This way we can always assume json and avoid conditional code.

==

scrapy/contrib/exporter/jsonlines.py
scrapy/tests/__init__.py
scrapy/tests/test_contrib_exporter.py
scrapy/utils/py26.py
scrapy/xlib/simplejson/__init__.py
scrapy/xlib/simplejson/decoder.py
scrapy/xlib/simplejson/encoder.py
scrapy/xlib/simplejson/ordered_dict.py
scrapy/xlib/simplejson/scanner.py
scrapy/xlib/simplejson/tool.py
==================
cd6aa72d;Pablo Hoffman;2010-04-12 10:42:07 -0300;fixed import

==

scrapy/command/commands/startproject.py
==================
025b34e1;Pablo Hoffman;2010-04-11 07:07:38 -0300;bugfix for python < 2.6

==

scrapy/utils/py26.py
==================
650d1c4f;Pablo Hoffman;2010-04-11 03:47:48 -0300;moved copytree() function from utils.python to utils.py26

==

scrapy/utils/py26.py
scrapy/utils/python.py
==================
be45acd4;Pablo Hoffman;2010-04-11 03:37:08 -0300;added scrapy.service and scrapy.tac for running from twistd

==

bin/scrapy.tac
scrapy/service.py
scrapy/utils/py26.py
==================
0dbb5d44;Daniel Grana;2010-04-09 14:16:00 -0300;images: avoid signing images based on spider name or request hostname, use request.meta instead

==

scrapy/contrib/aws.py
scrapy/contrib/pipeline/images.py
==================
68a875ed;Daniel Grana;2010-04-07 10:54:54 -0300;update ENCODING_ALIASES setting default value in settings documentation topic

==

docs/topics/settings.rst
==================
8b86e1d0;Daniel Grana;2010-04-07 00:29:53 -0300;Minimize effect of http://bugs.python.org/issue8271 on TextResponses by changing str.decode errors policy by custom `replace` alike error handler

==

scrapy/http/response/text.py
scrapy/tests/test_http_response.py
==================
3fcd69c3;Pablo Hoffman;2010-04-06 10:55:21 -0300;added a couple additional TwistedPluginSpiderManager tests

==

scrapy/tests/test_contrib_spidermanager/__init__.py
==================
2cd591e8;daniel;2010-04-06 07:22:50 +0100;add missing dropin.cache file required by default spidermanager tests

==

scrapy/tests/test_contrib_spidermanager/dropin.cache
==================
0b07742a;Daniel Grana;2010-04-05 15:07:43 -0300;gb2312 and gbk encodings was superseded by gb18030

==

scrapy/conf/default_settings.py
scrapy/tests/test_http_response.py
==================
0dfec044;Pablo Hoffman;2010-04-05 12:34:29 -0300;made Spider name required again (do not default)

==

scrapy/command/commands/fetch.py
scrapy/contrib_exp/crawlspider/spider.py
scrapy/shell.py
scrapy/spider/models.py
scrapy/tests/test_contrib_exp_crawlspider_rules.py
scrapy/tests/test_contrib_exp_crawlspider_spider.py
scrapy/tests/test_downloader_handlers.py
scrapy/tests/test_downloadermiddleware_cookies.py
scrapy/tests/test_downloadermiddleware_decompression.py
scrapy/tests/test_downloadermiddleware_defaultheaders.py
scrapy/tests/test_downloadermiddleware_httpauth.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_downloadermiddleware_httpproxy.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_downloadermiddleware_retry.py
scrapy/tests/test_downloadermiddleware_useragent.py
scrapy/tests/test_dupefilter.py
scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
scrapy/tests/test_spider.py
scrapy/tests/test_spidermiddleware_httperror.py
scrapy/tests/test_spidermiddleware_offsite.py
scrapy/tests/test_spidermiddleware_referer.py
scrapy/tests/test_spidermiddleware_urlfilter.py
scrapy/tests/test_spidermiddleware_urllength.py
scrapy/tests/test_stats.py
==================
70ac6642;Daniel Grana;2010-04-05 12:09:43 -0300;SEP-012: bugfix backward compatibility of Spider.domain_name and Spider.extra_domain_names
--HG--
extra : rebase_source : 66f779cddc6854092951078d443dbf9113f7576a

==

scrapy/spider/models.py
scrapy/tests/test_spider.py
==================
77a4d9ab;Pablo Hoffman;2010-04-05 11:53:22 -0300;use a default name for spiders constructed without names

==

scrapy/command/commands/fetch.py
scrapy/shell.py
scrapy/spider/models.py
scrapy/tests/test_spider.py
==================
c99e1af7;Pablo Hoffman;2010-04-05 11:27:19 -0300;Added support for passing generic arguments to spider constructors (refs #152), extended Spider tests, added unittests for TwistedPluginSpiderManager

==

scrapy/contrib/spidermanager.py
scrapy/contrib/spiders/crawl.py
scrapy/contrib/spiders/init.py
scrapy/spider/models.py
scrapy/tests/test_contrib_spidermanager/__init__.py
scrapy/tests/test_contrib_spidermanager/spider1.py
scrapy/tests/test_contrib_spidermanager/spider2.py
scrapy/tests/test_spider.py
==================
de32612c;Pablo Hoffman;2010-04-02 02:49:51 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
db5c3df6;Rolando Espinoza La fuente;2010-04-01 18:27:22 -0300;SEP12 implementation
  * Rename BaseSpider.domain_name to BaseSpider.name

    This patch implements the domain_name to name change in BaseSpider class and
    change all spider instantiations to use the new attribute.

  * Add allowed_domains to spider

    This patch implements the merging of spider.domain_name and
    spider.extra_domain_names in spider.allowed_domains for offsite checking
    purposes.

    Note that spider.domain_name is not touched by this patch, only not used.

  * Remove spider.domain_name references from scrapy.stats

    * Rename domain_stats to spider_stats in MemoryStatsCollector
    * Use ``spider`` instead of ``domain`` in SimpledbStatsCollector
    * Rename domain_stats_history table to spider_data_history and rename domain
    field to spider in MysqlStatsCollector

  * Refactor genspider command

    The new signature for genspider is: genspider [options] <domain_name>.

    Genspider uses domain_name for spider name and for the module name.

  * Remove spider.domain_name references

  * Update crawl command signature <spider|url>

  * docs: updated references to domain_name

  * examples/experimental: use spider.name

  * genspider: require <name> <domain>

  * spidermanager: renamed crawl_domain to crawl_spider_name

  * spiderctl: updated references of *domain* to spider

  * added backward compatiblity with legacy spider's attributes
    'domain_name' and 'extra_domain_names'

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/downloader-middleware.rst
docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/firebug.rst
docs/topics/request-response.rst
docs/topics/shell.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
docs/topics/stats.rst
examples/experimental/googledir/googledir/spiders/google_directory.py
examples/experimental/imdb/imdb/spiders/imdb_site.py
examples/googledir/googledir/spiders/google_directory.py
scrapy/command/commands/crawl.py
scrapy/command/commands/genspider.py
scrapy/command/commands/parse.py
scrapy/contrib/aws.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/itemsampler.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/spidermanager.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/statsmailer.py
scrapy/contrib/webconsole/livestats.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/contrib/webconsole/stats.py
scrapy/core/manager.py
scrapy/log.py
scrapy/spider/models.py
scrapy/stats/collector/__init__.py
scrapy/stats/collector/simpledb.py
scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
scrapy/tests/test_commands.py
scrapy/tests/test_engine.py
scrapy/tests/test_spider.py
scrapy/tests/test_spidermiddleware_offsite.py
scrapy/utils/url.py
==================
35a70596;Rolando Espinoza La fuente;2010-04-01 17:16:38 -0300;cleanup and refactor of parse & fetch commands  * removed scrapy.utils.fetch  * each command schedule requests and start scrapy engine  * fetch command instance BaseSpider if given url does not match any spider or match more than one  * parse command schedule url if one spider matches  * parse and fetch doesn't support multiple urls as parameter  * force spider behavior --spider moved from BaseCommand to only commands: fetch, parse, crawl

==

scrapy/command/commands/crawl.py
scrapy/command/commands/fetch.py
scrapy/command/commands/parse.py
scrapy/command/models.py
scrapy/utils/fetch.py
scrapy/utils/spider.py
==================
dd477914;Rolando Espinoza La fuente;2010-04-01 17:16:38 -0300;spidermanager refactoring
  * Implements find/create method in Spider Manager API, removed fromdomain and fromurl

    This method is now in charge of spider resolution, it must return spider object
    from its argument or raise KeyError if no spider is found.

    This method obsoletes from_domain and from_url methods.

    The default implementation of resolve only searches against spider.name, it
    won't use spider.allowed_domains like the old fromdomain. This is the reason
    of why you must supply a spider if you want to crawl an url.

    Find methods returns only available spider names. Not spider instances.
    If no spider found returns empty list.

Affected modules:
    * command.models (force_domain)
        * removed spiders.force_domain
    * each command pass spider to crawl_* commands
    * command.commands.*
        * crawl
            * set spider from opts.spider if arg is url
            * group urls by spider to instance spider just once
        * genspider
            * use spiders.create() to check spider id
        * parse
            * log error if more than one spider found
    * core.manager
        * on crawl_* log message if multiple spiders found for url or request
    * shell
        * prints "Multiple found" if more than one spider found for url or request
        * populate_vars(): added spider keyword parameter

    * contrib.spidermanager:
        * removed fromdomain() & fromurl()
        * new create(spider_id) -> Spider. Raises KeyError if spider not found
        * new find_by_request(request) -> list(spiders)

==

scrapy/command/commands/crawl.py
scrapy/command/commands/genspider.py
scrapy/command/commands/parse.py
scrapy/command/models.py
scrapy/contrib/spidermanager.py
scrapy/core/manager.py
scrapy/shell.py
==================
8db67b17;Rolando Espinoza La fuente;2010-04-01 17:16:38 -0300;scrapy manager refactor  * ExecutionManager     * deprecated runonce(*args)     * changed start() to start(keep_alive=Bool)     * changed crawl(*args) to crawl(requests, spider=None)         * if no spider given, tries to resolve spider           for each request     * added crawl_url(url, spider=None)     * added crawl_request(request, spider=None)     * added crawl_domain(domain)     * added crawl_spider(spider)  * updated commands: crawl, runspider, start  * updated webconsole  * updated crawler  * updated tests.test_engine  * updated utils.fetch

==

scrapy/command/commands/crawl.py
scrapy/command/commands/runspider.py
scrapy/command/commands/start.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/core/manager.py
scrapy/shell.py
scrapy/tests/test_engine.py
scrapy/utils/fetch.py
==================
32f9c5fe;Pablo Hoffman;2010-04-01 04:05:53 -0300;removed old untested (and probably broken) code

==

extras/sql/scraping.sql
scrapy/stats/collector/mysql.py
==================
4dc886e3;Pablo Hoffman;2010-03-31 18:26:35 -0300;Improved comment

==

scrapy/tests/test_http_response.py
==================
83d5eff0;Pablo Hoffman;2010-03-31 18:21:41 -0300;More refactoring to encoding handling in TextResponse and subclasses

==

scrapy/http/response/text.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
==================
de896fa6;Pablo Hoffman;2010-03-31 16:29:53 -0300;Refactored implementation of Request.replace() and Response.replace()

==

scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
==================
2ed8a5bf;Pablo Hoffman;2010-03-27 13:25:06 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
2299deda;Pablo Hoffman;2010-03-26 14:02:33 -0300;updated wrong link in doc

==

docs/topics/settings.rst
==================
7cf2f87e;Pablo Hoffman;2010-03-26 08:29:34 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
996a1b35;Daniel Grana;2010-03-25 15:50:34 -0300;fix handling of relative base urls in get_base_url util
--HG--
extra : rebase_source : eb552219e6bf40bc0d2e35968c367105233b6ecc

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
1330697c;Pablo Hoffman;2010-03-25 15:47:10 -0300;Some improvements to Response encoding support:
* added encoding aliases, configurable through a new ENCODING_ALIASES setting
* Response.encoding now returns the real encoding detected for the body
* simplified TextResponse API by removing body_encoding() and
  headers_encoding() methods
* Response.encoding now tries to infer the encoding from the body always (it
  was done before only on HtmlResponse and TextResponse)
* removed scrapy.utils.encoding.add_encoding_alias() function
* updated implementation of scrapy.utils.response function to reflect these API
  changes
* updated documentation to reflect API changes

==

docs/topics/request-response.rst
docs/topics/settings.rst
scrapy/__init__.py
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/http/response/html.py
scrapy/http/response/text.py
scrapy/http/response/xml.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_encoding_aliases.py
scrapy/tests/test_http_response.py
scrapy/tests/test_utils_encoding.py
scrapy/tests/test_utils_response.py
scrapy/utils/encoding.py
scrapy/utils/response.py
==================
173e9438;Daniel Grana;2010-03-25 12:38:37 -0300;Support relative url used in base tag. closes #148
--HG--
extra : rebase_source : 1bff87c127a7e9d8d12c772b3068feb11eb5d97f

==

scrapy/contrib/linkextractors/htmlparser.py
scrapy/contrib/linkextractors/image.py
scrapy/contrib/linkextractors/lxmlparser.py
scrapy/contrib/linkextractors/regex.py
scrapy/contrib/linkextractors/sgml.py
scrapy/contrib_exp/crawlspider/reqext.py
scrapy/tests/test_contrib_exp_crawlspider_reqext.py
scrapy/tests/test_contrib_linkextractors.py
==================
9ddcd109;Pablo Hoffman;2010-03-25 11:45:06 -0300;sort setting alphabetically

==

docs/topics/settings.rst
==================
cb49567c;Pablo Hoffman;2010-03-24 12:15:18 -0300;Removed wrong line added in previous commit

==

scrapy/__init__.py
==================
45411926;Pablo Hoffman;2010-03-24 12:14:07 -0300;Improved encoding support by explicitly passing encoding to all str_to_unicode() and unicode_to_str() calls

==

scrapy/__init__.py
scrapy/conf/default_settings.py
scrapy/contrib/linkextractors/image.py
scrapy/selector/__init__.py
scrapy/utils/markup.py
scrapy/utils/python.py
scrapy/utils/url.py
==================
4fa833c8;Pablo Hoffman;2010-03-24 12:13:38 -0300;Added LOG_ENCODING setting

==

docs/topics/logging.rst
docs/topics/settings.rst
scrapy/log.py
==================
87e68e74;Pablo Hoffman;2010-03-22 13:37:37 -0300;Made MailSender non IO-blocking, and improved MailSender documentation

==

docs/topics/email.rst
scrapy/mail.py
==================
1dfc79b5;Pablo Hoffman;2010-03-20 20:48:11 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
264cd2e0;Pablo Hoffman;2010-03-19 10:32:42 -0300;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
403a21ec;Pablo Hoffman;2010-03-12 17:28:33 -0200;removed obsolete scrapy.crawler module

==

examples/scripts/count_and_follow_links.py
scrapy/crawler.py
==================
54ae2c36;Pablo Hoffman;2010-03-12 10:19:50 -0200;better implementation of open_in_browser() tests

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
38a296aa;Pablo Hoffman;2010-03-12 09:52:39 -0200;Added tests to open_in_browser() function

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
2ab94d75;Pablo Hoffman;2010-03-12 09:32:35 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
39e4df0c;Pablo Hoffman;2010-03-10 00:10:36 -0200;removed unmaintained (and untested) contrib_exp ShoveItemPipeline

==

scrapy/contrib_exp/pipeline/shoveitem.py
==================
a505a9d4;Pablo Hoffman;2010-03-04 11:09:16 -0200;minor code refactoring on scrapy.command.cmdline module

==

scrapy/command/cmdline.py
==================
4c1ec0c9;Pablo Hoffman;2010-03-04 10:58:18 -0200;replaced hacky command_executed dict by standard signal

==

scrapy/command/cmdline.py
==================
861f9691;Pablo Hoffman;2010-03-04 10:40:41 -0200;removed partly-obsolete module scrapy.contrib.groupsettings

==

scrapy/contrib/groupsettings.py
==================
d12cd22d;Pablo Hoffman;2010-03-04 10:15:58 -0200;switched default scheduler order to DFO, which consumes less memory by default

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
==================
700be320;Daniel Grana;2010-02-24 15:44:41 -0200;Automated merge with ssh://hg.scrapy.org/scrapy-0.8

==
==================
2322322e;Daniel Grana;2010-02-24 15:43:09 -0200;Add missing priority and errback arguments to Request.replace method signature

==

scrapy/http/request/__init__.py
scrapy/tests/test_http_request.py
==================
180c091f;Pablo Hoffman;2010-02-24 14:01:29 -0200;Fixed encoding issue (reported in #135) when the encoding declared in the HTTP header is unknown. This is the patch proposed by Rolando, with an update to the Request/Response documentation.

==

docs/topics/request-response.rst
scrapy/http/response/text.py
scrapy/tests/test_http_response.py
==================
bbef0fe8;Pablo Hoffman;2010-02-20 11:12:37 -0200;Automated merge with http://hg.scrapy.org/users/rolando/scrapy/

==
==================
7b1ad321;Rolando Espinoza La fuente;2010-02-19 21:31:17 -0400;examples/experimental: added imdb top movies spider

==

examples/experimental/imdb/imdb/__init__.py
examples/experimental/imdb/imdb/items.py
examples/experimental/imdb/imdb/pipelines.py
examples/experimental/imdb/imdb/settings.py
examples/experimental/imdb/imdb/spiders/__init__.py
examples/experimental/imdb/imdb/spiders/imdb_site.py
examples/experimental/imdb/scrapy-ctl.py
==================
cb99edd1;Pablo Hoffman;2010-02-19 23:16:55 -0200;simplified and improved AUTHORS file

==

AUTHORS
==================
a3d22c72;Pablo Hoffman;2010-02-19 23:11:24 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8/

==
==================
60961e54;Pablo Hoffman;2010-02-19 23:09:48 -0200;minor documentation fix (refs #135)

==

docs/topics/exporters.rst
==================
c1f81986;Pablo Hoffman;2010-02-19 21:53:18 -0200;Added RANDOMIZE_DOWNLOAD_DELAY setting

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/core/downloader/manager.py
==================
4a053a76;Rolando Espinoza La fuente;2010-02-19 18:28:16 -0400;examples/experimental: added gooledir crawler

==

examples/experimental/googledir/googledir/__init__.py
examples/experimental/googledir/googledir/items.py
examples/experimental/googledir/googledir/pipelines.py
examples/experimental/googledir/googledir/settings.py
examples/experimental/googledir/googledir/spiders/__init__.py
examples/experimental/googledir/googledir/spiders/google_directory.py
examples/experimental/googledir/scrapy-ctl.py
==================
a6a3f085;Rolando Espinoza La fuente;2010-02-19 18:22:38 -0400;docs: added crawlspider v2 outline documentation Sign-Off: Rolando Espinoza La fuente

==

docs/experimental/crawlspider-v2.rst
docs/experimental/index.rst
==================
17d15439;Rolando Espinoza La fuente;2010-02-19 18:19:01 -0400;contrib_exp: added crawlspider v2 package + tests Sign-Off: Rolando Espinoza La fuente

==

scrapy/contrib_exp/crawlspider/__init__.py
scrapy/contrib_exp/crawlspider/matchers.py
scrapy/contrib_exp/crawlspider/reqext.py
scrapy/contrib_exp/crawlspider/reqgen.py
scrapy/contrib_exp/crawlspider/reqproc.py
scrapy/contrib_exp/crawlspider/rules.py
scrapy/contrib_exp/crawlspider/spider.py
scrapy/tests/test_contrib_exp_crawlspider_matchers.py
scrapy/tests/test_contrib_exp_crawlspider_reqext.py
scrapy/tests/test_contrib_exp_crawlspider_reqgen.py
scrapy/tests/test_contrib_exp_crawlspider_reqproc.py
scrapy/tests/test_contrib_exp_crawlspider_rules.py
scrapy/tests/test_contrib_exp_crawlspider_spider.py
==================
7ddd4441;Rolando Espinoza La fuente;2010-02-19 17:57:48 -0400;utils.python: added equal_attributes() to compare two objects arbitrary attributes Sign-Off: Rolando Espinoza La fuente

==

scrapy/tests/test_utils_python.py
scrapy/utils/python.py
==================
72350409;Rolando Espinoza La fuente;2010-02-19 17:41:45 -0400;merged upstream

==
==================
23fcf48a;Pablo Hoffman;2010-02-19 16:34:01 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8/

==
==================
53dfc4d3;Pablo Hoffman;2010-02-19 16:32:30 -0200;fixed bug which was causing the DOWNLOAD_DELAY setting to be ignored (the spider download_delay attribute was working though)

==

scrapy/core/downloader/manager.py
==================
a67c3897;Pablo Hoffman;2010-02-19 15:44:23 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8/

==
==================
51faec5d;Pablo Hoffman;2010-02-19 15:42:54 -0200;fixed bug which was considering DOWNLOAD_DELAY as an int setting, where it should be a float

==

scrapy/core/downloader/manager.py
==================
8dc95bf1;Daniel Grana;2010-02-18 16:52:45 -0200;Automated merge with ssh://hg.scrapy.org/scrapy-0.8

==
==================
91f4d6dc;Daniel Grana;2010-02-18 16:51:05 -0200;docs: adds another spider example that yields multiples requests/items from a single callback

==

docs/topics/spiders.rst
==================
d337aeb7;Pablo Hoffman;2010-01-31 18:11:43 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
57d60eae;Pablo Hoffman;2010-01-31 18:11:13 -0200;sort settings doc alphabetically by setting name

==

docs/topics/settings.rst
==================
843b3719;Pablo Hoffman;2010-01-28 10:56:49 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
b1c27567;Pablo Hoffman;2010-01-28 10:56:04 -0200;added spiders to some error logging in Engine and Scraper core components

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/log.py
==================
407f0671;Pablo Hoffman;2010-01-18 18:17:08 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
67858af8;Pablo Hoffman;2010-01-18 18:16:58 -0200;fixed doc typo

==

docs/topics/item-pipeline.rst
==================
49ac3bd2;Pablo Hoffman;2010-01-17 05:20:23 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
496db555;Pablo Hoffman;2010-01-17 05:19:51 -0200;added some encoding aliases not provided in Python by default - fixes #130

==

scrapy/__init__.py
scrapy/tests/test_encoding_aliases.py
scrapy/utils/encoding.py
==================
c0da2edf;Pablo Hoffman;2010-01-13 15:52:06 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
08eeaf98;Pablo Hoffman;2010-01-13 15:51:08 -0200;fixed description of LOG_STDOUT setting

==

docs/topics/settings.rst
==================
8e5a3baf;Pablo Hoffman;2010-01-13 12:21:26 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
48739ae6;Pablo Hoffman;2010-01-13 12:20:24 -0200;install.rst: added explanation about why libxml2 2.6.28 or above is required

==

docs/intro/install.rst
==================
1402da31;Rolando Espinoza La fuente;2010-01-11 12:28:22 -0400;docs: fixed typos and updated code examples

==

docs/intro/tutorial.rst
docs/topics/item-pipeline.rst
==================
7bbc14dd;Rolando Espinoza La fuente;2010-01-11 12:26:43 -0400;templates: updated code

==

scrapy/templates/project/module/pipelines.py.tmpl
scrapy/templates/spiders/crawl.tmpl
==================
e7ef2eba;Pablo Hoffman;2009-12-13 14:24:10 -0200;Automated merge with http://hg.scrapy.org/scrapy-0.8

==
==================
d60412ce;Pablo Hoffman;2009-12-13 14:23:31 -0200;titlecased Scrapy easy_install and some fixes to sign_release.sh script

==

docs/intro/install.rst
extras/sign_release.sh
==================
34971ea6;Pablo Hoffman;2009-12-12 18:15:18 -0200;bumped version to 0.9-dev

==

scrapy/__init__.py
==================
8a801e71;Pablo Hoffman;2009-12-12 18:02:42 -0200;Added tag 0.8 for changeset eef0b17d8752

==

.hgtags
==================
980ca75d;Pablo Hoffman;2009-12-12 18:02:25 -0200;Removed tag 0.8-rc1

==

.hgtags
==================
cd9a2d8e;Pablo Hoffman;2009-12-12 17:57:20 -0200;removed rc1 from version 0.8 (good enough for a stable release)

==

scrapy/__init__.py
==================
422d6fac;Pablo Hoffman;2009-12-12 16:52:07 -0200;Automated merge with http://hg.scrapy.org/scrapy-stable

==
==================
9d50604d;Pablo Hoffman;2009-12-12 16:51:59 -0200;added |version| to documentation title

==

docs/index.rst
==================
b6493f8b;Pablo Hoffman;2009-12-12 16:15:49 -0200;Added tag 0.8-rc1 for changeset 22de0cc4b778

==

.hgtags
==================
1fda0e78;Pablo Hoffman;2009-12-12 15:54:52 -0200;removed (pretty useless) build_release.sh script - see http://dev.scrapy.org/wiki/ScrapyReleaseProcedure

==

extras/build_release.sh
==================
024c00a5;Pablo Hoffman;2009-12-12 15:48:02 -0200;title-cased project name in setup.py

==

setup.py
==================
a953efd8;Pablo Hoffman;2009-12-12 15:40:16 -0200;Automated merge with http://hg.scrapy.org/scrapy-stable

==
==================
f22fe95a;Pablo Hoffman;2009-12-12 15:31:03 -0200;changed version to 0.8-rc1

==

scrapy/__init__.py
==================
3d6f598a;Pablo Hoffman;2009-12-12 15:30:21 -0200;added minor delay to httpcache tests, for them to pass on win32

==

scrapy/tests/test_downloadermiddleware_httpcache.py
==================
9c31fc44;Pablo Hoffman;2009-12-12 11:07:50 -0200;Changed character used in unit test because it's not a valid file name char on win32

==

scrapy/tests/test_downloader_handlers.py
==================
3012030b;Pablo Hoffman;2009-12-12 10:57:17 -0200;Fixed bug in file:// downloader handler with uris containing percent-escaped chars

==

scrapy/core/downloader/handlers/file.py
scrapy/tests/test_downloader_handlers.py
==================
cca4be4d;Pablo Hoffman;2009-12-11 23:52:53 -0200;uncommented some lines in extras/build_release.sh

==

extras/build_release.sh
==================
4ecc909b;Ismael Carnales;2009-12-04 15:37:24 -0200;Fix RobotsTxtMiddleware reference in doc

==

docs/topics/downloader-middleware.rst
==================
fe88aad2;Pablo Hoffman;2009-12-02 23:30:00 -0200;removed some old code from scrapy.spider.models

==

scrapy/spider/models.py
==================
41894c77;Pablo Hoffman;2009-12-02 23:06:17 -0200;adjusted some core code and comments for consistency after the move to spider references

==

scrapy/core/downloader/manager.py
==================
57bae533;Pablo Hoffman;2009-12-02 15:52:17 -0200;Added Settings class tests, and fixed minor bug

==

scrapy/conf/__init__.py
scrapy/tests/test_conf.py
==================
dbe0a687;Pablo Hoffman;2009-12-02 15:11:11 -0200;Decoupled Settings class from environment settings singleton (scrapy.conf.settings)

==

scrapy/conf/__init__.py
==================
925eecce;Pablo Hoffman;2009-12-02 13:59:58 -0200;fixed bug in OpenSSL depedency test which was comparing versions alphabetically, instead of numerically

==

scrapy/tests/test_dependencies.py
==================
dda7e01d;Pablo Hoffman;2009-12-02 11:26:34 -0200;don't fail if OpenSSL is not installed in test_dependencies.py

==

scrapy/tests/test_dependencies.py
==================
07344666;Ismael Carnales;2009-12-01 10:47:11 -0200;Move webconsole extensions doc to webconsole topic

==

docs/topics/extensions.rst
docs/topics/webconsole.rst
==================
e694c8ed;Ismael Carnales;2009-11-30 11:38:56 -0200;Remove domain references in close spider extension doc

==

docs/topics/extensions.rst
==================
12a7ff73;Ismael Carnales;2009-11-30 11:36:18 -0200;Rename Close domain to close spider in extensions doc

==

docs/topics/extensions.rst
==================
8d9cedd8;Ismael Carnales;2009-11-30 11:29:19 -0200;Reorder signals doc to respect alphabetical order

==

docs/topics/signals.rst
==================
93cc3d27;Ismael Carnales;2009-11-30 11:04:15 -0200;Correct param formatting in item pipelines doc

==

docs/topics/item-pipeline.rst
==================
cabee59d;Pablo Hoffman;2009-11-28 22:15:09 -0200;Fixed compatibility issues with Twisted 9 (closes #128)

==

scrapy/core/downloader/webclient.py
==================
6084be3b;Pablo Hoffman;2009-11-28 16:21:59 -0200;added iter_all() function to scrapy.util.trackref module and improved memory leaks documentation. also added a new FAQ antry about memory issues

==

docs/faq.rst
docs/topics/leaks.rst
scrapy/utils/trackref.py
==================
de35eee3;Pablo Hoffman;2009-11-28 12:31:05 -0200;Automated merge after applying ajones patch

==
==================
207aae2b;Pablo Hoffman;2009-11-26 19:12:33 -0200;Fixed logging of "Spider closed" message in engine

==

scrapy/core/engine.py
==================
34fcf6ba;Pablo Hoffman;2009-11-26 18:37:45 -0200;Added informative message when trying to use trackref and it's not enabled

==

scrapy/utils/trackref.py
==================
fd508911;Pablo Hoffman;2009-11-26 17:00:16 -0200;Keep track of pending next-request calls in the engine and downloader, to cancel them properly when the spider is closed. This also avoids keeping spider references alive, after they are closed.

==

scrapy/core/downloader/manager.py
scrapy/core/engine.py
==================
c0f1c8de;Pablo Hoffman;2009-11-26 16:10:28 -0200;use DelayedCall.active() instead DelayedCall.called, to support cancelled tasks

==

scrapy/contrib/closespider.py
==================
88417a3e;Pablo Hoffman;2009-11-25 22:51:58 -0200;Fixed bug in LiveStats webconsole module which was keeping references to spiders alive, after they were closed

==

scrapy/contrib/webconsole/livestats.py
==================
a2854e39;Pablo Hoffman;2009-11-25 22:28:59 -0200;Added hack to speed up processing of IgnoreRequest errors (#125)

==

scrapy/utils/defer.py
==================
a48516b1;Pablo Hoffman;2009-11-25 22:09:47 -0200;removed obsolete remove_escape_chars function - use replace_escape_chars instead

==

scrapy/utils/markup.py
==================
0dcf47a7;ajones1@gmail.com;2009-11-25 12:59:28 -0800;fix name errors on robots.txt middleware during spider_close

==

scrapy/contrib/downloadermiddleware/robotstxt.py
==================
a36909a3;Pablo Hoffman;2009-11-25 16:59:47 -0200;Added BaseSpider objects to trackref

==

scrapy/spider/models.py
==================
93117412;Pablo Hoffman;2009-11-25 16:54:36 -0200;Fixed memory leak in CachingResolver

==

scrapy/contrib/resolver.py
==================
1cfd9598;Pablo Hoffman;2009-11-25 11:20:43 -0200;remove wrong support for returning Responses in scheduler middlewares

==

scrapy/core/scheduler/middleware.py
==================
1a81ab6f;Pablo Hoffman;2009-11-21 15:17:38 -0200;renamed extension: DelayedCloseDomain to SpiderCloseDelay
--HG--
rename : scrapy/contrib/delayedclosedomain.py => scrapy/contrib/spiderclosedelay.py

==

scrapy/contrib/spiderclosedelay.py
==================
326090d4;Pablo Hoffman;2009-11-21 15:16:29 -0200;Reordered setting to preseve alphabetical order

==

scrapy/conf/default_settings.py
==================
a49aef2b;Pablo Hoffman;2009-11-21 15:06:03 -0200;Renamed exception: DontCloseDomain to DontCloseSpider (closes #120)

==

scrapy/contrib/delayedclosedomain.py
scrapy/core/engine.py
scrapy/core/exceptions.py
==================
0d75a3a6;Pablo Hoffman;2009-11-20 10:38:51 -0200;Automated merge with http://hg.scrapy.org/scrapy-stable/

==
==================
f86f62c5;Ismael Carnales;2009-11-20 09:30:06 -0200;Use setuptools for install, if not present fallback to distutils

==

setup.py
==================
dd662e09;Pablo Hoffman;2009-11-19 12:23:54 -0200;some minor fixes to scheduler middleware doc

==

docs/experimental/scheduler-middleware.rst
==================
8c14abad;Pablo Hoffman;2009-11-19 11:23:50 -0200;Automated merge with http://hg.scrapy.org/scrapy-stable/

==
==================
9ff4dbf6;Pablo Hoffman;2009-11-19 11:23:36 -0200;renamed file missing from previous commit
--HG--
rename : scrapy/xlib/patches.py => scrapy/xlib/twisted_250_monkeypatches.py

==

scrapy/xlib/twisted_250_monkeypatches.py
==================
f4e93700;Pablo Hoffman;2009-11-19 10:44:02 -0200;Automated merge with http://hg.scrapy.org/scrapy-stable/

==
==================
bf55a470;Pablo Hoffman;2009-11-19 10:41:36 -0200;prevent 'import scrapy' from failing when twisted module is not available, also moved twisted 2.5.0 monkeypatch into a more specific module name

==

scrapy/__init__.py
scrapy/xlib/patches.py
==================
c4f77c4d;Pablo Hoffman;2009-11-16 11:15:25 -0200;minor fixes to images doc (thanks amccloud)

==

docs/topics/images.rst
==================
0d6aee1f;Pablo Hoffman;2009-11-13 20:03:56 -0200;updated wrong documentation

==

docs/topics/signals.rst
==================
445d8cd9;Daniel Grana;2009-11-06 22:02:12 -0200;delay next_request check after stoping a spider close to avoid 100% cpu usage loops in some cases

==

scrapy/core/engine.py
==================
aeab5370;Pablo Hoffman;2009-11-14 20:28:59 -0200;StatsCollector: ported methods to receive spider instances (closes #113), removed list_domains() method, added iter_spider_stats() method

==

docs/topics/stats.rst
scrapy/contrib/corestats.py
scrapy/contrib/downloadermiddleware/stats.py
scrapy/contrib/itemsampler.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/statsmailer.py
scrapy/contrib/webconsole/stats.py
scrapy/contrib_exp/spiderprofiler.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/stats/collector/__init__.py
scrapy/stats/collector/mysql.py
scrapy/stats/collector/simpledb.py
scrapy/stats/signals.py
scrapy/tests/test_downloadermiddleware_stats.py
scrapy/tests/test_spidermiddleware_depth.py
scrapy/tests/test_stats.py
==================
c4c6e7c8;Pablo Hoffman;2009-11-13 20:04:39 -0200;Automated merge with http://hg.scrapy.org/scrapy-stable/

==
==================
505dfe6f;Pablo Hoffman;2009-11-13 17:21:59 -0200;fixed exception when running scrapy shell on a non-textual response (fixes #116)

==

scrapy/shell.py
==================
f3e861c8;Pablo Hoffman;2009-11-13 14:44:03 -0200;replaced old reference to domain instead of spider

==

scrapy/tests/test_downloadermiddleware_cookies.py
==================
07655d05;Pablo Hoffman;2009-11-13 14:38:22 -0200;renamed REQUESTS_PER_SPIDER setting to CONCURRENT_REQUESTS_PER_SPIDER

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/core/downloader/manager.py
==================
564abd10;Pablo Hoffman;2009-11-13 14:25:47 -0200;Refactored HttpCache middleware:
* simplified code
* performance improvements
* removed awkward/unused domain sectorization
* it can now receive Settings on constructor
* added unittests
* added documentation about filesystem storage structure

Also made scrapy.conf.Settings objects instantiable with a dict which is used to override default settings.

==

docs/topics/downloader-middleware.rst
docs/topics/settings.rst
scrapy/conf/__init__.py
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/tests/test_downloadermiddleware_httpcache.py
==================
db7fec1f;Pablo Hoffman;2009-11-12 12:17:39 -0200;fixed doc typo

==

docs/faq.rst
==================
415dec4e;Pablo Hoffman;2009-11-12 10:17:21 -0200;made offsite middleware log messages when filtering out requests

==

docs/faq.rst
docs/topics/spider-middleware.rst
scrapy/contrib/spidermiddleware/offsite.py
==================
ee08d38a;Pablo Hoffman;2009-11-06 16:56:17 -0200;removed deprecated SCRAPYSETTINGS_MODULE environment variable

==

scrapy/conf/__init__.py
==================
49e39bf1;Pablo Hoffman;2009-11-06 16:49:48 -0200;fixed typo

==

docs/api-stability.rst
==================
4a2a2048;Pablo Hoffman;2009-11-06 16:39:15 -0200;removed deprecated ScrapedItem (previously kept for backwards compatibility)

==

examples/googledir/googledir/settings.py
scrapy/item.py
scrapy/tests/test_item.py
==================
791f4932;Pablo Hoffman;2009-11-06 16:28:51 -0200;added clarification about versioning and api stability

==

docs/api-stability.rst
==================
9bf4e877;Pablo Hoffman;2009-11-06 16:20:38 -0200;removed deprecated scrapy.xpath module (previously kept for backwards compatibility)

==

scrapy/xpath/__init__.py
scrapy/xpath/selector.py
==================
40646d3c;Pablo Hoffman;2009-11-06 16:11:37 -0200;replaced remaining uses of log.msg() 'domain' argument to use 'spider' instead

==

scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/contrib/spidermanager.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/urllength.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/core/scraper.py
scrapy/spider/models.py
==================
fee1b751;Pablo Hoffman;2009-11-06 16:02:12 -0200;deprecated 'domain' argument in log.msg()

==

scrapy/log.py
==================
74d0e82d;Pablo Hoffman;2009-11-06 15:54:17 -0200;renamed CloseDomain extension to CloseSpider, and renamed CLOSEDOMAIN_* settings to CLOSESPIDER_*
--HG--
rename : scrapy/contrib/closedomain.py => scrapy/contrib/closespider.py

==

docs/topics/extensions.rst
scrapy/conf/default_settings.py
scrapy/contrib/closespider.py
==================
cff4592b;Pablo Hoffman;2009-11-06 15:48:49 -0200;changed label

==

scrapy/contrib/webconsole/livestats.py
==================
919cd5b7;Pablo Hoffman;2009-11-06 15:44:11 -0200;renamed setting CONCURRENT_DOMAINS to CONCURRENT_SPIDERS

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/core/downloader/manager.py
==================
d604dca9;Pablo Hoffman;2009-11-06 15:42:11 -0200;renamed setting REQUESTS_PER_DOMAIN to REQUESTS_PER_SPIDER

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/core/downloader/manager.py
==================
580d8246;Pablo Hoffman;2009-11-06 14:29:37 -0200;fixed images pipeline bug caused by recent api changes

==

scrapy/contrib/pipeline/images.py
==================
e5cae1e6;Pablo Hoffman;2009-11-06 14:19:56 -0200;renamed setting

==

scrapy/contrib/itemsampler.py
==================
7728a23e;Pablo Hoffman;2009-11-06 13:46:36 -0200;Changed item pipeline API to pass spider references (instead of domain names) to process_item() method

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/exporters.rst
docs/topics/item-pipeline.rst
scrapy/contrib/itemsampler.py
scrapy/contrib/pipeline/__init__.py
scrapy/contrib/pipeline/fileexport.py
scrapy/contrib/pipeline/media.py
scrapy/contrib_exp/pipeline/shoveitem.py
==================
a432c1ee;Pablo Hoffman;2009-11-04 14:49:24 -0200;updated logging doc to include new spider argument in log functions

==

docs/topics/logging.rst
==================
69058e3b;Pablo Hoffman;2009-11-04 14:45:56 -0200;fixed bug in log.msg when receiving new spider argument

==

scrapy/log.py
==================
55d584e4;Pablo Hoffman;2009-11-04 14:45:34 -0200;added missing spider argument to log.msg call

==

scrapy/core/downloader/manager.py
==================
87e322e5;Daniel Grana;2009-11-04 12:39:58 -0200;fixes to lxml link extractors api and encoding handling

==

scrapy/contrib/linkextractors/lxmlparser.py
==================
97c32270;Pablo Hoffman;2009-11-03 00:39:02 -0200;* Renamed domain_{opened,closed,idle} signals to spider_{opened,closed,idle} * Changed them to pass spider instances only (no domains) (refs #105)

==

docs/topics/exporters.rst
docs/topics/extensions.rst
docs/topics/item-pipeline.rst
docs/topics/leaks.rst
docs/topics/signals.rst
docs/topics/stats.rst
scrapy/contrib/closedomain.py
scrapy/contrib/delayedclosedomain.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/itemsampler.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/resolver.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/requestlimit.py
scrapy/contrib/webconsole/livestats.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/contrib_exp/pipeline/shoveitem.py
scrapy/core/engine.py
scrapy/core/signals.py
scrapy/log.py
scrapy/tests/test_downloadermiddleware_cookies.py
scrapy/tests/test_engine.py
scrapy/tests/test_spidermiddleware_offsite.py
==================
a3f29339;Pablo Hoffman;2009-11-02 20:28:36 -0200;another minor change in stats test

==

scrapy/tests/test_stats.py
==================
65b60653;Pablo Hoffman;2009-11-02 19:16:42 -0200;minor change in stats test

==

scrapy/tests/test_stats.py
==================
4d4f5dca;Pablo Hoffman;2009-10-31 14:37:46 -0200;Automated merge with http://hg.scrapy.org/scrapy-stable

==
==================
d5ae94df;Pablo Hoffman;2009-10-31 14:36:38 -0200;fixed bug when using log.start() with log level module constants instead of string names, and added regression tests

==

scrapy/log.py
scrapy/tests/test_log.py
==================
904cde65;Pablo Hoffman;2009-10-29 13:47:10 -0200;added clarification about new dont_click argument of FormRequest.from_response() method

==

docs/topics/request-response.rst
==================
77b8cfad;Pablo Hoffman;2009-10-29 13:35:32 -0200;changed odd logic in if statement

==

scrapy/http/request/form.py
==================
b7a00cd2;Daniel Grana;2009-10-29 13:24:30 -0200;return a generator in CrawlSpider

==

scrapy/contrib/spiders/crawl.py
==================
a244d23b;Ismael Carnales;2009-10-29 13:18:13 -0200;added dont_click attr to FormRequest

==

docs/topics/request-response.rst
scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
b41c5b5d;Pablo Hoffman;2009-10-29 10:41:20 -0200;fixed typo in intro/install doc (thanks phaithful)

==

docs/intro/install.rst
==================
9b5fef4f;Pablo Hoffman;2009-10-28 09:34:31 -0200;fixed typo in intro/install doc (thanks phaithful)

==

docs/intro/install.rst
==================
7baff291;Pablo Hoffman;2009-10-21 16:37:30 -0200;fixed bug caused when instantiating selectors with responses containing empty bodies

==

scrapy/selector/factories.py
scrapy/tests/test_selector.py
==================
53ae45ad;Pablo Hoffman;2009-10-21 16:25:49 -0200;restored previous try/except catch all blocks for Libxml2Document __del__() method

==

scrapy/selector/document.py
==================
7296a7b8;Pablo Hoffman;2009-10-21 16:13:41 -0200;added DEFAULT_RESPONSE_ENCODING setting

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/http/response/text.py
scrapy/tests/test_http_response.py
==================
3d7a4c89;Daniel Grana;2009-10-21 13:57:06 -0200;fix get_meta_refresh bug raised for TextResponses without encoding

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
6405efa5;Daniel Grana;2009-10-21 12:46:18 -0200;factorize redirectmw code that handles 302 and meta-refresh redirections
--HG--
extra : rebase_source : f78fee093ac076d4a0630982dc4bade16755fa3b

==

scrapy/contrib/downloadermiddleware/redirect.py
==================
5371d900;Ismael Carnales;2009-10-21 12:14:41 -0200;corrected the banner from scrapyctl webconsole module

==

scrapy/contrib/webconsole/spiderctl.py
==================
0d637a67;Daniel Grana;2009-10-21 11:35:36 -0200;ensure meta refresh redirections use GET requests even if coming from POSTs

==

scrapy/contrib/downloadermiddleware/redirect.py
scrapy/tests/test_downloadermiddleware_redirect.py
==================
939e302b;Pablo Hoffman;2009-10-21 09:37:04 -0200;make get_meta_refresh() function more robust and changed interface to return (int, str) as (interval, absolute_url)

==

scrapy/contrib/downloadermiddleware/redirect.py
scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
720bc166;Pablo Hoffman;2009-10-20 17:21:56 -0200;updated new clickdata argument doc

==

docs/topics/request-response.rst
==================
6abb3c17;Daniel Grana;2009-10-20 15:51:41 -0200;Improve FormRequest.from_response method to pass click data arguments to ClientForm library

==

docs/topics/request-response.rst
scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
789cba2b;daniel;2009-10-15 16:26:05 +0100;improve csviter memeory usage by use of a generator instead of splitlines

==

scrapy/utils/iterators.py
==================
d6735b39;Daniel Grana;2009-10-15 11:19:52 -0200;do not modify request.headers inside http download handler

==

scrapy/core/downloader/webclient.py
scrapy/tests/test_downloader_handlers.py
==================
cc85c463;Daniel Grana;2009-10-14 18:37:51 -0200;add missing lxml iterators module

==

scrapy/contrib_exp/iterators.py
==================
23c49bcb;Daniel Grana;2009-10-14 13:22:28 -0200;move lxml based xmliter function to contrib_exp

==

scrapy/tests/test_utils_iterators.py
scrapy/utils/iterators.py
==================
6bb84f07;Daniel Grana;2009-10-13 16:38:49 -0200;remove response body references from experimental decompression mw

==

scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/tests/test_downloadermiddleware_decompression.py
==================
f7fbbfec;Daniel Grana;2009-10-10 23:31:16 -0200;rollback xmliter functions to private, we won\'t support multiples versions of xmliter

==

scrapy/tests/test_utils_iterators.py
scrapy/utils/iterators.py
==================
6db5a37c;Daniel Grana;2009-10-09 17:00:31 -0200;do specialized xmliter public functions and add tests

==

scrapy/tests/test_utils_iterators.py
scrapy/utils/iterators.py
==================
51c4be78;daniel;2009-10-09 04:02:48 +0100;Add a lxml based xmliter function enabled by default if lxml is available

==

scrapy/utils/iterators.py
==================
af090296;daniel;2009-10-08 16:32:42 +0100;trackref Libxml2Document objects and do not silence xml exceptions on __del__

==

scrapy/selector/document.py
==================
d7024dcd;daniel;2009-10-08 16:31:37 +0100;urllib does not support no_proxy in python < 2.6. Skip it tests.

==

scrapy/tests/test_downloadermiddleware_httpproxy.py
==================
2712d55c;Pablo Hoffman;2009-10-07 23:58:38 -0200;Automated merge with http://hg.scrapy.org/scrapy-stable

==
==================
10d6d490;Pablo Hoffman;2009-10-07 23:57:04 -0200;Added tag 0.7 for changeset 2077c6107e33

==

.hgtags
==================
bd481751;Pablo Hoffman;2009-10-07 22:57:25 -0200;moved images pipeline documentation to stable doc
--HG--
rename : docs/experimental/images.rst => docs/topics/images.rst

==

docs/experimental/index.rst
docs/index.rst
docs/topics/images.rst
==================
b4d202a6;Pablo Hoffman;2009-10-07 22:57:10 -0200;added note about memory usage extension not working on windows

==

docs/topics/extensions.rst
==================
daf86144;Pablo Hoffman;2009-10-07 22:39:19 -0200;another win32 bug fixed in images pipeline (regression tests already covered it)

==

scrapy/contrib/pipeline/images.py
==================
5c68e2b3;Pablo Hoffman;2009-10-07 22:34:38 -0200;fixed bug in images pipeline bug in win32 systems, and added regression tests

==

scrapy/contrib/pipeline/images.py
scrapy/tests/test_pipeline_images.py
==================
937acd91;Pablo Hoffman;2009-10-07 21:00:34 -0200;improved documentation of http proxy middleware

==

docs/faq.rst
docs/topics/downloader-middleware.rst
docs/topics/settings.rst
==================
d03bf1f2;Pablo Hoffman;2009-10-07 20:38:46 -0200;Automated merge with http://hg.scrapy.org/scrapy-stable

==
==================
37d9e015;Pablo Hoffman;2009-10-07 20:15:49 -0200;minor fix to tutorial

==

docs/intro/tutorial.rst
==================
1450af25;Pablo Hoffman;2009-10-06 22:47:17 -0200;some improvements to 'Crawled' log lines, delegating the formatting to a pluggable function

==

scrapy/conf/default_settings.py
scrapy/contrib/logformatter.py
scrapy/core/engine.py
scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/tests/test_contrib_logformatter.py
==================
bc64ca3e;Daniel Grana;2009-10-05 04:10:22 -0200;Add support to set http proxies per request, and obey enviroment variables http_proxy and no_proxy by default.

==

docs/topics/downloader-middleware.rst
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/httpproxy.py
scrapy/core/downloader/webclient.py
scrapy/tests/test_downloader_handlers.py
scrapy/tests/test_downloadermiddleware_httpproxy.py
==================
8aa7d153;Daniel Grana;2009-10-05 04:10:22 -0200;rewrote of downloader handlers
* add REQUEST_HANDLERS setting with defaults for file, http and https schemes
* add documentation of new setting
* add unittests for all the builtin handlers
* remove unused getPage function

==

docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/core/downloader/handlers.py
scrapy/core/downloader/handlers/__init__.py
scrapy/core/downloader/handlers/file.py
scrapy/core/downloader/handlers/http.py
scrapy/core/downloader/webclient.py
scrapy/tests/test_downloader_handlers.py
scrapy/tests/test_webclient.py
==================
40dc867a;Pablo Hoffman;2009-10-03 14:09:21 -0300;Automated merge with http://hg.scrapy.org/scrapy-stable

==
==================
aacb7965;Pablo Hoffman;2009-10-03 14:08:40 -0300;improved check for missing callback in Requests

==

scrapy/core/engine.py
scrapy/spider/middleware.py
==================
9710f263;Pablo Hoffman;2009-10-02 09:21:21 -0300;Automated merge with http://hg.scrapy.org/scrapy-stable

==
==================
0f1bb871;Pablo Hoffman;2009-10-02 09:20:22 -0300;fixed bug in parse command with requests which don't have __dict__ attribute

==

scrapy/utils/display.py
==================
64ad96ba;Ismael Carnales;2009-09-29 16:17:30 -0300;added LxmlItemLoader

==

scrapy/contrib_exp/loader/__init__.py
scrapy/contrib_exp/loader/lxmlloader.py
scrapy/tests/test_contrib_exp_loader_lxmlloader.py
==================
ea9f2360;Pablo Hoffman;2009-09-29 16:16:35 -0300;merge with scrapy-stable

==
==================
bb4871b7;Ismael Carnales;2009-09-29 16:05:34 -0300;added xpathitemloader tests

==

scrapy/tests/test_contrib_loader.py
==================
16ada1d5;Ismael Carnales;2009-09-29 16:05:32 -0300;fixed ItemLoader replace_value

==

scrapy/contrib/loader/__init__.py
==================
64ce9542;Pablo Hoffman;2009-09-29 14:22:10 -0300;Automated merge with http://hg.scrapy.org/scrapy-stable
--HG--
rename : extras/make_release.sh => extras/build_release.sh

==
==================
a0eec7ea;Pablo Hoffman;2009-09-29 09:44:02 -0300;some typos fixes and updates to install doc

==

docs/intro/install.rst
==================
4a371a6c;Pablo Hoffman;2009-09-29 09:33:20 -0300;removed unmaintained spidermonkey bindings

==

scrapy/tests/test_spidermonkey.py
scrapy/xlib/spidermonkey/INSTALL.scrapy
scrapy/xlib/spidermonkey/__init__.py
scrapy/xlib/spidermonkey/sm_settings.py
scrapy/xlib/spidermonkey/spidermonkey.py
==================
1646482b;Ismael Carnales;2009-09-29 08:41:34 -0300;reformatted installation guide

==

docs/intro/install.rst
==================
f565127e;Pablo Hoffman;2009-09-28 23:55:00 -0300;added some missing file to MANIFEST.in

==

MANIFEST.in
==================
4a9d9282;Pablo Hoffman;2009-09-28 23:54:01 -0300;removed obsolete scrapy architecture dia diagram

==

docs/media/scrapy-architecture.dia
==================
7e12d3d4;Pablo Hoffman;2009-09-28 23:16:17 -0300;removed old adaptors tests sample data

==

MANIFEST.in
scrapy/tests/sample_data/adaptors/enc-ascii.html
scrapy/tests/sample_data/adaptors/enc-cp1252.html
scrapy/tests/sample_data/adaptors/enc-latin1.html
scrapy/tests/sample_data/adaptors/enc-utf8-meta-latin1.html
scrapy/tests/sample_data/adaptors/enc-utf8.html
scrapy/tests/sample_data/adaptors/extr_unquoted.xml
==================
7428e4ce;Pablo Hoffman;2009-09-28 23:07:00 -0300;splitted make_release.sh in: build_release.sh and sign_release.sh
--HG--
rename : extras/make_release.sh => extras/build_release.sh

==

extras/build_release.sh
extras/sign_release.sh
==================
1dcb9ed7;Pablo Hoffman;2009-09-28 22:53:05 -0300;Merge with stable repo

==
==================
504293b8;Pablo Hoffman;2009-09-28 22:29:23 -0300;renamed tag: 0.7.0-rc1 to 0.7-rc1

==

.hgtags
==================
2be73996;Pablo Hoffman;2009-09-28 22:28:49 -0300;bumped version to 0.7 final

==

scrapy/__init__.py
==================
e0ccb2cc;Daniel Grana;2009-09-28 12:44:05 -0300;ignore request if spider is not opened in downloader when called from engine.download

==

scrapy/core/engine.py
==================
749b1365;Daniel Grana;2009-09-28 12:40:16 -0300;Automated merge with ssh://hg.scrapy.org/scrapy-stable

==
==================
1f9e0f10;Daniel Grana;2009-09-28 12:38:49 -0300;don't log ignored requests errors at images pipeline

==

scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/media.py
==================
706cb439;Daniel Grana;2009-09-23 14:54:33 -0300;Automated merge with ssh://hg.scrapy.org/scrapy-stable

==
==================
c7957712;Daniel Grana;2009-09-23 14:53:40 -0300;remove unused line from project settings template

==

scrapy/templates/project/module/settings.py.tmpl
==================
bd0dc21e;Daniel Grana;2009-09-23 14:28:41 -0300;Automated merge with ssh://hg.scrapy.org/scrapy-stable

==
==================
dfd35c52;Daniel Grana;2009-09-23 14:26:58 -0300;Add common javascript mimetypes to be detected as TextResponses, also improve mimetype detection to avoid querying twice classes dict

==

scrapy/core/downloader/responsetypes/__init__.py
==================
bae726a1;Daniel Grana;2009-09-22 11:33:15 -0300;Automated merge with ssh://hg.scrapy.org/scrapy-stable

==
==================
ef0e5d36;Ismael Carnales;2009-09-22 11:25:42 -0300;updated spider templates to reflect the new spider callback return policy

==

scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
==================
5862ba7d;Ismael Carnales;2009-09-22 11:25:40 -0300;modified doc to reflect the new spider callback return policy (lists not needed)

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/spiders.rst
==================
802f918b;Ismael Carnales;2009-09-22 11:25:38 -0300;removed obsolete doc static file

==

docs/_static/items_adaptors-sample1.html
==================
337253f9;Daniel Grana;2009-09-21 13:59:46 -0300;Automated merge with file:///home/dan/src/hg/scrapy-stable

==
==================
6467c705;Daniel Grana;2009-09-21 13:57:16 -0300;check iterable output of crawl spider and add tests for common function used to iterate spider output

==

scrapy/contrib/spiders/crawl.py
scrapy/core/scraper.py
scrapy/tests/test_utils_spider.py
scrapy/utils/spider.py
==================
201ce525;Pablo Hoffman;2009-09-21 13:07:52 -0300;make_release.sh: disabled bdist_wininst command as it doesn't package data files properly on Linux - refs #109

==

extras/make_release.sh
==================
12ebcfd6;Pablo Hoffman;2009-09-18 15:31:54 -0300;bumped version to 0.8

==

scrapy/__init__.py
==================
b6155801;Pablo Hoffman;2009-09-18 00:52:41 -0300;Added tag 0.7.0-rc1 for changeset f4a14daa04e6

==

.hgtags
==================
bc778a0e;Pablo Hoffman;2009-09-17 15:28:36 -0300;make_release.sh: added warning about broken bdist_wininst

==

extras/make_release.sh
==================
1b28858b;Daniel Grana;2009-09-17 14:26:42 -0300;improve XmlRpcRequest and update tests to cover more cases

==

scrapy/http/request/rpc.py
scrapy/tests/test_http_request.py
==================
48c3fb3a;Pablo Hoffman;2009-09-17 12:21:43 -0300;made XmlRpcRequestTest inherit from RequestTest and removed redundant test

==

scrapy/tests/test_http_request.py
==================
6845505e;Pablo Hoffman;2009-09-17 11:46:47 -0300;added make_release.sh script

==

extras/make_release.sh
==================
6e109144;Pablo Hoffman;2009-09-17 11:22:48 -0300;added pypi classifiers to setup.py

==

setup.py
==================
6e938729;Pablo Hoffman;2009-09-17 11:06:55 -0300;updated installation guide for using releases

==

docs/intro/install.rst
==================
653db1d6;Pablo Hoffman;2009-09-17 02:01:40 -0300;added bitmap for windows installer

==

extras/setup_wininst.bmp
setup.cfg
==================
132557dd;Pablo Hoffman;2009-09-16 22:40:36 -0300;some deployment changes in preparation for the 0.7.0 release candidate

==

MANIFEST.in
docs/conf.py
docs/topics/scrapy-ctl.rst
scrapy/__init__.py
scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_commands.py
setup.py
==================
fd41f060;Ismael Carnales;2009-09-16 14:19:16 -0300;added doc on how to enable an Item Pipeline component

==

docs/topics/item-pipeline.rst
==================
404e7e09;Ismael Carnales;2009-09-16 14:10:11 -0300;changed spider doc references in BaseSpider class

==

docs/topics/spiders.rst
==================
062730cb;Daniel Grana;2009-09-16 00:17:50 -0300;fix csv exporter documentation

==

docs/topics/item-pipeline.rst
==================
08aedcbe;Daniel Grana;2009-09-15 09:35:24 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
e8514445;Daniel Grana;2009-09-15 09:35:21 -0300;bugfix image thumb when no thumb is configured

==

scrapy/contrib/pipeline/images.py
==================
02e228ad;Pablo Hoffman;2009-09-15 09:27:30 -0300;added support for returning deferreds in spider manager close_domain() method, and making sure engine_stopped signal is always sent (even when no spiders have run)

==

scrapy/core/engine.py
==================
66ff3b30;Pablo Hoffman;2009-09-15 08:44:31 -0300;renamed defer_failed to defer_fail

==

scrapy/utils/defer.py
==================
56b292e0;Pablo Hoffman;2009-09-14 22:05:52 -0300;XmlItemExporter: added built-in support for exporting multi-valued fields (for convenience)

==

docs/topics/exporters.rst
scrapy/contrib/exporter/__init__.py
scrapy/tests/test_contrib_exporter.py
==================
e8960bf6;Pablo Hoffman;2009-09-14 22:05:14 -0300;added runspider command to run spiders directly, without having to create a project

==

docs/faq.rst
scrapy/command/commands/runspider.py
==================
fcbbb500;Pablo Hoffman;2009-09-14 20:35:47 -0300;ported spiderctl web console extensin to work with new core based on spider references

==

scrapy/contrib/webconsole/spiderctl.py
==================
47aa7166;Pablo Hoffman;2009-09-14 20:35:07 -0300;adapted web console to use unix timestamps for uptime instead of datetime

==

scrapy/management/web.py
==================
bc463bc9;Pablo Hoffman;2009-09-14 20:28:46 -0300;using time.time() instead of datetime.utcnow() in engine.start_time atttribute

==

scrapy/core/engine.py
scrapy/utils/engine.py
==================
7e07f76e;Pablo Hoffman;2009-09-14 20:27:54 -0300;made pending_spiders attribute protected in spider scheduler

==

scrapy/contrib/spiderscheduler.py
==================
9b684326;Pablo Hoffman;2009-09-14 12:27:29 -0300;commented out line that was preventing errors from propagating to the request errback

==

scrapy/core/engine.py
==================
2322312c;Pablo Hoffman;2009-09-14 10:31:29 -0300;Logging requests instead of responses in 'Crawled ...' messages

==

scrapy/core/engine.py
==================
6f64dfe5;Pablo Hoffman;2009-09-14 10:06:54 -0300;renamed spider manager close_domain() method to close_spider()

==

scrapy/contrib/spidermanager.py
scrapy/core/engine.py
==================
99467d4e;Pablo Hoffman;2009-09-13 20:51:43 -0300;Changed (unstable) scheduler middleware API to receive spider (instead of domain) in enqueue_request method

==

docs/experimental/scheduler-middleware.rst
scrapy/contrib/dupefilter.py
scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/core/engine.py
scrapy/core/scheduler/middleware.py
scrapy/tests/test_dupefilter.py
scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
==================
00873cd1;Pablo Hoffman;2009-09-12 21:27:58 -0300;Another Spider Manager simplification: removed add_spider() method

==

scrapy/contrib/spidermanager.py
==================
dc825500;Pablo Hoffman;2009-09-12 21:04:21 -0300;Do not impose an arbitrary encoding in spider templates, because we don't know beforehand what enconding our users will use in their editors.

==

scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
==================
58bdd730;Pablo Hoffman;2009-09-12 20:59:04 -0300;fixed deprecated import in 'crawl' spider template (thanks Anibal)

==

scrapy/templates/spiders/crawl.tmpl
==================
90407d27;Pablo Hoffman;2009-09-12 19:33:16 -0300;added missing colon

==

scrapy/crawler.py
==================
3f30fee6;Pablo Hoffman;2009-09-12 19:32:23 -0300;added first (not yet stable) revision of Crawler class, which allows to use the Scrapy crawler from stand-alone scripts

==

examples/scripts/count_and_follow_links.py
scrapy/crawler.py
==================
1381c1e5;Pablo Hoffman;2009-09-12 14:50:05 -0300;removed (no longer needed) hack in setup.py

==

setup.py
==================
921fc4f3;Pablo Hoffman;2009-09-12 14:34:18 -0300;Big Scrapy core refactoring to pass around spider references instead of domains.
This is to avoid accessing the scrapy.spider.spiders singleton for "resolving"
spiders, which is considered an "evil" practice because it ties us to the
singleton model for the spider resolver, which is a bad thing.

This change will also work as the foundation for the API cleaning that we'll
perform for 0.8. We decided to introduce this change now to have a more common
basecode between 0.7 and 0.8, which will allow us to better support 0.7 until
0.8 is released.

However, this change doesn't modify the stable/documented API, nor does it
change the core logic. Those changes will land on the 0.8 branch, after 0.7 is
released.

--HG--
rename : scrapy/contrib/domainsch.py => scrapy/contrib/spiderscheduler.py

==

docs/topics/settings.rst
scrapy/command/commands/fetch.py
scrapy/command/commands/parse.py
scrapy/conf/default_settings.py
scrapy/contrib/closedomain.py
scrapy/contrib/domainsch.py
scrapy/contrib/itemsampler.py
scrapy/contrib/pipeline/__init__.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/spidermanager.py
scrapy/contrib/spiderscheduler.py
scrapy/core/downloader/manager.py
scrapy/core/engine.py
scrapy/core/manager.py
scrapy/core/scheduler/middleware.py
scrapy/core/scheduler/schedulers.py
scrapy/core/scraper.py
scrapy/fetcher.py
scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/shell.py
scrapy/spider/models.py
scrapy/tests/test_engine.py
scrapy/tests/test_spiders/__init__.py
scrapy/tests/test_spiders/testspider.py
scrapy/utils/engine.py
scrapy/utils/fetch.py
==================
655cfe13;Pablo Hoffman;2009-09-11 19:38:31 -0300;removed unused imports

==

scrapy/command/commands/crawl.py
==================
0c292e33;Pablo Hoffman;2009-09-11 19:36:00 -0300;removed hacky --callback option to crawl command

==

scrapy/command/commands/crawl.py
==================
e854d0d6;Pablo Hoffman;2009-09-11 19:32:05 -0300;removed redundant --nopipelines function. same behaviour can be obtained by clearing the ITEM_PIPELINES setting

==

scrapy/command/commands/crawl.py
==================
8d49dc2f;Pablo Hoffman;2009-09-11 17:36:00 -0300;changed IMAGES_THUMBS setting to a dict instead of a list of tuples, and more improvements to images pipeline doc

==

docs/experimental/images.rst
scrapy/contrib/pipeline/images.py
==================
e20f7667;Pablo Hoffman;2009-09-11 16:55:37 -0300;fixed some typos

==

docs/experimental/images.rst
==================
c2fe350f;Pablo Hoffman;2009-09-11 16:53:36 -0300;more changes to images pipeline doc

==

docs/experimental/images.rst
==================
ada46a2d;Ismael Carnales;2009-09-11 15:30:46 -0300;styled imagesp doc

==

docs/experimental/images.rst
==================
be0f2bee;Pablo Hoffman;2009-09-11 13:27:31 -0300;more cleanup to scheduler middelware doc, and permanentely moved to experimental doc

==

docs/experimental/scheduler-middleware.rst
docs/index.rst
==================
0af052b6;Pablo Hoffman;2009-09-11 12:19:18 -0300;removed confusing title

==

docs/experimental/images.rst
==================
f3240748;Pablo Hoffman;2009-09-11 12:03:23 -0300;changed link to scheduler middleware doc, now in experimental

==

docs/index.rst
==================
3998a0cb;Ismael Carnales;2009-09-11 11:58:53 -0300;added more scheduler middleware documentation, and moved it to experimental
--HG--
rename : docs/topics/scheduler-middleware.rst => docs/experimental/scheduler-middleware.rst

==

docs/experimental/index.rst
docs/experimental/scheduler-middleware.rst
docs/index.rst
docs/topics/scheduler-middleware.rst
==================
d242a205;Pablo Hoffman;2009-09-11 11:47:12 -0300;updated images pipeline doc

==

docs/experimental/images.rst
==================
40d38b18;Daniel Grana;2009-09-11 11:04:47 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
96bc6780;Daniel Grana;2009-09-11 11:03:53 -0300;imagespipeline: change scraped_url to url

==

scrapy/contrib/pipeline/images.py
==================
0174bee4;Pablo Hoffman;2009-09-10 19:27:47 -0300;simplified implementation of scrapy.fetcher

==

scrapy/fetcher.py
==================
f1bb8dc2;Pablo Hoffman;2009-09-10 19:06:46 -0300;first cleanup of spider manager api
- removed asdict() and reload() methods
- added list() method
- removed default spider

==

docs/topics/settings.rst
scrapy/command/commands/list.py
scrapy/command/models.py
scrapy/conf/default_settings.py
scrapy/contrib/spidermanager.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/fetcher.py
==================
f85813cd;Pablo Hoffman;2009-09-10 18:32:50 -0300;added FAQ entry about scrapy recipes and community spiders

==

docs/faq.rst
==================
73446482;Daniel Grana;2009-09-10 16:28:08 -0300;allow to override httpclientfactory

==

scrapy/conf/default_settings.py
scrapy/core/downloader/handlers.py
==================
269724a2;Pablo Hoffman;2009-09-08 22:32:17 -0300;added Debugger extension, removed StackTraceDump from extensions available by default

==

docs/topics/extensions.rst
docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/debug.py
==================
2974c2c4;Pablo Hoffman;2009-09-07 15:20:41 -0300;some additional checks on using unicode url/body in Request/Response objects

==

scrapy/http/request/__init__.py
scrapy/http/response/text.py
scrapy/tests/test_http_response.py
==================
7a88c0d8;Pablo Hoffman;2009-09-07 14:57:50 -0300;shell: fixed bug when typing exit() in python console - fixes #103

==

scrapy/shell.py
==================
4ddfa9a2;Ismael Carnales;2009-09-07 12:18:57 -0300;stlyed downloaded middleware doc

==

docs/topics/downloader-middleware.rst
==================
e3df11e5;Ismael Carnales;2009-09-07 12:03:24 -0300;added module directive to spidermw documentation

==

docs/topics/spider-middleware.rst
==================
30c2ad3f;Ismael Carnales;2009-09-07 11:14:47 -0300;added urllength spider middleware test

==

scrapy/tests/test_spidermiddleware_urllength.py
==================
c4ad2bea;Ismael Carnales;2009-09-07 11:14:47 -0300;added urlfilter spidermw test

==

scrapy/tests/test_spidermiddleware_urlfilter.py
==================
43bd00de;Ismael Carnales;2009-09-07 11:14:46 -0300;added referer spider middleware test

==

scrapy/tests/test_spidermiddleware_referer.py
==================
1c700749;Ismael Carnales;2009-09-07 11:14:45 -0300;added offside spider middleware test

==

scrapy/tests/test_spidermiddleware_offsite.py
==================
083635eb;Ismael Carnales;2009-09-07 11:14:43 -0300;added depth spider middleware test

==

scrapy/tests/test_spidermiddleware_depth.py
==================
f0b5892a;Ismael Carnales;2009-09-07 11:14:38 -0300;fixed stats downloadermw test

==

scrapy/tests/test_downloadermiddleware_stats.py
==================
82ca5e26;Pablo Hoffman;2009-09-07 09:38:24 -0300;renamed test_xpath.py to test_selector.py
--HG--
rename : scrapy/tests/test_xpath.py => scrapy/tests/test_selector.py

==

scrapy/tests/test_selector.py
==================
4023914b;Pablo Hoffman;2009-09-07 09:37:46 -0300;added support for instantiating TextResponse (or any subclass) with unicode urls, improved organization of request/response unittests

==

scrapy/http/response/__init__.py
scrapy/http/response/text.py
scrapy/selector/__init__.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
==================
e2bd1be9;Pablo Hoffman;2009-09-04 18:07:51 -0300;better aws code arrangement
--HG--
rename : scrapy/tests/test_aws.py => scrapy/tests/test_utils_aws.py

==

scrapy/contrib/aws.py
scrapy/tests/test_utils_aws.py
scrapy/utils/aws.py
==================
827aa19c;Pablo Hoffman;2009-09-04 17:38:14 -0300;removed obsolete scrapy.utils.db module

==

docs/topics/settings.rst
scrapy/stats/collector/mysql.py
scrapy/utils/db.py
==================
74661502;Pablo Hoffman;2009-09-04 17:32:34 -0300;removed some more obsolete middlewares

==

scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/cache.py
scrapy/contrib/downloadermiddleware/common.py
==================
861a803c;Pablo Hoffman;2009-09-04 17:22:56 -0300;removed obsolete RestrictMiddleware

==

docs/topics/settings.rst
docs/topics/spider-middleware.rst
scrapy/conf/default_settings.py
scrapy/contrib/spidermiddleware/restrict.py
==================
06311021;Pablo Hoffman;2009-09-04 17:19:03 -0300;removed backwards compatibility for old errorpages downloader middlware

==

scrapy/contrib/downloadermiddleware/errorpages.py
==================
043e7355;Ismael Carnales;2009-09-04 14:11:56 -0300;added some missing spidermw tests

==

scrapy/tests/test_spidermiddleware_httperror.py
==================
7e258716;Ismael Carnales;2009-09-04 12:39:02 -0300;added missing middleware docs

==

docs/topics/downloader-middleware.rst
docs/topics/spider-middleware.rst
==================
6d127d7f;Ismael Carnales;2009-09-04 12:29:43 -0300;added some missing middlewares tests

==

scrapy/tests/test_downloadermiddleware_defaultheaders.py
scrapy/tests/test_downloadermiddleware_stats.py
==================
aefb9406;Pablo Hoffman;2009-09-04 13:46:04 -0300;more updates to spider middleware doc

==

docs/topics/spider-middleware.rst
==================
d04640be;Pablo Hoffman;2009-09-04 13:29:16 -0300;some improvements to spider middleware doc

==

docs/topics/spider-middleware.rst
==================
96bb223c;Pablo Hoffman;2009-09-04 12:59:58 -0300;removed (pretty useless) DebugMiddleware

==

docs/topics/downloader-middleware.rst
scrapy/contrib/downloadermiddleware/debug.py
==================
86de5180;Pablo Hoffman;2009-09-04 12:36:29 -0300;fixed bug in robots middleware reported by fencer in #101

==

scrapy/contrib/downloadermiddleware/robotstxt.py
==================
dad05957;Pablo Hoffman;2009-09-04 01:16:58 -0300;added comment downloader backout policy

==

scrapy/core/downloader/manager.py
==================
2ae11e92;Daniel Grana;2009-09-03 16:58:36 -0300;meassure downloader backout based on active requests that includes those in downlodermw plus queue

==

scrapy/core/downloader/manager.py
==================
8b4304d5;Daniel Grana;2009-09-03 16:26:05 -0300;change csv exporter to check flag inmediately instead of calling another function

==

scrapy/contrib/exporter/__init__.py
==================
5ff8ed86;Daniel Grana;2009-09-03 16:10:45 -0300;media_pipeline: let failures reach item_completed
--HG--
extra : rebase_source : ec574d95957646498f021c25953ac1405d1c748c

==

scrapy/contrib/pipeline/media.py
==================
8a715701;Pablo Hoffman;2009-09-03 14:31:00 -0300;fixed another doc typo

==

docs/experimental/djangoitems.rst
==================
760cf452;Pablo Hoffman;2009-09-03 14:30:17 -0300;automatic merge

==
==================
0d493615;Pablo Hoffman;2009-09-03 14:29:20 -0300;some code rearrangement without functionality changes

==

scrapy/contrib/exporter/__init__.py
==================
0e7b2a6d;Daniel Grana;2009-09-03 13:58:39 -0300;write header line by default when using csv exporter
--HG--
extra : rebase_source : 2d2d7153dde5e3f77e682e16d2e4408f732f234e

==

docs/topics/exporters.rst
scrapy/contrib/exporter/__init__.py
scrapy/tests/test_contrib_exporter.py
==================
c33d6bbd;Pablo Hoffman;2009-09-03 12:41:04 -0300;avoid shutting down the reactor from two places, for now

==

scrapy/core/manager.py
==================
3c1bb7bc;Ismael Carnales;2009-09-03 11:23:25 -0300;fixed typo in djangoitems doc (thanks anibal)

==

docs/experimental/djangoitems.rst
==================
be764900;Pablo Hoffman;2009-09-03 10:25:55 -0300;avoid stopping reactor if it's already in shutdown stage (where reactor.running is still True)

==

scrapy/core/engine.py
==================
0643010f;Pablo Hoffman;2009-09-03 09:47:59 -0300;engine: stopping reactor when there's nothing left to do

==

scrapy/core/engine.py
scrapy/tests/test_engine.py
==================
a7f5c6f8;Pablo Hoffman;2009-09-03 08:27:48 -0300;Some enhancements to Scrapy core:
- added graceful shutdown (with one ^C) and forced shutdown (two ^C)
- added optional loglevel to IgnoreRequest exception
- calling Spider Manager close_domain() function from engine to avoid race
  conditions caused by signal dispatch order
- moved twisted reactor controlling logic outside the engine and into the
  scrapy manager
- made log.err function respect the current log level filter

==

scrapy/command/cmdline.py
scrapy/contrib/spidermanager.py
scrapy/core/downloader/manager.py
scrapy/core/engine.py
scrapy/core/exceptions.py
scrapy/core/manager.py
scrapy/log.py
scrapy/utils/ossignal.py
==================
51eb641f;Pablo Hoffman;2009-09-02 20:53:55 -0300;fix bug in scrapy shell which was hiding the objects fetch/view/shelp when started without a url as argument

==

scrapy/shell.py
==================
37929f42;Pablo Hoffman;2009-09-02 20:43:05 -0300;spider manager: added protection to avoid reloading non-spider modules

==

scrapy/contrib/spidermanager.py
==================
11f296b7;Pablo Hoffman;2009-09-02 16:22:45 -0300;removed hack for switching standard descriptors in favor of using LOG_STDOUT=False by default

==

scrapy/conf/commands/crawl.py
scrapy/log.py
scrapy/shell.py
scrapy/utils/pdb.py
==================
8ed743f2;Daniel Grana;2009-09-02 15:38:53 -0300;remove obsolete s3 images pipeline

==

scrapy/contrib/pipeline/s3images.py
==================
45bc12e2;Pablo Hoffman;2009-09-02 12:09:36 -0300;added scrapy.utils.pdb module with set_trace() function

==

scrapy/log.py
scrapy/shell.py
scrapy/utils/pdb.py
==================
19c0093e;Daniel Grana;2009-09-02 01:31:08 -0300;fix images pipeline tests

==

scrapy/tests/test_pipeline_images.py
==================
11c82023;Daniel Grana;2009-09-01 19:18:05 -0300;remove MEDIA_NAME from imagespipeline
--HG--
extra : rebase_source : 976f3ca2fccf185399a733904b9763498ebf43f6

==

scrapy/contrib/pipeline/images.py
==================
d6adc141;Daniel Grana;2009-09-01 18:00:56 -0300;imagepipeline: simplify configuraiton using a single setting to setup different backend stores
--HG--
extra : rebase_source : cd0d5f560dcde0003974e360282a233ba387c5be

==

scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/s3images.py
==================
b05fd806;Daniel Grana;2009-09-01 18:00:55 -0300;imagepipeline: return a dict instead of a path joined with checksum with a hash
--HG--
extra : rebase_source : cd450c66be44381e905264ecff3f709bb9d302d4

==

scrapy/contrib/pipeline/images.py
==================
91ff9c9d;Daniel Grana;2009-09-01 18:00:55 -0300;mediapipeline: simplify and return results of item_media_* to item_completed in order
--HG--
extra : rebase_source : 71228e29b0a969df06ac62d90d6e3cefc03ecdfc

==

scrapy/contrib/pipeline/media.py
==================
db5420f8;Pablo Hoffman;2009-09-02 00:48:29 -0300;reload spider modules silently

==

scrapy/contrib/spidermanager.py
==================
596d2c44;Pablo Hoffman;2009-09-01 23:00:49 -0300;moved CoreStats extension to scrapy.contrib.corestats
--HG--
rename : scrapy/stats/corestats.py => scrapy/contrib/corestats.py

==

docs/topics/extensions.rst
docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/corestats.py
==================
5ce2b66c;Pablo Hoffman;2009-09-01 22:53:04 -0300;added proper recycling of spider resources to spider manager

==

scrapy/contrib/spidermanager.py
==================
34d55900;Pablo Hoffman;2009-09-01 22:50:36 -0300;removed empty scrapy.contrib.spider module

==

scrapy/contrib/spider/__init__.py
==================
6a50af05;Pablo Hoffman;2009-09-01 22:49:15 -0300;removed useless SpiderReloader extension

==

docs/topics/extensions.rst
docs/topics/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/spider/reloader.py
==================
79851aef;Pablo Hoffman;2009-09-01 22:38:37 -0300;moved SpiderProfiler extension to scrapy.contrib_exp and removed references from documentation
--HG--
rename : scrapy/contrib/spider/profiler.py => scrapy/contrib_exp/spiderprofiler.py

==

docs/topics/extensions.rst
docs/topics/settings.rst
scrapy/contrib_exp/spiderprofiler.py
==================
d3c51fd6;Pablo Hoffman;2009-09-01 21:07:47 -0300;improved images pipeline documentation

==

docs/experimental/images.rst
scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/media.py
==================
18fd6351;Pablo Hoffman;2009-09-01 12:52:40 -0300;another doc typo

==

docs/topics/settings.rst
==================
538cc980;Pablo Hoffman;2009-09-01 12:47:53 -0300;fixed doc typo

==

docs/topics/settings.rst
==================
e1b33ef1;Pablo Hoffman;2009-09-01 09:04:41 -0300;added missing module from previous commit

==

scrapy/contrib/spidermanager.py
==================
df0e1f00;Pablo Hoffman;2009-09-01 08:56:54 -0300;exporters doc: fixed example and some typos

==

docs/topics/exporters.rst
scrapy/conf/default_settings.py
scrapy/spider/__init__.py
scrapy/spider/manager.py
==================
f68dedb2;Pablo Hoffman;2009-08-31 22:48:01 -0300;commented out code that raises sporadically

==

scrapy/core/scraper.py
==================
ac8f46ce;Pablo Hoffman;2009-08-31 21:01:35 -0300;added File Export Pipeline reference to Exporters doc

==

docs/topics/exporters.rst
docs/topics/item-pipeline.rst
==================
8d006e9e;Pablo Hoffman;2009-08-31 20:47:12 -0300;moved item exporters doc to stable doc
--HG--
rename : docs/experimental/exporters.rst => docs/topics/exporters.rst

==

docs/experimental/index.rst
docs/index.rst
docs/topics/exporters.rst
docs/topics/item-pipeline.rst
==================
0b152c99;Pablo Hoffman;2009-08-31 20:40:41 -0300;added File Export Pipeline, a wrapper to use Item Exporters as Item Pipelines

==

docs/topics/item-pipeline.rst
scrapy/contrib/pipeline/fileexport.py
==================
3c6deaef;Pablo Hoffman;2009-08-31 18:53:55 -0300;Some additional improvements to scrapy.command.cmdline logic:
- calling scrapymanager.configure() for all commands
- finally added some unittests to check cmdline behaviour!

==

scrapy/command/cmdline.py
scrapy/command/models.py
scrapy/core/manager.py
scrapy/tests/test_cmdline/__init__.py
scrapy/tests/test_cmdline/extensions.py
scrapy/tests/test_cmdline/settings.py
scrapy/tests/test_cmdline/settings2.py
==================
6c58d06f;Pablo Hoffman;2009-08-31 18:50:20 -0300;wrapped some big lines

==

scrapy/command/commands/fetch.py
scrapy/command/commands/parse.py
==================
b6c1392f;Pablo Hoffman;2009-08-31 18:43:51 -0300;added 'settings' command for querying scrapy settings

==

scrapy/command/commands/settings.py
scrapy/conf/commands/settings.py
==================
60299c49;Pablo Hoffman;2009-08-31 13:42:44 -0300;raise NotConfigured in web/telnetconsole when disabled

==

scrapy/management/telnet.py
scrapy/management/web.py
==================
8fab5249;Pablo Hoffman;2009-08-31 12:44:32 -0300;moved engine.getstatus() method to scrapy.utils.engine function, to leave reporting logic out of engine code. added est() shortcut to telnet console

==

docs/topics/telnetconsole.rst
scrapy/contrib/memusage.py
scrapy/contrib/webconsole/enginestatus.py
scrapy/core/engine.py
scrapy/management/telnet.py
scrapy/utils/engine.py
==================
dd80f6ac;Pablo Hoffman;2009-08-31 12:14:30 -0300;MemoryUsage: changed .virtual property to methodd. SpiderProfiler: removed dependency on MemoryUsage extension

==

scrapy/contrib/memusage.py
scrapy/contrib/spider/profiler.py
==================
e8e760c9;Pablo Hoffman;2009-08-31 12:04:01 -0300;more simplifications to scrapy engine: removed addtasks method

==

scrapy/conf/default_settings.py
scrapy/contrib/memusage.py
scrapy/core/engine.py
scrapy/utils/mysql.py
==================
1dd996f0;Pablo Hoffman;2009-08-31 11:17:28 -0300;added missing import

==

scrapy/stats/collector/simpledb.py
==================
8f013bf2;Pablo Hoffman;2009-08-31 10:17:12 -0300;imported ismael patch for depreacting old SCRAPYSETTINGS_MODULE envvar

==

scrapy/conf/__init__.py
==================
268acc30;Pablo Hoffman;2009-08-31 09:44:55 -0300;merge with trunk

==
==================
4f00c12a;Pablo Hoffman;2009-08-31 09:44:31 -0300;removed unneeded logic from engine

==

scrapy/core/engine.py
scrapy/management/telnet.py
scrapy/management/web.py
==================
91df6fcc;Daniel Grana;2009-08-31 08:58:29 -0300;test genspider in a single testcase

==

scrapy/tests/test_commands.py
==================
bcf81cd3;Pablo Hoffman;2009-08-31 07:36:09 -0300;minor simplification to how default settings are loaded

==

scrapy/conf/__init__.py
==================
06276116;Pablo Hoffman;2009-08-30 12:37:30 -0300;simpledb collector: moved to_sdb_value function to utils.simpledb, and added unittests

==

scrapy/stats/collector/simpledb.py
scrapy/tests/test_utils_simpledb.py
scrapy/utils/simpledb.py
==================
1f50c24b;Daniel Grana;2009-08-30 01:55:39 -0300;one minus command testing line

==

scrapy/tests/test_commands.py
==================
8ef2cf0a;Daniel Grana;2009-08-30 01:51:34 -0300;more command testing simplifications

==

scrapy/tests/test_commands.py
==================
719fc2e7;Daniel Grana;2009-08-30 01:08:23 -0300;sdb stats: extend type serializations, allow timestamp to be other than now

==

scrapy/stats/collector/simpledb.py
==================
7cb546ba;Daniel Grana;2009-08-29 21:04:32 -0300;use explicit relative import on djangoitem tests
--HG--
extra : rebase_source : f4f72679106bd9f72ddd9ee7d1f27209248f59be

==

scrapy/tests/test_djangoitem/__init__.py
==================
884f0c87;Pablo Hoffman;2009-08-29 19:44:13 -0300;Stats collectin: fixed race condition between stats persistance and population of stats on domain close

==

docs/topics/stats.rst
scrapy/stats/collector/__init__.py
scrapy/stats/collector/mysql.py
scrapy/stats/collector/simpledb.py
==================
895c70e0;Pablo Hoffman;2009-08-29 18:23:55 -0300;doc: fixed some links to scrapy-ctl topic

==

docs/topics/settings.rst
==================
64572124;Pablo Hoffman;2009-08-29 18:20:13 -0300;added doc about SCRAPY_SETTINGS_MODULE

==

docs/topics/settings.rst
==================
9dc7a3a3;Pablo Hoffman;2009-08-29 18:10:28 -0300;some minor adjustments to logging doc

==

docs/topics/logging.rst
scrapy/log.py
==================
91ee7122;Pablo Hoffman;2009-08-29 05:35:22 -0300;some minor changes to test_commands.py

==

scrapy/tests/test_commands.py
==================
5ba466a6;Pablo Hoffman;2009-08-29 05:03:40 -0300;fixed unnapropiate handling of missing django module in djangitem tests

==

scrapy/tests/test_djangoitem/__init__.py
==================
6e028fd9;Pablo Hoffman;2009-08-29 04:59:51 -0300;fixed JsonLinesItemExporterTest

==

scrapy/tests/test_contrib_exporter.py
==================
60cbf24c;Pablo Hoffman;2009-08-29 04:29:47 -0300;more cleanups to startproject and project templates
--HG--
rename : scrapy/templates/project/root/scrapy-ctl.py => scrapy/templates/project/scrapy-ctl.py

==

docs/topics/settings.rst
examples/googledir/googledir/settings.py
scrapy/command/commands/genspider.py
scrapy/command/commands/startproject.py
scrapy/templates/project/module/items.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/templates/project/module/settings.py.tmpl
scrapy/templates/project/module/spiders/__init__.py
scrapy/templates/project/scrapy-ctl.py
==================
c87216f0;Pablo Hoffman;2009-08-29 03:46:58 -0300;doc: added missing :synopsis: to some modules

==

docs/experimental/images.rst
docs/topics/scheduler-middleware.rst
docs/topics/spider-middleware.rst
==================
2f55d793;Pablo Hoffman;2009-08-29 03:37:59 -0300;replaced :ref: by :doc: links in doc index

==

docs/index.rst
==================
924219dd;Pablo Hoffman;2009-08-28 20:32:55 -0300;- added reference documentation about scrapy-ctl.py script - yet another refactor to cmdline module - removed help command (use -h to help now)
--HG--
rename : docs/experimental/scripts.rst => docs/topics/scrapy-ctl.rst

==

docs/experimental/index.rst
docs/experimental/scripts.rst
docs/index.rst
docs/topics/scrapy-ctl.rst
scrapy/command/cmdline.py
scrapy/command/commands/help.py
scrapy/command/commands/shell.py
==================
566758ee;Pablo Hoffman;2009-08-28 19:38:04 -0300;removed useless --restrict command line argument

==

scrapy/command/commands/crawl.py
==================
046e63b1;Pablo Hoffman;2009-08-28 18:26:29 -0300;added --version command line option

==

scrapy/command/models.py
==================
18e9fd97;Pablo Hoffman;2009-08-28 18:07:35 -0300;some better code reusage

==

scrapy/tests/test_commands.py
==================
7dd43da9;Pablo Hoffman;2009-08-28 18:01:06 -0300;removed unnecesary assertEqual's

==

scrapy/tests/test_commands.py
==================
83a2b580;Pablo Hoffman;2009-08-28 17:58:50 -0300;renamed test_scrapy_ctl.py to test_commands.py
--HG--
rename : scrapy/tests/test_scrapy_ctl.py => scrapy/tests/test_commands.py

==

scrapy/tests/test_commands.py
==================
ee40929d;Pablo Hoffman;2009-08-28 17:52:44 -0300;some line wrapping at 80 cols

==

scrapy/command/commands/crawl.py
==================
3e7e321a;Pablo Hoffman;2009-08-28 17:47:45 -0300;sorted out import order and removed unused imports from previous changeset

==

scrapy/command/commands/genspider.py
scrapy/command/commands/startproject.py
scrapy/tests/test_scrapy_ctl.py
==================
0b68d4bb;Ismael Carnales;2009-08-28 14:42:07 -0300;added tests for scrapy-ctl commands

==

scrapy/command/commands/genspider.py
scrapy/command/commands/startproject.py
scrapy/tests/test_scrapy_ctl.py
==================
3616ccb4;Ismael Carnales;2009-08-28 11:20:05 -0300;changed SCRAPYSETTINGS_MODULE to SCRAPY_SETTINGS_MODULE

==

examples/googledir/scrapy-ctl.py
scrapy/conf/__init__.py
scrapy/templates/project/root/scrapy-ctl.py
==================
0bfa1a91;Pablo Hoffman;2009-08-28 02:21:32 -0300;removed wrong docstring

==

scrapy/stats/collector/simpledb.py
==================
da20cf53;Pablo Hoffman;2009-08-27 20:05:11 -0300;added compatibility with python 2.5

==

scrapy/utils/response.py
==================
609aed45;Pablo Hoffman;2009-08-27 19:33:33 -0300;added inspect_response() function for inspecting responses from spiders

==

docs/topics/shell.rst
scrapy/log.py
scrapy/shell.py
==================
ea4f16ba;Pablo Hoffman;2009-08-27 18:24:08 -0300;refactored scrapy shell implementation, dropping IPython dependency, and adding a new 'view' shortcut

==

docs/index.rst
docs/topics/shell.rst
scrapy/command/commands/shell.py
scrapy/shell.py
==================
13be33f0;Pablo Hoffman;2009-08-27 18:20:51 -0300;added open_in_browser function to scrapy.utils.response

==

scrapy/utils/response.py
==================
02de8cb6;Pablo Hoffman;2009-08-27 14:41:49 -0300;some other minor code cleanups for Settings class

==

scrapy/conf/__init__.py
==================
90e6aefb;Pablo Hoffman;2009-08-27 14:08:48 -0300;some refactoring to Settings class

==

scrapy/conf/__init__.py
==================
78481bf4;Pablo Hoffman;2009-08-27 12:10:31 -0300;fixed bug when spider returns None

==

scrapy/core/scraper.py
==================
ab0def3f;Pablo Hoffman;2009-08-27 11:49:35 -0300;made scrapy.command.cmdline module executable from command line

==

scrapy/command/cmdline.py
==================
62513746;Pablo Hoffman;2009-08-26 16:18:25 -0300;fixed bug in help command (thanks slav0nic for reporting)

==

scrapy/command/commands/help.py
==================
0e163a98;Ismael Carnales;2009-08-26 11:58:40 -0300;added override field save test to DjangoItem

==

scrapy/tests/test_djangoitem/__init__.py
==================
62e03419;Ismael Carnales;2009-08-26 11:45:59 -0300;fixed bug in DjangoItem

==

scrapy/contrib_exp/djangoitem.py
==================
8efe6eb5;Ismael Carnales;2009-08-26 11:38:49 -0300;made DjangoItem a descendant of Item and its metaclass

==

scrapy/contrib_exp/djangoitem.py
scrapy/item.py
==================
fb39bca2;Ismael Carnales;2009-08-26 08:44:22 -0300;added djangoitem doc

==

docs/experimental/djangoitems.rst
docs/experimental/index.rst
==================
65ab611f;Pablo Hoffman;2009-08-26 08:30:18 -0300;more updates to HttpErrorMiddleware doc

==

docs/topics/spider-middleware.rst
==================
44783a3a;Pablo Hoffman;2009-08-26 00:18:58 -0300;minor improvements to FAQ entry

==

docs/faq.rst
==================
4dba75a7;Pablo Hoffman;2009-08-25 20:13:58 -0300;updated HttpErrorMiddleware doc

==

docs/topics/spider-middleware.rst
==================
14c6c462;Daniel Grana;2009-08-25 16:51:41 -0300;remove debug line :(

==

scrapy/contrib/exporter/__init__.py
==================
fe4683d6;Daniel Grana;2009-08-25 16:50:40 -0300;pylinted decorators utils

==

scrapy/contrib/exporter/__init__.py
scrapy/utils/decorator.py
==================
9f1ed637;Daniel Grana;2009-08-24 20:27:08 -0300;report caller's file:lineno of deprecated function instead of file:lineno of deprecated function

==

scrapy/utils/decorator.py
==================
9bafa732;Ismael Carnales;2009-08-24 17:30:58 -0300;fixed errors in djangoitem tests

==

scrapy/tests/test_djangoitem/__init__.py
==================
decbdc53;Ismael Carnales;2009-08-24 17:16:18 -0300;added DjangoItem item class

==

scrapy/contrib_exp/djangoitem.py
scrapy/item.py
scrapy/tests/test_djangoitem/__init__.py
scrapy/tests/test_djangoitem/models.py
scrapy/tests/test_djangoitem/settings.py
==================
7b30c31b;Daniel Grana;2009-08-24 16:46:25 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
9fbaef90;Daniel Grana;2009-08-24 16:46:20 -0300;fix spider templates handling in genspider command

==

scrapy/command/commands/genspider.py
==================
8a074c9c;Pablo Hoffman;2009-08-24 15:43:36 -0300;removed scrapy-admin.py command, and left only scrapy-ctl as the only scrapy command

==

bin/scrapy-admin.py
bin/scrapy-ctl.py
docs/experimental/scripts.rst
docs/intro/install.rst
docs/intro/tutorial.rst
docs/topics/settings.rst
scrapy/command/cmdline.py
scrapy/command/commands/crawl.py
scrapy/command/commands/fetch.py
scrapy/command/commands/genspider.py
scrapy/command/commands/help.py
scrapy/command/commands/list.py
scrapy/command/commands/parse.py
scrapy/command/commands/shell.py
scrapy/command/commands/start.py
scrapy/command/commands/startproject.py
scrapy/command/models.py
scrapy/conf/__init__.py
scrapy/conf/commands/startproject.py
scrapy/spider/manager.py
scrapy/tests/test_downloadermiddleware_cookies.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_downloadermiddleware_retry.py
scrapy/tests/test_downloadermiddleware_useragent.py
scrapy/tests/test_engine.py
setup.py
==================
39540b18;Ismael Carnales;2009-08-24 15:11:04 -0300;changed torrent in overview doc

==

docs/intro/overview.rst
==================
4b5aa308;Ismael Carnales;2009-08-24 14:34:17 -0300;minor update to tutorial

==

docs/intro/tutorial.rst
==================
03630408;Pablo Hoffman;2009-08-24 13:56:44 -0300;doc: added FAQ entry about Accept-Language

==

docs/faq.rst
==================
85282a4b;Ismael Carnales;2009-08-24 12:02:44 -0300;added scrapy commandline scripts doc

==

docs/experimental/index.rst
docs/experimental/scripts.rst
docs/topics/settings.rst
==================
ead8cb9f;Pablo Hoffman;2009-08-24 11:57:21 -0300;removed documentation about ugly DontCloseDomain exception (which will be removed in the future)

==

docs/topics/exceptions.rst
docs/topics/signals.rst
==================
74f706b3;Pablo Hoffman;2009-08-24 10:54:34 -0300;renamed "parse_item" method of XMLFeedSpider to "parse_node", keeping backwards compatibility

==

docs/topics/spiders.rst
scrapy/contrib/spiders/feed.py
==================
31693eb9;Pablo Hoffman;2009-08-24 10:34:05 -0300;dropped "cache" attribute of Request and Response objects

==

docs/topics/request-response.rst
scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
scrapy/tests/test_utils_python.py
==================
79bf4c81;Pablo Hoffman;2009-08-24 10:21:04 -0300;replaced old memoizemethod decorator with a more efficient one (memoizemethod_noargs)

==

scrapy/http/response/html.py
scrapy/http/response/text.py
scrapy/http/response/xml.py
scrapy/tests/test_utils_python.py
scrapy/utils/python.py
==================
4f292542;Pablo Hoffman;2009-08-24 09:54:02 -0300;minor improvements to Response.__repr__

==

scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
==================
b71de57b;Pablo Hoffman;2009-08-24 09:47:26 -0300;some simplifications to Request and Response classes

==

scrapy/http/request/form.py
scrapy/http/request/rpc.py
scrapy/http/response/__init__.py
scrapy/http/response/html.py
scrapy/http/response/text.py
scrapy/http/response/xml.py
==================
81832773;Pablo Hoffman;2009-08-24 08:58:51 -0300;ported get_base_url and get_meta_refresh to use WeakKeyDictionary (instead of Request.cache)

==

scrapy/utils/response.py
==================
49e11d34;Pablo Hoffman;2009-08-24 08:45:23 -0300;switched request_fingerprint to use WeakKeyDictionary for caching (instead of Request.cache)

==

scrapy/tests/test_utils_request.py
scrapy/utils/request.py
==================
0186c693;Pablo Hoffman;2009-08-24 08:07:20 -0300;HTTP auth middleware: added doc and unittest

==

docs/faq.rst
docs/topics/downloader-middleware.rst
scrapy/tests/test_downloadermiddleware_httpauth.py
==================
c7e91640;Pablo Hoffman;2009-08-24 07:57:00 -0300;fixed test name

==

scrapy/tests/test_downloadermiddleware_useragent.py
==================
2cb0cfe7;Pablo Hoffman;2009-08-24 07:29:30 -0300;simplified some code

==

scrapy/core/scraper.py
==================
73e7788b;Daniel Grana;2009-08-24 01:25:14 -0300;dont try to guess if spider output is iterable for Items and Requests objects

==

scrapy/core/scraper.py
scrapy/tests/test_spiders/testspider.py
==================
6e2bd49a;Daniel Grana;2009-08-24 01:16:49 -0300;Host header must include port number when port used for connecting is not default protocol port

==

scrapy/core/downloader/webclient.py
scrapy/tests/test_webclient.py
==================
46aaea9f;Pablo Hoffman;2009-08-23 20:36:00 -0300;doc: improved documentation about debugging leaks

==

docs/experimental/exporters.rst
docs/topics/leaks.rst
==================
0ed84924;Pablo Hoffman;2009-08-23 05:48:35 -0300;some improvements to item exporters
- passed previous class attributes to instances attributes
- better handling of constructor arguments
- better coverage on unittets (including encoding)
- updated documentation with new changes

==

docs/experimental/exporters.rst
scrapy/contrib/exporter/__init__.py
scrapy/contrib/exporter/jsonlines.py
scrapy/tests/test_contrib_exporter.py
==================
de899091;Pablo Hoffman;2009-08-22 16:38:25 -0300;send_catch_log: pass through results from sendRobust

==

scrapy/tests/test_utils_signal.py
scrapy/utils/signal.py
==================
499dc667;Pablo Hoffman;2009-08-22 16:22:31 -0300;utils.signal: made send_catch_log function more robust (by using pydispatch.robust.sendRobust) and added unittests

==

scrapy/tests/test_utils_signal.py
scrapy/utils/signal.py
==================
f204da82;Pablo Hoffman;2009-08-22 16:22:02 -0300;disconnecting signal handlers after using them in stats unittests

==

scrapy/tests/test_stats.py
==================
825cec51;Pablo Hoffman;2009-08-21 23:23:46 -0300;fixed bug recently introduced in stats collector closing logic, and added unittests

==

scrapy/stats/collector/__init__.py
scrapy/tests/test_stats.py
==================
7461710e;Pablo Hoffman;2009-08-21 21:54:10 -0300;added some missing dots

==

docs/index.rst
==================
9635a783;Pablo Hoffman;2009-08-21 21:49:54 -0300;rearranged documentation into a better organization
--HG--
rename : docs/topics/index.rst => docs/index.rst

==

docs/_templates/index.html
docs/_templates/layout.html
docs/conf.py
docs/contents.rst
docs/experimental/index.rst
docs/index.rst
docs/intro/index.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/reference.rst
docs/topics/index.rst
docs/topics/signals.rst
==================
4761e0c8;Pablo Hoffman;2009-08-21 19:11:59 -0300;minor doc correction

==

docs/topics/leaks.rst
==================
012fd1cc;Pablo Hoffman;2009-08-21 16:29:23 -0300;moved api-stability.rst doc to root and updated it
--HG--
rename : docs/misc/api-stability.rst => docs/api-stability.rst

==

docs/api-stability.rst
docs/contents.rst
docs/misc/index.rst
docs/reference.rst
==================
07c1f3b8;Pablo Hoffman;2009-08-21 16:13:25 -0300;updated ugly argument name

==

scrapy/contrib/spiders/feed.py
==================
50507873;Ismael Carnales;2009-08-21 16:10:45 -0300;removed spider templates from project, addeded sumcommands to manage templates in genspider

==

scrapy/command/commands/genspider.py
scrapy/templates/spiders/basic.tmpl
scrapy/templates/spiders/crawl.tmpl
scrapy/templates/spiders/csvfeed.tmpl
scrapy/templates/spiders/xmlfeed.tmpl
==================
ef6f04eb;Pablo Hoffman;2009-08-21 16:07:16 -0300;moved doc about debugging memory leaks to its own topic and added doc about trackref module

==

docs/faq.rst
docs/topics/index.rst
docs/topics/leaks.rst
docs/topics/telnetconsole.rst
==================
4980eb49;Pablo Hoffman;2009-08-21 15:07:52 -0300;added titles to signals doc

==

docs/topics/signals.rst
==================
daea3f8a;Pablo Hoffman;2009-08-21 15:05:06 -0300;sphinx docs: replaced custom :exception: xref by standard :exc:

==

docs/_ext/scrapydocs.py
docs/experimental/images.rst
docs/topics/downloader-middleware.rst
docs/topics/exceptions.rst
docs/topics/extensions.rst
docs/topics/item-pipeline.rst
docs/topics/settings.rst
docs/topics/signals.rst
==================
e2b8817c;Ismael Carnales;2009-08-21 14:21:22 -0300;updated project templates to new item

==

scrapy/templates/project/module/items.py.tmpl
scrapy/templates/project/module/templates/spider_crawl.tmpl
scrapy/templates/project/module/templates/spider_csvfeed.tmpl
scrapy/templates/project/module/templates/spider_xmlfeed.tmpl
==================
c08d3aa9;Ismael Carnales;2009-08-21 14:16:27 -0300;updated tutorial to use new items api

==

docs/intro/tutorial.rst
==================
37760eb1;Pablo Hoffman;2009-08-21 08:54:12 -0300;improved consistency of logging settings to use LOG_*

==

docs/topics/logging.rst
docs/topics/settings.rst
scrapy/command/models.py
scrapy/conf/commands/shell.py
scrapy/conf/default_settings.py
scrapy/log.py
scrapy/stats/corestats.py
==================
f0689a9e;Ismael Carnales;2009-08-21 08:34:53 -0300;fixed error in link extractors doc, thanks tarasm

==

docs/topics/link-extractors.rst
==================
bdc0ec68;Daniel Grana;2009-08-20 20:30:08 -0300;remove undefined variable from image pipeline

==

scrapy/contrib/pipeline/images.py
==================
e7e1cba4;Pablo Hoffman;2009-08-20 18:39:04 -0300;updated some docstings

==

scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/s3images.py
scrapy/utils/misc.py
==================
41f1972e;Pablo Hoffman;2009-08-20 18:17:48 -0300;removed unused TRACE log level and improved logging documentation

==

docs/topics/logging.rst
docs/topics/settings.rst
docs/topics/spiders.rst
scrapy/log.py
==================
297a8ac7;Pablo Hoffman;2009-08-20 17:37:46 -0300;moved caching resolver to an extension in contrib.resolver

==

scrapy/contrib/resolver.py
scrapy/core/downloader/manager.py
scrapy/core/downloader/resolver.py
==================
a767b704;Pablo Hoffman;2009-08-20 17:11:12 -0300;removed old blocking caching DNS resolver and replaced by a non-blocking one installed as the default reactor resolver
--HG--
rename : scrapy/core/downloader/dnscache.py => scrapy/core/downloader/resolver.py

==

scrapy/core/downloader/dnscache.py
scrapy/core/downloader/handlers.py
scrapy/core/downloader/manager.py
scrapy/core/downloader/resolver.py
==================
cbed0f1e;Pablo Hoffman;2009-08-20 16:02:40 -0300;moved send_catch_log to new scrapy.utils.signal module

==

scrapy/core/downloader/handlers.py
scrapy/core/downloader/middleware.py
scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/core/signals.py
scrapy/stats/collector/__init__.py
scrapy/utils/signal.py
==================
8fad0a57;Pablo Hoffman;2009-08-20 15:33:35 -0300;fixed bug with defer_fail rename

==

scrapy/utils/defer.py
==================
eeac040f;Pablo Hoffman;2009-08-20 14:40:37 -0300;minor docstring update

==

scrapy/xlib/__init__.py
==================
119bb110;Pablo Hoffman;2009-08-20 14:37:38 -0300;removed unused chain_deferred function, renamed defer_fail to defer_failed

==

scrapy/utils/defer.py
==================
b7633503;Pablo Hoffman;2009-08-20 14:29:39 -0300;removed unused module: scrapy.contrib_exp.history

==

scrapy/contrib_exp/history/__init__.py
scrapy/contrib_exp/history/history.py
scrapy/contrib_exp/history/memorystore.py
scrapy/contrib_exp/history/middleware.py
scrapy/contrib_exp/history/scheduler.py
scrapy/contrib_exp/history/sqlstore.py
==================
b65c87cb;Pablo Hoffman;2009-08-20 14:23:49 -0300;removed unused module: scrapy.utils.c14n

==

scrapy/tests/test_c14nurls.py
scrapy/utils/c14n.py
==================
5de409a6;Pablo Hoffman;2009-08-20 14:20:45 -0300;removed unused module: scrapy.tests.serialization

==

scrapy/tests/test_serialization.py
scrapy/utils/serialization.py
==================
20e82335;Pablo Hoffman;2009-08-20 14:09:24 -0300;rename some exporter methods and complete exporter tests refactoring

==

docs/experimental/exporters.rst
scrapy/contrib/exporter/__init__.py
scrapy/contrib/exporter/jsonlines.py
scrapy/tests/test_contrib_exporter.py
==================
6b7162f3;Ismael Carnales;2009-08-20 12:58:10 -0300;updated JsonLinesItemExporter to new exporters API

==

scrapy/contrib/exporter/jsonlines.py
scrapy/tests/test_contrib_exporter.py
==================
3152e66f;Pablo Hoffman;2009-08-20 10:54:58 -0300;deprecate domain_open signal and handle stats domain open/close directly from the engine

==

docs/experimental/exporters.rst
docs/topics/item-pipeline.rst
docs/topics/signals.rst
docs/topics/stats.rst
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/webconsole/livestats.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/contrib_exp/history/middleware.py
scrapy/contrib_exp/pipeline/shoveitem.py
scrapy/core/engine.py
scrapy/core/signals.py
scrapy/stats/collector/__init__.py
==================
5522560d;Pablo Hoffman;2009-08-20 10:25:43 -0300;updated example project to use new selectors module

==

examples/googledir/googledir/spiders/google_directory.py
==================
06db0bc1;Pablo Hoffman;2009-08-19 22:41:26 -0300;updated some documentation references in source code

==

scrapy/conf/default_settings.py
scrapy/contrib/closedomain.py
scrapy/contrib/debug.py
scrapy/contrib/downloadermiddleware/defaultheaders.py
scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/contrib/linkextractors/__init__.py
scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/httperror.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/requestlimit.py
scrapy/contrib/spidermiddleware/restrict.py
scrapy/contrib/spidermiddleware/urllength.py
scrapy/contrib/spiders/crawl.py
scrapy/contrib/spiders/feed.py
scrapy/contrib/webconsole/scheduler.py
scrapy/core/exceptions.py
scrapy/core/signals.py
scrapy/http/request/__init__.py
scrapy/http/request/form.py
scrapy/http/request/rpc.py
scrapy/http/response/__init__.py
scrapy/http/response/html.py
scrapy/http/response/text.py
scrapy/http/response/xml.py
scrapy/link.py
scrapy/log.py
scrapy/mail.py
scrapy/selector/__init__.py
scrapy/spider/models.py
==================
33b53c59;Pablo Hoffman;2009-08-19 21:50:52 -0300;moved scrapy.xpath to scrapy.selector
--HG--
rename : scrapy/xpath/__init__.py => scrapy/selector/__init__.py
rename : scrapy/xpath/document.py => scrapy/selector/document.py
rename : scrapy/xpath/factories.py => scrapy/selector/factories.py

==

docs/intro/tutorial.rst
docs/topics/loaders.rst
docs/topics/selectors.rst
docs/topics/shell.rst
docs/topics/spiders.rst
scrapy/command/commands/shell.py
scrapy/contrib/linkextractors/image.py
scrapy/contrib/linkextractors/sgml.py
scrapy/contrib/loader/__init__.py
scrapy/contrib/spiders/feed.py
scrapy/selector/__init__.py
scrapy/selector/document.py
scrapy/selector/factories.py
scrapy/tests/test_contrib_loader.py
scrapy/tests/test_xpath.py
scrapy/utils/iterators.py
scrapy/utils/test.py
scrapy/xpath/__init__.py
scrapy/xpath/selector.py
==================
dcc90fc1;Pablo Hoffman;2009-08-19 21:39:59 -0300;declared loaders api stable and updated example project to use them
--HG--
rename : docs/experimental/loaders.rst => docs/topics/loaders.rst

==

docs/experimental/index.rst
docs/topics/index.rst
docs/topics/loaders.rst
examples/googledir/googledir/items.py
examples/googledir/googledir/spiders/google_directory.py
scrapy/contrib/loader/__init__.py
==================
e8504a05;Pablo Hoffman;2009-08-19 21:39:58 -0300;moved scrapy.newitem to scrapy.item and declared newitem api officially stable. updated docs and example project. deprecated old ScrapedItem

==

docs/experimental/exporters.rst
docs/experimental/index.rst
docs/experimental/loaders.rst
docs/experimental/newitems.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/topics/firebug.rst
docs/topics/item-pipeline.rst
docs/topics/items.rst
docs/topics/settings.rst
docs/topics/signals.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
examples/googledir/googledir/items.py
examples/googledir/googledir/pipelines.py
examples/googledir/googledir/spiders/google_directory.py
scrapy/conf/default_settings.py
scrapy/contrib/loader/__init__.py
scrapy/item.py
scrapy/newitem.py
scrapy/tests/test_contrib_exporter.py
scrapy/tests/test_contrib_loader.py
scrapy/tests/test_engine.py
scrapy/tests/test_item.py
scrapy/tests/test_newitem.py
scrapy/tests/test_spiders/testspider.py
scrapy/tests/test_utils_misc.py
==================
314e8dea;Ismael Carnales;2009-08-19 19:05:33 -0300;added new item exporter tests, introduced some api changes

==

docs/experimental/exporters.rst
scrapy/contrib/exporter/__init__.py
scrapy/contrib/exporter/jsonlines.py
scrapy/tests/test_contrib_exporter.py
==================
907fad6d;Pablo Hoffman;2009-08-19 16:49:49 -0300;make sure input processors always receive iterables as input

==

docs/experimental/loaders.rst
scrapy/contrib/loader/__init__.py
scrapy/tests/test_contrib_loader.py
==================
1d351c28;Pablo Hoffman;2009-08-19 16:16:34 -0300;minor change to offsite middleware regex, for clarity (doesn't change behaviour)

==

scrapy/contrib/spidermiddleware/offsite.py
==================
f3c6d83a;Pablo Hoffman;2009-08-19 15:20:29 -0300;added check to CsvItemExporter

==

scrapy/contrib/exporter/__init__.py
==================
741a6d78;Pablo Hoffman;2009-08-19 13:09:39 -0300;item exporters refactoring
--HG--
rename : scrapy/contrib/exporter/jsonexporter.py => scrapy/contrib/exporter/jsonlines.py

==

docs/experimental/exporters.rst
scrapy/contrib/exporter/__init__.py
scrapy/contrib/exporter/jsonexporter.py
scrapy/contrib/exporter/jsonlines.py
scrapy/tests/test_contrib_exporter.py
==================
9c5dad3f;Pablo Hoffman;2009-08-19 11:19:36 -0300;renamed scrapy.utils.ref module to scrapy.utils.trackref, and improved docstring
--HG--
rename : scrapy/utils/ref.py => scrapy/utils/trackref.py

==

scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/item.py
scrapy/management/telnet.py
scrapy/utils/trackref.py
scrapy/xpath/selector.py
==================
e947e1d4;Pablo Hoffman;2009-08-18 20:40:04 -0300;added some unittests to make sure certain objects are using __slots__ and are also weak-referenceable

==

scrapy/http/request/form.py
scrapy/http/response/html.py
scrapy/http/response/xml.py
scrapy/link.py
scrapy/tests/test_http_headers.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
scrapy/tests/test_xpath.py
scrapy/utils/datatypes.py
scrapy/xpath/selector.py
==================
240e0681;Pablo Hoffman;2009-08-18 20:00:54 -0300;scarpy.xpath: added __weakref__ to __slots__, removed unused XPathSelector.response attribute, moved deprecated methods to the bottom

==

scrapy/xpath/document.py
scrapy/xpath/selector.py
==================
00527fc9;Pablo Hoffman;2009-08-18 19:57:05 -0300;added __slots__ to XPathSelector and Libxml2Document classes

==

scrapy/xpath/document.py
scrapy/xpath/selector.py
==================
64ffe6b2;Pablo Hoffman;2009-08-18 19:44:25 -0300;added scrapy.utils.ref module for tracking references to live instances, for certain objects

==

scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/item.py
scrapy/management/telnet.py
scrapy/utils/ref.py
scrapy/xpath/selector.py
==================
82e4b6ad;Pablo Hoffman;2009-08-18 15:38:20 -0300;merge with ismael repo

==
==================
e01d31c4;Pablo Hoffman;2009-08-18 15:35:53 -0300;another improvement to doc navbar

==

docs/_templates/layout.html
==================
be4226ce;Ismael Carnales;2009-08-18 15:21:39 -0300;merge

==
==================
f88fb278;Ismael Carnales;2009-08-18 15:18:49 -0300;fixed error in xpath selectors doc

==

docs/topics/selectors.rst
==================
67c0c6a9;Ismael Carnales;2009-08-18 15:13:23 -0300;corrected indentation in xpath selectors doc

==

docs/topics/selectors.rst
==================
ff837e5a;Pablo Hoffman;2009-08-18 15:12:44 -0300;doc: improved top navbar

==

docs/_templates/layout.html
==================
428dfe0d;Ismael Carnales;2009-08-18 15:06:33 -0300;corrected the style of spiders documentation

==

docs/topics/spiders.rst
==================
0192282d;Pablo Hoffman;2009-08-18 14:36:18 -0300;reorganized doc and moved robotstxt doc inside downloader middlewares doc

==

docs/_templates/layout.html
docs/experimental/index.rst
docs/topics/downloader-middleware.rst
docs/topics/index.rst
docs/topics/robotstxt.rst
==================
33089d28;Ismael Carnales;2009-08-18 14:05:15 -0300;merged topics and reference doc

==

docs/_templates/index.html
docs/_templates/layout.html
docs/contents.rst
docs/faq.rst
docs/ref/downloader-middleware.rst
docs/ref/extension-manager.rst
docs/ref/extensions.rst
docs/ref/index.rst
docs/ref/link-extractors.rst
docs/ref/selectors.rst
docs/ref/settings.rst
docs/ref/spider-middleware.rst
docs/ref/spiders.rst
docs/reference.rst
docs/topics/downloader-middleware.rst
docs/topics/email.rst
docs/topics/exceptions.rst
docs/topics/extensions.rst
docs/topics/index.rst
docs/topics/link-extractors.rst
docs/topics/logging.rst
docs/topics/request-response.rst
docs/topics/scheduler-middleware.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/signals.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
docs/topics/stats.rst
docs/topics/telnetconsole.rst
docs/topics/webconsole.rst
==================
e82d9d88;Pablo Hoffman;2009-08-18 12:43:25 -0300;some speedups to offsite spider middleware using regexes and urlparse_cached

==

scrapy/contrib/spidermiddleware/offsite.py
==================
7f304614;Pablo Hoffman;2009-08-18 11:05:36 -0300;added support for defining EXTENSIONS setting using dicts, like middleware settings
--HG--
rename : scrapy/tests/test_utils_middleware.py => scrapy/tests/test_utils_conf.py
rename : scrapy/utils/middleware.py => scrapy/utils/conf.py

==

docs/ref/extension-manager.rst
docs/ref/settings.rst
docs/topics/extensions.rst
scrapy/conf/default_settings.py
scrapy/core/downloader/middleware.py
scrapy/core/scheduler/middleware.py
scrapy/extension.py
scrapy/spider/middleware.py
scrapy/tests/test_utils_conf.py
scrapy/utils/conf.py
scrapy/utils/middleware.py
==================
1bbe7991;Ismael Carnales;2009-08-18 09:35:32 -0300;added documentation for ImagesPipeline

==

docs/experimental/images.rst
docs/ref/settings.rst
==================
ec8f934a;Ismael Carnales;2009-08-18 09:02:23 -0300;corrected import path in scrapy-admin.py

==

bin/scrapy-admin.py
==================
4b910881;Pablo Hoffman;2009-08-18 00:59:32 -0300;make sure get_vmvalue_from_procfs returns int

==

scrapy/tests/test_utils_memory.py
scrapy/utils/memory.py
==================
49cc1b1e;Daniel Grana;2009-08-17 21:42:37 -0300;add missing future import for python 2.5

==

scrapy/utils/template.py
==================
16c51353;Pablo Hoffman;2009-08-17 21:22:05 -0300;updated select() method in crawl spider template

==

scrapy/templates/project/module/templates/spider_crawl.tmpl
==================
9ae3a194;Pablo Hoffman;2009-08-17 21:16:55 -0300;remove Url class and use str instead for Request and Response urls. Also added urlparse_cached function for achieving the same caching functionality provided by old Url class

==

scrapy/contrib/aws.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/core/downloader/handlers.py
scrapy/core/downloader/webclient.py
scrapy/http/__init__.py
scrapy/http/cookies.py
scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/http/url.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
scrapy/tests/test_http_url.py
scrapy/tests/test_utils_httpobj.py
scrapy/tests/test_webclient.py
scrapy/utils/httpobj.py
scrapy/utils/request.py
==================
29710461;Pablo Hoffman;2009-08-17 19:11:43 -0300;some refactoring to robotstxt downloader middleware

==

scrapy/contrib/downloadermiddleware/robotstxt.py
==================
d6da7eb0;Pablo Hoffman;2009-08-17 18:32:24 -0300;removed backwards compatibility alias: load_class

==

scrapy/utils/misc.py
==================
e71764e7;Pablo Hoffman;2009-08-17 18:30:40 -0300;removed unused functions: memoize, gzip_file

==

scrapy/utils/misc.py
==================
50de128e;Pablo Hoffman;2009-08-17 18:21:21 -0300;removed unused items_to_csv function

==

scrapy/tests/test_utils_misc.py
scrapy/utils/misc.py
==================
6dfda357;Pablo Hoffman;2009-08-17 18:19:59 -0300;removed unused dict_updatedefault function

==

scrapy/utils/misc.py
==================
c81987f6;Pablo Hoffman;2009-08-17 18:16:44 -0300;removed unused hash_values function

==

scrapy/tests/test_utils_misc.py
scrapy/utils/misc.py
==================
4f06f6ef;Pablo Hoffman;2009-08-17 18:13:45 -0300;applied fix to deprecated decorator to warn only once (thanks Dan)

==

scrapy/utils/decorator.py
==================
41036af6;Pablo Hoffman;2009-08-17 17:59:34 -0300;some refactoring to genspider command

==

scrapy/command/commands/genspider.py
scrapy/utils/misc.py
scrapy/utils/template.py
==================
48b40bd6;Ismael Carnales;2009-08-17 15:58:06 -0300;renamed x method of selectors to select

==

docs/intro/overview.rst
docs/intro/tutorial.rst
docs/ref/selectors.rst
docs/ref/spiders.rst
docs/topics/firebug.rst
docs/topics/selectors.rst
docs/topics/shell.rst
examples/googledir/googledir/spiders/google_directory.py
scrapy/contrib/linkextractors/image.py
scrapy/contrib/linkextractors/sgml.py
scrapy/contrib/loader/__init__.py
scrapy/contrib/spiders/feed.py
scrapy/tests/test_utils_iterators.py
scrapy/tests/test_xpath.py
scrapy/utils/decorator.py
scrapy/utils/iterators.py
scrapy/xpath/selector.py
==================
59e0a83a;Pablo Hoffman;2009-08-17 14:48:11 -0300;removed more obsolete adaptors code

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
==================
1bf56821;Pablo Hoffman;2009-08-17 14:41:06 -0300;removed unused modules

==

scrapy/conf/commands/log.py
scrapy/conf/commands/stats.py
==================
62c29e4d;Pablo Hoffman;2009-08-17 14:39:54 -0300;removed unused module

==

scrapy/xlib/lrucache.py
==================
db8b2950;Pablo Hoffman;2009-08-17 14:25:38 -0300;removed duplicated code from memdebug extension (already present in memusage extension)

==

scrapy/contrib/memdebug.py
==================
b20837a0;Pablo Hoffman;2009-08-17 13:01:33 -0300;added __slots__ to Request/Response/Headers objects, to reduce memory footprint

==

scrapy/http/headers.py
scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/http/response/text.py
==================
45ed662e;Pablo Hoffman;2009-08-17 09:41:02 -0300;some cleanup to memusage and memdebug extensions

==

scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/tests/test_utils_memory.py
scrapy/utils/memory.py
==================
f1980a3d;Pablo Hoffman;2009-08-15 20:54:34 -0300;updated some RFC numbers

==

scrapy/utils/url.py
==================
08424ee0;Pablo Hoffman;2009-08-15 20:44:11 -0300;OffsiteMiddleware: isolate policy of urls belonging to spiders into a separate method

==

scrapy/contrib/spidermiddleware/offsite.py
==================
bc873501;Pablo Hoffman;2009-08-15 20:34:40 -0300;removed legacy comment, and wrapped some lines to 80 columns

==

scrapy/utils/url.py
==================
08194186;Pablo Hoffman;2009-08-15 19:44:37 -0300;improved docstring a encoding parameter of safe_url_string function. also added some unittests

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
2463842a;Pablo Hoffman;2009-08-15 17:14:35 -0300;HttpErrorMiddleware: performance improvement and added support for 'handle_httpstatus_list' request meta key

==

scrapy/contrib/spidermiddleware/httperror.py
==================
8c2f62ba;Ismael Carnales;2009-08-14 09:16:29 -0300;added Item Exporters documentation

==

docs/experimental/exporters.rst
docs/experimental/index.rst
==================
7fca2f26;Daniel Grana;2009-08-14 01:34:35 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
e0ccbed4;Daniel Grana;2009-08-14 01:33:36 -0300;imported patch improve_download_troughput.patch

==

scrapy/core/engine.py
==================
02b01c3d;Pablo Hoffman;2009-08-13 23:24:24 -0300;loaders doc: fixed outdated line

==

docs/experimental/loaders.rst
==================
6a74b513;Daniel Grana;2009-08-13 23:23:08 -0300;remove dupes words in loaders doc, and unused import in example
--HG--
extra : rebase_source : ea7886725af7a54bd1031cb28f92efbdfe921d9e

==

docs/experimental/loaders.rst
==================
5494237c;Pablo Hoffman;2009-08-13 22:30:07 -0300;upgraded bundled beautifulsoup to 3.0.7a

==

scrapy/xlib/BeautifulSoup.py
==================
23d0c08c;Pablo Hoffman;2009-08-13 22:29:13 -0300;added missing module in previous commit

==

scrapy/utils/db.py
==================
d6f4e382;Pablo Hoffman;2009-08-13 22:14:55 -0300;moved scrapy.utils.db module to scrapy.utils.mysql
--HG--
rename : scrapy/utils/db.py => scrapy/utils/mysql.py

==

scrapy/utils/mysql.py
==================
8be62e25;Pablo Hoffman;2009-08-13 22:11:30 -0300;commented out line until we find a proper fix

==

scrapy/core/scraper.py
==================
d8722c8c;Pablo Hoffman;2009-08-13 22:09:19 -0300;cleaned up scrapy.utils.db module

==

scrapy/conf/default_settings.py
scrapy/utils/db.py
==================
bebc8b20;Pablo Hoffman;2009-08-13 21:50:41 -0300;removed obsolete scrapy.contrib.item module (RobustScrapedItem model)

==

scrapy/contrib/item/__init__.py
scrapy/contrib/item/adaptors.py
scrapy/contrib/item/models.py
scrapy/tests/test_robustscrapeditem.py
==================
16249814;Pablo Hoffman;2009-08-13 15:33:20 -0300;added tests for builtin loader processors

==

scrapy/tests/test_contrib_loader.py
==================
066fd9fa;Ismael Carnales;2009-08-13 13:32:02 -0300;renamed internal names of Item Loader

==

scrapy/contrib/loader/__init__.py
==================
ecca7f64;Ismael Carnales;2009-08-13 13:30:50 -0300;fixes to Item Loader doc

==

docs/experimental/loaders.rst
==================
8131d674;Pablo Hoffman;2009-08-13 09:24:41 -0300;fixed outdated documentation (refs #97)

==

docs/ref/settings.rst
==================
5d29c342;Pablo Hoffman;2009-08-12 21:53:34 -0300;converted scrapy.newitem package to module
--HG--
rename : scrapy/newitem/__init__.py => scrapy/newitem.py

==

scrapy/newitem.py
==================
f0aea4aa;Pablo Hoffman;2009-08-12 21:52:15 -0300;moved scrapy.newitem.exporters to scrapy.contrib.exporter
--HG--
rename : scrapy/newitem/exporters/__init__.py => scrapy/contrib/exporter/__init__.py
rename : scrapy/newitem/exporters/jsonexporter.py => scrapy/contrib/exporter/jsonexporter.py
rename : scrapy/tests/test_itemexporters.py => scrapy/tests/test_contrib_exporter.py

==

scrapy/contrib/exporter/__init__.py
scrapy/contrib/exporter/jsonexporter.py
scrapy/tests/test_contrib_exporter.py
==================
c99e572f;Pablo Hoffman;2009-08-12 21:51:29 -0300;changed some variable names to avoid confusion

==

scrapy/tests/test_contrib_loader.py
==================
5aeab5b2;Pablo Hoffman;2009-08-12 21:31:50 -0300;converted scrapy.item package to module
--HG--
rename : scrapy/item/models.py => scrapy/item.py

==

docs/intro/tutorial.rst
scrapy/command/commands/parse.py
scrapy/contrib/pipeline/__init__.py
scrapy/contrib/spiders/feed.py
scrapy/core/scraper.py
scrapy/item.py
scrapy/item/__init__.py
scrapy/newitem/__init__.py
scrapy/utils/display.py
==================
991afdf6;Pablo Hoffman;2009-08-12 19:23:04 -0300;some minor fixes to loaders doc

==

docs/experimental/loaders.rst
==================
6452e193;Pablo Hoffman;2009-08-12 19:09:02 -0300;removed obsolete adaptors code

==

scrapy/contrib_exp/adaptors/__init__.py
scrapy/contrib_exp/adaptors/date.py
scrapy/contrib_exp/adaptors/extraction.py
scrapy/contrib_exp/adaptors/markup.py
scrapy/contrib_exp/adaptors/misc.py
scrapy/contrib_exp/newitem/__init__.py
scrapy/contrib_exp/newitem/adaptors.py
scrapy/tests/test_adaptors.py
scrapy/tests/test_robustscrapeditem.py
==================
e6dd4d09;Pablo Hoffman;2009-08-12 18:43:08 -0300;renamed ApplyConcat processor to MapCompose

==

docs/experimental/loaders.rst
scrapy/contrib/loader/processor.py
scrapy/tests/test_contrib_loader.py
==================
4e74f324;Pablo Hoffman;2009-08-12 18:09:36 -0300;renamed Pipe processor to Compose and documented it

==

docs/experimental/loaders.rst
scrapy/contrib/loader/processor.py
scrapy/tests/test_contrib_loader.py
==================
958c3d99;Pablo Hoffman;2009-08-12 17:42:01 -0300;fixed some links to item loaders doc

==

docs/contents.rst
docs/experimental/index.rst
==================
d94b6335;Pablo Hoffman;2009-08-12 17:40:27 -0300;renamed ItemLoader method populate_item() to load_item()

==

docs/experimental/loaders.rst
scrapy/contrib/loader/__init__.py
scrapy/tests/test_contrib_loader.py
==================
77670a6b;Ismael Carnales;2009-08-12 17:23:53 -0300;added Pipe parser

==

scrapy/contrib/loader/processor.py
scrapy/tests/test_contrib_loader.py
==================
aace51f3;Pablo Hoffman;2009-08-12 17:37:43 -0300;merge with ismael branch

==
==================
cf566d62;Pablo Hoffman;2009-08-12 16:56:30 -0300;fixed bug with html meta refresh in multiple lines (thanks Molvo for the patch)

==

scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
1dc59288;Pablo Hoffman;2009-08-12 16:49:07 -0300;Moved Item Loader to its final location in scrapy.contrib.loader, and updated doc/tests
--HG--
rename : docs/experimental/itemparser.rst => docs/experimental/loaders.rst
rename : scrapy/contrib/itemparser/__init__.py => scrapy/contrib/loader/__init__.py
rename : scrapy/contrib/itemparser/common.py => scrapy/contrib/loader/common.py
rename : scrapy/contrib/itemparser/parsers.py => scrapy/contrib/loader/processor.py
rename : scrapy/tests/test_itemparser.py => scrapy/tests/test_contrib_loader.py

==

docs/experimental/itemparser.rst
docs/experimental/loaders.rst
scrapy/contrib/itemparser/common.py
scrapy/contrib/loader/__init__.py
scrapy/contrib/loader/common.py
scrapy/contrib/loader/processor.py
scrapy/tests/test_contrib_loader.py
==================
7cbbc3ff;Pablo Hoffman;2009-08-12 16:49:05 -0300;Renamed Loader to ItemParser (SEP-8 proposal). Documentation and unittests also updated.
--HG--
rename : docs/experimental/loaders.rst => docs/experimental/itemparser.rst
rename : scrapy/newitem/loader/__init__.py => scrapy/contrib/itemparser/__init__.py
rename : scrapy/newitem/loader/expanders.py => scrapy/contrib/itemparser/parsers.py
rename : scrapy/tests/test_itemloader.py => scrapy/tests/test_itemparser.py

==

docs/experimental/index.rst
docs/experimental/itemparser.rst
docs/experimental/loaders.rst
scrapy/contrib/itemparser/__init__.py
scrapy/contrib/itemparser/common.py
scrapy/contrib/itemparser/parsers.py
scrapy/newitem/loader/__init__.py
scrapy/newitem/loader/expanders.py
scrapy/newitem/loader/reducers.py
scrapy/tests/test_itemloader.py
scrapy/tests/test_itemparser.py
==================
d4aa72d2;Pablo Hoffman;2009-08-12 13:50:15 -0300;removed obsolete documentation about Robust Scraped Item and Adaptors

==

docs/topics/adaptors.rst
docs/topics/items.rst
==================
c83fb1c7;Ismael Carnales;2009-08-12 10:17:06 -0300;added newitem exporter tests and fixed exporter errors

==

scrapy/newitem/exporters/__init__.py
scrapy/tests/test_itemexporters.py
==================
bc4ec80d;Pablo Hoffman;2009-08-11 17:10:37 -0300;restored stats tests, and added some more for max_value/min_value attribute

==

scrapy/tests/test_stats.py
==================
a938e3c7;Pablo Hoffman;2009-08-11 16:59:30 -0300;merge with ismael repo

==
==================
4dbeaf75;Ismael Carnales;2009-08-11 16:55:15 -0300;updated item exporters to new version of item, added JSONItemExporter

==

scrapy/newitem/exporters/__init__.py
scrapy/newitem/exporters/jsonexporter.py
==================
e69311ef;Pablo Hoffman;2009-08-11 16:37:52 -0300;added missing text to new stats collector methods

==

docs/topics/stats.rst
==================
45cbe133;Daniel Grana;2009-08-11 16:30:04 -0300;fix typo in stats docs

==

docs/topics/stats.rst
==================
8f16e7f9;Daniel Grana;2009-08-11 16:23:23 -0300;remove `default` parameter from max_value/min_value stats methods, update docs, and add new methods to dummy collector

==

docs/topics/stats.rst
scrapy/core/scraper.py
scrapy/stats/collector/__init__.py
==================
9b620652;Daniel Grana;2009-08-11 15:54:22 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
02cb1e34;Daniel Grana;2009-08-11 15:47:26 -0300;colllect max itemproc_size and active_size in scraper per domain

==

scrapy/core/scraper.py
==================
cd8eed77;Daniel Grana;2009-08-11 15:46:44 -0300;stats collector gains two new methods to store values only if greater/lower than previous value

==

docs/topics/stats.rst
scrapy/stats/collector/__init__.py
==================
5fac9096;Ismael Carnales;2009-08-11 15:23:38 -0300;try to import json from python 2.6 or fallback to simplejson

==

scrapy/tests/test_serialization.py
scrapy/utils/serialization.py
==================
9a531b55;Daniel Grana;2009-08-11 15:11:31 -0300;remove compiled pys before running tests

==

bin/runtests.sh
==================
edb7150b;Daniel Grana;2009-08-11 12:39:05 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
743d3261;Daniel Grana;2009-08-11 12:39:02 -0300;returning None from process_response is not allowed, ignore the request using exception instead

==

scrapy/contrib/downloadermiddleware/redirect.py
scrapy/tests/test_downloadermiddleware_redirect.py
==================
36149980;Ismael Carnales;2009-08-11 09:23:45 -0300;fixed error in doc

==

docs/topics/spider-middleware.rst
==================
10a527da;Pablo Hoffman;2009-08-10 21:02:46 -0300;removed unused scrapy.contrib.codecs module

==

scrapy/contrib/codecs/__init__.py
scrapy/contrib/codecs/x_mac_roman.py
==================
7ac75979;Pablo Hoffman;2009-08-10 21:02:46 -0300;removed obsolete scrapy.contrib.cluster

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/cluster/__init__.py
scrapy/contrib/cluster/crawler/__init__.py
scrapy/contrib/cluster/crawler/manager.py
scrapy/contrib/cluster/hooks/__init__.py
scrapy/contrib/cluster/hooks/svn.py
scrapy/contrib/cluster/master/__init__.py
scrapy/contrib/cluster/master/manager.py
scrapy/contrib/cluster/master/web.py
scrapy/contrib/cluster/master/ws_api.txt
scrapy/contrib/cluster/tools/scrapy-cluster-ctl.py
scrapy/contrib/cluster/tools/test-worker.py
scrapy/contrib/cluster/worker/__init__.py
scrapy/contrib/cluster/worker/manager.py
scrapy/tests/test_engine.py
==================
a0e2086b;Pablo Hoffman;2009-08-10 21:02:46 -0300;moved deprecated scrapy.item.adaptors to scrapy.contrib.item, and added deprecation warning
--HG--
rename : scrapy/item/adaptors.py => scrapy/contrib/item/adaptors.py

==

scrapy/contrib/item/__init__.py
scrapy/contrib/item/adaptors.py
scrapy/contrib/item/models.py
scrapy/contrib_exp/adaptors/misc.py
scrapy/tests/test_adaptors.py
scrapy/tests/test_robustscrapeditem.py
==================
e9662216;Pablo Hoffman;2009-08-10 21:02:46 -0300;removed backwards compatibility support for importing link extractors from scrapy.link.extractors
--HG--
rename : scrapy/link/__init__.py => scrapy/link.py

==

scrapy/link.py
scrapy/link/extractors.py
==================
c0532712;Pablo Hoffman;2009-08-10 21:02:24 -0300;removed unnecesary response ResponseSoup extension, and replaced by a utils function with cache support

==

docs/ref/extensions.rst
docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/response/__init__.py
scrapy/contrib/response/soup.py
scrapy/tests/test_contrib_response_soup.py
scrapy/tests/test_utils_response.py
scrapy/utils/response.py
==================
d334c035;Pablo Hoffman;2009-08-10 20:52:43 -0300;removed unnecesary ResponseLibxml2 extension and moved libxml2 document caching functionality to Libxml2Document using weak references

==

docs/ref/extensions.rst
docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/tests/test_libxml2.py
scrapy/tests/test_xpath.py
scrapy/tests/test_xpath_extension.py
scrapy/utils/test.py
scrapy/xpath/document.py
scrapy/xpath/extension.py
scrapy/xpath/selector.py
==================
21f2bb67;Daniel Grana;2009-08-10 20:28:37 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
7078cdc3;Daniel Grana;2009-08-10 20:28:32 -0300;remove unmantained web server code

==

scrapy/contrib/web/__init__.py
scrapy/contrib/web/http.py
scrapy/contrib/web/json.py
scrapy/contrib/web/service.py
scrapy/contrib/web/site.py
==================
49bab477;Pablo Hoffman;2009-08-10 19:42:20 -0300;XPathSelector: added 're' argument to add_xpath method, exposed selector attribute

==

docs/experimental/loaders.rst
scrapy/newitem/loader/__init__.py
scrapy/tests/test_itemloader.py
==================
dfa4a484;Pablo Hoffman;2009-08-10 10:23:42 -0300;removed unused module: scrapy.xpath.types

==

scrapy/xpath/__init__.py
scrapy/xpath/types.py
==================
50fcc672;Pablo Hoffman;2009-08-10 10:13:30 -0300;improved reducers examples

==

docs/experimental/loaders.rst
==================
5be0cee5;Pablo Hoffman;2009-08-09 20:54:22 -0300;added TreeExpander example

==

docs/experimental/loaders.rst
scrapy/newitem/loader/expanders.py
scrapy/tests/test_itemloader.py
==================
38f82e39;Pablo Hoffman;2009-08-09 18:06:12 -0300;loaders doc: added information about expanders/reducers declaration precendece, and other minor improvements

==

docs/experimental/loaders.rst
docs/experimental/newitems.rst
==================
b296d416;Pablo Hoffman;2009-08-09 17:08:42 -0300;minor doc update for making it more windows-friendly

==

docs/intro/overview.rst
docs/topics/settings.rst
==================
80b96fc1;Pablo Hoffman;2009-08-08 16:07:10 -0300;minor changes to referer logging when crawling

==

scrapy/core/engine.py
==================
b8eb08f4;Pablo Hoffman;2009-08-08 15:29:50 -0300;additional cleanup to scrapy.xpath module

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/xpath/factories.py
scrapy/xpath/selector.py
==================
467dbef2;Pablo Hoffman;2009-08-08 15:12:40 -0300;fixed bug when no project module setting is defined

==

scrapy/command/cmdline.py
==================
91eea82e;Pablo Hoffman;2009-08-08 07:26:20 -0300;added XPathLoader for working with XPath Selectors more conveniently

==

docs/experimental/loaders.rst
docs/experimental/newitems.rst
docs/topics/items.rst
scrapy/newitem/loader/__init__.py
scrapy/tests/test_itemloader.py
==================
10cdc70f;Pablo Hoffman;2009-08-08 06:03:46 -0300;some cleanup to scrapy.xpath module
--HG--
rename : scrapy/xpath/constructors.py => scrapy/xpath/factories.py

==

scrapy/xpath/document.py
scrapy/xpath/extension.py
scrapy/xpath/factories.py
scrapy/xpath/selector.py
==================
661aeb5c;Pablo Hoffman;2009-08-08 05:01:18 -0300;moved ItemPipelineManager from scrapy.item.pipeline to scrapy.contrib.pipeline

==

scrapy/conf/default_settings.py
scrapy/contrib/pipeline/__init__.py
scrapy/item/pipeline.py
==================
174ef14d;Pablo Hoffman;2009-08-08 04:57:18 -0300;some cleanup to item pipeline code

==

scrapy/item/pipeline.py
==================
a67dc6c7;Pablo Hoffman;2009-08-08 04:42:14 -0300;removed unused module

==

scrapy/conf/commands/test.py
==================
5786bbd2;Pablo Hoffman;2009-08-08 04:29:54 -0300;cleaned up scrapy.command.cmdline module

==

scrapy/command/cmdline.py
==================
6b20f1f7;Pablo Hoffman;2009-08-08 04:02:49 -0300;added "Global Options" group to command line options, improved help display, splitted --profile option in --profile + --lsprof

==

scrapy/command/cmdline.py
scrapy/command/models.py
==================
1339b182;Pablo Hoffman;2009-08-08 03:08:19 -0300;some changes to command line options: use 'resolve' conflict_handler, improved option help messages, removed -f option, changed -o option to -L, removed redundant --nolog option

==

scrapy/command/cmdline.py
scrapy/command/models.py
==================
417f0a3a;Daniel Grana;2009-08-07 21:29:19 -0300;remove stat of warning level notification not reached

==

scrapy/contrib/memusage.py
==================
3901e06f;Daniel Grana;2009-08-07 21:24:41 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
9aaf010a;Daniel Grana;2009-08-07 21:24:36 -0300;add stats of memory usage

==

scrapy/contrib/memusage.py
==================
14148b6e;Pablo Hoffman;2009-08-07 14:45:28 -0300;fixed unittest codes broken in previous commit

==

scrapy/tests/test_itemloader.py
==================
db90e26a;Pablo Hoffman;2009-08-07 14:39:30 -0300;renamed ItemLoader class to Loader

==

docs/experimental/loaders.rst
scrapy/newitem/loader/__init__.py
scrapy/tests/test_itemloader.py
==================
e585c6ca;Pablo Hoffman;2009-08-07 14:28:58 -0300;relocated experimental newitems/loaders doc, and added example for extending fields metadata
--HG--
rename : docs/experimental/newitem-loader.rst => docs/experimental/loaders.rst
rename : docs/experimental/newitem.rst => docs/experimental/newitems.rst

==

docs/experimental/index.rst
docs/experimental/loaders.rst
docs/experimental/newitems.rst
==================
d95e99f5;Pablo Hoffman;2009-08-07 03:50:09 -0300;Added documentation for Items and Loaders, removed obsolete Item Adaptors documentation
--HG--
rename : docs/experimental/topics/newitem/index.rst => docs/experimental/newitem.rst

==

docs/experimental/index.rst
docs/experimental/newitem-loader.rst
docs/experimental/newitem.rst
docs/experimental/ref/index.rst
docs/experimental/ref/newitem/fields.rst
docs/experimental/ref/newitem/index.rst
docs/experimental/topics/index.rst
docs/experimental/topics/newitem/adaptors.rst
docs/experimental/topics/newitem/index.rst
docs/faq.rst
docs/topics/items.rst
==================
efa08318;Pablo Hoffman;2009-08-07 03:48:42 -0300;renamed JoinStrings reducer to Join, accept item as first positional argument in ItemLoader constructor, removed expanders and reducers docstrings (will be moved to documentation)

==

scrapy/newitem/loader/__init__.py
scrapy/newitem/loader/expanders.py
scrapy/newitem/loader/reducers.py
scrapy/tests/test_itemloader.py
==================
3658acd9;Pablo Hoffman;2009-08-06 21:29:40 -0300;newitem: reverting to use 'default' Field key instead of 'default_factory'

==

scrapy/newitem/__init__.py
scrapy/tests/test_newitem.py
==================
78b69ec9;Pablo Hoffman;2009-08-06 14:35:52 -0300;merge

==
==================
d142489b;Pablo Hoffman;2009-08-06 14:35:24 -0300;remove_entities: added test for encoding argument

==

scrapy/tests/test_utils_markup.py
==================
f2c2609e;Pablo Hoffman;2009-08-06 14:31:59 -0300;remove_entities: added support for common browser hack for numeric character references in the 80-9F range

==

scrapy/tests/test_utils_markup.py
scrapy/utils/markup.py
==================
c3f7bfea;Pablo Hoffman;2009-08-06 14:26:38 -0300;remove_entities: added encoding argument, and removed some empty lines

==

scrapy/utils/markup.py
==================
82dc2096;Daniel Grana;2009-08-06 12:28:49 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
6ef991b7;Daniel Grana;2009-08-06 12:07:22 -0300;normalize times used for stats to UTC

==

scrapy/core/engine.py
scrapy/stats/collector/mysql.py
scrapy/stats/collector/simpledb.py
scrapy/stats/corestats.py
==================
80db8abe;Pablo Hoffman;2009-08-06 11:56:32 -0300;use time.time() instead of datetime in SpiderProfiler extensions, which is faster and simpler

==

scrapy/contrib/spider/profiler.py
==================
de48406f;Pablo Hoffman;2009-08-06 11:37:20 -0300;added 3 common content-types (for feeds) to ResponseTypes class

==

scrapy/core/downloader/responsetypes/__init__.py
==================
a23ff370;Pablo Hoffman;2009-08-05 11:38:01 -0300;ItemLoader: added one more test and improved other test names

==

scrapy/newitem/loader/__init__.py
scrapy/tests/test_itemloader.py
==================
7bc7af01;Pablo Hoffman;2009-08-05 00:41:02 -0300;ItemLoader: some more code cleanups, and added many more tests

==

scrapy/newitem/__init__.py
scrapy/newitem/loader/__init__.py
scrapy/newitem/loader/expanders.py
scrapy/newitem/loader/reducers.py
scrapy/tests/test_itemloader.py
==================
9081e84e;Pablo Hoffman;2009-08-04 20:02:49 -0300;ItemLoader: sorted out module locations, and added more tests
--HG--
rename : scrapy/newitem/reducers.py => scrapy/newitem/loader/reducers.py

==

scrapy/newitem/loader/__init__.py
scrapy/newitem/loader/expanders.py
scrapy/newitem/loader/reducers.py
scrapy/tests/test_itemloader.py
==================
ac9f4c9c;Pablo Hoffman;2009-08-04 19:26:31 -0300;Refatored scrapy.newitem package:
- left only one type of Field - just a dict wrapper to contain field metadata
- removed Item Builder and tests
- adapted Item Loader to work with new Field class

==

scrapy/newitem/__init__.py
scrapy/newitem/builder/__init__.py
scrapy/newitem/fields.py
scrapy/newitem/loader/__init__.py
scrapy/newitem/models.py
scrapy/newitem/reducers.py
scrapy/tests/test_itemadaptor.py
scrapy/tests/test_itembuilder.py
scrapy/tests/test_itemloader.py
scrapy/tests/test_newitem.py
==================
114dba28;Pablo Hoffman;2009-08-04 09:10:21 -0300;some minor simplifications to tree_expander() function

==

scrapy/newitem/loader/__init__.py
==================
8d705ec3;Pablo Hoffman;2009-08-03 22:53:08 -0300;added ItemLoader class, an alternative implementation of ItemBuilder with a slightly different API

==

scrapy/newitem/loader/__init__.py
scrapy/tests/test_itemloader.py
scrapy/utils/datatypes.py
==================
f05695d7;Ismael Carnales;2009-08-03 17:27:57 -0300;added first implementation of ItemBuilder

==

scrapy/newitem/builder/__init__.py
scrapy/newitem/builder/reducers.py
scrapy/tests/test_itembuilder.py
==================
32894643;Ismael Carnales;2009-08-03 15:00:04 -0300;added ListField documentation, ordered field reference alphabetically

==

docs/experimental/ref/newitem/fields.rst
==================
cf638e68;Ismael Carnales;2009-08-03 15:00:02 -0300;made ListField init with an instance (not a class) of Field

==

scrapy/newitem/fields.py
scrapy/tests/test_itemadaptor.py
scrapy/tests/test_newitem.py
==================
d8b85ae7;Ismael Carnales;2009-08-02 18:43:35 -0300;moved MultiValuedField to ListField

==

scrapy/newitem/fields.py
scrapy/tests/test_itemadaptor.py
scrapy/tests/test_newitem.py
==================
fcb33c79;Pablo Hoffman;2009-07-31 17:24:30 -0300;removed obsolete pipeline

==

scrapy/contrib/pipeline/show.py
==================
7c049d2e;Pablo Hoffman;2009-07-31 16:51:29 -0300;use standard 'mcs' for first argument of meta class __new__ method

==

scrapy/newitem/models.py
==================
02c454c2;Pablo Hoffman;2009-07-31 16:49:27 -0300;newitem: added warning when trying to access item field value via getattr instead of getitem

==

scrapy/newitem/models.py
==================
c3427e07;Pablo Hoffman;2009-07-31 16:36:35 -0300;added domain_stats parameter to stats_domain_closed signal

==

docs/topics/stats.rst
scrapy/contrib/statsmailer.py
scrapy/stats/collector/__init__.py
==================
73172b24;Pablo Hoffman;2009-07-30 16:58:24 -0300;added from_unicode_list() method to Field objects

==

docs/experimental/ref/newitem/fields.rst
scrapy/newitem/fields.py
scrapy/tests/test_itemadaptor.py
scrapy/tests/test_newitem.py
==================
c0dcd764;Pablo Hoffman;2009-07-30 13:51:43 -0300;moved unused scrapy.core.scheduler.store module to scrapy.contrib_exp.history
--HG--
rename : scrapy/core/scheduler/store.py => scrapy/contrib_exp/history/memorystore.py
rename : scrapy/contrib_exp/history/store.py => scrapy/contrib_exp/history/sqlstore.py

==

scrapy/conf/default_settings.py
scrapy/contrib_exp/history/memorystore.py
scrapy/contrib_exp/history/middleware.py
scrapy/contrib_exp/history/sqlstore.py
scrapy/core/scheduler/__init__.py
==================
8ecd16b5;Daniel Grana;2009-07-29 21:02:15 -0300;remove obsolete monkey patch for twisted 2.5

==

scrapy/xlib/patches.py
==================
b336de73;Pablo Hoffman;2009-07-29 19:50:38 -0300;fixed minor bugs with spiderctl webconsole extension

==

scrapy/contrib/webconsole/spiderctl.py
==================
4a1fc74d;Pablo Hoffman;2009-07-29 19:26:12 -0300;fixed spiderstats webconsole extension

==

scrapy/contrib/webconsole/livestats.py
==================
01b79e38;Pablo Hoffman;2009-07-29 19:15:19 -0300;fixed StatsCollector webconsole extension

==

scrapy/contrib/webconsole/stats.py
==================
a86b12a8;Pablo Hoffman;2009-07-29 19:01:36 -0300;moved patches.py to xlib/patches.py to avoid import errors
--HG--
rename : scrapy/patches.py => scrapy/xlib/patches.py

==

scrapy/__init__.py
scrapy/xlib/patches.py
==================
8ec7c9e0;Pablo Hoffman;2009-07-29 18:59:34 -0300;WEBCONSOLE_PORT setting now defaults to 6080

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
==================
fde4f219;Pablo Hoffman;2009-07-29 18:41:15 -0300;don't use packages when modules are enough
--HG--
rename : scrapy/extension/__init__.py => scrapy/extension.py
rename : scrapy/fetcher/__init__.py => scrapy/fetcher.py
rename : scrapy/log/__init__.py => scrapy/log.py
rename : scrapy/mail/__init__.py => scrapy/mail.py
rename : scrapy/patches/monkeypatches.py => scrapy/patches.py

==

scrapy/__init__.py
scrapy/extension.py
scrapy/fetcher.py
scrapy/log.py
scrapy/mail.py
scrapy/patches.py
scrapy/patches/__init__.py
==================
230bcef7;Pablo Hoffman;2009-07-29 18:26:29 -0300;some refactor of settings manager (without changing API): don't fail if no settings module is found (fail on scrapy.cmdline instead). also, some code improvements for clarity.

==

scrapy/command/cmdline.py
scrapy/conf/__init__.py
==================
d57c0100;Pablo Hoffman;2009-07-29 08:23:38 -0300;another minor fix to exporters

==

scrapy/newitem/exporters.py
==================
c3d732f2;Pablo Hoffman;2009-07-28 23:00:35 -0300;another bug fix in pprint item exporter

==

scrapy/newitem/exporters.py
==================
643f9372;Pablo Hoffman;2009-07-28 20:53:03 -0300;removed wrong self from base constructor calls

==

scrapy/newitem/exporters.py
==================
bb7b6815;Pablo Hoffman;2009-07-28 20:20:44 -0300;added Item Exporters

==

scrapy/newitem/exporters.py
scrapy/newitem/fields.py
==================
75cf903e;Pablo Hoffman;2009-07-28 12:27:25 -0300;adapted project template to use the new Link Extractors location

==

scrapy/templates/project/module/templates/spider_crawl.tmpl
==================
64d91555;Pablo Hoffman;2009-07-28 12:23:13 -0300;CloseDomain extension: fixed bug on domain close when not using CLOSEDOMAIN_TIMEOUT

==

scrapy/contrib/closedomain.py
==================
fcc91901;Pablo Hoffman;2009-07-27 15:42:35 -0300;finished cleaning up closedomain documentation, and updated default settings

==

docs/ref/extensions.rst
docs/ref/settings.rst
scrapy/conf/default_settings.py
==================
09ba6927;Pablo Hoffman;2009-07-27 15:23:50 -0300;Some changes to CloseDomain extension:
- added support for closing by item passed count (CLOSEDOMAIN_ITEMPASSED)
- removed support for sending notification emails (since that's the job of
  another extension)

==

docs/ref/extensions.rst
scrapy/contrib/closedomain.py
==================
9da66698;Pablo Hoffman;2009-07-25 18:56:12 -0300;moved httprepr() method (from Request and Response objects) to scrapy.utils functions

==

docs/ref/request-response.rst
scrapy/contrib/downloadermiddleware/stats.py
scrapy/contrib/itemsampler.py
scrapy/http/request/__init__.py
scrapy/http/response/__init__.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
scrapy/tests/test_utils_request.py
scrapy/tests/test_utils_response.py
scrapy/utils/request.py
scrapy/utils/response.py
==================
bed3c380;Daniel Grana;2009-07-25 15:22:15 -0300;fix delayedclosedomain extension bug due to changing lastseen from datetime to time.time

==

scrapy/contrib/delayedclosedomain.py
==================
fdcdc307;Daniel Grana;2009-07-25 15:21:22 -0300;ignore docs/build

==

.hgignore
==================
c615ace6;Pablo Hoffman;2009-07-24 13:14:36 -0300;doc: updated google directory links in firebug guide

==

docs/topics/firebug.rst
==================
96c3cdbe;Daniel Grana;2009-07-24 12:59:38 -0300;improve OffsiteMiddleware reference docs
--HG--
extra : rebase_source : 3ed3f23fc1ec63b521ead029c5749898f3ab05d7

==

docs/ref/spider-middleware.rst
==================
d21a22ea;Pablo Hoffman;2009-07-23 13:03:25 -0300;fixed stats collector bug which wasn't throwing the stats_domain_closing signal (on subclasses) before the persisting stage

==

scrapy/stats/collector/__init__.py
==================
38c3f7d0;Pablo Hoffman;2009-07-23 11:49:48 -0300;Some changes to logging of scraped items:
1. "Scraped Item" log level changed to DEBUG
2. "Dropped Item" log level changed to WARNING
3. added "Passed Item" log message with INFO level

==

docs/intro/tutorial.rst
scrapy/core/scraper.py
==================
e43e28bf;Pablo Hoffman;2009-07-23 09:12:49 -0300;minimal doc improvement

==

docs/intro/tutorial.rst
==================
6d24ae59;Ismael Carnales;2009-07-23 09:05:14 -0300;added reference to working with relative xpaths in the tutorial

==

docs/intro/tutorial.rst
docs/topics/selectors.rst
==================
9baa6bb2;Pablo Hoffman;2009-07-23 01:56:56 -0300;minor selectors doc fix

==

docs/topics/selectors.rst
==================
6eb2609d;Ismael Carnales;2009-07-22 15:34:56 -0300;removed old serializators from newitem

==

scrapy/newitem/serialization.py
==================
3c4afb23;Ismael Carnales;2009-07-22 15:13:36 -0300;moved newitem from scrapy.contrib_exp to scrapy.newitem

==

docs/experimental/ref/newitem/fields.rst
docs/experimental/topics/newitem/index.rst
scrapy/contrib_exp/newitem/__init__.py
scrapy/newitem/__init__.py
scrapy/newitem/fields.py
scrapy/newitem/models.py
scrapy/newitem/serialization.py
scrapy/tests/test_itemadaptor.py
scrapy/tests/test_newitem.py
==================
eb3a1dc1;Ismael Carnales;2009-07-22 15:13:33 -0300;return default values for newitem in __getitem__

==

scrapy/contrib_exp/newitem/models.py
==================
202894dd;Ismael Carnales;2009-07-22 10:25:22 -0300;fixes to newitem doc

==

docs/experimental/topics/newitem/index.rst
==================
7d8ba054;Pablo Hoffman;2009-07-21 17:38:46 -0300;fixed typo in doc

==

docs/ref/scheduler-middleware.rst
==================
aa345e11;Pablo Hoffman;2009-07-21 17:19:19 -0300;Added spider middleware documentation

==

docs/ref/index.rst
docs/ref/settings.rst
docs/ref/spider-middleware.rst
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/httperror.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/requestlimit.py
scrapy/contrib/spidermiddleware/restrict.py
scrapy/contrib/spidermiddleware/urlfilter.py
scrapy/contrib/spidermiddleware/urllength.py
==================
90f1d9e4;Ismael Carnales;2009-07-21 16:52:27 -0300;Added Scheduler middleware reference documentation

==

docs/ref/index.rst
docs/ref/scheduler-middleware.rst
scrapy/contrib/schedulermiddleware/duplicatesfilter.py
==================
7afc9157;Ismael Carnales;2009-07-21 16:11:21 -0300;added BaseItem as base item class, and moved extra functionality of ScrapedItem to RobustScrapedItem

==

scrapy/command/commands/parse.py
scrapy/contrib/item/models.py
scrapy/contrib/spiders/crawl.py
scrapy/contrib/spiders/feed.py
scrapy/contrib/web/service.py
scrapy/contrib_exp/newitem/models.py
scrapy/core/scraper.py
scrapy/item/__init__.py
scrapy/item/models.py
scrapy/item/pipeline.py
scrapy/utils/display.py
==================
00d9ce66;Ismael Carnales;2009-07-21 12:22:49 -0300;fixes to newitem doc

==

docs/experimental/topics/newitem/index.rst
==================
894a5d81;Ismael Carnales;2009-07-21 12:20:49 -0300;changed the newitem API to a dict-like interface

==

docs/experimental/topics/newitem/index.rst
scrapy/contrib_exp/newitem/adaptors.py
scrapy/contrib_exp/newitem/models.py
scrapy/tests/test_itemadaptor.py
scrapy/tests/test_newitem.py
==================
6fcbd03b;Pablo Hoffman;2009-07-21 11:48:31 -0300;removed obsolete code

==

examples/experimental/googledir/googledir/__init__.py
examples/experimental/googledir/googledir/items.py
examples/experimental/googledir/googledir/pipelines.py
examples/experimental/googledir/googledir/settings.py
examples/experimental/googledir/googledir/spiders/__init__.py
examples/experimental/googledir/googledir/spiders/google_directory.py
examples/experimental/googledir/googledir/templates/spider_basic.tmpl
examples/experimental/googledir/googledir/templates/spider_crawl.tmpl
examples/experimental/googledir/googledir/templates/spider_csvfeed.tmpl
examples/experimental/googledir/googledir/templates/spider_xmlfeed.tmpl
examples/experimental/googledir/scrapy-ctl.py
==================
4a10e1da;Pablo Hoffman;2009-07-21 11:31:14 -0300;some cleanup to genspider command, disabled log and fixed inconsistencies reported in #55

==

scrapy/command/commands/genspider.py
scrapy/conf/commands/genspider.py
==================
29c92fe8;Pablo Hoffman;2009-07-21 01:42:44 -0300;applied patch contributed by Manuel Aristaran for adding non-standard port support to mysql uri parsing in mysql_connect. closes #82

==

scrapy/utils/db.py
==================
9867e7b2;Pablo Hoffman;2009-07-21 01:11:48 -0300;removed references to obsolete ENABLED_SPIDERS_FILE setting

==

docs/ref/settings.rst
examples/experimental/googledir/googledir/settings.py
scrapy/conf/default_settings.py
==================
b9e3f72b;Pablo Hoffman;2009-07-20 11:44:12 -0300;Fixed encoding bug in tricky Response cloning case (reported in #90) and added unittests.

==

scrapy/http/response/text.py
scrapy/tests/test_http_response.py
==================
cc33ac4f;Ismael Carnales;2009-07-16 13:00:25 -0300;moved item.fields to item._fields in newitem

==

scrapy/contrib_exp/newitem/adaptors.py
scrapy/contrib_exp/newitem/models.py
==================
92b746d8;Pablo Hoffman;2009-07-17 12:49:53 -0300;SimpledbStatsCollector: moved domain creation to constructor

==

docs/topics/stats.rst
scrapy/stats/collector/simpledb.py
==================
97a854a5;Pablo Hoffman;2009-07-17 08:57:45 -0300;some cleanup to googledir example project

==

examples/googledir/googledir/items.py
examples/googledir/googledir/pipelines.py
examples/googledir/googledir/settings.py
examples/googledir/googledir/spiders/google_directory.py
==================
292757f3;Pablo Hoffman;2009-07-16 19:15:19 -0300;added link to architecture overview and fixed old link

==

docs/topics/architecture.rst
==================
136014d7;Pablo Hoffman;2009-07-16 17:29:29 -0300;Added section about relative xpaths to XPathSelectors doc

==

docs/topics/selectors.rst
==================
0fd603e2;Pablo Hoffman;2009-07-16 11:16:46 -0300;Automated merge with http://hg.scrapy.org/users/ismael/scrapy-newitem/

==
==================
c2f12327;Pablo Hoffman;2009-07-16 10:48:10 -0300;added dumping of global scrapy stats at engine shutdown

==

docs/ref/settings.rst
scrapy/stats/collector/__init__.py
==================
a9069e8e;Ismael Carnales;2009-07-16 09:58:44 -0300;reorganized experimental doc in topics and ref, slitted long documents, introduced minor changes

==

docs/experimental/index.rst
docs/experimental/ref/index.rst
docs/experimental/ref/newitem/fields.rst
docs/experimental/ref/newitem/index.rst
docs/experimental/topics/index.rst
docs/experimental/topics/newitem/adaptors.rst
docs/experimental/topics/newitem/index.rst
docs/topics/items.rst
==================
a4a1c4b1;Pablo Hoffman;2009-07-16 09:46:30 -0300;fixed and improved formatting of StatsMailer extension

==

scrapy/contrib/statsmailer.py
==================
9006d1f0;Daniel Grana;2009-07-16 01:34:51 -0300;remove already deleted webconsole extension from default settings

==

scrapy/conf/default_settings.py
==================
7deb9d9b;Pablo Hoffman;2009-07-15 22:18:19 -0300;removed unused scrapy.utils.datatypes.Sitemap class

==

scrapy/utils/datatypes.py
==================
6648b5da;Pablo Hoffman;2009-07-15 22:15:11 -0300;updated logging of report in memdebug extension

==

scrapy/contrib/memdebug.py
==================
11258259;Pablo Hoffman;2009-07-15 22:10:00 -0300;doc: minor updates to tutorial

==

docs/intro/tutorial.rst
==================
db6afcf3;Pablo Hoffman;2009-07-15 22:09:26 -0300;updated scrapy command line help

==

scrapy/command/cmdline.py
==================
5faf725c;Pablo Hoffman;2009-07-15 22:05:20 -0300;updated parse command help

==

scrapy/command/commands/parse.py
==================
9a800b5a;Pablo Hoffman;2009-07-15 21:55:39 -0300;removed obsolete log command

==

scrapy/command/commands/log.py
==================
fc2c6f99;Pablo Hoffman;2009-07-15 21:34:56 -0300;updated help of some commands

==

scrapy/command/commands/crawl.py
scrapy/command/commands/genspider.py
scrapy/command/commands/list.py
scrapy/command/commands/start.py
==================
fd4aed7d;Pablo Hoffman;2009-07-15 21:34:12 -0300;renamed download command to fetch
--HG--
rename : scrapy/command/commands/download.py => scrapy/command/commands/fetch.py

==

scrapy/command/commands/fetch.py
==================
a24516ed;Pablo Hoffman;2009-07-15 21:18:58 -0300;updated list command to show only spider domain names

==

scrapy/command/commands/list.py
==================
55823056;Pablo Hoffman;2009-07-15 21:02:51 -0300;renamed old STATS_DEBUG setting to STATS_DUMP

==

docs/ref/settings.rst
docs/topics/stats.rst
scrapy/conf/default_settings.py
scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/stats/collector/__init__.py
==================
996fdb7e;Ismael Carnales;2009-07-15 09:31:16 -0300;applied tn patch: check for project_name in scrapy-admin to be a valid module name, closes #92

==

bin/scrapy-admin.py
==================
7f281cf2;Pablo Hoffman;2009-07-15 01:40:44 -0300;some minor updates to doc

==

docs/experimental/newitem.rst
docs/ref/index.rst
docs/topics/stats.rst
==================
07235346;Pablo Hoffman;2009-07-15 01:25:50 -0300;removed obsolete settings

==

scrapy/conf/default_settings.py
==================
8480f49c;Pablo Hoffman;2009-07-15 00:30:40 -0300;Complete stats refactoring and documentation
--HG--
rename : scrapy/stats/statscollector.py => scrapy/stats/collector/__init__.py

==

docs/ref/settings.rst
docs/topics/stats.rst
scrapy/command/commands/stats.py
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/stats.py
scrapy/contrib/itemsampler.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/spider/profiler.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/web/stats.py
scrapy/contrib/webconsole/spiderstats.py
scrapy/core/scraper.py
scrapy/stats/__init__.py
scrapy/stats/collector/__init__.py
scrapy/stats/collector/mysql.py
scrapy/stats/collector/simpledb.py
scrapy/stats/corestats.py
scrapy/stats/signals.py
scrapy/stats/statscollector.py
scrapy/store/__init__.py
scrapy/store/db.py
scrapy/tests/test_stats.py
scrapy/tests/test_storedb.py
scrapy/utils/misc.py
==================
0227c53b;Ismael Carnales;2009-07-14 15:55:52 -0300;reorganize newitem documentation

==

docs/experimental/index.rst
docs/experimental/newitem-adaptors.rst
docs/experimental/newitem-fields.rst
docs/experimental/newitem.rst
==================
16789466;Pablo Hoffman;2009-07-14 12:41:25 -0300;some improvement to Libxml2Document cleanup: avoid noisy errors, and make sure both cleaning up functions are called

==

scrapy/xpath/document.py
==================
7b149d82;Daniel Grana;2009-07-14 11:45:58 -0300;Automated merge with http://hg.scrapy.org/users/ismael/scrapy-newitem

==
==================
d59facd6;Ismael Carnales;2009-07-14 10:23:27 -0300;fix item adaptor tests

==

scrapy/tests/test_itemadaptor.py
==================
129b6e02;Pablo Hoffman;2009-07-14 10:08:55 -0300;some code cleanup to newitem.adaptors module which don't affect any functionality

==

scrapy/contrib_exp/newitem/adaptors.py
==================
ac21b42f;Ismael Carnales;2009-07-14 09:57:46 -0300;better assertRaises in newitem tests

==

scrapy/tests/test_newitem.py
==================
a6e822a8;Ismael Carnales;2009-07-14 09:36:33 -0300;use assertEqual instead of assert in newitem tests

==

scrapy/tests/test_newitem.py
==================
c0d8b121;Pablo Hoffman;2009-07-14 09:15:29 -0300;TextField: fixed type error bug with empty lists

==

scrapy/contrib_exp/newitem/fields.py
scrapy/tests/test_newitem.py
==================
7fb88934;Pablo Hoffman;2009-07-14 08:46:15 -0300;fixed link to experimental doc

==

docs/_templates/index.html
==================
f1dc4e4a;Pablo Hoffman;2009-07-14 08:39:38 -0300;corrected TextField examples

==

docs/experimental/newitem-fields.rst
==================
bffcd453;Daniel Grana;2009-07-14 02:29:59 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
95a0b1c6;Daniel Grana;2009-07-14 02:29:43 -0300;split next_request method to allow calling it even when backout is needed

==

scrapy/core/engine.py
==================
ae82f8c7;Pablo Hoffman;2009-07-13 22:19:25 -0300;made BaseField.to_python() raise NotImplementedError (already documented) and adapted unittest

==

scrapy/contrib_exp/newitem/fields.py
scrapy/tests/test_newitem.py
==================
a8aae41a;Pablo Hoffman;2009-07-13 22:16:43 -0300;removed unused files

==

docs/experimental/_images/scrapy_architecture.odg
docs/experimental/_images/scrapy_architecture.png
==================
5c39d173;Pablo Hoffman;2009-07-13 22:15:54 -0300;merged proposed and experimental documentation, as it didn't make sense to keep two separate sections
--HG--
rename : docs/proposed/_images/scrapy_architecture.odg => docs/experimental/_images/scrapy_architecture.odg
rename : docs/proposed/_images/scrapy_architecture.png => docs/experimental/_images/scrapy_architecture.png
rename : docs/proposed/index.rst => docs/experimental/index.rst
rename : docs/proposed/newitem-fields.rst => docs/experimental/newitem-fields.rst
rename : docs/proposed/newitem.rst => docs/experimental/newitem.rst

==

docs/_templates/index.html
docs/contents.rst
docs/experimental.rst
docs/experimental/_images/scrapy_architecture.odg
docs/experimental/_images/scrapy_architecture.png
docs/experimental/index.rst
docs/experimental/newitem-fields.rst
docs/experimental/newitem.rst
docs/proposed/index.rst
==================
26bb8ef6;Pablo Hoffman;2009-07-13 22:05:48 -0300;doc: improved newitem fields reference

==

docs/proposed/newitem-fields.rst
==================
2bf39b7c;Pablo Hoffman;2009-07-13 22:05:18 -0300;minor layout cleanups to newitem doc

==

docs/proposed/newitem.rst
==================
74fcfc2c;Pablo Hoffman;2009-07-13 22:03:56 -0300;deprecated old adaptors documentation

==

docs/topics/adaptors.rst
==================
c73ff819;Pablo Hoffman;2009-07-13 21:10:29 -0300;newitem fields: dropped support in to_python() for converting from None for default value, improved raising of TypeError instead of ValueError when appropiate, added and adapted unittests

==

scrapy/contrib_exp/newitem/fields.py
scrapy/tests/test_newitem.py
==================
72457c3e;Ismael Carnales;2009-07-13 17:03:38 -0300;better handling of default value in newitem

==

scrapy/contrib_exp/newitem/fields.py
scrapy/contrib_exp/newitem/models.py
scrapy/tests/test_newitem.py
==================
47d937f3;Ismael Carnales;2009-07-13 15:54:48 -0300;only accept unicode strings in text fields

==

docs/proposed/newitem-fields.rst
docs/proposed/newitem.rst
scrapy/contrib_exp/newitem/fields.py
scrapy/tests/test_newitem.py
==================
d75afaa1;Ismael Carnales;2009-07-13 15:54:46 -0300;renamed StringField to TextField

==

docs/proposed/newitem-fields.rst
docs/proposed/newitem.rst
scrapy/contrib_exp/newitem/fields.py
scrapy/tests/test_newitem.py
==================
8634a0d1;Pablo Hoffman;2009-07-13 14:00:41 -0300;more efficient Item implementation and added support for using custom methods (unittests included)

==

scrapy/contrib_exp/newitem/models.py
scrapy/tests/test_newitem.py
==================
dff51038;Pablo Hoffman;2009-07-13 13:33:47 -0300;doc: updated SCHEDULER_MIDDLEWARES_BASE setting

==

docs/ref/settings.rst
==================
b44409a2;Ismael Carnales;2009-07-13 10:31:32 -0300;added TimeField to newitem

==

docs/proposed/newitem-fields.rst
scrapy/contrib_exp/newitem/fields.py
scrapy/tests/test_newitem.py
==================
5eebe1f4;Pablo Hoffman;2009-07-13 00:04:00 -0300;fixed bug in fetcher caused by recent spider manager changes (thanks andres)

==

scrapy/fetcher/__init__.py
==================
e3fe0ef2;Pablo Hoffman;2009-07-11 22:19:56 -0300;Some changes to newitem API and implementation:
- Dropped support for wildcard importing from newitem package (must now import
  from newitem.fields and don't use wildcard)
- Removed assign() method from Fields as it was apparently redundant (with
  to_python() method) and I couldn't find any reason for keeping it (neither in
  the docs nor in the tests)
- Moved deiter() method of Field to StringField, as its both its purpose and
  implementation was specific for strings. if it's really needed as a general
  purpose method, it could be restored. Also, no unittest was broken because of
  this change, which sort-of reinforces my point.
- Renamed (previously mentioned) StringField.deiter() method to
  StringField.to_single(), for better consistency with to_python() method
- Removed Field class as it was useless without the deiter() functionality (now
  belonging to StringField class)
- Moved ansi_date_re module variable to DateField class attribute
- Simplified implementation of DecimalField, FloatField and IntegerField to one
  line of code (using tests to make sure not to break any functionality)
- Renamed ItemMeta class (in models.py) to _ItemMeta to highlight its protected
  state (should not be externally imported)
- Added support for instantiating new items with dicts, to support
  deserializing items with their repr() string
- Added unittests for new functionality introduced

==

scrapy/contrib_exp/newitem/__init__.py
scrapy/contrib_exp/newitem/fields.py
scrapy/contrib_exp/newitem/models.py
scrapy/tests/test_itemadaptor.py
scrapy/tests/test_newitem.py
==================
5054b67a;Pablo Hoffman;2009-07-11 21:26:52 -0300;improved newitems doc and marked robust scraped items as deprecated

==

docs/proposed/newitem-fields.rst
docs/proposed/newitem.rst
docs/topics/items.rst
==================
1a153d47;Pablo Hoffman;2009-07-11 17:19:20 -0300;improved invalid xpath exception message in xpath selectors, and added unittests

==

scrapy/tests/test_xpath.py
scrapy/xpath/selector.py
==================
fc64360a;Pablo Hoffman;2009-07-11 16:42:32 -0300;removed unused lines

==

scrapy/contrib/memdebug.py
==================
e3caf00d;Pablo Hoffman;2009-07-10 16:41:02 -0300;simplified implementation of spider manager by removing knowledge of enabled spiders

==

scrapy/contrib/cluster/master/web.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/core/manager.py
scrapy/spider/manager.py
==================
4cd1fa9c;dgrana;2009-07-10 05:29:27 +0100;generate dropin.cache for spiders under tests

==

setup.py
==================
92708108;Pablo Hoffman;2009-07-09 18:45:40 -0300;improved usage of urljoin_rfc function, adding unittests and encoding where needed

==

scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/linkextractors/htmlparser.py
scrapy/contrib/linkextractors/image.py
scrapy/contrib/linkextractors/lxmlparser.py
scrapy/contrib/linkextractors/regex.py
scrapy/contrib/linkextractors/sgml.py
scrapy/contrib_exp/adaptors/extraction.py
scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
d5d2c5c9;Daniel Grana;2009-07-09 17:13:30 -0300;update documentation to recent pydispatcher import path change

==

docs/topics/extensions.rst
docs/topics/item-pipeline.rst
docs/topics/webconsole.rst
==================
18fbd7c7;Daniel Grana;2009-07-09 16:58:07 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
eff8ea61;Daniel Grana;2009-07-09 16:57:03 -0300;remove response from item_passed and item_dropped signal api

==

docs/ref/signals.rst
scrapy/core/scraper.py
==================
5da32d9f;Pablo Hoffman;2009-07-09 16:50:13 -0300;fixed Sphinx warning

==

docs/proposed/newitem-fields.rst
==================
ae7333d5;Pablo Hoffman;2009-07-09 16:49:20 -0300;added simplejson optional dependency to doc

==

docs/intro/install.rst
==================
aba16c20;Daniel Grana;2009-07-09 14:38:56 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
a8de5cef;Daniel Grana;2009-07-09 14:37:59 -0300;remove xlib hack that appends scrapy/xlib to sys.path

==

scrapy/__init__.py
scrapy/command/cmdline.py
scrapy/contrib/closedomain.py
scrapy/contrib/cluster/master/manager.py
scrapy/contrib/cluster/master/web.py
scrapy/contrib/delayedclosedomain.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/itemsampler.py
scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/response/soup.py
scrapy/contrib/spider/profiler.py
scrapy/contrib/spider/reloader.py
scrapy/contrib/spidermiddleware/requestlimit.py
scrapy/contrib/statsmailer.py
scrapy/contrib/web/service.py
scrapy/contrib/webconsole/enginestatus.py
scrapy/contrib/webconsole/livestats.py
scrapy/contrib/webconsole/scheduler.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/contrib/webconsole/spiderstats.py
scrapy/contrib/webconsole/stats.py
scrapy/contrib_exp/history/middleware.py
scrapy/contrib_exp/pipeline/shoveitem.py
scrapy/core/downloader/dnscache.py
scrapy/core/engine.py
scrapy/core/signals.py
scrapy/http/request/form.py
scrapy/http/response/text.py
scrapy/log/__init__.py
scrapy/management/web.py
scrapy/stats/corestats.py
scrapy/stats/statscollector.py
scrapy/tests/test_contrib_response_soup.py
scrapy/tests/test_engine.py
scrapy/tests/test_spidermonkey.py
scrapy/xlib/ClientForm.py
scrapy/xlib/pydispatch/dispatcher.py
scrapy/xlib/pydispatch/robust.py
==================
32c25f5a;Ismael Carnales;2009-07-09 13:03:54 -0300;complete the newitem tests

==

scrapy/tests/test_newitem.py
==================
25b53df1;Ismael Carnales;2009-07-09 13:02:49 -0300;merge with trunk

==
==================
60e7b807;Pablo Hoffman;2009-07-09 12:57:10 -0300;removed signal docs from core.signals module, to leave them only in once place (the doc)

==

docs/ref/signals.rst
scrapy/core/scraper.py
scrapy/core/signals.py
==================
f31f75c0;Ismael Carnales;2009-07-09 12:54:02 -0300;remove required attribute from newitem (until we add a validation framework)

==

scrapy/contrib_exp/newitem/fields.py
==================
9e3e41f9;Ismael Carnales;2009-07-09 11:29:04 -0300;added more newitem documentation in proposed

==

docs/proposed/index.rst
docs/proposed/newitem-fields.rst
docs/proposed/newitem.rst
==================
b071681c;Pablo Hoffman;2009-07-09 11:14:33 -0300;removed duplicated spiders doc (which used autodoc)

==

docs/proposed/spiders.rst
==================
4f19115a;Pablo Hoffman;2009-07-09 10:56:15 -0300;removed old setting from default_settings.py, updated doc of CONCURRENT_ITEMS setting

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
==================
a4b728f2;Pablo Hoffman;2009-07-09 10:55:30 -0300;Scraper: added lower limit for responses sizes, removed redundant line

==

scrapy/core/scraper.py
==================
8b26e496;Pablo Hoffman;2009-07-08 23:48:06 -0300;Added new ItemProcessor component to Scraper component

==

docs/ref/settings.rst
docs/ref/signals.rst
scrapy/conf/default_settings.py
scrapy/contrib/spidermiddleware/itempipeline.py
scrapy/core/engine.py
scrapy/core/manager.py
scrapy/core/scraper.py
scrapy/item/pipeline.py
scrapy/stats/corestats.py
scrapy/utils/defer.py
==================
42b86a38;Pablo Hoffman;2009-07-08 18:19:54 -0300;removed wtf line

==

scrapy/tests/test_http_cookies.py
==================
5cbafaea;pablo;2009-07-08 09:19:35 -0300;StackTraceDump extension: using USR2 signal to avoid collision with other stuff that uses USR1 (such as twistd log rotation)

==

scrapy/contrib/debug.py
==================
b83851dc;Daniel Grana;2009-07-07 16:24:59 -0300;remove unused lines from shell command

==

scrapy/command/commands/shell.py
==================
8e5ede71;Daniel Grana;2009-07-07 16:22:23 -0300;shell command was broken by recent commits because scrapyengine.crawl does not returns a deferred anymore, now we use scrapyengine.schedule that returns the deferred of the download response

==

scrapy/command/commands/shell.py
==================
1ba98606;damian;2009-07-07 12:35:24 -0300;test.test_utils_url: update parameter name; utils.url: minor code clean up

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
460f690c;damian;2009-07-07 11:20:26 -0300;utils.url: add_or_replace_parameter function fixed, quoted urls support and test cases added

==

scrapy/tests/test_utils_url.py
scrapy/utils/url.py
==================
c205f7d8;pablo;2009-07-06 20:38:39 -0300;added missing comment for non-trivial code

==

scrapy/contrib/pipeline/s3images.py
==================
a15dc943;Daniel Grana;2009-07-06 16:16:49 -0300;images: images uploaded trough amazon s3 special spider must be scheduled

==

scrapy/contrib/pipeline/s3images.py
==================
2e520058;Daniel Grana;2009-07-06 15:35:36 -0300;rewrite RequestLimitMiddleware spidermw so it does not consume spider output at once
--HG--
rename : scrapy/contrib/spidermiddleware/limit.py => scrapy/contrib/spidermiddleware/requestlimit.py

==

scrapy/conf/default_settings.py
scrapy/contrib/spidermiddleware/limit.py
scrapy/contrib/spidermiddleware/requestlimit.py
==================
31b3d7ce;Pablo Hoffman;2009-07-06 15:31:50 -0300;Added flow control mechanism to new Scraper component, to prevent cases where memory fills because of requests being downloaded much faster than they can be processed (by the spiders)

==

scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/pipeline/s3images.py
scrapy/contrib/web/service.py
scrapy/core/engine.py
scrapy/core/scraper.py
==================
4f1d3887;Daniel Grana;2009-07-06 15:31:50 -0300;Cleanup scrapyengine.crawl by moving functionality inside a new component named Scraper

==

scrapy/core/engine.py
scrapy/core/scraper.py
scrapy/spider/middleware.py
==================
3cb18dbb;Daniel Grana;2009-07-06 15:31:50 -0300;Move itempipeline functionality outside of engine as a spidermiddleware

==

scrapy/conf/default_settings.py
scrapy/contrib/spidermiddleware/itempipeline.py
scrapy/core/engine.py
scrapy/item/pipeline.py
==================
2ce43ebb;pablo;2009-07-06 01:07:45 -0300;made downloader/scheduler/spider middlewares code more consistent, added enabled/disabled/loaded informational attributes to all of them

==

scrapy/core/downloader/middleware.py
scrapy/core/scheduler/middleware.py
scrapy/spider/middleware.py
==================
f467c233;Daniel Grana;2009-07-03 01:32:24 -0300;downloader: process queue inmediately after downloading the response

==

scrapy/core/downloader/manager.py
==================
0c4c1538;Pablo Hoffman;2009-07-01 09:51:57 -0300;improved Scrapy documentation index for better usability

==

docs/_templates/index.html
docs/_templates/layout.html
docs/conf.py
docs/contents.rst
docs/experimental.rst
docs/faq.rst
docs/index.rst
docs/intro/overview.rst
docs/proposed/index.rst
docs/proposed/introduction.rst
docs/ref/index.rst
==================
af6db169;Pablo Hoffman;2009-06-26 12:27:03 -0300;added scrapy.log.logmessage_received signal

==

scrapy/log/__init__.py
==================
80cd534f;Pablo Hoffman;2009-06-25 16:48:04 -0300;removed redundant botname from log lines

==

docs/intro/tutorial.rst
scrapy/log/__init__.py
==================
18301b7e;Pablo Hoffman;2009-06-25 14:13:45 -0300;downloader: performance improvement for sites that use download delay (replace datetime by time)

==

scrapy/core/downloader/manager.py
==================
7933e00e;Pablo Hoffman;2009-06-25 12:10:55 -0300;set more proper request priority for robots middleware and media pipeline

==

scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/pipeline/media.py
==================
c22d2b15;Pablo Hoffman;2009-06-25 09:56:38 -0300;engine: added domain_is_open() method, added docstring for domain_is_closed() method

==

scrapy/core/engine.py
==================
8de09fe4;Pablo Hoffman;2009-06-24 17:08:16 -0300;improved documentation of Downloader._download() method and fixed bug with process_queue() being called too early

==

scrapy/core/downloader/manager.py
==================
830cd4f1;Daniel Grana;2009-06-24 13:45:50 -0300;Restore download process queue processing after finish with recent transferred response

==

scrapy/core/downloader/manager.py
scrapy/core/engine.py
==================
87df33ce;Pablo Hoffman;2009-06-24 10:36:36 -0300;s/_next_request_called/_next_request_pending/

==

scrapy/core/engine.py
==================
51029e37;Pablo Hoffman;2009-06-24 10:34:44 -0300;engine: removed obsolete docstring and simplified next_request method

==

scrapy/core/engine.py
==================
d7d18d27;Daniel Grana;2009-06-24 10:28:34 -0300;avoid rescheduling next_request calls

==

scrapy/core/engine.py
==================
2b65f20c;Pablo Hoffman;2009-06-23 21:50:46 -0300;engine: removed redundant line and unused import

==

scrapy/core/engine.py
==================
7578ab00;Daniel Grana;2009-06-23 16:47:58 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
73b60788;Daniel Grana;2009-06-23 16:47:32 -0300;log framework errors at the end of crawling

==

scrapy/core/engine.py
==================
93fcf6e3;Pablo Hoffman;2009-06-23 16:11:23 -0300;added web console docstring pointing to documentation, improved telnet console docstring

==

scrapy/management/telnet.py
scrapy/management/web.py
==================
834ac9fc;Pablo Hoffman;2009-06-23 16:08:58 -0300;Some telnet console changes:
- added telnet console documentation
- added documentation for debugging memory leaks with guppy
- sorted out shell alises
- set default port (TELNETCONSOLE_PORT) to 6023

==

docs/faq.rst
docs/ref/extensions.rst
docs/ref/settings.rst
docs/topics/index.rst
docs/topics/telnetconsole.rst
scrapy/conf/default_settings.py
scrapy/management/telnet.py
==================
32bae804;Daniel Grana;2009-06-23 14:59:03 -0300;add basic mustbe_deferred tests

==

scrapy/tests/test_utils_defer.py
==================
9b78f929;daniel;2009-06-23 14:45:16 -0700;remove obsolete deferred_imap util, use coiterate+imap instead

==

scrapy/tests/test_utils_defer.py
scrapy/utils/defer.py
==================
e9c724e5;dgrana;2009-06-23 13:26:24 -0700;no need for two callbacks while processing scraping responses

==

scrapy/core/engine.py
==================
68093758;dgrana;2009-06-23 13:19:35 -0700;restore call to next_request inside pipeline output processor

==

scrapy/core/engine.py
==================
21ed9a24;dgrana;2009-06-23 13:14:22 -0700;fix replace of deferred_imap by coiterate+imap and fix broken engine test

==

scrapy/core/engine.py
==================
49b413ba;dgrana;2009-06-23 13:00:01 -0700;merge

==
==================
38f184e4;dgrana;2009-06-23 12:53:13 -0700;remove calls to chain_deferred and deferred_imap

==

scrapy/core/engine.py
==================
a8fd107a;Pablo Hoffman;2009-06-22 23:01:41 -0300;engine: some extra simplifications and removed debug mode

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/core/engine.py
==================
a1cca0da;Pablo Hoffman;2009-06-22 22:55:18 -0300;removed obsolete file

==

scrapy/conf/commands/scrape.py
==================
a8a44aa0;Pablo Hoffman;2009-06-22 21:28:35 -0300;engine: domains are now polled and closed when they're idle, instead of being notified by the downloader

==

scrapy/core/downloader/manager.py
scrapy/core/engine.py
==================
5271d1f1;Pablo Hoffman;2009-06-22 20:01:29 -0300;renamed engine.resume() method to engine.unpause()

==

scrapy/core/engine.py
==================
b3a624ed;Pablo Hoffman;2009-06-22 19:59:36 -0300;engine: simplified next_request and removed 'domain in self.closing' check

==

scrapy/core/engine.py
==================
ab0950b6;Pablo Hoffman;2009-06-22 18:40:17 -0300;added exception reporting to global_tests in engine.get_status()

==

scrapy/core/engine.py
==================
b037ef6a;Pablo Hoffman;2009-06-22 18:37:39 -0300;added clear_pending_requests to scheduler

==

scrapy/core/scheduler/schedulers.py
==================
fb8e24ac;Pablo Hoffman;2009-06-22 16:25:44 -0300;more downloader cleanup and fixed bug which was preventing domains to get properly closed

==

scrapy/core/downloader/manager.py
scrapy/core/engine.py
==================
e8543ca1;Pablo Hoffman;2009-06-22 15:05:26 -0300;minor clean up to engine domain closing

==

scrapy/core/engine.py
==================
b488e3b4;Daniel Grana;2009-06-22 14:24:04 -0300;catch downloader process_queue exceptions

==

scrapy/core/downloader/manager.py
==================
e6bf2821;Daniel Grana;2009-06-22 14:06:15 -0300;remove request from transferring state prior to returning downloaded response

==

scrapy/core/downloader/manager.py
==================
400a54bf;Pablo Hoffman;2009-06-21 22:00:16 -0300;Added reasons when closing domains ('reason' argument to engine close_domain method), replaced old 'status' parameter by new 'reason' parameter in domain_closed signal. updated and improved signals doc

==

docs/ref/signals.rst
scrapy/contrib/itemsampler.py
scrapy/core/downloader/dnscache.py
scrapy/core/engine.py
scrapy/core/signals.py
scrapy/stats/corestats.py
scrapy/stats/statscollector.py
scrapy/tests/test_engine.py
==================
ab2dd764;Pablo Hoffman;2009-06-21 16:27:48 -0300;downloader: some improvements to instantiation of SiteInfo (ex. SiteDetails) objects

==

scrapy/core/downloader/manager.py
==================
7bf610d0;Pablo Hoffman;2009-06-21 16:06:36 -0300;additional simplifications to downloader (several methods removed) and added more info to engine getstatus() method

==

scrapy/contrib/delayedclosedomain.py
scrapy/contrib/webconsole/livestats.py
scrapy/core/downloader/manager.py
scrapy/core/engine.py
==================
fda1fe0e;Pablo Hoffman;2009-06-21 15:38:26 -0300;decreased enabled extension/middlewares/pipelines log messages level to DEBUG

==

scrapy/core/downloader/middleware.py
scrapy/core/manager.py
scrapy/core/scheduler/middleware.py
scrapy/item/pipeline.py
scrapy/spider/middleware.py
==================
89712a4a;Pablo Hoffman;2009-06-21 14:23:51 -0300;downloader: renamed SiteDetails.downloading to SiteDetails.transferring, for clarity

==

scrapy/core/downloader/manager.py
==================
abe4f812;Pablo Hoffman;2009-06-21 14:16:40 -0300;downloader: added site.closed additional check to domain already closed

==

scrapy/core/downloader/manager.py
==================
5944f659;Daniel Grana;2009-06-21 03:03:14 -0300;restore downloader enqueing after middleware

==

scrapy/core/downloader/manager.py
scrapy/core/downloader/middleware.py
==================
cd1ad337;Daniel Grana;2009-06-21 02:54:31 -0300;Downloader cleanup
* remove debug messages
* move deactivating of downloads to last callback
* simplify calling of download_any function
* raises RuntimeError while openinng/closing twice

==

scrapy/core/downloader/manager.py
scrapy/core/downloader/middleware.py
==================
31d5d519;Daniel Grana;2009-06-21 01:37:58 -0300;remove obsolete lambda_deferred function

==

scrapy/utils/defer.py
==================
bd59748d;Daniel Grana;2009-06-21 01:25:31 -0300;simplify chain_deferred implementation
--HG--
extra : rebase_source : e8a3639051c560f8fa2d75fc5469194723fe3ef9

==

scrapy/utils/defer.py
==================
61b1e67c;Pablo Hoffman;2009-06-20 21:57:03 -0300;core: fixed engine getstatus() method for recent changes

==

scrapy/core/engine.py
==================
adccd9a0;Pablo Hoffman;2009-06-20 20:29:07 -0300;Sorted out Duplicate Filter API.
--HG--
rename : scrapy/dupefilter/__init__.py => scrapy/contrib/dupefilter.py

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/dupefilter.py
scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/dupefilter/__init__.py
scrapy/tests/test_dupefilter.py
==================
47970e91;Daniel Grana;2009-06-20 19:23:26 -0300;core: Invert request priority meaning, a higher request.priority value means more priority

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/core/scheduler/schedulers.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_downloadermiddleware_retry.py
==================
18b6fecc;Daniel Grana;2009-06-20 19:19:07 -0300;Remove custom redirection priority of request returned by downloadermiddleware

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/core/engine.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_downloadermiddleware_retry.py
==================
00b49752;Daniel Grana;2009-06-20 18:15:02 -0300;Multiples changes to core scheduling and duplicates filtering
* removed starters from engine
* moved schedulermiddleware to scheduler
* raise RuntimeError when trying to open/close a scheduler domain twice
* removed dupesfilter singleton and spidermw dupefilter middleware

--HG--
extra : rebase_source : e4c3ad4b970cbc8f532bc751ba9d8a944ca16be5

==

scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/core/engine.py
scrapy/core/scheduler/middleware.py
scrapy/core/scheduler/schedulers.py
scrapy/dupefilter/__init__.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
scrapy/tests/test_spidermiddleware_duplicatesfilter.py
==================
728ec7c5;Pablo Hoffman;2009-06-19 19:41:56 -0300;minor adjustment to FifoDomainScheduler and improved documentation of domain scheduler API (remove_pending_domain method removes all ocurrences)

==

scrapy/contrib/domainsch.py
==================
161335fe;Pablo Hoffman;2009-06-19 17:55:54 -0300;Added domain schedulers (whose functionality was previously mixed with the Scrapy Scheduler) and removed domain prioritizers whose functionality became duplicated by the new domain schedulers.

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/domainsch.py
scrapy/contrib/prioritizers.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/core/engine.py
scrapy/core/manager.py
scrapy/core/prioritizers.py
scrapy/core/scheduler/schedulers.py
==================
3cb12e5d;Pablo Hoffman;2009-06-18 14:43:56 -0300;Moved init_domain functionality out of the engine (refs #88) and into the spider level. A new spider (InitSpider, not yet documented) was added to provide initialization facilities.
Also renamed make_request_from_url to make_requests_from_url and allowed it to
return iterables.

==

docs/ref/spiders.rst
scrapy/contrib/spiders/crawl.py
scrapy/contrib/spiders/feed.py
scrapy/contrib/spiders/init.py
scrapy/core/engine.py
scrapy/core/manager.py
scrapy/spider/models.py
==================
b040e6a3;Pablo Hoffman;2009-06-18 14:33:05 -0300;removed unused GenericSpider

==

scrapy/contrib/spiders/generic.py
==================
e716fad0;Pablo Hoffman;2009-06-18 09:44:02 -0300;engine: log error when reactor.listenTCP fails instead of failing

==

scrapy/core/engine.py
==================
d23dcbb3;Pablo Hoffman;2009-06-17 09:17:50 -0300;engine: minor code simplification and fixed potential KeyError bug

==

scrapy/core/engine.py
==================
9022f84c;daniel;2009-06-17 05:01:04 -0300;decompressionmw: use a temporal filename because None is failing in some cases

==

scrapy/contrib_exp/downloadermiddleware/decompression.py
==================
2c93bc40;daniel;2009-06-17 03:41:42 -0300;decompressionmw: relative hardcoded filename raises OSError when process has not write access to CWD

==

scrapy/contrib_exp/downloadermiddleware/decompression.py
==================
d175ced4;daniel;2009-06-17 02:45:46 -0300;Automated merge with ssh://hg.scrapy.org/scrapy

==
==================
74f6bd3a;Pablo Hoffman;2009-06-16 13:14:40 -0300;removed python2.5 from rpm-install.sh script

==

scripts/rpm-install.sh
==================
584a844e;pablo;2009-06-16 17:10:43 +0100;Fixed distutils packaging for all setup.py bdist formats
--HG--
rename : scrapy/bin/scrapy-admin.py => bin/scrapy-admin.py

==

MANIFEST.in
bin/scrapy-admin.py
scripts/rpm-install.sh
setup.cfg
setup.py
==================
ead54669;Pablo Hoffman;2009-06-16 11:06:42 -0300;changed format of --set SETTING:VALUE to --set SETTING=VALUE

==

scrapy/command/models.py
==================
e5b99a56;Pablo Hoffman;2009-06-15 19:44:26 -0300;Several core changes:
Execution Manager:

* added control_reactor argument to delegate external twisted
  reactor control (for example by twistd)
* now it loads spiders (if not already loaded)
* now it stars the log (if not already started)
* removed *args from configure() method
* removed **opts from runonce and start methods

Execution engine:

* added control_reactor argument to to delegate external twisted
  reactor control (for example by twistd)
* changed some functions and method names for clarity
* improve handling of exceptions in st() method
* regrouped close_domain, closed_domain, and _close_domain method
  for legibilty

Scheduler:

* replaced pending_domains_count (dict) by pending_domains (set)
* simplified some doc

==

scrapy/core/engine.py
scrapy/core/manager.py
scrapy/core/scheduler/schedulers.py
==================
3c919f25;Pablo Hoffman;2009-06-15 19:40:56 -0300;Several core changes:
Execution Manager:

* added control_reactor argument to delegate external twisted
  reactor control (for example by twistd)
* now it loads spiders (if not already loaded)
* now it stars the log (if not already started)
* removed *args from configure() method
* removed **opts from runonce and start methods

Execution engine:

* added control_reactor argument to to delegate external twisted
  reactor control (for example by twistd)
* changed some functions and method names for clarity
* improve handling of exceptions in st() method
* regrouped close_domain, closed_domain, and _close_domain method
  for legibilty

Scheduler:

* replaced pending_domains_count (dict) by pending_domains (set)
* simplified some doc

==

scrapy/command/commands/crawl.py
scrapy/command/commands/start.py
scrapy/core/manager.py
==================
5e3ef5a2;Pablo Hoffman;2009-06-15 18:59:40 -0300;item pipeline: added check for domain not already closed

==

scrapy/item/pipeline.py
==================
aeb9734a;Pablo Hoffman;2009-06-15 18:58:37 -0300;downloader: made log message visible only when debug_mode is on

==

scrapy/core/downloader/manager.py
==================
ff76f46d;Pablo Hoffman;2009-06-15 18:55:09 -0300;removed noisy comment and moved import to the top

==

scrapy/command/cmdline.py
==================
1d8cec63;Pablo Hoffman;2009-06-15 18:50:47 -0300;scrapy.log: check if twisted log started before

==

scrapy/log/__init__.py
==================
a8d430b4;daniel;2009-06-15 12:35:42 -0300;httpcache: add domain to logging message

==

scrapy/contrib/downloadermiddleware/httpcache.py
==================
fd0e4901;Pablo Hoffman;2009-06-12 15:38:21 -0300;added StatsMailer extension

==

docs/ref/extensions.rst
docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/statsmailer.py
==================
7c2476bb;Pablo Hoffman;2009-06-12 08:31:30 -0300;fixed a couple of bugs caused by adding priority to Requests (thanks Artem for reporting)

==

scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/pipeline/media.py
==================
4a1a0135;Pablo Hoffman;2009-06-11 22:25:47 -0300;Added 'priority' attribute to Requests and removed old 'priority' argument passed through engine, scheduler and scheduler middleware calls

==

docs/ref/request-response.rst
scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/contrib_exp/history/scheduler.py
scrapy/core/engine.py
scrapy/core/scheduler/middleware.py
scrapy/core/scheduler/schedulers.py
scrapy/http/request/__init__.py
scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
==================
962dbeba;Pablo Hoffman;2009-06-11 08:33:01 -0300;fixed typo in docstring

==

scrapy/http/request/rpc.py
==================
e55158eb;Pablo Hoffman;2009-06-10 18:00:32 -0300;Merged olveyra's patch

==
==================
635ac1ca;Pablo Hoffman;2009-06-10 14:21:36 -0300;Simplified domain prioritizers, so that they don't receive domains in the constructor (domain prioritizers will be refactored later anyway) and simplified Scrapy Manager code thanks to this.
Added make_request_from_url method to BaseSpider, splitting funtionality to
create requests from URLs which was previously done all in start_requests.

==

docs/ref/spiders.rst
scrapy/contrib/prioritizers.py
scrapy/core/manager.py
scrapy/core/prioritizers.py
scrapy/spider/models.py
==================
a74b0b17;Pablo Hoffman;2009-06-09 13:09:35 -0300;additional simplification of OffsiteMiddleware

==

scrapy/contrib/spidermiddleware/offsite.py
==================
eca05c9e;Pablo Hoffman;2009-06-09 12:37:15 -0300;OffsiteMiddleware: removed logging and simplified implementation

==

scrapy/contrib/spidermiddleware/offsite.py
==================
6524def4;molveyra;2009-06-04 10:44:40 -0300;dont check guid in RobustScrapedItem.validate. Instead, raise NotImplemented.

==

scrapy/contrib/item/models.py
==================
87fbc9c5;Daniel Grana;2009-05-28 21:47:41 -0300;spidermw: add domain name to warning about missing callbacks in requests

==

scrapy/spider/middleware.py
==================
727e67af;Daniel Grana;2009-05-28 21:41:02 -0300;spidermw: ignore and warn about requests without callback returned by spiders

==

scrapy/spider/middleware.py
==================
cfafa011;Daniel Grana;2009-05-28 21:10:30 -0300;spidermw: check for __iter__ instead of trying to iter() that may cause that a string pass as iterable

==

scrapy/spider/middleware.py
==================
0f690b03;Pablo Hoffman;2009-05-28 13:57:25 -0300;added deprecation warning to ErrorPages downloader middleware

==

scrapy/contrib/downloadermiddleware/errorpages.py
==================
1aac6943;Pablo Hoffman;2009-05-28 13:52:56 -0300;updated settings doc

==

docs/ref/settings.rst
==================
04e7f8f5;Pablo Hoffman;2009-05-28 13:45:26 -0300;merged with Daniel's HttpException-removal branch

==
==================
abda5edf;Daniel Grana;2009-05-28 09:31:43 -0300;decompressionmw: dont try to do decompress empty responses

==

scrapy/contrib_exp/downloadermiddleware/decompression.py
==================
85dbdf57;Daniel Grana;2009-05-28 09:30:31 -0300;finally remove HttpException
in this changeset:
* remove HttpException from engine and core exceptions
* replace dwmw ErrorPages with spidermw HttpError
* bugfix image pipeline media_to_download method when stat_key returns None

==

scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/errorpages.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/spidermiddleware/httperror.py
scrapy/core/engine.py
scrapy/core/exceptions.py
==================
0e5bea67;Daniel Grana;2009-05-28 00:27:42 -0300;images: adapt images pipeline to recent changes on HttpException topic

==

scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/s3images.py
==================
7eaa3ed2;Daniel Grana;2009-05-27 16:51:36 -0300;stop raising HttpException at download handlers and adapt download middlewares

==

docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/errorpages.py
scrapy/contrib/downloadermiddleware/httpcache.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/contrib/downloadermiddleware/stats.py
scrapy/core/downloader/handlers.py
scrapy/tests/test_downloadermiddleware_cookies.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_downloadermiddleware_retry.py
scrapy/utils/response.py
==================
c8827552;Daniel Grana;2009-05-26 15:48:34 -0300;fix typo at WEBCONSOLE_ENABLED setting documentaion of default value. thanks dzen

==

docs/ref/settings.rst
==================
89950af8;Pablo Hoffman;2009-05-25 23:45:10 -0300;cluster: fixed KeyError when crawler process failed to start

==

scrapy/contrib/cluster/worker/manager.py
==================
6d1ffa71;Pablo Hoffman;2009-05-25 20:14:50 -0300;renamed CrawlDebug downloader middleware to DebugMiddleware

==

docs/ref/downloader-middleware.rst
docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/debug.py
==================
b1dad251;Pablo Hoffman;2009-05-25 14:41:06 -0300;Deprecated Common Downloader Middleware and added DefaultHeaders Downloader Middleware

==

docs/intro/tutorial.rst
docs/ref/downloader-middleware.rst
docs/ref/settings.rst
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/common.py
scrapy/contrib/downloadermiddleware/defaultheaders.py
==================
90d408b0;Pablo Hoffman;2009-05-24 19:13:06 -0300;Some changes to HTTP cache middleware:
* documented
* moved from scrapy.contrib.downloadermiddleware.cache.CacheMiddleware to
  scrapy.contrib.downloadermiddleware.httpcache.HttpCacheMiddleware
* settings prefix changed from CACHE2_ to HTTPCACHE_

--HG--
rename : scrapy/contrib/downloadermiddleware/cache.py => scrapy/contrib/downloadermiddleware/httpcache.py

==

docs/ref/downloader-middleware.rst
docs/ref/settings.rst
docs/topics/extensions.rst
examples/experimental/googledir/googledir/settings.py
scrapy/command/commands/crawl.py
scrapy/conf/default_settings.py
scrapy/contrib/downloadermiddleware/cache.py
scrapy/contrib/downloadermiddleware/httpcache.py
==================
19f2992b;Pablo Hoffman;2009-05-23 18:31:54 -0300;applied Patrick patch: test_storedb: add base class for both mysql tests

==

scrapy/tests/test_storedb.py
==================
dae0b197;Daniel Grana;2009-05-22 13:21:46 -0300;aws: missing import

==

scrapy/contrib/aws.py
==================
4efcf78a;Daniel Grana;2009-05-22 13:14:16 -0300;aws: take AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY from enviroment just like boto does

==

scrapy/contrib/aws.py
==================
39558441;Ismael Carnales;2009-05-21 15:01:48 +0000;Removed FieldValueError in favour of ValueError

==

scrapy/contrib_exp/newitem/fields.py
==================
c03e2460;Ismael Carnales;2009-05-21 14:57:52 +0000;Added DateTimeField

==

scrapy/contrib_exp/newitem/fields.py
scrapy/tests/test_newitem.py
==================
d5f0cae7;Ismael Carnales;2009-05-21 14:55:14 +0000;New implementation of Field and MultiValuedField

==

scrapy/contrib_exp/newitem/fields.py
scrapy/contrib_exp/newitem/models.py
==================
0cc289ac;Ismael Carnales;2009-05-21 14:51:50 +0000;New and simpler implementation of BooleanField

==

scrapy/contrib_exp/newitem/fields.py
==================
55d922a4;Ismael Carnales;2009-05-21 14:50:35 +0000;Fixed BooleanField default value

==

scrapy/contrib_exp/newitem/fields.py
==================
1ffe64da;Ismael Carnales;2009-05-21 14:48:43 +0000;Added test for newitem fields

==

scrapy/tests/test_newitem.py
==================
48bfd3fe;Pablo Hoffman;2009-05-20 02:15:31 -0300;renamed old setting

==

scrapy/conf/default_settings.py
==================
befd28ee;Pablo Hoffman;2009-05-20 00:57:44 -0300;docs/tutorial: added reminder about adding pipeline to ITEM_PIPELINES settings (thanks jamie)

==

docs/intro/tutorial.rst
==================
04610a25;Pablo Hoffman;2009-05-19 03:07:08 -0300;fixed bug in tutorial regarding csv writer pipeline, and other minor corrections

==

docs/intro/tutorial.rst
==================
abfc52cd;Daniel Grana;2009-05-19 01:50:44 -0300;docs: modify install document to mercurial based installation instructions

==

docs/intro/install.rst
==================
13bb9934;Pablo Hoffman;2009-05-18 23:06:27 -0300;moved htmlparser and lxml based link extractors to scrapy.contrib.linkextractors, with the rest of the link extractors

==

scrapy/contrib/linkextractors/htmlparser.py
scrapy/contrib/linkextractors/lxmlparser.py
scrapy/contrib_exp/link/__init__.py
==================
c161c29e;Pablo Hoffman;2009-05-18 21:32:17 -0300;simplified some scrapy.log implementation code

==

scrapy/log/__init__.py
==================
a8a3de17;Pablo Hoffman;2009-05-18 21:11:03 -0300;removed unused line

==

scrapy/core/engine.py
==================
b8773434;Pablo Hoffman;2009-05-18 20:59:26 -0300;fixed docstring

==

scrapy/xpath/constructors.py
==================
59e504a0;Pablo Hoffman;2009-05-18 19:27:51 -0300;removed code from scrapy.link to avoid cyclic imports from scrapy.contrib.linkextractors.sgml

==

scrapy/link/__init__.py
==================
86498abd;Pablo Hoffman;2009-05-18 19:19:37 -0300;Sorted out Link Extractors organization by moving all them to scrapy.contrib.linkextractors.
The most relevant being:
    scrapy.link.extractors.RegexLinkExtractor

which was moved to:
    scrapy.contrib.linkextractors.sgml.SgmlLinkExtractor

The old location still works but throws a deprecation warning. It will be
removed before the 0.7 release.

Documentation and tests were also updated.

Also, in this changeset, a new regex-based link extractor was added to
scrapy.contrib.linkextractors.regex.

--HG--
rename : scrapy/tests/sample_data/link_extractor/regex_linkextractor.html => scrapy/tests/sample_data/link_extractor/sgml_linkextractor.html
rename : scrapy/tests/test_link.py => scrapy/tests/test_contrib_linkextractors.py

==

docs/intro/overview.rst
docs/proposed/spiders.rst
docs/ref/link-extractors.rst
docs/ref/spiders.rst
docs/topics/firebug.rst
scrapy/contrib/linkextractors/__init__.py
scrapy/contrib/linkextractors/image.py
scrapy/contrib/linkextractors/regex.py
scrapy/contrib/linkextractors/sgml.py
scrapy/contrib/spiders/generic.py
scrapy/contrib_exp/adaptors/extraction.py
scrapy/link/__init__.py
scrapy/link/extractors.py
scrapy/tests/sample_data/link_extractor/sgml_linkextractor.html
scrapy/tests/test_contrib_linkextractors.py
scrapy/tests/test_spiders/testspider.py
==================
7b34e083;pablo;2009-05-16 20:11:23 -0300;sorted out running of unittests:
1. removed scrapy.tests.run module which didn't work well because of a problem
   with Twisted trial
2. added runtests.bat script for running tests in windows
3. added additional lookup path for trial in unix systems

==

bin/runtests.bat
bin/runtests.sh
scrapy/tests/__init__.py
scrapy/tests/run.py
==================
eb649d66;Pablo Hoffman;2009-05-15 19:19:05 -0300;fixed bug with unittests data in win32

==

scrapy/tests/__init__.py
==================
ba48a24b;Pablo Hoffman;2009-05-15 15:03:42 -0300;sorted out some tests sample data paths and fixed bug with test in windows

==

scrapy/tests/__init__.py
scrapy/tests/run.py
scrapy/tests/test_adaptors.py
scrapy/tests/test_downloadermiddleware_decompression.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_engine.py
scrapy/tests/test_link.py
scrapy/tests/test_utils_iterators.py
==================
85cd7ea1;Pablo Hoffman;2009-05-14 20:21:02 -0300;fixed encoding bug in xmliter (thanks Atamert!), added unittests and updated utils.iterator unittest names for consistency

==

scrapy/tests/test_utils_iterators.py
scrapy/xpath/selector.py
==================
7166f9f6;Daniel Grana;2009-05-14 14:10:09 -0300;url2guid: allow reutrning None and single values
--HG--
extra : rebase_source : 1a24237cb6d90d30fe8f086dbb210858f1627620

==

scrapy/contrib/web/service.py
==================
766c8a4e;Pablo Hoffman;2009-05-14 08:32:48 -0300;fixed some doc typos reported by phaithful

==

docs/ref/request-response.rst
docs/ref/spiders.rst
==================
314a1c2b;Pablo Hoffman;2009-05-11 01:40:40 -0300;improved configuration of middlewares using dicts and orders (closes #85)

==

docs/ref/settings.rst
docs/topics/downloader-middleware.rst
docs/topics/spider-middleware.rst
examples/experimental/googledir/googledir/settings.py
scrapy/conf/default_settings.py
scrapy/core/downloader/middleware.py
scrapy/core/scheduler/middleware.py
scrapy/spider/middleware.py
scrapy/tests/test_utils_middleware.py
scrapy/utils/middleware.py
==================
3dee4b67;Daniel Grana;2009-05-08 12:01:02 -0300;redirect: 3xx status code based redirection requires Location header to be set

==

scrapy/contrib/downloadermiddleware/redirect.py
scrapy/tests/test_downloadermiddleware_redirect.py
==================
05f1e0c1;Daniel Grana;2009-05-07 17:29:30 -0300;adding .svn to hgignore to help with hg2svn autocommits

==

.hgignore
==================
9be90070;Pablo Hoffman;2009-05-07 16:35:13 -0300;merge

==
==================
edf5b672;Pablo Hoffman;2009-05-07 16:33:06 -0300;renamed remove_escape_chars to replace_escape_chars (adaptor and function), added more tests to replace_escape_chars, keeping backwards compatibility

==

scrapy/contrib_exp/adaptors/__init__.py
scrapy/contrib_exp/adaptors/markup.py
scrapy/tests/test_utils_markup.py
scrapy/utils/markup.py
==================
91657c0d;Pablo Hoffman;2009-05-07 14:52:32 -0300;Sorted exceptions reference alphabetically

==

docs/ref/exceptions.rst
==================
c1c7b2d6;Pablo Hoffman;2009-05-07 14:52:32 -0300;Sorted exceptions reference alphabetically
--HG--
extra : rebase_source : 1c6a192a76fcc90103ea324f6baf4387ba65e14a

==

docs/ref/exceptions.rst
==================
da7b9358;Ismael Carnales;2009-05-07 16:03:41 +0000;updated docstrings for remove_escape_chars and its adaptor factory

==

scrapy/contrib_exp/adaptors/markup.py
scrapy/utils/markup.py
==================
1b3d40e6;Ismael Carnales;2009-05-07 15:44:38 +0000;force replace_by to be unicode in remove_escape_chars, added tests

==

scrapy/tests/test_utils_markup.py
scrapy/utils/markup.py
==================
7eb79488;Ismael Carnales;2009-05-07 15:24:40 +0000;added a replace_str param to remove_escape_chars and added remove_escape adaptor using it

==

scrapy/contrib_exp/adaptors/__init__.py
scrapy/contrib_exp/adaptors/markup.py
scrapy/utils/markup.py
==================
77b25d30;Ismael Carnales;2009-05-07 12:06:18 -0300;Added serialization functions to newitem

==

scrapy/contrib_exp/newitem/serialization.py
==================
426282bb;Pablo Hoffman;2009-05-07 00:36:39 -0300;fixed bug with FormRequest class which wasn't setting method=POST by default

==

scrapy/http/request/form.py
scrapy/tests/test_http_request.py
==================
33909e05;Daniel Grana;2009-05-06 15:59:50 -0300;ignore pycs and twisted temp trial dir and dropin.cache

==

.hgignore
==================
ba69c29e;Daniel Grana;2009-05-06 15:55:17 -0300;mv scrapy/trunk to root as part of svn2hg migration
--HG--
rename : scrapy/trunk/AUTHORS => AUTHORS
rename : scrapy/trunk/INSTALL => INSTALL
rename : scrapy/trunk/LICENSE => LICENSE
rename : scrapy/trunk/README => README
rename : scrapy/trunk/bin/runtests.sh => bin/runtests.sh
rename : scrapy/trunk/docs/Makefile => docs/Makefile
rename : scrapy/trunk/docs/README => docs/README
rename : scrapy/trunk/docs/_ext/scrapydocs.py => docs/_ext/scrapydocs.py
rename : scrapy/trunk/docs/_static/items_adaptors-sample1.html => docs/_static/items_adaptors-sample1.html
rename : scrapy/trunk/docs/_static/scrapydoc.css => docs/_static/scrapydoc.css
rename : scrapy/trunk/docs/_static/selectors-sample1.html => docs/_static/selectors-sample1.html
rename : scrapy/trunk/docs/conf.py => docs/conf.py
rename : scrapy/trunk/docs/faq.rst => docs/faq.rst
rename : scrapy/trunk/docs/index.rst => docs/index.rst
rename : scrapy/trunk/docs/intro/index.rst => docs/intro/index.rst
rename : scrapy/trunk/docs/intro/install.rst => docs/intro/install.rst
rename : scrapy/trunk/docs/intro/overview.rst => docs/intro/overview.rst
rename : scrapy/trunk/docs/intro/tutorial.rst => docs/intro/tutorial.rst
rename : scrapy/trunk/docs/media/scrapy-architecture.dia => docs/media/scrapy-architecture.dia
rename : scrapy/trunk/docs/misc/api-stability.rst => docs/misc/api-stability.rst
rename : scrapy/trunk/docs/misc/index.rst => docs/misc/index.rst
rename : scrapy/trunk/docs/proposed/_images/scrapy_architecture.odg => docs/proposed/_images/scrapy_architecture.odg
rename : scrapy/trunk/docs/proposed/_images/scrapy_architecture.png => docs/proposed/_images/scrapy_architecture.png
rename : scrapy/trunk/docs/proposed/index.rst => docs/proposed/index.rst
rename : scrapy/trunk/docs/proposed/introduction.rst => docs/proposed/introduction.rst
rename : scrapy/trunk/docs/proposed/newitem.rst => docs/proposed/newitem.rst
rename : scrapy/trunk/docs/proposed/spiders.rst => docs/proposed/spiders.rst
rename : scrapy/trunk/docs/ref/downloader-middleware.rst => docs/ref/downloader-middleware.rst
rename : scrapy/trunk/docs/ref/email.rst => docs/ref/email.rst
rename : scrapy/trunk/docs/ref/exceptions.rst => docs/ref/exceptions.rst
rename : scrapy/trunk/docs/ref/extension-manager.rst => docs/ref/extension-manager.rst
rename : scrapy/trunk/docs/ref/extensions.rst => docs/ref/extensions.rst
rename : scrapy/trunk/docs/ref/index.rst => docs/ref/index.rst
rename : scrapy/trunk/docs/ref/link-extractors.rst => docs/ref/link-extractors.rst
rename : scrapy/trunk/docs/ref/logging.rst => docs/ref/logging.rst
rename : scrapy/trunk/docs/ref/request-response.rst => docs/ref/request-response.rst
rename : scrapy/trunk/docs/ref/selectors.rst => docs/ref/selectors.rst
rename : scrapy/trunk/docs/ref/settings.rst => docs/ref/settings.rst
rename : scrapy/trunk/docs/ref/signals.rst => docs/ref/signals.rst
rename : scrapy/trunk/docs/ref/spiders.rst => docs/ref/spiders.rst
rename : scrapy/trunk/docs/topics/_images/adaptors_diagram.png => docs/topics/_images/adaptors_diagram.png
rename : scrapy/trunk/docs/topics/_images/adaptors_diagram.svg => docs/topics/_images/adaptors_diagram.svg
rename : scrapy/trunk/docs/topics/_images/firebug1.png => docs/topics/_images/firebug1.png
rename : scrapy/trunk/docs/topics/_images/firebug2.png => docs/topics/_images/firebug2.png
rename : scrapy/trunk/docs/topics/_images/firebug3.png => docs/topics/_images/firebug3.png
rename : scrapy/trunk/docs/topics/_images/scrapy_architecture.odg => docs/topics/_images/scrapy_architecture.odg
rename : scrapy/trunk/docs/topics/_images/scrapy_architecture.png => docs/topics/_images/scrapy_architecture.png
rename : scrapy/trunk/docs/topics/adaptors.rst => docs/topics/adaptors.rst
rename : scrapy/trunk/docs/topics/architecture.rst => docs/topics/architecture.rst
rename : scrapy/trunk/docs/topics/downloader-middleware.rst => docs/topics/downloader-middleware.rst
rename : scrapy/trunk/docs/topics/extensions.rst => docs/topics/extensions.rst
rename : scrapy/trunk/docs/topics/firebug.rst => docs/topics/firebug.rst
rename : scrapy/trunk/docs/topics/firefox.rst => docs/topics/firefox.rst
rename : scrapy/trunk/docs/topics/index.rst => docs/topics/index.rst
rename : scrapy/trunk/docs/topics/item-pipeline.rst => docs/topics/item-pipeline.rst
rename : scrapy/trunk/docs/topics/items.rst => docs/topics/items.rst
rename : scrapy/trunk/docs/topics/link-extractors.rst => docs/topics/link-extractors.rst
rename : scrapy/trunk/docs/topics/robotstxt.rst => docs/topics/robotstxt.rst
rename : scrapy/trunk/docs/topics/selectors.rst => docs/topics/selectors.rst
rename : scrapy/trunk/docs/topics/settings.rst => docs/topics/settings.rst
rename : scrapy/trunk/docs/topics/shell.rst => docs/topics/shell.rst
rename : scrapy/trunk/docs/topics/spider-middleware.rst => docs/topics/spider-middleware.rst
rename : scrapy/trunk/docs/topics/spiders.rst => docs/topics/spiders.rst
rename : scrapy/trunk/docs/topics/stats.rst => docs/topics/stats.rst
rename : scrapy/trunk/docs/topics/webconsole.rst => docs/topics/webconsole.rst
rename : scrapy/trunk/examples/experimental/googledir/googledir/__init__.py => examples/experimental/googledir/googledir/__init__.py
rename : scrapy/trunk/examples/experimental/googledir/googledir/items.py => examples/experimental/googledir/googledir/items.py
rename : scrapy/trunk/examples/experimental/googledir/googledir/pipelines.py => examples/experimental/googledir/googledir/pipelines.py
rename : scrapy/trunk/examples/experimental/googledir/googledir/settings.py => examples/experimental/googledir/googledir/settings.py
rename : scrapy/trunk/examples/experimental/googledir/googledir/spiders/__init__.py => examples/experimental/googledir/googledir/spiders/__init__.py
rename : scrapy/trunk/examples/experimental/googledir/googledir/spiders/google_directory.py => examples/experimental/googledir/googledir/spiders/google_directory.py
rename : scrapy/trunk/examples/experimental/googledir/googledir/templates/spider_basic.tmpl => examples/experimental/googledir/googledir/templates/spider_basic.tmpl
rename : scrapy/trunk/examples/experimental/googledir/googledir/templates/spider_crawl.tmpl => examples/experimental/googledir/googledir/templates/spider_crawl.tmpl
rename : scrapy/trunk/examples/experimental/googledir/googledir/templates/spider_csvfeed.tmpl => examples/experimental/googledir/googledir/templates/spider_csvfeed.tmpl
rename : scrapy/trunk/examples/experimental/googledir/googledir/templates/spider_xmlfeed.tmpl => examples/experimental/googledir/googledir/templates/spider_xmlfeed.tmpl
rename : scrapy/trunk/examples/experimental/googledir/scrapy-ctl.py => examples/experimental/googledir/scrapy-ctl.py
rename : scrapy/trunk/examples/googledir/googledir/__init__.py => examples/googledir/googledir/__init__.py
rename : scrapy/trunk/examples/googledir/googledir/items.py => examples/googledir/googledir/items.py
rename : scrapy/trunk/examples/googledir/googledir/pipelines.py => examples/googledir/googledir/pipelines.py
rename : scrapy/trunk/examples/googledir/googledir/settings.py => examples/googledir/googledir/settings.py
rename : scrapy/trunk/examples/googledir/googledir/spiders/__init__.py => examples/googledir/googledir/spiders/__init__.py
rename : scrapy/trunk/examples/googledir/googledir/spiders/google_directory.py => examples/googledir/googledir/spiders/google_directory.py
rename : scrapy/trunk/examples/googledir/scrapy-ctl.py => examples/googledir/scrapy-ctl.py
rename : scrapy/trunk/extras/sql/scraping.sql => extras/sql/scraping.sql
rename : scrapy/trunk/profiling/priorityqueue/pq_classes.py => profiling/priorityqueue/pq_classes.py
rename : scrapy/trunk/profiling/priorityqueue/run.py => profiling/priorityqueue/run.py
rename : scrapy/trunk/profiling/priorityqueue/test_cases.py => profiling/priorityqueue/test_cases.py
rename : scrapy/trunk/scrapy/__init__.py => scrapy/__init__.py
rename : scrapy/trunk/scrapy/bin/scrapy-admin.py => scrapy/bin/scrapy-admin.py
rename : scrapy/trunk/scrapy/command/__init__.py => scrapy/command/__init__.py
rename : scrapy/trunk/scrapy/command/cmdline.py => scrapy/command/cmdline.py
rename : scrapy/trunk/scrapy/command/commands/__init__.py => scrapy/command/commands/__init__.py
rename : scrapy/trunk/scrapy/command/commands/crawl.py => scrapy/command/commands/crawl.py
rename : scrapy/trunk/scrapy/command/commands/download.py => scrapy/command/commands/download.py
rename : scrapy/trunk/scrapy/command/commands/genspider.py => scrapy/command/commands/genspider.py
rename : scrapy/trunk/scrapy/command/commands/help.py => scrapy/command/commands/help.py
rename : scrapy/trunk/scrapy/command/commands/list.py => scrapy/command/commands/list.py
rename : scrapy/trunk/scrapy/command/commands/log.py => scrapy/command/commands/log.py
rename : scrapy/trunk/scrapy/command/commands/parse.py => scrapy/command/commands/parse.py
rename : scrapy/trunk/scrapy/command/commands/shell.py => scrapy/command/commands/shell.py
rename : scrapy/trunk/scrapy/command/commands/start.py => scrapy/command/commands/start.py
rename : scrapy/trunk/scrapy/command/commands/stats.py => scrapy/command/commands/stats.py
rename : scrapy/trunk/scrapy/command/models.py => scrapy/command/models.py
rename : scrapy/trunk/scrapy/conf/__init__.py => scrapy/conf/__init__.py
rename : scrapy/trunk/scrapy/conf/commands/__init__.py => scrapy/conf/commands/__init__.py
rename : scrapy/trunk/scrapy/conf/commands/crawl.py => scrapy/conf/commands/crawl.py
rename : scrapy/trunk/scrapy/conf/commands/help.py => scrapy/conf/commands/help.py
rename : scrapy/trunk/scrapy/conf/commands/list.py => scrapy/conf/commands/list.py
rename : scrapy/trunk/scrapy/conf/commands/log.py => scrapy/conf/commands/log.py
rename : scrapy/trunk/scrapy/conf/commands/scrape.py => scrapy/conf/commands/scrape.py
rename : scrapy/trunk/scrapy/conf/commands/shell.py => scrapy/conf/commands/shell.py
rename : scrapy/trunk/scrapy/conf/commands/stats.py => scrapy/conf/commands/stats.py
rename : scrapy/trunk/scrapy/conf/commands/test.py => scrapy/conf/commands/test.py
rename : scrapy/trunk/scrapy/conf/default_settings.py => scrapy/conf/default_settings.py
rename : scrapy/trunk/scrapy/contrib/__init__.py => scrapy/contrib/__init__.py
rename : scrapy/trunk/scrapy/contrib/aws.py => scrapy/contrib/aws.py
rename : scrapy/trunk/scrapy/contrib/closedomain.py => scrapy/contrib/closedomain.py
rename : scrapy/trunk/scrapy/contrib/cluster/__init__.py => scrapy/contrib/cluster/__init__.py
rename : scrapy/trunk/scrapy/contrib/cluster/crawler/__init__.py => scrapy/contrib/cluster/crawler/__init__.py
rename : scrapy/trunk/scrapy/contrib/cluster/crawler/manager.py => scrapy/contrib/cluster/crawler/manager.py
rename : scrapy/trunk/scrapy/contrib/cluster/hooks/__init__.py => scrapy/contrib/cluster/hooks/__init__.py
rename : scrapy/trunk/scrapy/contrib/cluster/hooks/svn.py => scrapy/contrib/cluster/hooks/svn.py
rename : scrapy/trunk/scrapy/contrib/cluster/master/__init__.py => scrapy/contrib/cluster/master/__init__.py
rename : scrapy/trunk/scrapy/contrib/cluster/master/manager.py => scrapy/contrib/cluster/master/manager.py
rename : scrapy/trunk/scrapy/contrib/cluster/master/web.py => scrapy/contrib/cluster/master/web.py
rename : scrapy/trunk/scrapy/contrib/cluster/master/ws_api.txt => scrapy/contrib/cluster/master/ws_api.txt
rename : scrapy/trunk/scrapy/contrib/cluster/tools/scrapy-cluster-ctl.py => scrapy/contrib/cluster/tools/scrapy-cluster-ctl.py
rename : scrapy/trunk/scrapy/contrib/cluster/tools/test-worker.py => scrapy/contrib/cluster/tools/test-worker.py
rename : scrapy/trunk/scrapy/contrib/cluster/worker/__init__.py => scrapy/contrib/cluster/worker/__init__.py
rename : scrapy/trunk/scrapy/contrib/cluster/worker/manager.py => scrapy/contrib/cluster/worker/manager.py
rename : scrapy/trunk/scrapy/contrib/codecs/__init__.py => scrapy/contrib/codecs/__init__.py
rename : scrapy/trunk/scrapy/contrib/codecs/x_mac_roman.py => scrapy/contrib/codecs/x_mac_roman.py
rename : scrapy/trunk/scrapy/contrib/debug.py => scrapy/contrib/debug.py
rename : scrapy/trunk/scrapy/contrib/delayedclosedomain.py => scrapy/contrib/delayedclosedomain.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/__init__.py => scrapy/contrib/downloadermiddleware/__init__.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py => scrapy/contrib/downloadermiddleware/cache.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/common.py => scrapy/contrib/downloadermiddleware/common.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/cookies.py => scrapy/contrib/downloadermiddleware/cookies.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/debug.py => scrapy/contrib/downloadermiddleware/debug.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/errorpages.py => scrapy/contrib/downloadermiddleware/errorpages.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/httpauth.py => scrapy/contrib/downloadermiddleware/httpauth.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/httpcompression.py => scrapy/contrib/downloadermiddleware/httpcompression.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py => scrapy/contrib/downloadermiddleware/redirect.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py => scrapy/contrib/downloadermiddleware/retry.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/robotstxt.py => scrapy/contrib/downloadermiddleware/robotstxt.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/stats.py => scrapy/contrib/downloadermiddleware/stats.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/useragent.py => scrapy/contrib/downloadermiddleware/useragent.py
rename : scrapy/trunk/scrapy/contrib/groupsettings.py => scrapy/contrib/groupsettings.py
rename : scrapy/trunk/scrapy/contrib/item/__init__.py => scrapy/contrib/item/__init__.py
rename : scrapy/trunk/scrapy/contrib/item/models.py => scrapy/contrib/item/models.py
rename : scrapy/trunk/scrapy/contrib/itemsampler.py => scrapy/contrib/itemsampler.py
rename : scrapy/trunk/scrapy/contrib/link_extractors.py => scrapy/contrib/link_extractors.py
rename : scrapy/trunk/scrapy/contrib/memdebug.py => scrapy/contrib/memdebug.py
rename : scrapy/trunk/scrapy/contrib/memusage.py => scrapy/contrib/memusage.py
rename : scrapy/trunk/scrapy/contrib/pipeline/__init__.py => scrapy/contrib/pipeline/__init__.py
rename : scrapy/trunk/scrapy/contrib/pipeline/images.py => scrapy/contrib/pipeline/images.py
rename : scrapy/trunk/scrapy/contrib/pipeline/media.py => scrapy/contrib/pipeline/media.py
rename : scrapy/trunk/scrapy/contrib/pipeline/s3images.py => scrapy/contrib/pipeline/s3images.py
rename : scrapy/trunk/scrapy/contrib/pipeline/show.py => scrapy/contrib/pipeline/show.py
rename : scrapy/trunk/scrapy/contrib/prioritizers.py => scrapy/contrib/prioritizers.py
rename : scrapy/trunk/scrapy/contrib/response/__init__.py => scrapy/contrib/response/__init__.py
rename : scrapy/trunk/scrapy/contrib/response/soup.py => scrapy/contrib/response/soup.py
rename : scrapy/trunk/scrapy/contrib/schedulermiddleware/__init__.py => scrapy/contrib/schedulermiddleware/__init__.py
rename : scrapy/trunk/scrapy/contrib/schedulermiddleware/duplicatesfilter.py => scrapy/contrib/schedulermiddleware/duplicatesfilter.py
rename : scrapy/trunk/scrapy/contrib/spider/__init__.py => scrapy/contrib/spider/__init__.py
rename : scrapy/trunk/scrapy/contrib/spider/profiler.py => scrapy/contrib/spider/profiler.py
rename : scrapy/trunk/scrapy/contrib/spider/reloader.py => scrapy/contrib/spider/reloader.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/__init__.py => scrapy/contrib/spidermiddleware/__init__.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/depth.py => scrapy/contrib/spidermiddleware/depth.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py => scrapy/contrib/spidermiddleware/duplicatesfilter.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py => scrapy/contrib/spidermiddleware/limit.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/offsite.py => scrapy/contrib/spidermiddleware/offsite.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/referer.py => scrapy/contrib/spidermiddleware/referer.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/restrict.py => scrapy/contrib/spidermiddleware/restrict.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/urlfilter.py => scrapy/contrib/spidermiddleware/urlfilter.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/urllength.py => scrapy/contrib/spidermiddleware/urllength.py
rename : scrapy/trunk/scrapy/contrib/spiders/__init__.py => scrapy/contrib/spiders/__init__.py
rename : scrapy/trunk/scrapy/contrib/spiders/crawl.py => scrapy/contrib/spiders/crawl.py
rename : scrapy/trunk/scrapy/contrib/spiders/feed.py => scrapy/contrib/spiders/feed.py
rename : scrapy/trunk/scrapy/contrib/spiders/generic.py => scrapy/contrib/spiders/generic.py
rename : scrapy/trunk/scrapy/contrib/web/__init__.py => scrapy/contrib/web/__init__.py
rename : scrapy/trunk/scrapy/contrib/web/http.py => scrapy/contrib/web/http.py
rename : scrapy/trunk/scrapy/contrib/web/json.py => scrapy/contrib/web/json.py
rename : scrapy/trunk/scrapy/contrib/web/service.py => scrapy/contrib/web/service.py
rename : scrapy/trunk/scrapy/contrib/web/site.py => scrapy/contrib/web/site.py
rename : scrapy/trunk/scrapy/contrib/web/stats.py => scrapy/contrib/web/stats.py
rename : scrapy/trunk/scrapy/contrib/webconsole/__init__.py => scrapy/contrib/webconsole/__init__.py
rename : scrapy/trunk/scrapy/contrib/webconsole/enginestatus.py => scrapy/contrib/webconsole/enginestatus.py
rename : scrapy/trunk/scrapy/contrib/webconsole/livestats.py => scrapy/contrib/webconsole/livestats.py
rename : scrapy/trunk/scrapy/contrib/webconsole/scheduler.py => scrapy/contrib/webconsole/scheduler.py
rename : scrapy/trunk/scrapy/contrib/webconsole/spiderctl.py => scrapy/contrib/webconsole/spiderctl.py
rename : scrapy/trunk/scrapy/contrib/webconsole/spiderstats.py => scrapy/contrib/webconsole/spiderstats.py
rename : scrapy/trunk/scrapy/contrib/webconsole/stats.py => scrapy/contrib/webconsole/stats.py
rename : scrapy/trunk/scrapy/contrib_exp/__init__.py => scrapy/contrib_exp/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/adaptors/__init__.py => scrapy/contrib_exp/adaptors/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/adaptors/date.py => scrapy/contrib_exp/adaptors/date.py
rename : scrapy/trunk/scrapy/contrib_exp/adaptors/extraction.py => scrapy/contrib_exp/adaptors/extraction.py
rename : scrapy/trunk/scrapy/contrib_exp/adaptors/markup.py => scrapy/contrib_exp/adaptors/markup.py
rename : scrapy/trunk/scrapy/contrib_exp/adaptors/misc.py => scrapy/contrib_exp/adaptors/misc.py
rename : scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/__init__.py => scrapy/contrib_exp/downloadermiddleware/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/decompression.py => scrapy/contrib_exp/downloadermiddleware/decompression.py
rename : scrapy/trunk/scrapy/contrib_exp/history/__init__.py => scrapy/contrib_exp/history/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/history/history.py => scrapy/contrib_exp/history/history.py
rename : scrapy/trunk/scrapy/contrib_exp/history/middleware.py => scrapy/contrib_exp/history/middleware.py
rename : scrapy/trunk/scrapy/contrib_exp/history/scheduler.py => scrapy/contrib_exp/history/scheduler.py
rename : scrapy/trunk/scrapy/contrib_exp/history/store.py => scrapy/contrib_exp/history/store.py
rename : scrapy/trunk/scrapy/contrib_exp/link/__init__.py => scrapy/contrib_exp/link/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/newitem/__init__.py => scrapy/contrib_exp/newitem/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py => scrapy/contrib_exp/newitem/adaptors.py
rename : scrapy/trunk/scrapy/contrib_exp/newitem/fields.py => scrapy/contrib_exp/newitem/fields.py
rename : scrapy/trunk/scrapy/contrib_exp/newitem/models.py => scrapy/contrib_exp/newitem/models.py
rename : scrapy/trunk/scrapy/contrib_exp/pipeline/shoveitem.py => scrapy/contrib_exp/pipeline/shoveitem.py
rename : scrapy/trunk/scrapy/core/__init__.py => scrapy/core/__init__.py
rename : scrapy/trunk/scrapy/core/downloader/__init__.py => scrapy/core/downloader/__init__.py
rename : scrapy/trunk/scrapy/core/downloader/dnscache.py => scrapy/core/downloader/dnscache.py
rename : scrapy/trunk/scrapy/core/downloader/handlers.py => scrapy/core/downloader/handlers.py
rename : scrapy/trunk/scrapy/core/downloader/manager.py => scrapy/core/downloader/manager.py
rename : scrapy/trunk/scrapy/core/downloader/middleware.py => scrapy/core/downloader/middleware.py
rename : scrapy/trunk/scrapy/core/downloader/responsetypes/__init__.py => scrapy/core/downloader/responsetypes/__init__.py
rename : scrapy/trunk/scrapy/core/downloader/responsetypes/mime.types => scrapy/core/downloader/responsetypes/mime.types
rename : scrapy/trunk/scrapy/core/downloader/webclient.py => scrapy/core/downloader/webclient.py
rename : scrapy/trunk/scrapy/core/engine.py => scrapy/core/engine.py
rename : scrapy/trunk/scrapy/core/exceptions.py => scrapy/core/exceptions.py
rename : scrapy/trunk/scrapy/core/manager.py => scrapy/core/manager.py
rename : scrapy/trunk/scrapy/core/prioritizers.py => scrapy/core/prioritizers.py
rename : scrapy/trunk/scrapy/core/scheduler/__init__.py => scrapy/core/scheduler/__init__.py
rename : scrapy/trunk/scrapy/core/scheduler/middleware.py => scrapy/core/scheduler/middleware.py
rename : scrapy/trunk/scrapy/core/scheduler/schedulers.py => scrapy/core/scheduler/schedulers.py
rename : scrapy/trunk/scrapy/core/scheduler/store.py => scrapy/core/scheduler/store.py
rename : scrapy/trunk/scrapy/core/signals.py => scrapy/core/signals.py
rename : scrapy/trunk/scrapy/dupefilter/__init__.py => scrapy/dupefilter/__init__.py
rename : scrapy/trunk/scrapy/extension/__init__.py => scrapy/extension/__init__.py
rename : scrapy/trunk/scrapy/fetcher/__init__.py => scrapy/fetcher/__init__.py
rename : scrapy/trunk/scrapy/http/__init__.py => scrapy/http/__init__.py
rename : scrapy/trunk/scrapy/http/cookies.py => scrapy/http/cookies.py
rename : scrapy/trunk/scrapy/http/headers.py => scrapy/http/headers.py
rename : scrapy/trunk/scrapy/http/request/__init__.py => scrapy/http/request/__init__.py
rename : scrapy/trunk/scrapy/http/request/form.py => scrapy/http/request/form.py
rename : scrapy/trunk/scrapy/http/request/rpc.py => scrapy/http/request/rpc.py
rename : scrapy/trunk/scrapy/http/response/__init__.py => scrapy/http/response/__init__.py
rename : scrapy/trunk/scrapy/http/response/html.py => scrapy/http/response/html.py
rename : scrapy/trunk/scrapy/http/response/text.py => scrapy/http/response/text.py
rename : scrapy/trunk/scrapy/http/response/xml.py => scrapy/http/response/xml.py
rename : scrapy/trunk/scrapy/http/url.py => scrapy/http/url.py
rename : scrapy/trunk/scrapy/item/__init__.py => scrapy/item/__init__.py
rename : scrapy/trunk/scrapy/item/adaptors.py => scrapy/item/adaptors.py
rename : scrapy/trunk/scrapy/item/models.py => scrapy/item/models.py
rename : scrapy/trunk/scrapy/item/pipeline.py => scrapy/item/pipeline.py
rename : scrapy/trunk/scrapy/link/__init__.py => scrapy/link/__init__.py
rename : scrapy/trunk/scrapy/link/extractors.py => scrapy/link/extractors.py
rename : scrapy/trunk/scrapy/log/__init__.py => scrapy/log/__init__.py
rename : scrapy/trunk/scrapy/mail/__init__.py => scrapy/mail/__init__.py
rename : scrapy/trunk/scrapy/management/__init__.py => scrapy/management/__init__.py
rename : scrapy/trunk/scrapy/management/telnet.py => scrapy/management/telnet.py
rename : scrapy/trunk/scrapy/management/web.py => scrapy/management/web.py
rename : scrapy/trunk/scrapy/patches/__init__.py => scrapy/patches/__init__.py
rename : scrapy/trunk/scrapy/patches/monkeypatches.py => scrapy/patches/monkeypatches.py
rename : scrapy/trunk/scrapy/spider/__init__.py => scrapy/spider/__init__.py
rename : scrapy/trunk/scrapy/spider/manager.py => scrapy/spider/manager.py
rename : scrapy/trunk/scrapy/spider/middleware.py => scrapy/spider/middleware.py
rename : scrapy/trunk/scrapy/spider/models.py => scrapy/spider/models.py
rename : scrapy/trunk/scrapy/stats/__init__.py => scrapy/stats/__init__.py
rename : scrapy/trunk/scrapy/stats/corestats.py => scrapy/stats/corestats.py
rename : scrapy/trunk/scrapy/stats/statscollector.py => scrapy/stats/statscollector.py
rename : scrapy/trunk/scrapy/store/__init__.py => scrapy/store/__init__.py
rename : scrapy/trunk/scrapy/store/db.py => scrapy/store/db.py
rename : scrapy/trunk/scrapy/templates/project/module/__init__.py => scrapy/templates/project/module/__init__.py
rename : scrapy/trunk/scrapy/templates/project/module/items.py.tmpl => scrapy/templates/project/module/items.py.tmpl
rename : scrapy/trunk/scrapy/templates/project/module/pipelines.py.tmpl => scrapy/templates/project/module/pipelines.py.tmpl
rename : scrapy/trunk/scrapy/templates/project/module/settings.py.tmpl => scrapy/templates/project/module/settings.py.tmpl
rename : scrapy/trunk/scrapy/templates/project/module/spiders/__init__.py => scrapy/templates/project/module/spiders/__init__.py
rename : scrapy/trunk/scrapy/templates/project/module/templates/spider_basic.tmpl => scrapy/templates/project/module/templates/spider_basic.tmpl
rename : scrapy/trunk/scrapy/templates/project/module/templates/spider_crawl.tmpl => scrapy/templates/project/module/templates/spider_crawl.tmpl
rename : scrapy/trunk/scrapy/templates/project/module/templates/spider_csvfeed.tmpl => scrapy/templates/project/module/templates/spider_csvfeed.tmpl
rename : scrapy/trunk/scrapy/templates/project/module/templates/spider_xmlfeed.tmpl => scrapy/templates/project/module/templates/spider_xmlfeed.tmpl
rename : scrapy/trunk/scrapy/templates/project/root/scrapy-ctl.py => scrapy/templates/project/root/scrapy-ctl.py
rename : scrapy/trunk/scrapy/tests/__init__.py => scrapy/tests/__init__.py
rename : scrapy/trunk/scrapy/tests/run.py => scrapy/tests/run.py
rename : scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-ascii.html => scrapy/tests/sample_data/adaptors/enc-ascii.html
rename : scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-cp1252.html => scrapy/tests/sample_data/adaptors/enc-cp1252.html
rename : scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-latin1.html => scrapy/tests/sample_data/adaptors/enc-latin1.html
rename : scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-utf8-meta-latin1.html => scrapy/tests/sample_data/adaptors/enc-utf8-meta-latin1.html
rename : scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-utf8.html => scrapy/tests/sample_data/adaptors/enc-utf8.html
rename : scrapy/trunk/scrapy/tests/sample_data/adaptors/extr_unquoted.xml => scrapy/tests/sample_data/adaptors/extr_unquoted.xml
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.tar => scrapy/tests/sample_data/compressed/feed-sample1.tar
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml => scrapy/tests/sample_data/compressed/feed-sample1.xml
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml.bz2 => scrapy/tests/sample_data/compressed/feed-sample1.xml.bz2
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml.gz => scrapy/tests/sample_data/compressed/feed-sample1.xml.gz
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.zip => scrapy/tests/sample_data/compressed/feed-sample1.zip
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/html-gzip.bin => scrapy/tests/sample_data/compressed/html-gzip.bin
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/html-rawdeflate.bin => scrapy/tests/sample_data/compressed/html-rawdeflate.bin
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/html-zlibdeflate.bin => scrapy/tests/sample_data/compressed/html-zlibdeflate.bin
rename : scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample1.xml => scrapy/tests/sample_data/feeds/feed-sample1.xml
rename : scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample2.xml => scrapy/tests/sample_data/feeds/feed-sample2.xml
rename : scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample3.csv => scrapy/tests/sample_data/feeds/feed-sample3.csv
rename : scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample4.csv => scrapy/tests/sample_data/feeds/feed-sample4.csv
rename : scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample5.csv => scrapy/tests/sample_data/feeds/feed-sample5.csv
rename : scrapy/trunk/scrapy/tests/sample_data/link_extractor/image_linkextractor.html => scrapy/tests/sample_data/link_extractor/image_linkextractor.html
rename : scrapy/trunk/scrapy/tests/sample_data/link_extractor/linkextractor_latin1.html => scrapy/tests/sample_data/link_extractor/linkextractor_latin1.html
rename : scrapy/trunk/scrapy/tests/sample_data/link_extractor/linkextractor_noenc.html => scrapy/tests/sample_data/link_extractor/linkextractor_noenc.html
rename : scrapy/trunk/scrapy/tests/sample_data/link_extractor/regex_linkextractor.html => scrapy/tests/sample_data/link_extractor/regex_linkextractor.html
rename : scrapy/trunk/scrapy/tests/sample_data/test_site/index.html => scrapy/tests/sample_data/test_site/index.html
rename : scrapy/trunk/scrapy/tests/sample_data/test_site/item1.html => scrapy/tests/sample_data/test_site/item1.html
rename : scrapy/trunk/scrapy/tests/sample_data/test_site/item2.html => scrapy/tests/sample_data/test_site/item2.html
rename : scrapy/trunk/scrapy/tests/test_adaptors.py => scrapy/tests/test_adaptors.py
rename : scrapy/trunk/scrapy/tests/test_aws.py => scrapy/tests/test_aws.py
rename : scrapy/trunk/scrapy/tests/test_c14nurls.py => scrapy/tests/test_c14nurls.py
rename : scrapy/trunk/scrapy/tests/test_contrib_response_soup.py => scrapy/tests/test_contrib_response_soup.py
rename : scrapy/trunk/scrapy/tests/test_dependencies.py => scrapy/tests/test_dependencies.py
rename : scrapy/trunk/scrapy/tests/test_downloadermiddleware_cookies.py => scrapy/tests/test_downloadermiddleware_cookies.py
rename : scrapy/trunk/scrapy/tests/test_downloadermiddleware_decompression.py => scrapy/tests/test_downloadermiddleware_decompression.py
rename : scrapy/trunk/scrapy/tests/test_downloadermiddleware_httpcompression.py => scrapy/tests/test_downloadermiddleware_httpcompression.py
rename : scrapy/trunk/scrapy/tests/test_downloadermiddleware_redirect.py => scrapy/tests/test_downloadermiddleware_redirect.py
rename : scrapy/trunk/scrapy/tests/test_downloadermiddleware_retry.py => scrapy/tests/test_downloadermiddleware_retry.py
rename : scrapy/trunk/scrapy/tests/test_downloadermiddleware_useragent.py => scrapy/tests/test_downloadermiddleware_useragent.py
rename : scrapy/trunk/scrapy/tests/test_dupefilter.py => scrapy/tests/test_dupefilter.py
rename : scrapy/trunk/scrapy/tests/test_engine.py => scrapy/tests/test_engine.py
rename : scrapy/trunk/scrapy/tests/test_http_cookies.py => scrapy/tests/test_http_cookies.py
rename : scrapy/trunk/scrapy/tests/test_http_headers.py => scrapy/tests/test_http_headers.py
rename : scrapy/trunk/scrapy/tests/test_http_request.py => scrapy/tests/test_http_request.py
rename : scrapy/trunk/scrapy/tests/test_http_response.py => scrapy/tests/test_http_response.py
rename : scrapy/trunk/scrapy/tests/test_http_url.py => scrapy/tests/test_http_url.py
rename : scrapy/trunk/scrapy/tests/test_item.py => scrapy/tests/test_item.py
rename : scrapy/trunk/scrapy/tests/test_itemadaptor.py => scrapy/tests/test_itemadaptor.py
rename : scrapy/trunk/scrapy/tests/test_libxml2.py => scrapy/tests/test_libxml2.py
rename : scrapy/trunk/scrapy/tests/test_link.py => scrapy/tests/test_link.py
rename : scrapy/trunk/scrapy/tests/test_newitem.py => scrapy/tests/test_newitem.py
rename : scrapy/trunk/scrapy/tests/test_pipeline_images.py => scrapy/tests/test_pipeline_images.py
rename : scrapy/trunk/scrapy/tests/test_responsetypes.py => scrapy/tests/test_responsetypes.py
rename : scrapy/trunk/scrapy/tests/test_robustscrapeditem.py => scrapy/tests/test_robustscrapeditem.py
rename : scrapy/trunk/scrapy/tests/test_schedulermiddleware_duplicatesfilter.py => scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
rename : scrapy/trunk/scrapy/tests/test_serialization.py => scrapy/tests/test_serialization.py
rename : scrapy/trunk/scrapy/tests/test_spidermiddleware_duplicatesfilter.py => scrapy/tests/test_spidermiddleware_duplicatesfilter.py
rename : scrapy/trunk/scrapy/tests/test_spidermonkey.py => scrapy/tests/test_spidermonkey.py
rename : scrapy/trunk/scrapy/tests/test_spiders/__init__.py => scrapy/tests/test_spiders/__init__.py
rename : scrapy/trunk/scrapy/tests/test_spiders/testspider.py => scrapy/tests/test_spiders/testspider.py
rename : scrapy/trunk/scrapy/tests/test_stats.py => scrapy/tests/test_stats.py
rename : scrapy/trunk/scrapy/tests/test_storedb.py => scrapy/tests/test_storedb.py
rename : scrapy/trunk/scrapy/tests/test_utils_datatypes.py => scrapy/tests/test_utils_datatypes.py
rename : scrapy/trunk/scrapy/tests/test_utils_defer.py => scrapy/tests/test_utils_defer.py
rename : scrapy/trunk/scrapy/tests/test_utils_iterators.py => scrapy/tests/test_utils_iterators.py
rename : scrapy/trunk/scrapy/tests/test_utils_markup.py => scrapy/tests/test_utils_markup.py
rename : scrapy/trunk/scrapy/tests/test_utils_misc.py => scrapy/tests/test_utils_misc.py
rename : scrapy/trunk/scrapy/tests/test_utils_python.py => scrapy/tests/test_utils_python.py
rename : scrapy/trunk/scrapy/tests/test_utils_request.py => scrapy/tests/test_utils_request.py
rename : scrapy/trunk/scrapy/tests/test_utils_response.py => scrapy/tests/test_utils_response.py
rename : scrapy/trunk/scrapy/tests/test_utils_url.py => scrapy/tests/test_utils_url.py
rename : scrapy/trunk/scrapy/tests/test_webclient.py => scrapy/tests/test_webclient.py
rename : scrapy/trunk/scrapy/tests/test_xpath.py => scrapy/tests/test_xpath.py
rename : scrapy/trunk/scrapy/tests/test_xpath_extension.py => scrapy/tests/test_xpath_extension.py
rename : scrapy/trunk/scrapy/utils/__init__.py => scrapy/utils/__init__.py
rename : scrapy/trunk/scrapy/utils/c14n.py => scrapy/utils/c14n.py
rename : scrapy/trunk/scrapy/utils/datatypes.py => scrapy/utils/datatypes.py
rename : scrapy/trunk/scrapy/utils/db.py => scrapy/utils/db.py
rename : scrapy/trunk/scrapy/utils/defer.py => scrapy/utils/defer.py
rename : scrapy/trunk/scrapy/utils/display.py => scrapy/utils/display.py
rename : scrapy/trunk/scrapy/utils/http.py => scrapy/utils/http.py
rename : scrapy/trunk/scrapy/utils/iterators.py => scrapy/utils/iterators.py
rename : scrapy/trunk/scrapy/utils/markup.py => scrapy/utils/markup.py
rename : scrapy/trunk/scrapy/utils/misc.py => scrapy/utils/misc.py
rename : scrapy/trunk/scrapy/utils/python.py => scrapy/utils/python.py
rename : scrapy/trunk/scrapy/utils/request.py => scrapy/utils/request.py
rename : scrapy/trunk/scrapy/utils/response.py => scrapy/utils/response.py
rename : scrapy/trunk/scrapy/utils/serialization.py => scrapy/utils/serialization.py
rename : scrapy/trunk/scrapy/utils/test.py => scrapy/utils/test.py
rename : scrapy/trunk/scrapy/utils/url.py => scrapy/utils/url.py
rename : scrapy/trunk/scrapy/xlib/BeautifulSoup.py => scrapy/xlib/BeautifulSoup.py
rename : scrapy/trunk/scrapy/xlib/ClientForm.py => scrapy/xlib/ClientForm.py
rename : scrapy/trunk/scrapy/xlib/__init__.py => scrapy/xlib/__init__.py
rename : scrapy/trunk/scrapy/xlib/lrucache.py => scrapy/xlib/lrucache.py
rename : scrapy/trunk/scrapy/xlib/lsprofcalltree.py => scrapy/xlib/lsprofcalltree.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/__init__.py => scrapy/xlib/pydispatch/__init__.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/dispatcher.py => scrapy/xlib/pydispatch/dispatcher.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/errors.py => scrapy/xlib/pydispatch/errors.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/license.txt => scrapy/xlib/pydispatch/license.txt
rename : scrapy/trunk/scrapy/xlib/pydispatch/robust.py => scrapy/xlib/pydispatch/robust.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/robustapply.py => scrapy/xlib/pydispatch/robustapply.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/saferef.py => scrapy/xlib/pydispatch/saferef.py
rename : scrapy/trunk/scrapy/xlib/spidermonkey/INSTALL.scrapy => scrapy/xlib/spidermonkey/INSTALL.scrapy
rename : scrapy/trunk/scrapy/xlib/spidermonkey/__init__.py => scrapy/xlib/spidermonkey/__init__.py
rename : scrapy/trunk/scrapy/xlib/spidermonkey/sm_settings.py => scrapy/xlib/spidermonkey/sm_settings.py
rename : scrapy/trunk/scrapy/xlib/spidermonkey/spidermonkey.py => scrapy/xlib/spidermonkey/spidermonkey.py
rename : scrapy/trunk/scrapy/xpath/__init__.py => scrapy/xpath/__init__.py
rename : scrapy/trunk/scrapy/xpath/constructors.py => scrapy/xpath/constructors.py
rename : scrapy/trunk/scrapy/xpath/document.py => scrapy/xpath/document.py
rename : scrapy/trunk/scrapy/xpath/extension.py => scrapy/xpath/extension.py
rename : scrapy/trunk/scrapy/xpath/selector.py => scrapy/xpath/selector.py
rename : scrapy/trunk/scrapy/xpath/types.py => scrapy/xpath/types.py
rename : scrapy/trunk/scripts/rpm-install.sh => scripts/rpm-install.sh
rename : scrapy/trunk/setup.cfg => setup.cfg
rename : scrapy/trunk/setup.py => setup.py

==

AUTHORS
INSTALL
LICENSE
README
bin/runtests.sh
docs/Makefile
docs/README
docs/_ext/scrapydocs.py
docs/_static/items_adaptors-sample1.html
docs/_static/scrapydoc.css
docs/_static/selectors-sample1.html
docs/conf.py
docs/faq.rst
docs/index.rst
docs/intro/index.rst
docs/intro/install.rst
docs/intro/overview.rst
docs/intro/tutorial.rst
docs/media/scrapy-architecture.dia
docs/misc/api-stability.rst
docs/misc/index.rst
docs/proposed/_images/scrapy_architecture.odg
docs/proposed/_images/scrapy_architecture.png
docs/proposed/index.rst
docs/proposed/introduction.rst
docs/proposed/newitem.rst
docs/proposed/spiders.rst
docs/ref/downloader-middleware.rst
docs/ref/email.rst
docs/ref/exceptions.rst
docs/ref/extension-manager.rst
docs/ref/extensions.rst
docs/ref/index.rst
docs/ref/link-extractors.rst
docs/ref/logging.rst
docs/ref/request-response.rst
docs/ref/selectors.rst
docs/ref/settings.rst
docs/ref/signals.rst
docs/ref/spiders.rst
docs/topics/_images/adaptors_diagram.png
docs/topics/_images/adaptors_diagram.svg
docs/topics/_images/firebug1.png
docs/topics/_images/firebug2.png
docs/topics/_images/firebug3.png
docs/topics/_images/scrapy_architecture.odg
docs/topics/_images/scrapy_architecture.png
docs/topics/adaptors.rst
docs/topics/architecture.rst
docs/topics/downloader-middleware.rst
docs/topics/extensions.rst
docs/topics/firebug.rst
docs/topics/firefox.rst
docs/topics/index.rst
docs/topics/item-pipeline.rst
docs/topics/items.rst
docs/topics/link-extractors.rst
docs/topics/robotstxt.rst
docs/topics/selectors.rst
docs/topics/settings.rst
docs/topics/shell.rst
docs/topics/spider-middleware.rst
docs/topics/spiders.rst
docs/topics/stats.rst
docs/topics/webconsole.rst
examples/experimental/googledir/googledir/__init__.py
examples/experimental/googledir/googledir/items.py
examples/experimental/googledir/googledir/pipelines.py
examples/experimental/googledir/googledir/settings.py
examples/experimental/googledir/googledir/spiders/__init__.py
examples/experimental/googledir/googledir/spiders/google_directory.py
examples/experimental/googledir/googledir/templates/spider_basic.tmpl
examples/experimental/googledir/googledir/templates/spider_crawl.tmpl
examples/experimental/googledir/googledir/templates/spider_csvfeed.tmpl
examples/experimental/googledir/googledir/templates/spider_xmlfeed.tmpl
examples/experimental/googledir/scrapy-ctl.py
examples/googledir/googledir/__init__.py
examples/googledir/googledir/items.py
examples/googledir/googledir/pipelines.py
examples/googledir/googledir/settings.py
examples/googledir/googledir/spiders/__init__.py
examples/googledir/googledir/spiders/google_directory.py
examples/googledir/scrapy-ctl.py
extras/sql/scraping.sql
profiling/priorityqueue/pq_classes.py
profiling/priorityqueue/run.py
profiling/priorityqueue/test_cases.py
scrapy/__init__.py
scrapy/bin/scrapy-admin.py
scrapy/branches/cluster-refactor/INSTALL
scrapy/branches/cluster-refactor/scrapy/__init__.py
scrapy/branches/cluster-refactor/scrapy/bin/scrapy-admin.py
scrapy/branches/cluster-refactor/scrapy/command/cmdline.py
scrapy/branches/cluster-refactor/scrapy/command/commands/crawl.py
scrapy/branches/cluster-refactor/scrapy/command/commands/genspider.py
scrapy/branches/cluster-refactor/scrapy/command/commands/getattr.py
scrapy/branches/cluster-refactor/scrapy/command/commands/parse.py
scrapy/branches/cluster-refactor/scrapy/command/commands/replay.py
scrapy/branches/cluster-refactor/scrapy/command/commands/shell.py
scrapy/branches/cluster-refactor/scrapy/command/commands/stats.py
scrapy/branches/cluster-refactor/scrapy/command/models.py
scrapy/branches/cluster-refactor/scrapy/conf/__init__.py
scrapy/branches/cluster-refactor/scrapy/conf/core_settings.py
scrapy/branches/cluster-refactor/scrapy/conf/project_template/items.py
scrapy/branches/cluster-refactor/scrapy/conf/project_template/scrapy-ctl.py
scrapy/branches/cluster-refactor/scrapy/conf/project_template/scrapy_settings.py
scrapy/branches/cluster-refactor/scrapy/contrib/adaptorpipeline.py
scrapy/branches/cluster-refactor/scrapy/contrib/closedomain.py
scrapy/branches/cluster-refactor/scrapy/contrib/debug.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/cache.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/common.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/compression.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/cookies.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/debug.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/retry.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/robots.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/useragent.py
scrapy/branches/cluster-refactor/scrapy/contrib/history/middleware.py
scrapy/branches/cluster-refactor/scrapy/contrib/history/scheduler.py
scrapy/branches/cluster-refactor/scrapy/contrib/item/models.py
scrapy/branches/cluster-refactor/scrapy/contrib/memdebug.py
scrapy/branches/cluster-refactor/scrapy/contrib/memusage.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/images.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/media.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/s3images.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/shoveitem.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/show.py
scrapy/branches/cluster-refactor/scrapy/contrib/response/soup.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/depth.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/limit.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/offsite.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/referer.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/restrict.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/urlfilter.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/urllength.py
scrapy/branches/cluster-refactor/scrapy/contrib/spiders.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/livestats.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/schedstats.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/spiderctl.py
scrapy/branches/cluster-refactor/scrapy/core/downloader/handlers.py
scrapy/branches/cluster-refactor/scrapy/core/downloader/manager.py
scrapy/branches/cluster-refactor/scrapy/core/downloader/middleware.py
scrapy/branches/cluster-refactor/scrapy/core/engine.py
scrapy/branches/cluster-refactor/scrapy/core/exceptions.py
scrapy/branches/cluster-refactor/scrapy/core/manager.py
scrapy/branches/cluster-refactor/scrapy/core/scheduler/__init__.py
scrapy/branches/cluster-refactor/scrapy/core/scheduler/filter.py
scrapy/branches/cluster-refactor/scrapy/core/scheduler/schedulers.py
scrapy/branches/cluster-refactor/scrapy/core/signals.py
scrapy/branches/cluster-refactor/scrapy/extension/__init__.py
scrapy/branches/cluster-refactor/scrapy/http/__init__.py
scrapy/branches/cluster-refactor/scrapy/http/headers.py
scrapy/branches/cluster-refactor/scrapy/http/request.py
scrapy/branches/cluster-refactor/scrapy/http/response.py
scrapy/branches/cluster-refactor/scrapy/item/__init__.py
scrapy/branches/cluster-refactor/scrapy/item/adaptors.py
scrapy/branches/cluster-refactor/scrapy/item/models.py
scrapy/branches/cluster-refactor/scrapy/item/pipeline.py
scrapy/branches/cluster-refactor/scrapy/link/__init__.py
scrapy/branches/cluster-refactor/scrapy/link/extractors.py
scrapy/branches/cluster-refactor/scrapy/log/__init__.py
scrapy/branches/cluster-refactor/scrapy/mail/__init__.py
scrapy/branches/cluster-refactor/scrapy/management/web.py
scrapy/branches/cluster-refactor/scrapy/patches/monkeypatches.py
scrapy/branches/cluster-refactor/scrapy/replay/__init__.py
scrapy/branches/cluster-refactor/scrapy/spider/manager.py
scrapy/branches/cluster-refactor/scrapy/spider/middleware.py
scrapy/branches/cluster-refactor/scrapy/spider/models.py
scrapy/branches/cluster-refactor/scrapy/stats/corestats.py
scrapy/branches/cluster-refactor/scrapy/tests/__init__.py
scrapy/branches/cluster-refactor/scrapy/tests/test_adaptors.py
scrapy/branches/cluster-refactor/scrapy/tests/test_decompress.py
scrapy/branches/cluster-refactor/scrapy/tests/test_defaultencoding.py
scrapy/branches/cluster-refactor/scrapy/tests/test_engine.py
scrapy/branches/cluster-refactor/scrapy/tests/test_http_request.py
scrapy/branches/cluster-refactor/scrapy/tests/test_http_response.py
scrapy/branches/cluster-refactor/scrapy/tests/test_http_url.py
scrapy/branches/cluster-refactor/scrapy/tests/test_libxml2.py
scrapy/branches/cluster-refactor/scrapy/tests/test_link.py
scrapy/branches/cluster-refactor/scrapy/tests/test_pipeline_images.py
scrapy/branches/cluster-refactor/scrapy/tests/test_serialization.py
scrapy/branches/cluster-refactor/scrapy/tests/test_spiders/testplugin.py
scrapy/branches/cluster-refactor/scrapy/tests/test_storedb.py
scrapy/branches/cluster-refactor/scrapy/tests/test_utils_datatypes.py
scrapy/branches/cluster-refactor/scrapy/tests/test_utils_markup.py
scrapy/branches/cluster-refactor/scrapy/tests/test_utils_url.py
scrapy/branches/cluster-refactor/scrapy/tests/test_utils_xml.py
scrapy/branches/cluster-refactor/scrapy/tests/test_xpath.py
scrapy/branches/cluster-refactor/scrapy/utils/datatypes.py
scrapy/branches/cluster-refactor/scrapy/utils/db.py
scrapy/branches/cluster-refactor/scrapy/utils/decompressor.py
scrapy/branches/cluster-refactor/scrapy/utils/defer.py
scrapy/branches/cluster-refactor/scrapy/utils/iterators.py
scrapy/branches/cluster-refactor/scrapy/utils/markup.py
scrapy/branches/cluster-refactor/scrapy/utils/misc.py
scrapy/branches/cluster-refactor/scrapy/utils/python.py
scrapy/branches/cluster-refactor/scrapy/utils/response.py
scrapy/branches/cluster-refactor/scrapy/utils/url.py
scrapy/branches/cluster-refactor/scrapy/utils/xml.py
scrapy/branches/cluster-refactor/scrapy/xpath/constructors.py
scrapy/branches/cluster-refactor/scrapy/xpath/extension.py
scrapy/branches/cluster-refactor/scrapy/xpath/selector.py
scrapy/branches/cluster-refactor/setup.cfg
scrapy/branches/cluster-refactor/setup.py
scrapy/command/__init__.py
scrapy/command/cmdline.py
scrapy/command/commands/__init__.py
scrapy/command/commands/crawl.py
scrapy/command/commands/download.py
scrapy/command/commands/genspider.py
scrapy/command/commands/help.py
scrapy/command/commands/list.py
scrapy/command/commands/log.py
scrapy/command/commands/parse.py
scrapy/command/commands/shell.py
scrapy/command/commands/start.py
scrapy/command/commands/stats.py
scrapy/command/models.py
scrapy/conf/__init__.py
scrapy/conf/commands/__init__.py
scrapy/conf/commands/crawl.py
scrapy/conf/commands/help.py
scrapy/conf/commands/list.py
scrapy/conf/commands/log.py
scrapy/conf/commands/scrape.py
scrapy/conf/commands/shell.py
scrapy/conf/commands/stats.py
scrapy/conf/commands/test.py
scrapy/conf/default_settings.py
scrapy/contrib/__init__.py
scrapy/contrib/aws.py
scrapy/contrib/closedomain.py
scrapy/contrib/cluster/__init__.py
scrapy/contrib/cluster/crawler/__init__.py
scrapy/contrib/cluster/crawler/manager.py
scrapy/contrib/cluster/hooks/__init__.py
scrapy/contrib/cluster/hooks/svn.py
scrapy/contrib/cluster/master/__init__.py
scrapy/contrib/cluster/master/manager.py
scrapy/contrib/cluster/master/web.py
scrapy/contrib/cluster/master/ws_api.txt
scrapy/contrib/cluster/tools/scrapy-cluster-ctl.py
scrapy/contrib/cluster/tools/test-worker.py
scrapy/contrib/cluster/worker/__init__.py
scrapy/contrib/cluster/worker/manager.py
scrapy/contrib/codecs/__init__.py
scrapy/contrib/codecs/x_mac_roman.py
scrapy/contrib/debug.py
scrapy/contrib/delayedclosedomain.py
scrapy/contrib/downloadermiddleware/__init__.py
scrapy/contrib/downloadermiddleware/cache.py
scrapy/contrib/downloadermiddleware/common.py
scrapy/contrib/downloadermiddleware/cookies.py
scrapy/contrib/downloadermiddleware/debug.py
scrapy/contrib/downloadermiddleware/errorpages.py
scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/contrib/downloadermiddleware/redirect.py
scrapy/contrib/downloadermiddleware/retry.py
scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/contrib/downloadermiddleware/stats.py
scrapy/contrib/downloadermiddleware/useragent.py
scrapy/contrib/groupsettings.py
scrapy/contrib/item/__init__.py
scrapy/contrib/item/models.py
scrapy/contrib/itemsampler.py
scrapy/contrib/link_extractors.py
scrapy/contrib/memdebug.py
scrapy/contrib/memusage.py
scrapy/contrib/pipeline/__init__.py
scrapy/contrib/pipeline/images.py
scrapy/contrib/pipeline/media.py
scrapy/contrib/pipeline/s3images.py
scrapy/contrib/pipeline/show.py
scrapy/contrib/prioritizers.py
scrapy/contrib/response/__init__.py
scrapy/contrib/response/soup.py
scrapy/contrib/schedulermiddleware/__init__.py
scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/contrib/spider/__init__.py
scrapy/contrib/spider/profiler.py
scrapy/contrib/spider/reloader.py
scrapy/contrib/spidermiddleware/__init__.py
scrapy/contrib/spidermiddleware/depth.py
scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/contrib/spidermiddleware/limit.py
scrapy/contrib/spidermiddleware/offsite.py
scrapy/contrib/spidermiddleware/referer.py
scrapy/contrib/spidermiddleware/restrict.py
scrapy/contrib/spidermiddleware/urlfilter.py
scrapy/contrib/spidermiddleware/urllength.py
scrapy/contrib/spiders/__init__.py
scrapy/contrib/spiders/crawl.py
scrapy/contrib/spiders/feed.py
scrapy/contrib/spiders/generic.py
scrapy/contrib/web/__init__.py
scrapy/contrib/web/http.py
scrapy/contrib/web/json.py
scrapy/contrib/web/service.py
scrapy/contrib/web/site.py
scrapy/contrib/web/stats.py
scrapy/contrib/webconsole/__init__.py
scrapy/contrib/webconsole/enginestatus.py
scrapy/contrib/webconsole/livestats.py
scrapy/contrib/webconsole/scheduler.py
scrapy/contrib/webconsole/spiderctl.py
scrapy/contrib/webconsole/spiderstats.py
scrapy/contrib/webconsole/stats.py
scrapy/contrib_exp/__init__.py
scrapy/contrib_exp/adaptors/__init__.py
scrapy/contrib_exp/adaptors/date.py
scrapy/contrib_exp/adaptors/extraction.py
scrapy/contrib_exp/adaptors/markup.py
scrapy/contrib_exp/adaptors/misc.py
scrapy/contrib_exp/downloadermiddleware/__init__.py
scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/contrib_exp/history/__init__.py
scrapy/contrib_exp/history/history.py
scrapy/contrib_exp/history/middleware.py
scrapy/contrib_exp/history/scheduler.py
scrapy/contrib_exp/history/store.py
scrapy/contrib_exp/link/__init__.py
scrapy/contrib_exp/newitem/__init__.py
scrapy/contrib_exp/newitem/adaptors.py
scrapy/contrib_exp/newitem/fields.py
scrapy/contrib_exp/newitem/models.py
scrapy/contrib_exp/pipeline/shoveitem.py
scrapy/core/__init__.py
scrapy/core/downloader/__init__.py
scrapy/core/downloader/dnscache.py
scrapy/core/downloader/handlers.py
scrapy/core/downloader/manager.py
scrapy/core/downloader/middleware.py
scrapy/core/downloader/responsetypes/__init__.py
scrapy/core/downloader/responsetypes/mime.types
scrapy/core/downloader/webclient.py
scrapy/core/engine.py
scrapy/core/exceptions.py
scrapy/core/manager.py
scrapy/core/prioritizers.py
scrapy/core/scheduler/__init__.py
scrapy/core/scheduler/middleware.py
scrapy/core/scheduler/schedulers.py
scrapy/core/scheduler/store.py
scrapy/core/signals.py
scrapy/dupefilter/__init__.py
scrapy/extension/__init__.py
scrapy/fetcher/__init__.py
scrapy/http/__init__.py
scrapy/http/cookies.py
scrapy/http/headers.py
scrapy/http/request/__init__.py
scrapy/http/request/form.py
scrapy/http/request/rpc.py
scrapy/http/response/__init__.py
scrapy/http/response/html.py
scrapy/http/response/text.py
scrapy/http/response/xml.py
scrapy/http/url.py
scrapy/item/__init__.py
scrapy/item/adaptors.py
scrapy/item/models.py
scrapy/item/pipeline.py
scrapy/link/__init__.py
scrapy/link/extractors.py
scrapy/log/__init__.py
scrapy/mail/__init__.py
scrapy/management/__init__.py
scrapy/management/telnet.py
scrapy/management/web.py
scrapy/patches/__init__.py
scrapy/patches/monkeypatches.py
scrapy/spider/__init__.py
scrapy/spider/manager.py
scrapy/spider/middleware.py
scrapy/spider/models.py
scrapy/stats/__init__.py
scrapy/stats/corestats.py
scrapy/stats/statscollector.py
scrapy/store/__init__.py
scrapy/store/db.py
scrapy/templates/project/module/__init__.py
scrapy/templates/project/module/items.py.tmpl
scrapy/templates/project/module/pipelines.py.tmpl
scrapy/templates/project/module/settings.py.tmpl
scrapy/templates/project/module/spiders/__init__.py
scrapy/templates/project/module/templates/spider_basic.tmpl
scrapy/templates/project/module/templates/spider_crawl.tmpl
scrapy/templates/project/module/templates/spider_csvfeed.tmpl
scrapy/templates/project/module/templates/spider_xmlfeed.tmpl
scrapy/templates/project/root/scrapy-ctl.py
scrapy/tests/__init__.py
scrapy/tests/run.py
scrapy/tests/sample_data/adaptors/enc-ascii.html
scrapy/tests/sample_data/adaptors/enc-cp1252.html
scrapy/tests/sample_data/adaptors/enc-latin1.html
scrapy/tests/sample_data/adaptors/enc-utf8-meta-latin1.html
scrapy/tests/sample_data/adaptors/enc-utf8.html
scrapy/tests/sample_data/adaptors/extr_unquoted.xml
scrapy/tests/sample_data/compressed/feed-sample1.tar
scrapy/tests/sample_data/compressed/feed-sample1.xml
scrapy/tests/sample_data/compressed/feed-sample1.xml.bz2
scrapy/tests/sample_data/compressed/feed-sample1.xml.gz
scrapy/tests/sample_data/compressed/feed-sample1.zip
scrapy/tests/sample_data/compressed/html-gzip.bin
scrapy/tests/sample_data/compressed/html-rawdeflate.bin
scrapy/tests/sample_data/compressed/html-zlibdeflate.bin
scrapy/tests/sample_data/feeds/feed-sample1.xml
scrapy/tests/sample_data/feeds/feed-sample2.xml
scrapy/tests/sample_data/feeds/feed-sample3.csv
scrapy/tests/sample_data/feeds/feed-sample4.csv
scrapy/tests/sample_data/feeds/feed-sample5.csv
scrapy/tests/sample_data/link_extractor/image_linkextractor.html
scrapy/tests/sample_data/link_extractor/linkextractor_latin1.html
scrapy/tests/sample_data/link_extractor/linkextractor_noenc.html
scrapy/tests/sample_data/link_extractor/regex_linkextractor.html
scrapy/tests/sample_data/test_site/index.html
scrapy/tests/sample_data/test_site/item1.html
scrapy/tests/sample_data/test_site/item2.html
scrapy/tests/test_adaptors.py
scrapy/tests/test_aws.py
scrapy/tests/test_c14nurls.py
scrapy/tests/test_contrib_response_soup.py
scrapy/tests/test_dependencies.py
scrapy/tests/test_downloadermiddleware_cookies.py
scrapy/tests/test_downloadermiddleware_decompression.py
scrapy/tests/test_downloadermiddleware_httpcompression.py
scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/tests/test_downloadermiddleware_retry.py
scrapy/tests/test_downloadermiddleware_useragent.py
scrapy/tests/test_dupefilter.py
scrapy/tests/test_engine.py
scrapy/tests/test_http_cookies.py
scrapy/tests/test_http_headers.py
scrapy/tests/test_http_request.py
scrapy/tests/test_http_response.py
scrapy/tests/test_http_url.py
scrapy/tests/test_item.py
scrapy/tests/test_itemadaptor.py
scrapy/tests/test_libxml2.py
scrapy/tests/test_link.py
scrapy/tests/test_newitem.py
scrapy/tests/test_pipeline_images.py
scrapy/tests/test_responsetypes.py
scrapy/tests/test_robustscrapeditem.py
scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
scrapy/tests/test_serialization.py
scrapy/tests/test_spidermiddleware_duplicatesfilter.py
scrapy/tests/test_spidermonkey.py
scrapy/tests/test_spiders/__init__.py
scrapy/tests/test_spiders/testspider.py
scrapy/tests/test_stats.py
scrapy/tests/test_storedb.py
scrapy/tests/test_utils_datatypes.py
scrapy/tests/test_utils_defer.py
scrapy/tests/test_utils_iterators.py
scrapy/tests/test_utils_markup.py
scrapy/tests/test_utils_misc.py
scrapy/tests/test_utils_python.py
scrapy/tests/test_utils_request.py
scrapy/tests/test_utils_response.py
scrapy/tests/test_utils_url.py
scrapy/tests/test_webclient.py
scrapy/tests/test_xpath.py
scrapy/tests/test_xpath_extension.py
scrapy/trunk/README
scrapy/trunk/docs/media/scrapy-architecture.dia
scrapy/trunk/extras/sql/scraping.sql
scrapy/trunk/scrapy/command/__init__.py
scrapy/trunk/scrapy/command/commands/download.py
scrapy/trunk/scrapy/command/commands/help.py
scrapy/trunk/scrapy/command/commands/list.py
scrapy/trunk/scrapy/command/commands/log.py
scrapy/trunk/scrapy/command/commands/start.py
scrapy/trunk/scrapy/conf/commands/crawl.py
scrapy/trunk/scrapy/conf/commands/help.py
scrapy/trunk/scrapy/conf/commands/list.py
scrapy/trunk/scrapy/conf/commands/log.py
scrapy/trunk/scrapy/conf/commands/scrape.py
scrapy/trunk/scrapy/conf/commands/stats.py
scrapy/trunk/scrapy/conf/commands/test.py
scrapy/trunk/scrapy/contrib/cluster/worker/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/errorpages.py
scrapy/trunk/scrapy/contrib/groupsettings.py
scrapy/trunk/scrapy/contrib/item/__init__.py
scrapy/trunk/scrapy/contrib/pipeline/__init__.py
scrapy/trunk/scrapy/contrib/prioritizers.py
scrapy/trunk/scrapy/contrib/response/__init__.py
scrapy/trunk/scrapy/contrib/schedulermiddleware/__init__.py
scrapy/trunk/scrapy/contrib/spider/__init__.py
scrapy/trunk/scrapy/contrib/spider/profiler.py
scrapy/trunk/scrapy/contrib/spider/reloader.py
scrapy/trunk/scrapy/contrib/spidermiddleware/__init__.py
scrapy/trunk/scrapy/contrib/web/__init__.py
scrapy/trunk/scrapy/contrib/web/http.py
scrapy/trunk/scrapy/contrib/web/json.py
scrapy/trunk/scrapy/contrib/web/service.py
scrapy/trunk/scrapy/contrib/web/site.py
scrapy/trunk/scrapy/contrib/web/stats.py
scrapy/trunk/scrapy/contrib/webconsole/__init__.py
scrapy/trunk/scrapy/contrib/webconsole/enginestatus.py
scrapy/trunk/scrapy/contrib/webconsole/spiderstats.py
scrapy/trunk/scrapy/contrib/webconsole/stats.py
scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/__init__.py
scrapy/trunk/scrapy/contrib_exp/history/__init__.py
scrapy/trunk/scrapy/contrib_exp/history/history.py
scrapy/trunk/scrapy/contrib_exp/history/store.py
scrapy/trunk/scrapy/core/__init__.py
scrapy/trunk/scrapy/core/downloader/__init__.py
scrapy/trunk/scrapy/core/prioritizers.py
scrapy/trunk/scrapy/core/scheduler/store.py
scrapy/trunk/scrapy/fetcher/__init__.py
scrapy/trunk/scrapy/http/url.py
scrapy/trunk/scrapy/management/__init__.py
scrapy/trunk/scrapy/management/telnet.py
scrapy/trunk/scrapy/patches/__init__.py
scrapy/trunk/scrapy/spider/__init__.py
scrapy/trunk/scrapy/stats/__init__.py
scrapy/trunk/scrapy/stats/statscollector.py
scrapy/trunk/scrapy/store/__init__.py
scrapy/trunk/scrapy/store/db.py
scrapy/trunk/scrapy/templates/project/module/__init__.py
scrapy/trunk/scrapy/templates/project/module/spiders/__init__.py
scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.tar
scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml
scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml.bz2
scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml.gz
scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.zip
scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample1.xml
scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample2.xml
scrapy/trunk/scrapy/tests/sample_data/test_site/index.html
scrapy/trunk/scrapy/tests/sample_data/test_site/item1.html
scrapy/trunk/scrapy/tests/sample_data/test_site/item2.html
scrapy/trunk/scrapy/tests/test_c14nurls.py
scrapy/trunk/scrapy/tests/test_dependencies.py
scrapy/trunk/scrapy/tests/test_spidermonkey.py
scrapy/trunk/scrapy/tests/test_spiders/__init__.py
scrapy/trunk/scrapy/tests/test_stats.py
scrapy/trunk/scrapy/utils/__init__.py
scrapy/trunk/scrapy/utils/c14n.py
scrapy/trunk/scrapy/utils/display.py
scrapy/trunk/scrapy/utils/serialization.py
scrapy/trunk/scrapy/xlib/BeautifulSoup.py
scrapy/trunk/scrapy/xlib/__init__.py
scrapy/trunk/scrapy/xlib/lrucache.py
scrapy/trunk/scrapy/xlib/lsprofcalltree.py
scrapy/trunk/scrapy/xlib/pydispatch/__init__.py
scrapy/trunk/scrapy/xlib/pydispatch/dispatcher.py
scrapy/trunk/scrapy/xlib/pydispatch/errors.py
scrapy/trunk/scrapy/xlib/pydispatch/license.txt
scrapy/trunk/scrapy/xlib/pydispatch/robust.py
scrapy/trunk/scrapy/xlib/pydispatch/robustapply.py
scrapy/trunk/scrapy/xlib/pydispatch/saferef.py
scrapy/trunk/scrapy/xlib/spidermonkey/INSTALL.scrapy
scrapy/trunk/scrapy/xlib/spidermonkey/__init__.py
scrapy/trunk/scrapy/xlib/spidermonkey/sm_settings.py
scrapy/trunk/scrapy/xlib/spidermonkey/spidermonkey.py
scrapy/trunk/scrapy/xpath/__init__.py
scrapy/trunk/scrapy/xpath/document.py
scrapy/trunk/scrapy/xpath/types.py
scrapy/trunk/scripts/rpm-install.sh
scrapy/utils/__init__.py
scrapy/utils/c14n.py
scrapy/utils/datatypes.py
scrapy/utils/db.py
scrapy/utils/defer.py
scrapy/utils/display.py
scrapy/utils/http.py
scrapy/utils/iterators.py
scrapy/utils/markup.py
scrapy/utils/misc.py
scrapy/utils/python.py
scrapy/utils/request.py
scrapy/utils/response.py
scrapy/utils/serialization.py
scrapy/utils/test.py
scrapy/utils/url.py
scrapy/xlib/BeautifulSoup.py
scrapy/xlib/ClientForm.py
scrapy/xlib/__init__.py
scrapy/xlib/lrucache.py
scrapy/xlib/lsprofcalltree.py
scrapy/xlib/pydispatch/__init__.py
scrapy/xlib/pydispatch/dispatcher.py
scrapy/xlib/pydispatch/errors.py
scrapy/xlib/pydispatch/license.txt
scrapy/xlib/pydispatch/robust.py
scrapy/xlib/pydispatch/robustapply.py
scrapy/xlib/pydispatch/saferef.py
scrapy/xlib/spidermonkey/INSTALL.scrapy
scrapy/xlib/spidermonkey/__init__.py
scrapy/xlib/spidermonkey/sm_settings.py
scrapy/xlib/spidermonkey/spidermonkey.py
scrapy/xpath/__init__.py
scrapy/xpath/constructors.py
scrapy/xpath/document.py
scrapy/xpath/extension.py
scrapy/xpath/selector.py
scrapy/xpath/types.py
scripts/rpm-install.sh
setup.cfg
setup.py
sites/scrapy.org/Makefile
sites/scrapy.org/README
sites/scrapy.org/docs/old/basics.rst
sites/scrapy.org/docs/old/tutorial/index.rst
sites/scrapy.org/docs/old/tutorial/tutorial1.rst
sites/scrapy.org/docs/old/tutorial/tutorial2.rst
sites/scrapy.org/docs/old/tutorial/tutorial3.rst
sites/scrapy.org/scrapyorg/__init__.py
sites/scrapy.org/scrapyorg/article/__init__.py
sites/scrapy.org/scrapyorg/article/urls.py
sites/scrapy.org/scrapyorg/article/views.py
sites/scrapy.org/scrapyorg/blog/__init__.py
sites/scrapy.org/scrapyorg/blog/admin.py
sites/scrapy.org/scrapyorg/blog/feeds.py
sites/scrapy.org/scrapyorg/blog/managers.py
sites/scrapy.org/scrapyorg/blog/models.py
sites/scrapy.org/scrapyorg/blog/sitemap.py
sites/scrapy.org/scrapyorg/blog/templates/base.html
sites/scrapy.org/scrapyorg/blog/templates/blog/base_blog.html
sites/scrapy.org/scrapyorg/blog/templates/blog/category_detail.html
sites/scrapy.org/scrapyorg/blog/templates/blog/category_list.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_archive_day.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_archive_month.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_archive_year.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_detail.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_list.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_search.html
sites/scrapy.org/scrapyorg/blog/templates/feeds/posts_description.html
sites/scrapy.org/scrapyorg/blog/templates/feeds/posts_title.html
sites/scrapy.org/scrapyorg/blog/templates_backup/admin/blog/post/change_form.html
sites/scrapy.org/scrapyorg/blog/templates_backup/inlines/default.html
sites/scrapy.org/scrapyorg/blog/templatetags/__init__.py
sites/scrapy.org/scrapyorg/blog/templatetags/blog.py
sites/scrapy.org/scrapyorg/blog/tests.py
sites/scrapy.org/scrapyorg/blog/urls.py
sites/scrapy.org/scrapyorg/blog/views.py
sites/scrapy.org/scrapyorg/docs/__init__.py
sites/scrapy.org/scrapyorg/docs/models.py
sites/scrapy.org/scrapyorg/docs/urls.py
sites/scrapy.org/scrapyorg/docs/views.py
sites/scrapy.org/scrapyorg/download/__init__.py
sites/scrapy.org/scrapyorg/download/admin.py
sites/scrapy.org/scrapyorg/download/models.py
sites/scrapy.org/scrapyorg/download/templatetags/__init__.py
sites/scrapy.org/scrapyorg/download/templatetags/download_tags.py
sites/scrapy.org/scrapyorg/download/urls.py
sites/scrapy.org/scrapyorg/download/views.py
sites/scrapy.org/scrapyorg/lib/__init__.py
sites/scrapy.org/scrapyorg/lib/templatetags.py
sites/scrapy.org/scrapyorg/local_settings.py.template
sites/scrapy.org/scrapyorg/manage.py
sites/scrapy.org/scrapyorg/settings.py
sites/scrapy.org/scrapyorg/urls.py
sites/scrapy.org/static/images/box-borders-bottom.gif
sites/scrapy.org/static/images/box-borders-bottom.png
sites/scrapy.org/static/images/box-borders-top.png
sites/scrapy.org/static/images/footer-bg.jpg
sites/scrapy.org/static/images/icon-arrow.gif
sites/scrapy.org/static/images/icon-author.gif
sites/scrapy.org/static/images/logo.jpg
sites/scrapy.org/static/images/main-bg.jpg
sites/scrapy.org/static/style/pygments.css
sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/admin/base_site.html
sites/scrapy.org/templates/articles/community.html
sites/scrapy.org/templates/articles/doc.html
sites/scrapy.org/templates/articles/download.html
sites/scrapy.org/templates/articles/home.html
sites/scrapy.org/templates/base.html
sites/scrapy.org/templates/base_doc.html
sites/scrapy.org/templates/base_home.html
sites/scrapy.org/templates/base_weblog.html
sites/scrapy.org/templates/blog/base_blog.html
sites/scrapy.org/templates/blog/category_detail.html
sites/scrapy.org/templates/blog/category_list.html
sites/scrapy.org/templates/blog/post_archive_day.html
sites/scrapy.org/templates/blog/post_archive_month.html
sites/scrapy.org/templates/blog/post_archive_year.html
sites/scrapy.org/templates/blog/post_detail.html
sites/scrapy.org/templates/blog/post_list.html
sites/scrapy.org/templates/blog/post_search.html
sites/scrapy.org/templates/blog_back/entry_archive.html
sites/scrapy.org/templates/blog_back/entry_archive_day.html
sites/scrapy.org/templates/blog_back/entry_archive_month.html
sites/scrapy.org/templates/blog_back/entry_archive_year.html
sites/scrapy.org/templates/blog_back/entry_detail.html
sites/scrapy.org/templates/docs/doc.html
sites/scrapy.org/templates/footer.html
sites/scrapy.org/templates/header.html
sites/static.scrapy.org/asc.png
sites/static.scrapy.org/attachment.png
sites/static.scrapy.org/changeset.png
sites/static.scrapy.org/closedticket.png
sites/static.scrapy.org/collapsed.png
sites/static.scrapy.org/css/about.css
sites/static.scrapy.org/css/admin.css
sites/static.scrapy.org/css/browser.css
sites/static.scrapy.org/css/changeset.css
sites/static.scrapy.org/css/code.css
sites/static.scrapy.org/css/diff.css
sites/static.scrapy.org/css/prefs.css
sites/static.scrapy.org/css/report.css
sites/static.scrapy.org/css/roadmap.css
sites/static.scrapy.org/css/search.css
sites/static.scrapy.org/css/ticket.css
sites/static.scrapy.org/css/timeline.css
sites/static.scrapy.org/css/trac-0.11rc2.css.diff
sites/static.scrapy.org/css/trac.css
sites/static.scrapy.org/css/wiki.css
sites/static.scrapy.org/desc.png
sites/static.scrapy.org/dots.gif
sites/static.scrapy.org/draft.png
sites/static.scrapy.org/edit_toolbar.png
sites/static.scrapy.org/editedticket.png
sites/static.scrapy.org/envelope.png
sites/static.scrapy.org/expanded.png
sites/static.scrapy.org/expander_normal.png
sites/static.scrapy.org/expander_normal_hover.png
sites/static.scrapy.org/expander_open.png
sites/static.scrapy.org/expander_open_hover.png
sites/static.scrapy.org/extlink.gif
sites/static.scrapy.org/feed.png
sites/static.scrapy.org/file.png
sites/static.scrapy.org/folder.png
sites/static.scrapy.org/guide/basic-workflow.png
sites/static.scrapy.org/guide/original-workflow.png
sites/static.scrapy.org/ics.png
sites/static.scrapy.org/imggrid.png
sites/static.scrapy.org/js/blame.js
sites/static.scrapy.org/js/diff.js
sites/static.scrapy.org/js/expand_dir.js
sites/static.scrapy.org/js/folding.js
sites/static.scrapy.org/js/ie_pre7_hacks.js
sites/static.scrapy.org/js/jquery.js
sites/static.scrapy.org/js/keyboard_nav.js
sites/static.scrapy.org/js/noconflict.js
sites/static.scrapy.org/js/query.js
sites/static.scrapy.org/js/search.js
sites/static.scrapy.org/js/suggest.js
sites/static.scrapy.org/js/trac.js
sites/static.scrapy.org/js/wikitoolbar.js
sites/static.scrapy.org/loading.gif
sites/static.scrapy.org/lock-locked.png
sites/static.scrapy.org/logo.jpg
sites/static.scrapy.org/main-bg.jpg
sites/static.scrapy.org/milestone.png
sites/static.scrapy.org/newticket.png
sites/static.scrapy.org/parent.png
sites/static.scrapy.org/python.png
sites/static.scrapy.org/topbar_gradient.png
sites/static.scrapy.org/topbar_gradient2.png
sites/static.scrapy.org/trac.ico
sites/static.scrapy.org/trac_banner.png
sites/static.scrapy.org/trac_logo_mini.png
sites/static.scrapy.org/vgradient.png
sites/static.scrapy.org/wiki.png
==================
2de03b5e;Pablo Hoffman;2009-05-04 13:43:37 +0000;added process_value argument to Link extractors constructor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401103

==

scrapy/trunk/docs/ref/link-extractors.rst
scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_link.py
==================
2c29d6d6;Pablo Hoffman;2009-04-29 23:18:00 +0000;some improvements to spiders doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401102

==

scrapy/trunk/docs/ref/spiders.rst
==================
d4cc91ae;Pablo Hoffman;2009-04-29 23:16:02 +0000;removed redundant link extractors documentation in docstrings, and some updated to link extractors doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401101

==

scrapy/trunk/docs/ref/link-extractors.rst
scrapy/trunk/docs/topics/link-extractors.rst
scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
==================
239b056d;Pablo Hoffman;2009-04-29 19:04:27 +0000;fixed encoding problem in RegexLinkExtractor when extracting links using restrict_xpaths, and added unittests. also enabled previously disabled restrict_xpaths tests.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401100

==

scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/tests/test_link.py
==================
e5892050;Daniel Grana;2009-04-28 13:48:05 +0000;templates: fix default item class path
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401099

==

scrapy/trunk/scrapy/templates/project/module/settings.py.tmpl
==================
cc62bba8;Daniel Grana;2009-04-27 18:49:13 +0000;closedomain: check if domain was opened successfully before removing not existent task
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401098

==

scrapy/trunk/scrapy/contrib/closedomain.py
==================
940d0090;Pablo Hoffman;2009-04-27 18:18:01 +0000;commented out irrelevant cookie test, and converted file to use encoded chars instead of real chars with a encoding declaration on top
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401097

==

scrapy/trunk/scrapy/tests/test_http_cookies.py
==================
f4e7ee5d;Pablo Hoffman;2009-04-27 17:34:42 +0000;some improvements to XMLFeedSpider including namespaces patch submitted by talboito, refs #81
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401096

==

scrapy/trunk/docs/ref/spiders.rst
scrapy/trunk/scrapy/contrib/spiders/feed.py
==================
560dd3fd;Daniel Grana;2009-04-27 16:56:16 +0000;useragent: if spider user_agent attribute is None, use default useragent instead of not including one
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401095

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/useragent.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_useragent.py
==================
78fa0bc2;Pablo Hoffman;2009-04-27 15:20:46 +0000;increased log level of "Scraped" message to INFO
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401094

==

scrapy/trunk/scrapy/core/engine.py
==================
e72bc591;Pablo Hoffman;2009-04-27 14:09:33 +0000;added notice to pipelines.py project template about ITEM_PIPELINES settings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401093

==

scrapy/trunk/scrapy/templates/project/module/pipelines.py.tmpl
==================
1eac716e;Pablo Hoffman;2009-04-27 12:26:04 +0000;added COOKIES_DEBUG to default settings and doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401092

==

scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/scrapy/conf/default_settings.py
==================
b553bb3d;Pablo Hoffman;2009-04-27 12:20:24 +0000;removed TODO comment
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401091

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cookies.py
==================
8eaa9219;Daniel Grana;2009-04-27 06:52:38 +0000;test: fix webclient test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401090

==

scrapy/trunk/scrapy/tests/test_webclient.py
==================
e8ecc00c;Daniel Grana;2009-04-27 06:48:24 +0000;core: clean HTTP handling and add unittests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401089

==

scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/downloader/webclient.py
scrapy/trunk/scrapy/tests/test_webclient.py
==================
0842fafd;Daniel Grana;2009-04-27 06:47:26 +0000;useragent: add unittests to mw and prepare to remove UA from downloader handlers
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401088

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/useragent.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_useragent.py
==================
a86a89f4;Daniel Grana;2009-04-27 06:46:46 +0000;cookies: mv cookies module under http module
--HG--
rename : scrapy/trunk/scrapy/utils/cookies.py => scrapy/trunk/scrapy/http/cookies.py
rename : scrapy/trunk/scrapy/tests/test_utils_cookies.py => scrapy/trunk/scrapy/tests/test_http_cookies.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401087

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cookies.py
scrapy/trunk/scrapy/http/cookies.py
scrapy/trunk/scrapy/tests/test_http_cookies.py
==================
68f54a1a;Daniel Grana;2009-04-27 06:45:49 +0000;cookies: add test to check that wrapped cookiejar thread based lock is overrided
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401086

==

scrapy/trunk/scrapy/tests/test_utils_cookies.py
==================
45f55c0d;Daniel Grana;2009-04-23 13:27:04 +0000;cookies: check mw outputs. refs #73
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401085

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cookies.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_cookies.py
==================
315a24ad;Daniel Grana;2009-04-22 23:05:15 +0000;cookies: fix typo in cookiejar lock attribute name. refs #73
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401084

==

scrapy/trunk/scrapy/utils/cookies.py
==================
bec0b122;Pablo Hoffman;2009-04-22 20:03:56 +0000;changed settings doc according to reflect recent cookies refactoring
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401083

==

scrapy/trunk/docs/ref/settings.rst
==================
1b2c9e49;Daniel Grana;2009-04-22 17:52:43 +0000;cookies: fix test import. refs #73
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401082

==

scrapy/trunk/scrapy/tests/test_downloadermiddleware_cookies.py
==================
1ecf874a;Daniel Grana;2009-04-22 17:21:46 +0000;cookies: final new cookie middleware integration into core and enabled by default. refs #73
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401081

==

scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/cookies.py
scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/cookies.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/downloader/webclient.py
scrapy/trunk/scrapy/http/headers.py
scrapy/trunk/scrapy/tests/test_http_headers.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_utils_cookies.py
scrapy/trunk/scrapy/tests/test_webclient.py
scrapy/trunk/scrapy/utils/cookies.py
scrapy/trunk/scrapy/utils/request.py
==================
3de3c2a3;Daniel Grana;2009-04-21 17:13:12 +0000;cookies: fix merging user cookies
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401080

==

scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/cookies.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_cookies.py
==================
4a6f7af7;Daniel Grana;2009-04-21 13:33:42 +0000;cookies: now really add unittests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401079

==

scrapy/trunk/scrapy/tests/test_downloadermiddleware_cookies.py
scrapy/trunk/scrapy/tests/test_utils_cookies.py
==================
1ce1481e;Daniel Grana;2009-04-21 13:32:19 +0000;cookies: override cookielib cookiejar thread based lock by dummy lock
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401078

==

scrapy/trunk/scrapy/utils/cookies.py
==================
391dde86;Daniel Grana;2009-04-21 13:31:58 +0000;cookies: rename cookies dict as jars
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401077

==

scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/cookies.py
==================
48b436e8;Daniel Grana;2009-04-21 13:31:26 +0000;cookies: add unittest and bugfix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401076

==

scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/cookies.py
scrapy/trunk/scrapy/utils/cookies.py
==================
799301b8;Daniel Grana;2009-04-21 13:30:55 +0000;http: bugfix appendlist method not setting headers if first time
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401075

==

scrapy/trunk/scrapy/http/headers.py
scrapy/trunk/scrapy/tests/test_http_headers.py
==================
3170dd9f;Pablo Hoffman;2009-04-21 01:38:11 +0000;redirect mw: remove body and content-type/content-length headers on 302 redirects, and added tests. also renamed some tests to more meaningful names
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401074

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_redirect.py
==================
5861b345;Daniel Grana;2009-04-20 23:59:24 +0000;cookies: add cookiejar to wrap cookielib and remove cookielib from mw
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401073

==

scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/cookies.py
scrapy/trunk/scrapy/utils/cookies.py
==================
0f22dfec;Daniel Grana;2009-04-20 12:22:05 +0000;cluster: bugfix in remove and schedule actions
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401072

==

scrapy/trunk/scrapy/contrib/cluster/master/manager.py
==================
f6e83be6;Pablo Hoffman;2009-04-20 02:31:22 +0000;docs/request-response.rst: added sphinx :param: tags to improve documentation structure and readability. also documented default behaviour for FormRequest changes commited in r1069
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401071

==

scrapy/trunk/docs/ref/request-response.rst
==================
558a1a50;Pablo Hoffman;2009-04-20 02:29:19 +0000;FormRequest.from_response: fixed bug with setting method, override fields with those included in formdata, for those which already existed in the response <form>
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401070

==

scrapy/trunk/scrapy/http/request/form.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
be5106d7;Daniel Grana;2009-04-17 20:43:50 +0000;core: strip not working close delay support from core to (working) extension
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401069

==

scrapy/trunk/scrapy/contrib/delayedclosedomain.py
scrapy/trunk/scrapy/core/engine.py
==================
4d165719;Daniel Grana;2009-04-17 19:13:38 +0000;core: try to process requests after getting a DontCloseDomain to avoid delay on processing reinjected requests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401068

==

scrapy/trunk/scrapy/core/engine.py
==================
5f5962e6;Pablo Hoffman;2009-04-17 13:06:31 +0000;improved SCHEDULER_ORDER setting doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401067

==

scrapy/trunk/docs/faq.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/scrapy/core/scheduler/schedulers.py
==================
512b7594;Daniel Grana;2009-04-16 19:14:32 +0000;cookies: add TODO comments to experimental cookie mw
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401066

==

scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/cookies.py
==================
60b33025;Daniel Grana;2009-04-16 19:05:27 +0000;cookies: add new cookie middleware to experimental
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401065

==

scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/cookies.py
==================
d6c52d51;Daniel Grana;2009-04-16 18:58:56 +0000;cluster: promote new code as replacement of old pbcluster
--HG--
rename : scrapy/trunk/scrapy/contrib/pbcluster/crawler/__init__.py => scrapy/trunk/scrapy/contrib/cluster/crawler/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/cluster/crawler/manager.py => scrapy/trunk/scrapy/contrib/cluster/crawler/manager.py
rename : scrapy/trunk/scrapy/contrib_exp/cluster/hooks/__init__.py => scrapy/trunk/scrapy/contrib/cluster/hooks/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/cluster/hooks/svn.py => scrapy/trunk/scrapy/contrib/cluster/hooks/svn.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/master/__init__.py => scrapy/trunk/scrapy/contrib/cluster/master/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/cluster/master/manager.py => scrapy/trunk/scrapy/contrib/cluster/master/manager.py
rename : scrapy/trunk/scrapy/contrib_exp/cluster/master/web.py => scrapy/trunk/scrapy/contrib/cluster/master/web.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt => scrapy/trunk/scrapy/contrib/cluster/master/ws_api.txt
rename : scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py => scrapy/trunk/scrapy/contrib/cluster/tools/scrapy-cluster-ctl.py
rename : scrapy/trunk/scrapy/contrib_exp/cluster/tools/test-worker.py => scrapy/trunk/scrapy/contrib/cluster/tools/test-worker.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/worker/__init__.py => scrapy/trunk/scrapy/contrib/cluster/worker/__init__.py
rename : scrapy/trunk/scrapy/contrib_exp/cluster/worker/manager.py => scrapy/trunk/scrapy/contrib/cluster/worker/manager.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401064

==

scrapy/trunk/scrapy/contrib/cluster/__init__.py
scrapy/trunk/scrapy/contrib/cluster/crawler/__init__.py
scrapy/trunk/scrapy/contrib/cluster/crawler/manager.py
scrapy/trunk/scrapy/contrib/cluster/hooks/__init__.py
scrapy/trunk/scrapy/contrib/cluster/hooks/svn.py
scrapy/trunk/scrapy/contrib/cluster/master/__init__.py
scrapy/trunk/scrapy/contrib/cluster/master/manager.py
scrapy/trunk/scrapy/contrib/cluster/master/web.py
scrapy/trunk/scrapy/contrib/cluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib/cluster/tools/scrapy-cluster-ctl.py
scrapy/trunk/scrapy/contrib/cluster/tools/test-worker.py
scrapy/trunk/scrapy/contrib/cluster/worker/__init__.py
scrapy/trunk/scrapy/contrib/cluster/worker/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/__init__.py
scrapy/trunk/scrapy/contrib/pbcluster/crawler/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/testworker.py
scrapy/trunk/scrapy/contrib_exp/cluster/__init__.py
scrapy/trunk/scrapy/contrib_exp/cluster/crawler/__init__.py
scrapy/trunk/scrapy/contrib_exp/cluster/master/__init__.py
scrapy/trunk/scrapy/contrib_exp/cluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib_exp/cluster/tools/scrapy-cluster-ctl.py
scrapy/trunk/scrapy/contrib_exp/cluster/worker/__init__.py
==================
821f6be3;Daniel Grana;2009-04-16 18:23:12 +0000;http: fix xmlrpc request cloning
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401063

==

scrapy/trunk/scrapy/http/request/rpc.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
bbd41bda;Pablo Hoffman;2009-04-16 15:32:06 +0000;more cleanup of default project settings templates and added a notice as suggested by Mark Ellul
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401062

==

scrapy/trunk/scrapy/templates/project/module/settings.py.tmpl
==================
3fce2496;Pablo Hoffman;2009-04-15 01:31:04 +0000;modified page <title>
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401061

==

sites/scrapy.org/templates/base.html
==================
d18b78b8;Daniel Grana;2009-04-14 11:20:52 +0000;site: download section is linking to very old scrapy zip tarball
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401060

==

sites/scrapy.org/templates/articles/download.html
==================
fae3d7a8;Daniel Grana;2009-04-13 20:27:35 +0000;core: adapt redirection and media scheduler priorities
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401059

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/robotstxt.py
scrapy/trunk/scrapy/contrib/pipeline/media.py
scrapy/trunk/scrapy/core/engine.py
==================
b96a0c27;Daniel Grana;2009-04-13 16:42:26 +0000;core: change default priority to 0 to use balanced priorityqueue, and increase priority of redirected requests so memory doesnt hog because of redirection requests waiting for others requests to finish before they got a chance to be downloaded
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401058

==

scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/core/scheduler/schedulers.py
==================
29b3746d;Pablo Hoffman;2009-04-12 10:21:00 +0000;updated some homepage texts
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401057

==

sites/scrapy.org/templates/articles/doc.html
sites/scrapy.org/templates/articles/home.html
==================
74393606;Pablo Hoffman;2009-04-12 10:20:46 +0000;removed unused code from Makefile
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401056

==

sites/scrapy.org/Makefile
==================
74f39480;Pablo Hoffman;2009-04-12 09:16:31 +0000;added a couple of unittests for from_response errors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401055

==

scrapy/trunk/scrapy/http/request/form.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
54ad49f7;Pablo Hoffman;2009-04-12 09:05:00 +0000;doc: fixed a couple of broken links
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401054

==

scrapy/trunk/docs/intro/overview.rst
scrapy/trunk/docs/proposed/spiders.rst
==================
50efaab4;Pablo Hoffman;2009-04-12 08:31:55 +0000;- added from_response() class method to FormRequest to support pre-populating   HTML forms with fields taken from <form> elements contained in responses.   implemented using the ClientForm library
- added ClientForm to Scrapy bundled libraries (scrapy.xlib)

- added unittests for new from_response() method

- documented new from_response() method, added a user login example to
  illustrate it, and a new faq entry

- improved overall quality of request/response doc

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401053

==

scrapy/trunk/docs/faq.rst
scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/http/request/form.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/xlib/ClientForm.py
==================
5378a351;Pablo Hoffman;2009-04-11 18:34:44 +0000;some more tuning to installation guide
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401052

==

scrapy/trunk/docs/intro/install.rst
==================
b5bbf827;Pablo Hoffman;2009-04-11 06:44:09 +0000;added tips about using Firefox addons to inspect the live browser DOM
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401051

==

scrapy/trunk/docs/topics/firebug.rst
scrapy/trunk/docs/topics/firefox.rst
scrapy/trunk/docs/topics/index.rst
==================
9c005f8e;Pablo Hoffman;2009-04-11 05:05:58 +0000;skip image pipeline tests if Image module is not available
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401050

==

scrapy/trunk/scrapy/tests/test_pipeline_images.py
==================
3945c36f;Pablo Hoffman;2009-04-11 05:01:37 +0000;added scrapy.tests.run module to support running tests with 'python -m scrapy.tests.run' in Python 2.6, since Python 2.6 doesn't allow running packages with -m
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401049

==

scrapy/trunk/scrapy/tests/__init__.py
scrapy/trunk/scrapy/tests/run.py
==================
7e854af6;Pablo Hoffman;2009-04-11 04:56:39 +0000;skip serialization tests if simplejson module is not available
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401048

==

scrapy/trunk/scrapy/tests/test_serialization.py
==================
2799ffac;Pablo Hoffman;2009-04-10 11:01:56 +0000;doc: updated installation guide with setup.py install mechanism
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401047

==

scrapy/trunk/docs/intro/install.rst
==================
eb0826e8;Pablo Hoffman;2009-04-10 10:13:17 +0000;removed old .attribute() api from project spider templates until adaptors are stable
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401046

==

scrapy/trunk/scrapy/templates/project/module/templates/spider_crawl.tmpl
scrapy/trunk/scrapy/templates/project/module/templates/spider_csvfeed.tmpl
scrapy/trunk/scrapy/templates/project/module/templates/spider_xmlfeed.tmpl
==================
4a2bca83;Pablo Hoffman;2009-04-10 10:09:51 +0000;removed templates from googledir example (to keep it DRY) as they made no sense there
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401045

==

scrapy/trunk/examples/googledir/googledir/templates/spider_basic.tmpl
scrapy/trunk/examples/googledir/googledir/templates/spider_crawl.tmpl
scrapy/trunk/examples/googledir/googledir/templates/spider_csvfeed.tmpl
scrapy/trunk/examples/googledir/googledir/templates/spider_xmlfeed.tmpl
==================
d503735b;Pablo Hoffman;2009-04-10 09:59:17 +0000;removed old cluster from extensions loaded by default
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401044

==

scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/scrapy/conf/default_settings.py
==================
2bc0cdba;Pablo Hoffman;2009-04-10 09:51:50 +0000;added warning about twisted bug 3707 and installing pywin32
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401043

==

scrapy/trunk/docs/faq.rst
scrapy/trunk/docs/intro/install.rst
==================
8e7d5f69;Pablo Hoffman;2009-04-10 08:06:44 +0000;- fixed setup.py script (closes #80) - added .tmpl extension to project template files to prevent distutils from crashing when trying to compile those files - cleaned up some garbage from settings templates
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401042

==

scrapy/trunk/examples/googledir/googledir/items.py
scrapy/trunk/examples/googledir/googledir/settings.py
scrapy/trunk/examples/googledir/googledir/spiders/google_directory.py
scrapy/trunk/scrapy/bin/scrapy-admin.py
scrapy/trunk/scrapy/templates/project/module/items.py.tmpl
scrapy/trunk/scrapy/templates/project/module/pipelines.py.tmpl
scrapy/trunk/scrapy/templates/project/module/settings.py
scrapy/trunk/scrapy/templates/project/module/settings.py.tmpl
scrapy/trunk/scrapy/utils/misc.py
scrapy/trunk/setup.cfg
scrapy/trunk/setup.py
==================
324ec076;Pablo Hoffman;2009-04-10 08:03:26 +0000;moved examples/contrib_exp to examples/experimental
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401041

==

scrapy/trunk/examples/experimental/googledir/googledir/__init__.py
scrapy/trunk/examples/experimental/googledir/googledir/items.py
scrapy/trunk/examples/experimental/googledir/googledir/pipelines.py
scrapy/trunk/examples/experimental/googledir/googledir/settings.py
scrapy/trunk/examples/experimental/googledir/googledir/spiders/__init__.py
scrapy/trunk/examples/experimental/googledir/googledir/spiders/google_directory.py
scrapy/trunk/examples/experimental/googledir/googledir/templates/spider_basic.tmpl
scrapy/trunk/examples/experimental/googledir/googledir/templates/spider_crawl.tmpl
scrapy/trunk/examples/experimental/googledir/googledir/templates/spider_csvfeed.tmpl
scrapy/trunk/examples/experimental/googledir/googledir/templates/spider_xmlfeed.tmpl
scrapy/trunk/examples/experimental/googledir/scrapy-ctl.py
==================
317221d2;Pablo Hoffman;2009-04-10 08:01:25 +0000;removed old .attribute() API from doc - it will be restored in the future when adaptors code get stable
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401040

==

scrapy/trunk/docs/ref/spiders.rst
==================
46d9e681;Pablo Hoffman;2009-04-10 07:33:46 +0000;minor updates to a couple of settings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401039

==

scrapy/trunk/docs/ref/settings.rst
==================
7c66f173;Pablo Hoffman;2009-04-10 05:35:53 +0000;Several documentation changes:
- merged (and updated) new tutorial from proposed doc
- striped old tutorial and created new firebug topic
- added topic about useful third firefox add-ons
- rearranged main documentation index
- several assorted documentation fixes

--HG--
rename : scrapy/trunk/docs/proposed/tutorial.rst => scrapy/trunk/docs/intro/tutorial.rst
rename : scrapy/trunk/docs/intro/tutorial/scrot1.png => scrapy/trunk/docs/topics/_images/firebug1.png
rename : scrapy/trunk/docs/intro/tutorial/scrot2.png => scrapy/trunk/docs/topics/_images/firebug2.png
rename : scrapy/trunk/docs/intro/tutorial/scrot3.png => scrapy/trunk/docs/topics/_images/firebug3.png
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401038

==

scrapy/trunk/docs/faq.rst
scrapy/trunk/docs/index.rst
scrapy/trunk/docs/intro/index.rst
scrapy/trunk/docs/intro/install.rst
scrapy/trunk/docs/intro/tutorial.rst
scrapy/trunk/docs/intro/tutorial/index.rst
scrapy/trunk/docs/intro/tutorial/tutorial1.rst
scrapy/trunk/docs/intro/tutorial/tutorial2.rst
scrapy/trunk/docs/intro/tutorial/tutorial3.rst
scrapy/trunk/docs/intro/tutorial/tutorial4.rst
scrapy/trunk/docs/misc/api-stability.rst
scrapy/trunk/docs/proposed/index.rst
scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/selectors.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/docs/topics/_images/firebug1.png
scrapy/trunk/docs/topics/_images/firebug2.png
scrapy/trunk/docs/topics/_images/firebug3.png
scrapy/trunk/docs/topics/adaptors.rst
scrapy/trunk/docs/topics/architecture.rst
scrapy/trunk/docs/topics/firebug.rst
scrapy/trunk/docs/topics/firefox.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/selectors.rst
scrapy/trunk/docs/topics/shell.rst
==================
0fb3ee16;Pablo Hoffman;2009-04-03 04:13:21 +0000;more improvements to scrapy shell: added Request object, and support for modifying it and re-fetching it by issuing an empty 'get' command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401037

==

scrapy/trunk/docs/topics/shell.rst
scrapy/trunk/scrapy/command/commands/shell.py
==================
ef9f4961;Pablo Hoffman;2009-04-03 04:05:57 +0000;scrapy.xpath: added docstring pointing to the doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401036

==

scrapy/trunk/scrapy/xpath/selector.py
==================
b7bd00b3;Pablo Hoffman;2009-04-03 03:20:45 +0000;minor changes to some module descriptions
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401035

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/docs/ref/selectors.rst
==================
7e782365;Pablo Hoffman;2009-04-03 03:13:22 +0000;some code refactoring for the scrapy shell command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401034

==

scrapy/trunk/docs/topics/shell.rst
scrapy/trunk/scrapy/command/commands/shell.py
scrapy/trunk/scrapy/patches/monkeypatches.py
==================
b521ca4d;Pablo Hoffman;2009-04-03 01:33:52 +0000;massive improvements to xpath selectors doc. refs #25
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401033

==

scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/docs/ref/selectors.rst
scrapy/trunk/docs/topics/selectors.rst
scrapy/trunk/docs/topics/shell.rst
==================
d732a79e;Pablo Hoffman;2009-04-03 01:19:36 +0000;added documentation for scrapy shell. closes #78
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401032

==

scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/shell.rst
==================
931c29ea;Pablo Hoffman;2009-04-03 00:43:09 +0000;updated Scrapy architecture doc by adding reference to Scheduler middlewares. refs #31
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401031

==

scrapy/trunk/docs/topics/_images/scrapy_architecture.odg
scrapy/trunk/docs/topics/_images/scrapy_architecture.png
scrapy/trunk/docs/topics/architecture.rst
==================
87573597;Pablo Hoffman;2009-04-02 22:43:52 +0000;doc: added note about logging from spiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401030

==

scrapy/trunk/docs/ref/logging.rst
==================
1683c4e9;Daniel Grana;2009-04-01 14:29:56 +0000;tests: comment failed test until fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401029

==

scrapy/trunk/scrapy/tests/test_utils_url.py
==================
6ac767f8;artem;2009-04-01 13:40:30 +0000;tests: added url_query_parameter() fail case
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401028

==

scrapy/trunk/scrapy/tests/test_utils_url.py
==================
128de5a4;Daniel Grana;2009-03-31 04:00:58 +0000;cluster: add missing import
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401027

==

scrapy/trunk/scrapy/contrib_exp/cluster/worker/manager.py
==================
e15c928e;Daniel Grana;2009-03-31 03:50:13 +0000;cluster: add log gzipping support
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401026

==

scrapy/trunk/scrapy/contrib_exp/cluster/worker/manager.py
scrapy/trunk/scrapy/utils/misc.py
==================
c2852b13;Daniel Grana;2009-03-30 10:41:55 +0000;imagespipeline: restore original log message for uptodate image
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401025

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
==================
96ee661f;Daniel Grana;2009-03-27 06:59:38 +0000;pipeline: add missing future import for with statement at images pipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401024

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
==================
186d0e93;Daniel Grana;2009-03-27 06:46:06 +0000;Revert "added rule shorthand, for creating CrawlSpider rules"
This reverts commit r863.

This is not the place for this shorthand, and it hasn't the blessing of
BDFL. I look forward for the return of this shorthand.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401023

==

scrapy/trunk/scrapy/contrib/spiders/__init__.py
scrapy/trunk/scrapy/contrib/spiders/crawl.py
==================
7227b65d;Daniel Grana;2009-03-27 06:42:24 +0000;http: fix copy and failing appendlist method of Headers, also add missing tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401022

==

scrapy/trunk/scrapy/http/headers.py
scrapy/trunk/scrapy/tests/test_datatypes.py
scrapy/trunk/scrapy/tests/test_http_headers.py
scrapy/trunk/scrapy/tests/test_utils_datatypes.py
scrapy/trunk/scrapy/utils/datatypes.py
==================
1d0e2d12;Daniel Grana;2009-03-27 06:05:54 +0000;linkextractors: add arg_to_iter support to RegexLinkExtractor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401021

==

scrapy/trunk/docs/ref/link-extractors.rst
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_link.py
==================
4fa7e6ca;Daniel Grana;2009-03-27 05:42:47 +0000;tests: fix images tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401020

==

scrapy/trunk/scrapy/tests/test_pipeline_images.py
==================
5b7cfb31;Daniel Grana;2009-03-27 04:41:11 +0000;pipeline: refactor image pipelines moving common functionality to BaseImagesPipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401019

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
scrapy/trunk/scrapy/contrib/pipeline/s3images.py
scrapy/trunk/scrapy/utils/misc.py
==================
70a686c0;Daniel Grana;2009-03-25 13:15:55 +0000;http: add errback to Request constructor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401018

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/http/request/__init__.py
==================
828c3e09;Daniel Grana;2009-03-25 13:15:24 +0000;core: remove deferred_degenerator, instead use a cooperative map
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401017

==

scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/tests/test_utils_defer.py
scrapy/trunk/scrapy/utils/defer.py
==================
9d59bb31;Daniel Grana;2009-03-25 13:14:50 +0000;utils: remove unused function arg_to_list
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401016

==

scrapy/trunk/scrapy/tests/test_utils_misc.py
scrapy/trunk/scrapy/utils/misc.py
==================
de0d57cd;Daniel Grana;2009-03-25 13:14:26 +0000;log: add an twisted.python.log.err handler wrapper just like log.msg one
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401015

==

scrapy/trunk/scrapy/log/__init__.py
==================
7c4c1708;Pablo Hoffman;2009-03-24 21:21:39 +0000;added copy tests for Headers which need to pass but are currently failing
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401014

==

scrapy/trunk/scrapy/tests/test_http_headers.py
==================
d8c04407;Pablo Hoffman;2009-03-24 21:03:38 +0000;fixed bug in previous commit
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401013

==

scrapy/trunk/scrapy/http/request/__init__.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
0c963159;Pablo Hoffman;2009-03-24 20:02:42 +0000;- made Request.copy() use Request.replace() - added callback, dont_filter, encoding to Request copy/replace - fixed Request.replace() and Response.replace() which weren't working properly with empty arguments - added new test cases - added doc about copying requests and deferreds
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401012

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/http/request/__init__.py
scrapy/trunk/scrapy/http/response/__init__.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_http_response.py
==================
03fc6fc4;Pablo Hoffman;2009-03-22 22:05:23 +0000;made scrapy installation guide a bit more friendly for windows users
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401011

==

scrapy/trunk/docs/intro/install.rst
==================
30a3df0c;Pablo Hoffman;2009-03-22 19:25:08 +0000;added documentation about --set and small improvement
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401010

==

scrapy/trunk/docs/topics/settings.rst
scrapy/trunk/scrapy/command/models.py
==================
cbe8f8ff;Pablo Hoffman;2009-03-22 19:19:31 +0000;moved spider loading below command line option processing, so options overrided by --set argument are taken into account at spider module-level code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401009

==

scrapy/trunk/scrapy/command/cmdline.py
==================
28f947d2;Pablo Hoffman;2009-03-22 19:18:27 +0000;added support for overriding settings from command line arguments, as suggested by Mark Ellul
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401008

==

scrapy/trunk/scrapy/command/models.py
==================
482ec0c2;Pablo Hoffman;2009-03-22 16:27:35 +0000;fixed bug in passing request callback arguments example code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401007

==

scrapy/trunk/docs/ref/request-response.rst
==================
f4bd8a48;Pablo Hoffman;2009-03-22 16:24:56 +0000;added doc about passing arguments to request callbacks, as suggested by tarasm
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401006

==

scrapy/trunk/docs/ref/request-response.rst
==================
c476d586;Pablo Hoffman;2009-03-22 16:22:57 +0000;fixed typo in signals doc. closes #75
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401005

==

scrapy/trunk/docs/ref/signals.rst
==================
0b1184e4;Daniel Grana;2009-03-20 19:38:32 +0000;redirectmw: allow dont_filter requests to continue redirecting but limit max redirections by global setting and per request
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401004

==

scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_redirect.py
==================
87e63216;Daniel Grana;2009-03-20 19:37:55 +0000;retrymw: remove fingerprint cache and use request meta instead, add more tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401003

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_retry.py
==================
cab6387c;Andres Moreira;2009-03-19 13:11:27 +0000;profiling: add new priorityqueue implementation (PQ5c) with cache support. fixed bug in run.py with the use of the with statement.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401002

==

scrapy/trunk/profiling/priorityqueue/pq_classes.py
scrapy/trunk/profiling/priorityqueue/run.py
==================
bd1be0ac;Daniel Grana;2009-03-19 12:04:19 +0000;profiling: fix priority distribution and add new ones
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401001

==

scrapy/trunk/profiling/priorityqueue/run.py
==================
2e63ef60;Daniel Grana;2009-03-19 05:42:23 +0000;profiling: remove useless import
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401000

==

scrapy/trunk/profiling/priorityqueue/test_cases.py
==================
fdfa5302;Daniel Grana;2009-03-19 05:18:35 +0000;profiling: minor fixes and new testcase for IndexError exception
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40999

==

scrapy/trunk/profiling/priorityqueue/pq_classes.py
scrapy/trunk/profiling/priorityqueue/test_cases.py
==================
9d1855a6;Daniel Grana;2009-03-19 04:09:24 +0000;profiling: add alternative priorityqueue implementations and disable not useful ones from default runs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40998

==

scrapy/trunk/profiling/priorityqueue/pq_classes.py
scrapy/trunk/profiling/priorityqueue/run.py
==================
1c659ce6;Daniel Grana;2009-03-19 03:33:06 +0000;profiling: add list+deque+cache+islice just to compare with pure slice
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40997

==

scrapy/trunk/profiling/priorityqueue/pq_classes.py
scrapy/trunk/profiling/priorityqueue/run.py
==================
685807e3;Daniel Grana;2009-03-19 03:11:27 +0000;profiling: improve list+deque+cache performance
results:

 == With 1 priorities (/tmp/pq-13882-1-50000) ==

 pushpops = 50000, times = 30
 heapq implementation: 12.6956150532
 dict+deque implementation: 5.3080239296
 deque+heapq implementation: 3.11057305336
 deque+defaultdict+deque implementation: 3.06583619118
 list+deque implementation: 4.85028195381
 list+deque+cache implementation: 4.86092495918

 == With 3 priorities (/tmp/pq-13882-3-50000) ==

 pushpops = 50000, times = 30
 heapq implementation: 13.9048631191
 dict+deque implementation: 6.526501894
 deque+heapq implementation: 9.95749187469
 deque+defaultdict+deque implementation: 4.94318699837
 list+deque implementation: 5.48832702637
 list+deque+cache implementation: 4.77395009995

 == With 5 priorities (/tmp/pq-13882-5-50000) ==

 pushpops = 50000, times = 30
 heapq implementation: 14.1862449646
 dict+deque implementation: 7.45535206795
 deque+heapq implementation: 11.7175529003
 deque+defaultdict+deque implementation: 5.40972518921
 list+deque implementation: 5.87488412857
 list+deque+cache implementation: 4.73579287529

 == With 10 priorities (/tmp/pq-13882-10-50000) ==

 pushpops = 50000, times = 30
 heapq implementation: 14.2052979469
 dict+deque implementation: 9.94834208488
 deque+heapq implementation: 13.0460109711
 deque+defaultdict+deque implementation: 5.79300785065
 list+deque implementation: 6.9981739521
 list+deque+cache implementation: 4.81988596916

 == With 100 priorities (/tmp/pq-13882-100-50000) ==

 pushpops = 50000, times = 30
 heapq implementation: 14.9574189186
 dict+deque implementation: 55.6348400116
 deque+heapq implementation: 14.9515259266
 deque+defaultdict+deque implementation: 10.6776599884
 list+deque implementation: 25.9212520123
 list+deque+cache implementation: 4.77596998215

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40996

==

scrapy/trunk/profiling/priorityqueue/pq_classes.py
==================
44ba7412;Daniel Grana;2009-03-19 02:47:59 +0000;profiling: automatically test include new PriorityQueue classes in testcases
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40995

==

scrapy/trunk/profiling/priorityqueue/test_cases.py
==================
e1c1865c;Daniel Grana;2009-03-19 02:25:20 +0000;profiling: add options to priority queue profiler
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40994

==

scrapy/trunk/profiling/priorityqueue/run.py
==================
22c51638;Daniel Grana;2009-03-18 19:44:36 +0000;profiling: add priorityqueue alternatives and profiling / test cases
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40993

==

scrapy/trunk/profiling/priorityqueue/pq_classes.py
scrapy/trunk/profiling/priorityqueue/run.py
scrapy/trunk/profiling/priorityqueue/test_cases.py
==================
2951e842;Andres Moreira;2009-03-18 17:09:26 +0000;Improved PriorityQueue and PriorityStack that boost the performance again. Also updated the unittest for those datatypes.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40992

==

scrapy/trunk/scrapy/tests/test_utils_datatypes.py
scrapy/trunk/scrapy/utils/datatypes.py
==================
7b664a57;Pablo Hoffman;2009-03-18 00:47:07 +0000;grammar adjustment
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40991

==

scrapy/trunk/scrapy/core/engine.py
==================
fb3a2dab;Daniel Grana;2009-03-17 21:30:33 +0000;core: allow returning None from spiders to support pipeline/download throttling
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40990

==

scrapy/trunk/scrapy/core/engine.py
==================
c54a3fe7;Ismael Carnales;2009-03-17 15:22:57 +0000;removed item_to_dict
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40989

==

scrapy/trunk/scrapy/utils/misc.py
==================
63150e2e;Ismael Carnales;2009-03-16 01:12:57 +0000;added item_to_dict util function
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40988

==

scrapy/trunk/scrapy/utils/misc.py
==================
f9e5915f;Daniel Grana;2009-03-13 20:05:37 +0000;newitem: change itemadaptor tests to avoid false positives
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40987

==

scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
cbf6d76c;Andres Moreira;2009-03-12 19:06:57 +0000;Improved PriorityQueue and PriorityStack with a patch sent by Federico Feroldi. The new implementation is about two times faster than the old.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40986

==

scrapy/trunk/scrapy/utils/datatypes.py
==================
518a7c87;Ismael Carnales;2009-03-11 13:26:29 +0000;make field_adaptors non-public
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40985

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
2ba017b1;Ismael Carnales;2009-03-11 13:01:26 +0000;add tests for adaptation of multivaluated fields
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40984

==

scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
0be77115;Daniel Grana;2009-03-11 03:01:30 +0000;stats: fix stats key typo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40983

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/stats.py
==================
f8ce2414;Pablo Hoffman;2009-03-10 19:56:22 +0000;fixed MailSender documentation example - closes #74
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40982

==

scrapy/trunk/docs/ref/email.rst
==================
ec1a6af0;Ismael Carnales;2009-03-10 19:35:45 +0000;added MultiValuedField to newitem
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40981

==

scrapy/trunk/scrapy/contrib_exp/newitem/fields.py
scrapy/trunk/scrapy/tests/test_newitem.py
==================
2f75c2c9;Ismael Carnales;2009-03-10 19:17:53 +0000;removed unneeded import
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40980

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
04baa7ae;Ismael Carnales;2009-03-10 18:40:26 +0000;removed declarative from newitem (now using 'plain' metaclasses) added basic test for newitem
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40979

==

scrapy/trunk/scrapy/contrib_exp/newitem/declarative.py
scrapy/trunk/scrapy/contrib_exp/newitem/models.py
scrapy/trunk/scrapy/tests/test_newitem.py
==================
774e7f62;Ismael Carnales;2009-03-10 17:59:53 +0000;fixed default adaptor inheritance, added test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40978

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
67ab30a5;Daniel Grana;2009-03-10 17:51:03 +0000;core: add application/xhtml+xml support to responsetypes
more info at http://www.w3.org/TR/xhtml-media-types/#media-types

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40977

==

scrapy/trunk/scrapy/core/downloader/responsetypes/__init__.py
scrapy/trunk/scrapy/tests/test_responsetypes.py
==================
63e6ce6e;Ismael Carnales;2009-03-10 16:57:27 +0000;made IDENTITY a function of adaptor module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40976

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
698e6e73;Ismael Carnales;2009-03-10 16:34:48 +0000;moved default_adaptor logic fully to the metaclass in ItemAdaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40975

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
06e049e5;Ismael Carnales;2009-03-10 16:15:49 +0000;move meta class initialization to metaclass in ItemAdaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40974

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
f1053596;Ismael Carnales;2009-03-10 15:53:42 +0000;use metaclass __getattr__ to return default_adaptor in ItemAdaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40973

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
8bda81c0;Ismael Carnales;2009-03-10 14:03:27 +0000;add inheritance of item and adaptors to itemadaptor test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40972

==

scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
f9aa0a6a;Ismael Carnales;2009-03-10 13:38:32 +0000;removed is_adaptor check in ItemAdaptor in favour of funcion adaptizer
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40971

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
4093a4b8;Pablo Hoffman;2009-03-05 11:12:07 +0000;added support to run scrapy tests with: python -m scrapy.tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40970

==

scrapy/trunk/scrapy/tests/__init__.py
==================
e3c9f595;Daniel Grana;2009-03-04 20:11:12 +0000;contrib: fix a header bug in httpcompression middleware and add tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40969

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/trunk/scrapy/tests/sample_data/compressed/html-gzip.bin
scrapy/trunk/scrapy/tests/sample_data/compressed/html-rawdeflate.bin
scrapy/trunk/scrapy/tests/sample_data/compressed/html-zlibdeflate.bin
scrapy/trunk/scrapy/tests/test_downloadermiddleware_httpcompression.py
==================
8ad4211e;Ismael Carnales;2009-03-04 17:11:20 +0000;small changes to make code 3.0 compatible :)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40968

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
ec22373b;Ismael Carnales;2009-03-03 22:35:15 +0000;use ItemAdaptor.__classinit__ to set field_adaptors, also make defaulted field adaptors static_methods
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40967

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
b5b6b0ce;Ismael Carnales;2009-03-03 21:32:37 +0000;removed unneeded decorator from Item xD
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40966

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
154dded1;Ismael Carnales;2009-03-03 21:29:00 +0000;using declarative in ItemAdaptor, more to come
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40965

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
e744e875;Ismael Carnales;2009-03-03 21:18:40 +0000;code style changes for newitem, and only return fields or special attrs in Item
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40964

==

scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
d26b968f;Damian Canabal;2009-03-03 21:14:50 +0000;fixing typo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40963

==

scrapy/trunk/scrapy/contrib/schedulermiddleware/duplicatesfilter.py
==================
60de6394;Ismael Carnales;2009-03-03 21:12:37 +0000;added declarative module for declarative style classses and make Item use it
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40962

==

scrapy/trunk/scrapy/contrib_exp/newitem/declarative.py
scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
0d47fdf6;Daniel Grana;2009-03-03 15:18:17 +0000;utils: revert canonicalize_url implementation, it wasnt intended to be changed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40961

==

scrapy/trunk/scrapy/utils/url.py
==================
8724ee16;Daniel Grana;2009-03-03 15:05:50 +0000;utils: url canonicalization keeps blanks query parameters
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40960

==

scrapy/trunk/scrapy/tests/test_utils_request.py
scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
2e1a1705;Ismael Carnales;2009-03-03 07:42:54 +0000;added LxmlParserLinkExtractor a new try on link extracting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40959

==

scrapy/trunk/scrapy/contrib_exp/link/__init__.py
==================
309bf927;Daniel Grana;2009-03-03 05:37:41 +0000;xmlrpc: send request as POST by default and use dont_filter
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40958

==

scrapy/trunk/scrapy/http/request/rpc.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
ff7c6d37;Daniel Grana;2009-03-03 00:37:06 +0000;http: add XmlRpcRequest based on xmlrpclib
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40957

==

scrapy/trunk/scrapy/http/__init__.py
scrapy/trunk/scrapy/http/request/rpc.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
ab3fdbdb;Daniel Grana;2009-03-02 23:22:36 +0000;core: prevent download timeout from been accidentally disabled
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40956

==

scrapy/trunk/scrapy/core/downloader/handlers.py
==================
875e8e57;Ismael Carnales;2009-03-02 19:49:42 +0000;added lxml based link extractor for supporting sites with broken htm
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40955

==

scrapy/trunk/scrapy/contrib_exp/link/__init__.py
==================
127e5ae0;Ismael Carnales;2009-03-02 18:03:48 +0000;convert process_attr to a parameter in contructor so extending the class is not needed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40954

==

scrapy/trunk/scrapy/contrib_exp/link/__init__.py
==================
1f38460b;Daniel Grana;2009-03-02 17:29:48 +0000;allow returning None and non-iterables from spiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40953

==

scrapy/trunk/scrapy/spider/middleware.py
==================
2acdd9b4;Daniel Grana;2009-03-02 17:29:18 +0000;utils: add any value to iterable function
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40952

==

scrapy/trunk/scrapy/tests/test_utils_misc.py
scrapy/trunk/scrapy/utils/misc.py
==================
315934bf;Ismael Carnales;2009-03-02 17:27:29 +0000;added new LinkExtractor based on HTMLParser and with a hook for preprocessing the attribute
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40951

==

scrapy/trunk/scrapy/contrib_exp/link/__init__.py
==================
57c7c5e9;Daniel Grana;2009-03-02 15:37:57 +0000;images: log a short message when images request is ignored to dupefilter
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40950

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
==================
4b0d69cc;Pablo Hoffman;2009-03-02 14:52:34 +0000;removed some unused imports
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40949

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cookies.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/debug.py
scrapy/trunk/scrapy/contrib/pipeline/s3images.py
scrapy/trunk/scrapy/core/downloader/webclient.py
scrapy/trunk/scrapy/core/scheduler/middleware.py
scrapy/trunk/scrapy/http/response/html.py
scrapy/trunk/scrapy/http/response/xml.py
scrapy/trunk/scrapy/patches/monkeypatches.py
==================
d8f31f56;Ismael Carnales;2009-03-02 02:58:10 +0000;pass the item_instance of ItemAdaptor as an adaptor_arg
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40948

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
16c20f5c;Ismael Carnales;2009-03-01 14:26:11 +0000;added default_adaptor to ItemAdaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40947

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
f145e850;Ismael Carnales;2009-03-01 14:16:05 +0000;discover adaptors in the python way
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40946

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
41ef6c26;Ismael Carnales;2009-03-01 13:09:54 +0000;added default_adaptor to the newitem documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40945

==

scrapy/trunk/docs/proposed/newitem.rst
==================
67248194;Ismael Carnales;2009-03-01 12:59:28 +0000;updated newitem proposed docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40944

==

scrapy/trunk/docs/proposed/newitem.rst
==================
ff950e7a;Ismael Carnales;2009-03-01 12:28:55 +0000;added intro/tutorial for new Item and ItemAdaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40943

==

scrapy/trunk/docs/proposed/index.rst
scrapy/trunk/docs/proposed/items.rst
scrapy/trunk/docs/proposed/newitem.rst
==================
43b87acd;Daniel Grana;2009-03-01 11:14:30 +0000;docs: rename setting doc accordly
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40942

==

scrapy/trunk/docs/ref/settings.rst
==================
e998f922;Daniel Grana;2009-03-01 11:04:09 +0000;docs: document SCHEDULER_MIDDLEWARE setting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40941

==

scrapy/trunk/docs/ref/settings.rst
==================
ee80b1bc;Pablo Hoffman;2009-02-28 03:04:31 +0000;added doc about 'dont_merge_cookies' recently added by Damian
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40940

==

scrapy/trunk/docs/ref/request-response.rst
==================
ca22e332;Pablo Hoffman;2009-02-28 02:51:18 +0000;renamed to_list function to arg_to_list, added docstring and one more test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40939

==

scrapy/trunk/scrapy/tests/test_utils_misc.py
scrapy/trunk/scrapy/utils/misc.py
==================
10be9b69;Pablo Hoffman;2009-02-28 02:42:46 +0000;moved Ismael to Scrapy contributors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40938

==

scrapy/trunk/AUTHORS
==================
55fb3c0d;Pablo Hoffman;2009-02-28 02:42:32 +0000;removed UsageError from docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40937

==

scrapy/trunk/docs/ref/exceptions.rst
==================
d16169e9;Pablo Hoffman;2009-02-28 02:39:28 +0000;replaced UsageError exception by more standard (and explicit) ones such as TypeError and ValueError
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40936

==

scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/contrib/spiders/feed.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/exceptions.py
scrapy/trunk/scrapy/spider/models.py
scrapy/trunk/scrapy/tests/test_robustscrapeditem.py
scrapy/trunk/scrapy/tests/test_utils_misc.py
scrapy/trunk/scrapy/utils/misc.py
==================
bfe5a554;Daniel Grana;2009-02-27 18:48:09 +0000;newitem: clenaup ItemAdaptor inheritance search
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40935

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
e590764d;Pablo Hoffman;2009-02-27 18:47:48 +0000;added Andres to AUTHORS
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40934

==

scrapy/trunk/AUTHORS
==================
a88119aa;Daniel Grana;2009-02-27 18:44:40 +0000;newitem: redefine adaptor fields as staticmethods
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40933

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
7215ffa1;samus_;2009-02-25 09:53:44 +0000;a bit of convention
--HG--
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/http_compression.py => scrapy/trunk/scrapy/contrib/downloadermiddleware/httpcompression.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40932

==

scrapy/trunk/docs/proposed/tutorial.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/examples/contrib_exp/googledir/googledir/settings.py
scrapy/trunk/examples/googledir/googledir/settings.py
scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/httpcompression.py
scrapy/trunk/scrapy/templates/project/module/settings.py
==================
bf960fb1;samus_;2009-02-25 09:38:14 +0000;renamed scrapy.contrib.downloadermiddleware.compression.CompressionMiddleware to scrapy.contrib.downloadermiddleware.http_compression.HTTPCompressionMiddleware
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40931

==

scrapy/trunk/docs/proposed/tutorial.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/examples/contrib_exp/googledir/googledir/settings.py
scrapy/trunk/examples/googledir/googledir/settings.py
scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/http_compression.py
scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/trunk/scrapy/templates/project/module/settings.py
==================
bfcde7e0;Daniel Grana;2009-02-25 09:31:39 +0000;newitem: more tests on itemadaptor inheritance
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40930

==

scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
fdaa2ec3;Daniel Grana;2009-02-25 09:15:28 +0000;newitem: support multiple depth inheritance of ItemAdaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40929

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
03db6590;Daniel Grana;2009-02-25 08:44:58 +0000;newitem: make adaptor inheritance python2.5 compatible
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40928

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
0a598ff0;Ismael Carnales;2009-02-25 08:28:24 +0000;allow setting not adapted item values in ItemAdaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40927

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
6d2a3e09;Ismael Carnales;2009-02-25 07:42:35 +0000;added to_date adaptor to format a date suitable for DateField
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40926

==

scrapy/trunk/scrapy/contrib_exp/adaptors/__init__.py
scrapy/trunk/scrapy/contrib_exp/adaptors/date.py
==================
3e8945a4;Daniel Grana;2009-02-25 07:39:14 +0000;newitem: another fix to ItemAdaptor inheritance and tests included
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40925

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
cf3afb94;Daniel Grana;2009-02-25 06:52:06 +0000;newitem: fix itemadaptor inheritance
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40924

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
1fa5c7ba;samus_;2009-02-25 06:48:41 +0000;back to the basics 8)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40923

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
5af4f3a2;samus_;2009-02-25 06:37:17 +0000;fix except syntax
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40922

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
2f60224b;samus_;2009-02-25 06:33:08 +0000;fix except syntax
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40921

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
4675404f;Ismael Carnales;2009-02-25 06:30:31 +0000;ooops, removed extra print statement from adaptors.py
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40920

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
9fb0f509;Ismael Carnales;2009-02-25 06:24:55 +0000;renamed extractors to adaptors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40919

==

scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
c6e76dad;samus_;2009-02-25 05:49:23 +0000;(missed parameter)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40918

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
de1b9e5e;samus_;2009-02-25 05:48:01 +0000;added gzip support for logs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40917

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
82dc57e5;Daniel Grana;2009-02-25 00:29:10 +0000;headers: complete new Headers behaviour migration. closes #47
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40916

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/contrib/pipeline/s3images.py
scrapy/trunk/scrapy/core/downloader/responsetypes/__init__.py
scrapy/trunk/scrapy/http/headers.py
scrapy/trunk/scrapy/http/response/text.py
scrapy/trunk/scrapy/tests/test_http_headers.py
==================
5de0816d;Daniel Grana;2009-02-25 00:27:34 +0000;url: add custom port based testcase
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40915

==

scrapy/trunk/scrapy/tests/test_http_url.py
==================
5d3489ac;Daniel Grana;2009-02-25 00:27:02 +0000;headers: add docstring and title prior encoding keys. refs #47
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40914

==

scrapy/trunk/scrapy/http/headers.py
==================
987ceb54;Pablo Hoffman;2009-02-24 14:17:16 +0000;fixed import error (thanks Shane) and added some basic tests for ScrapedItem
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40913

==

scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/tests/test_item.py
==================
93453574;Daniel Grana;2009-02-24 06:58:12 +0000;headers: cleanup Headers class and add normvalue method to CaselessDict
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40912

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/http/headers.py
scrapy/trunk/scrapy/tests/test_datatypes.py
scrapy/trunk/scrapy/utils/datatypes.py
scrapy/trunk/scrapy/utils/http.py
==================
f4b55bfd;Daniel Grana;2009-02-24 06:57:28 +0000;datatypes: add CaselessDict test and cleanup
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40911

==

scrapy/trunk/scrapy/tests/test_datatypes.py
scrapy/trunk/scrapy/utils/datatypes.py
==================
d504a2b4;Daniel Grana;2009-02-24 05:13:31 +0000;bugfix newitem adaptor imports
--HG--
rename : scrapy/trunk/scrapy/tests/test_itemextractor.py => scrapy/trunk/scrapy/tests/test_itemadaptor.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40910

==

scrapy/trunk/scrapy/tests/test_itemadaptor.py
==================
119706ae;Daniel Grana;2009-02-24 05:12:58 +0000;headers: remove unused methods
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40909

==

scrapy/trunk/scrapy/http/headers.py
==================
5afa621d;Ismael Carnales;2009-02-24 04:04:25 +0000;moved extractors.py to adaptors.py
--HG--
rename : scrapy/trunk/scrapy/contrib_exp/newitem/extractors.py => scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40908

==

scrapy/trunk/examples/contrib_exp/googledir/googledir/items.py
scrapy/trunk/scrapy/contrib_exp/newitem/adaptors.py
==================
83982124;Ismael Carnales;2009-02-24 04:02:34 +0000;renamed ItemExtractor to ItemAdaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40907

==

scrapy/trunk/examples/contrib_exp/googledir/googledir/items.py
scrapy/trunk/examples/contrib_exp/googledir/googledir/spiders/google_directory.py
scrapy/trunk/scrapy/contrib_exp/newitem/extractors.py
==================
b2610274;Ismael Carnales;2009-02-24 03:51:40 +0000;minor code style changes to extractors.py
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40906

==

scrapy/trunk/scrapy/contrib_exp/newitem/extractors.py
==================
53983e6e;Daniel Grana;2009-02-24 03:42:21 +0000;newitem: remove ExtractorField and port googledir example
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40905

==

scrapy/trunk/examples/contrib_exp/googledir/googledir/items.py
scrapy/trunk/scrapy/contrib_exp/newitem/extractors.py
==================
15909ef6;Daniel Grana;2009-02-24 03:41:44 +0000;newitem: rename treeadapt as adaptor, and bugfix a mutable dictionary bug
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40904

==

scrapy/trunk/scrapy/contrib_exp/newitem/extractors.py
scrapy/trunk/scrapy/tests/test_itemextractor.py
scrapy/trunk/scrapy/utils/python.py
==================
ebe106b7;Damian Canabal;2009-02-24 00:48:50 +0000;check for dont_merge_cookies flag in request.meta
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40903

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cookies.py
==================
b0624e23;Daniel Grana;2009-02-23 20:27:02 +0000;proper rename dupefilter test
--HG--
rename : scrapy/trunk/scrapy/tests/test_filters.py => scrapy/trunk/scrapy/tests/test_dupefilter.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40902

==

scrapy/trunk/scrapy/tests/test_dupefilter.py
==================
d1265a41;Daniel Grana;2009-02-23 20:21:11 +0000;move dupe filter code outside of core. refs #49
--HG--
rename : scrapy/trunk/scrapy/core/filters.py => scrapy/trunk/scrapy/dupefilter/__init__.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40901

==

scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/dupefilter/__init__.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/trunk/scrapy/tests/test_filters.py
scrapy/trunk/scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
scrapy/trunk/scrapy/tests/test_spidermiddleware_duplicatesfilter.py
==================
c6326a04;Daniel Grana;2009-02-23 19:49:37 +0000;core: add a custom HTTPClientFactory to reuse url parsing, and remove malformed headers monkeypatches. closes #52
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40900

==

scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/downloader/webclient.py
scrapy/trunk/scrapy/patches/monkeypatches.py
scrapy/trunk/scrapy/tests/test_webclient.py
==================
86d02568;Pablo Hoffman;2009-02-21 21:26:10 +0000;added FAQ about HTTP proxies
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40899

==

scrapy/trunk/docs/faq.rst
==================
9d5a1d77;samus_;2009-02-20 18:17:55 +0000;adding to_list() util and test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40898

==

scrapy/trunk/scrapy/tests/test_utils_misc.py
scrapy/trunk/scrapy/utils/misc.py
==================
8d8a5c5c;Daniel Grana;2009-02-20 17:59:58 +0000;change ExtractorField callable signature to honor adaptor_args
and add alternative treeadapt implementation.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40897

==

scrapy/trunk/scrapy/contrib_exp/newitem/extractors.py
scrapy/trunk/scrapy/utils/python.py
==================
0c2e019f;Pablo Hoffman;2009-02-20 17:35:25 +0000;added test for load_object
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40896

==

scrapy/trunk/scrapy/tests/test_utils_misc.py
==================
059bf613;Ismael Carnales;2009-02-20 12:02:56 +0000;added example project that uses newitem and ItemExtractor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40895

==

scrapy/trunk/examples/contrib_exp/googledir/googledir/__init__.py
scrapy/trunk/examples/contrib_exp/googledir/googledir/items.py
scrapy/trunk/examples/contrib_exp/googledir/googledir/pipelines.py
scrapy/trunk/examples/contrib_exp/googledir/googledir/settings.py
scrapy/trunk/examples/contrib_exp/googledir/googledir/spiders/__init__.py
scrapy/trunk/examples/contrib_exp/googledir/googledir/spiders/google_directory.py
scrapy/trunk/examples/contrib_exp/googledir/googledir/templates/spider_basic.tmpl
scrapy/trunk/examples/contrib_exp/googledir/googledir/templates/spider_crawl.tmpl
scrapy/trunk/examples/contrib_exp/googledir/googledir/templates/spider_csvfeed.tmpl
scrapy/trunk/examples/contrib_exp/googledir/googledir/templates/spider_xmlfeed.tmpl
scrapy/trunk/examples/contrib_exp/googledir/scrapy-ctl.py
==================
5a5aef66;Ismael Carnales;2009-02-20 11:42:36 +0000;made newitem.Item inherit from ScrapedItem for compatibility
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40894

==

scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
8d5222f1;Daniel Grana;2009-02-20 11:31:09 +0000;core: add missing imports
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40893

==

scrapy/trunk/scrapy/contrib/schedulermiddleware/__init__.py
scrapy/trunk/scrapy/contrib/schedulermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/core/scheduler/middleware.py
scrapy/trunk/scrapy/tests/test_schedulermiddleware_duplicatesfilter.py
==================
4bf196fc;Daniel Grana;2009-02-20 11:28:37 +0000;core: add scheduler middleware and move duplicate fitler there
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40892

==

scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/core/scheduler/__init__.py
scrapy/trunk/scrapy/tests/test_spidermiddleware_duplicatesfilter.py
==================
549c30d8;Daniel Grana;2009-02-20 11:27:46 +0000;redirect: remove stupid set
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40891

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
==================
071aa71b;Daniel Grana;2009-02-19 19:53:30 +0000;add filters module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40890

==

scrapy/trunk/scrapy/core/filters.py
scrapy/trunk/scrapy/tests/test_filters.py
==================
0e98526d;Daniel Grana;2009-02-19 19:43:24 +0000;duplicatesfilter: add a singeton duplicates filter and adapt current middleware and redirection middleware
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40889

==

scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/trunk/scrapy/tests/test_spidermiddleware_duplicatesfilter.py
==================
ac735a18;Daniel Grana;2009-02-19 19:42:42 +0000;cleanup redirection middleware
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40888

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
==================
65e8be46;Ismael Carnales;2009-02-19 19:05:45 +0000;add typecheck of funcs in ExtractorField.__init__
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40887

==

scrapy/trunk/scrapy/contrib_exp/newitem/extractors.py
==================
edf5dfb2;Ismael Carnales;2009-02-19 18:56:59 +0000;added newitem.extractors based on old adaptors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40886

==

scrapy/trunk/scrapy/contrib_exp/newitem/extractors.py
==================
756cda38;Daniel Grana;2009-02-19 16:49:03 +0000;duplicatefilter: dont raise ignorerequest, but add request to filter on spider input
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40885

==

scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/tests/test_spidermiddleware_duplicatesfilter.py
==================
fe793500;Daniel Grana;2009-02-19 16:37:33 +0000;duplicatefilter: filter request prior to reach spider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40884

==

scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/tests/test_spidermiddleware_duplicatesfilter.py
==================
5338a48d;Daniel Grana;2009-02-19 16:17:08 +0000;remove missing import
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40883

==

scrapy/trunk/scrapy/command/commands/crawl.py
==================
26bcc826;Ismael Carnales;2009-02-19 14:46:23 +0000;renamed ItemField to Field for upcoming ItemExtractor and FieldExtractor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40882

==

scrapy/trunk/scrapy/contrib_exp/newitem/fields.py
scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
7fc8d590;Daniel Grana;2009-02-19 14:22:23 +0000;guid: cleanup guid attribute references including removal of replays and deprecated commands
--HG--
rename : scrapy/trunk/scrapy/contrib/history/__init__.py => scrapy/trunk/scrapy/contrib_exp/history/__init__.py
rename : scrapy/trunk/scrapy/contrib/history/history.py => scrapy/trunk/scrapy/contrib_exp/history/history.py
rename : scrapy/trunk/scrapy/contrib/history/middleware.py => scrapy/trunk/scrapy/contrib_exp/history/middleware.py
rename : scrapy/trunk/scrapy/contrib/history/scheduler.py => scrapy/trunk/scrapy/contrib_exp/history/scheduler.py
rename : scrapy/trunk/scrapy/contrib/history/store.py => scrapy/trunk/scrapy/contrib_exp/history/store.py
rename : scrapy/trunk/scrapy/contrib/pipeline/shoveitem.py => scrapy/trunk/scrapy/contrib_exp/pipeline/shoveitem.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40881

==

scrapy/trunk/scrapy/command/commands/getattr.py
scrapy/trunk/scrapy/command/commands/replay.py
scrapy/trunk/scrapy/contrib_exp/history/__init__.py
scrapy/trunk/scrapy/contrib_exp/history/history.py
scrapy/trunk/scrapy/contrib_exp/history/middleware.py
scrapy/trunk/scrapy/contrib_exp/history/scheduler.py
scrapy/trunk/scrapy/contrib_exp/history/store.py
scrapy/trunk/scrapy/contrib_exp/pipeline/shoveitem.py
scrapy/trunk/scrapy/replay/__init__.py
==================
81ce9bd4;Ismael Carnales;2009-02-19 13:57:40 +0000;calculate ItemField.default on __init__
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40880

==

scrapy/trunk/scrapy/contrib_exp/newitem/fields.py
==================
db4ccaf7;Ismael Carnales;2009-02-19 13:34:02 +0000;add __all__ to fields.py in newitem
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40879

==

scrapy/trunk/scrapy/contrib_exp/newitem/fields.py
==================
5c45ecb7;Ismael Carnales;2009-02-19 12:45:54 +0000;turned default_value() of ItemField into a property
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40878

==

scrapy/trunk/scrapy/contrib_exp/newitem/fields.py
scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
76c84bda;Ismael Carnales;2009-02-19 12:39:58 +0000;always deiter on ItemField value assignation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40877

==

scrapy/trunk/scrapy/contrib_exp/newitem/fields.py
scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
22549161;Daniel Grana;2009-02-19 11:55:09 +0000;duplicatefilter: fix unittest to filter a request with same url as start_requests. rel r868. ref #49
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40876

==

scrapy/trunk/scrapy/tests/test_spidermiddleware_duplicatesfilter.py
==================
1017f121;Ismael Carnales;2009-02-19 11:40:21 +0000;don't allow setting attributes that aren't fields, and return field default values on newitem
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40875

==

scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
d95878c0;Ismael Carnales;2009-02-19 11:26:01 +0000;corrected import paths in newitem
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40874

==

scrapy/trunk/scrapy/contrib_exp/newitem/__init__.py
scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
c11e5ad3;Pablo Hoffman;2009-02-19 11:07:41 +0000;fixed grammar error. thanks Fabio
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40873

==

scrapy/trunk/docs/faq.rst
==================
c546585a;samus_;2009-02-19 05:12:55 +0000;conflict solved, reverted r869 and applied changes for r868
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40872

==

scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_spidermiddleware_duplicatesfilter.py
==================
fefccfaa;samus_;2009-02-19 04:59:12 +0000;conflict among tests, reverting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40871

==

scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
==================
14900a74;samus_;2009-02-19 04:21:49 +0000;fix to default parameter (must be tuple not string)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40870

==

scrapy/trunk/scrapy/link/extractors.py
==================
de13bbe7;samus_;2009-02-19 04:19:05 +0000;fix to filter start_urls too
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40869

==

scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
==================
9739f932;Ismael Carnales;2009-02-18 18:57:26 +0000;move newitem from contrib to contrib.exp
--HG--
rename : scrapy/trunk/scrapy/contrib/newitem/__init__.py => scrapy/trunk/scrapy/contrib_exp/newitem/__init__.py
rename : scrapy/trunk/scrapy/contrib/newitem/fields.py => scrapy/trunk/scrapy/contrib_exp/newitem/fields.py
rename : scrapy/trunk/scrapy/contrib/newitem/models.py => scrapy/trunk/scrapy/contrib_exp/newitem/models.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40868

==

scrapy/trunk/scrapy/contrib_exp/newitem/__init__.py
scrapy/trunk/scrapy/contrib_exp/newitem/fields.py
scrapy/trunk/scrapy/contrib_exp/newitem/models.py
==================
30394531;Ismael Carnales;2009-02-18 18:38:26 +0000;added newitem with new item model and fields
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40867

==

scrapy/trunk/scrapy/contrib/newitem/__init__.py
scrapy/trunk/scrapy/contrib/newitem/fields.py
scrapy/trunk/scrapy/contrib/newitem/models.py
==================
918908db;samus_;2009-02-18 15:22:15 +0000;removed empty dir
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40866

==
==================
f8affd0c;Ismael Carnales;2009-02-18 13:36:47 +0000;added fields.py with ItemField class and subclasses based on Django's for new items
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40865

==

scrapy/trunk/scrapy/contrib/item/fields.py
==================
b20ac057;Ismael Carnales;2009-02-18 11:18:11 +0000;added rule shorthand, for creating CrawlSpider rules
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40864

==

scrapy/trunk/scrapy/contrib/spiders/__init__.py
scrapy/trunk/scrapy/contrib/spiders/crawl.py
==================
84f63b14;Daniel Grana;2009-02-17 14:20:19 +0000;cluster: merge spider settings prior to run spider, not when scheduling
also reformat some long lines.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40863

==

scrapy/trunk/scrapy/contrib_exp/cluster/master/manager.py
==================
714c3e20;Pablo Hoffman;2009-02-16 23:45:14 +0000;minor typo fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40862

==

scrapy/trunk/scrapy/utils/python.py
==================
489e86bd;Pablo Hoffman;2009-02-16 23:43:43 +0000;moved copytree function to scrapy.utils.python (more appropiate location) and fixed minor bug ('Error' not defined). also removed unused var 'project_module_path'
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40861

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
scrapy/trunk/scrapy/utils/misc.py
scrapy/trunk/scrapy/utils/python.py
==================
e6458d05;Ismael Carnales;2009-02-16 16:42:35 +0000;completed first version of basic tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40860

==

scrapy/trunk/docs/proposed/tutorial.rst
==================
730575a5;Ismael Carnales;2009-02-16 13:30:20 +0000;define WindowsError (also in shutils from 2.6)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40859

==

scrapy/trunk/scrapy/utils/misc.py
==================
5c1dd252;Ismael Carnales;2009-02-16 13:15:55 +0000;removed spiders cache from example project, thxs Michael
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40858

==

scrapy/trunk/examples/googledir/googledir/spiders/dropin.cache
==================
3e8bcafd;Ismael Carnales;2009-02-16 12:50:00 +0000;added copytree from python 2.6 to utils.misc and make startproject use it to ignore .svn and .pyc files
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40857

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
scrapy/trunk/scrapy/utils/misc.py
==================
522fe78c;Ismael Carnales;2009-02-16 11:52:49 +0000;remove old project example
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40856

==

scrapy/trunk/examples/google_bot/__init__.py
scrapy/trunk/examples/google_bot/items.py
scrapy/trunk/examples/google_bot/scrapy-ctl.py
scrapy/trunk/examples/google_bot/scrapy_settings.py
scrapy/trunk/examples/google_bot/spiders/__init__.py
scrapy/trunk/examples/google_bot/spiders/google_directory.py
scrapy/trunk/examples/google_bot/templates/spider_basic.tmpl
scrapy/trunk/examples/google_bot/templates/spider_crawl.tmpl
scrapy/trunk/examples/google_bot/templates/spider_csvfeed.tmpl
scrapy/trunk/examples/google_bot/templates/spider_xmlfeed.tmpl
==================
bb9a732e;Ismael Carnales;2009-02-16 11:51:07 +0000;updated tutorial with new googledir project from r853
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40855

==

scrapy/trunk/docs/intro/tutorial/tutorial1.rst
scrapy/trunk/docs/intro/tutorial/tutorial2.rst
scrapy/trunk/docs/intro/tutorial/tutorial3.rst
scrapy/trunk/docs/intro/tutorial/tutorial4.rst
==================
eb1e62a2;Ismael Carnales;2009-02-16 11:49:44 +0000;add new googledir example project with new structure
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40854

==

scrapy/trunk/examples/googledir/googledir/__init__.py
scrapy/trunk/examples/googledir/googledir/items.py
scrapy/trunk/examples/googledir/googledir/pipelines.py
scrapy/trunk/examples/googledir/googledir/settings.py
scrapy/trunk/examples/googledir/googledir/spiders/__init__.py
scrapy/trunk/examples/googledir/googledir/spiders/dropin.cache
scrapy/trunk/examples/googledir/googledir/spiders/google_directory.py
scrapy/trunk/examples/googledir/googledir/templates/spider_basic.tmpl
scrapy/trunk/examples/googledir/googledir/templates/spider_crawl.tmpl
scrapy/trunk/examples/googledir/googledir/templates/spider_csvfeed.tmpl
scrapy/trunk/examples/googledir/googledir/templates/spider_xmlfeed.tmpl
scrapy/trunk/examples/googledir/scrapy-ctl.py
==================
755235b5;Daniel Grana;2009-02-13 17:21:50 +0000;utils: renamed load_class function as load_object
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40853

==

scrapy/trunk/scrapy/command/commands/shell.py
scrapy/trunk/scrapy/contrib/history/middleware.py
scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/contrib_exp/cluster/worker/manager.py
scrapy/trunk/scrapy/core/downloader/middleware.py
scrapy/trunk/scrapy/core/downloader/responsetypes/__init__.py
scrapy/trunk/scrapy/core/manager.py
scrapy/trunk/scrapy/extension/__init__.py
scrapy/trunk/scrapy/item/pipeline.py
scrapy/trunk/scrapy/spider/manager.py
scrapy/trunk/scrapy/spider/middleware.py
scrapy/trunk/scrapy/utils/misc.py
==================
3876a182;Daniel Grana;2009-02-13 17:20:10 +0000;cluster: move branched cluster as experimental contrib
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40852

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/__init__.py
scrapy/trunk/scrapy/contrib_exp/cluster/__init__.py
scrapy/trunk/scrapy/contrib_exp/cluster/crawler/__init__.py
scrapy/trunk/scrapy/contrib_exp/cluster/crawler/manager.py
scrapy/trunk/scrapy/contrib_exp/cluster/hooks/__init__.py
scrapy/trunk/scrapy/contrib_exp/cluster/hooks/svn.py
scrapy/trunk/scrapy/contrib_exp/cluster/master/__init__.py
scrapy/trunk/scrapy/contrib_exp/cluster/master/manager.py
scrapy/trunk/scrapy/contrib_exp/cluster/master/web.py
scrapy/trunk/scrapy/contrib_exp/cluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib_exp/cluster/tools/scrapy-cluster-ctl.py
scrapy/trunk/scrapy/contrib_exp/cluster/tools/test-worker.py
scrapy/trunk/scrapy/contrib_exp/cluster/worker/__init__.py
scrapy/trunk/scrapy/contrib_exp/cluster/worker/manager.py
==================
47cf45c9;Pablo Hoffman;2009-02-12 20:58:42 +0000;removed redudant part of Scrapy introduction to make it simpler. thanks Ismael for pointing that out
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40851

==

scrapy/trunk/docs/intro/overview.rst
==================
8557f6bc;Daniel Grana;2009-02-12 15:55:11 +0000;duplicatefilter: lower log level of skipped requests message
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40850

==

scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
==================
2b142515;Daniel Grana;2009-02-12 08:00:07 +0000;cache: read metadata only when when looking for cached items. refs #61
thanks Patrick Mezard for patch.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40849

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
==================
d6864642;Daniel Grana;2009-02-12 07:59:40 +0000;storedb: gracefully fail test if mysql is not installed.
thanks Patrick Mezard for patch.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40848

==

scrapy/trunk/scrapy/tests/test_storedb.py
==================
3e4bc614;Daniel Grana;2009-02-12 07:39:57 +0000;core: remove obsolte groupfilter code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40847

==

scrapy/trunk/scrapy/core/scheduler/__init__.py
scrapy/trunk/scrapy/core/scheduler/filter.py
scrapy/trunk/scrapy/tests/test_groupfilter.py
==================
c9f2865c;Daniel Grana;2009-02-12 07:07:13 +0000;core: Get rid of duplicate filtering as a scheduler builtin feature. closes #49.
Implements a DuplicatesFilterMiddleware as spidermiddleware, a wraper
using a minimal defined API of a filtering class configurable by
settings.

Enabling this middleware doesn't gives us same functionality compared to
scheduler duplicate filter builtin, but it filter the most important
source for duplicate requests, the spiders.

What requests aren't filtered by new middleware? The ones originated
from any part of scrapy outside of spiders, like S3 images requests or
any other request manually schedule using ``scrapyengine.schedule()``
method.

Previously, we usually added dont_filter=True to requests created
outside of spiders to avoid collisions downloading same pages than
spider. Now, this is not required anymore because new middleware filters
just the spider generated requests.

There is a caveat, as usual downloadmiddlewares can returns a Request
object at any point of the chain, and that request is scheduled and
downloaded as usual too. One of the downloadmiddlewares using this
feature is RedirectMiddleware that counts on scheduler filtering builtin
to avoid redirection loops. I think we can implement a request time to
live decreasing counter and add it to request's ``meta`` attribute with
a default value if not present, and decrement each time the request is
redirected.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40846

==

scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
scrapy/trunk/scrapy/core/scheduler/schedulers.py
scrapy/trunk/scrapy/templates/project/module/settings.py
scrapy/trunk/scrapy/tests/test_spidermiddleware_duplicatesfilter.py
==================
0aba276a;Daniel Grana;2009-02-12 04:39:49 +0000;tutorial: indent class docstring
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40845

==

scrapy/trunk/docs/intro/tutorial/tutorial3.rst
==================
73d8177e;Daniel Grana;2009-02-12 04:38:13 +0000;tutorial: lot of line wrapping and changes to double backticks instead of emphatized words
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40844

==

scrapy/trunk/docs/intro/tutorial/tutorial1.rst
scrapy/trunk/docs/intro/tutorial/tutorial2.rst
scrapy/trunk/docs/intro/tutorial/tutorial3.rst
scrapy/trunk/docs/intro/tutorial/tutorial4.rst
==================
7c056c62;Daniel Grana;2009-02-12 03:58:54 +0000;tutorial: fix outofdate and broken tutorial after adaptors were moved to experimental
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40843

==

scrapy/trunk/docs/intro/tutorial/tutorial2.rst
scrapy/trunk/docs/intro/tutorial/tutorial3.rst
scrapy/trunk/docs/intro/tutorial/tutorial4.rst
==================
f43c58da;Daniel Grana;2009-02-10 18:27:59 +0000;adds a reference about empty request body and Content-Length header fix, closes #60.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40842

==

scrapy/trunk/scrapy/core/downloader/handlers.py
==================
8fdf06ed;Daniel Grana;2009-02-10 13:23:38 +0000;Avoid sending Content-Length header when body is an empty string.
Some sites can't handle "Content-Length: 0" header, but twisted
HTTPClientFactory adds Content-Length header unless body is None.

scrapy enforces request.body usage as string, using None is not
possible.

thanks Matt for report, See:
http://groups.google.com/group/scrapy-users/browse_thread/thread/380ffa111879989e?hl=en

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40841

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/core/downloader/handlers.py
==================
f4224be4;Pablo Hoffman;2009-02-10 06:20:43 +0000;- added get_meta_refresh to scrapy.utils.response - added tests for get_meta_refresh_url - added RedirectMiddleware tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40840

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_redirect.py
scrapy/trunk/scrapy/tests/test_utils_response.py
scrapy/trunk/scrapy/utils/response.py
==================
d376b209;Pablo Hoffman;2009-02-10 04:46:07 +0000;minor fix to doctest
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40839

==

scrapy/trunk/scrapy/utils/misc.py
==================
90c1597c;Pablo Hoffman;2009-02-10 02:43:19 +0000;fixed bug with items_to_csv and Excel. thanks Mat for the patch. See:
http://groups.google.com/group/scrapy-developers/browse_thread/thread/9e2b80d226333011

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40838

==

scrapy/trunk/scrapy/utils/misc.py
==================
1b2de801;Daniel Grana;2009-02-09 17:20:41 +0000;remove scrapy/dos external referenced from scrapy.org site
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40837

==
==================
844b59b5;Ismael Carnales;2009-02-09 15:06:22 +0000;reduced introduction text in proposed doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40836

==

scrapy/trunk/docs/proposed/introduction.rst
==================
d98f35af;Ismael Carnales;2009-02-09 14:29:48 +0000;added items section (ScrapedItems) to proposed doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40835

==

scrapy/trunk/docs/proposed/index.rst
scrapy/trunk/docs/proposed/items.rst
==================
3a3723ba;Ismael Carnales;2009-02-09 13:59:15 +0000;removed reference to guid in ScrapedItem
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40834

==

scrapy/trunk/scrapy/item/models.py
==================
38c62ca3;Pablo Hoffman;2009-02-08 21:00:26 +0000;settings must be documented in alphabetical order
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40833

==

scrapy/trunk/docs/ref/settings.rst
==================
45340d3d;Ismael Carnales;2009-02-06 20:19:17 +0000;better index for proposed documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40832

==

scrapy/trunk/docs/proposed/index.rst
scrapy/trunk/docs/proposed/spiders.rst
==================
5ca47288;Ismael Carnales;2009-02-06 20:15:34 +0000;added complete spiders topic and reference (in one file) using an autodoc and manual doc mix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40831

==

scrapy/trunk/docs/proposed/index.rst
scrapy/trunk/docs/proposed/introduction.rst
scrapy/trunk/docs/proposed/spiders.rst
==================
3fb945be;Ismael Carnales;2009-02-06 20:02:13 +0000;fixed doc on BaseSpider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40830

==

scrapy/trunk/scrapy/spider/models.py
==================
485b9c9e;Ismael Carnales;2009-02-06 20:01:27 +0000;updated docstrings of feedspiders for autodoc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40829

==

scrapy/trunk/scrapy/contrib/spiders/feed.py
==================
9ba07653;Ismael Carnales;2009-02-06 16:20:49 +0000;added a proposed introduction (with all the main topics) to the proposed documentation, this would be the start for the new tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40828

==

scrapy/trunk/docs/proposed/_images/scrapy_architecture.odg
scrapy/trunk/docs/proposed/_images/scrapy_architecture.png
scrapy/trunk/docs/proposed/index.rst
scrapy/trunk/docs/proposed/introduction.rst
scrapy/trunk/docs/proposed/tutorial.rst
==================
be04a7f3;Ismael Carnales;2009-02-05 15:39:52 +0000;modify docs configuration for autodoc to work
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40827

==

scrapy/trunk/docs/Makefile
scrapy/trunk/docs/conf.py
==================
96be669a;Ismael Carnales;2009-02-05 13:44:32 +0000;fix tutorial1 errors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40826

==

scrapy/trunk/docs/intro/tutorial/tutorial1.rst
==================
fe2f018b;Daniel Grana;2009-02-05 13:41:10 +0000;FormRequest: urlencode multiples values of a single key using doseq
this prevents urllib.urlencode from sending the repr of the value when
it founds a list or tuple.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40825

==

scrapy/trunk/scrapy/http/request/form.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
6650e563;Ismael Carnales;2009-02-05 13:35:14 +0000;changed representation of the project tree in the tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40824

==

scrapy/trunk/docs/intro/tutorial/tutorial1.rst
==================
8f349737;Daniel Grana;2009-02-05 12:43:30 +0000;add missing dashes to docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40823

==

scrapy/trunk/docs/ref/settings.rst
==================
bc2ea867;Daniel Grana;2009-02-05 12:39:43 +0000;Adds docs for PROJECT_NAME setting. refs #58
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40822

==

scrapy/trunk/docs/ref/settings.rst
==================
bf87fb84;Daniel Grana;2009-02-05 12:20:25 +0000;add proper docstring to string_camelcase. refs #58
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40821

==

scrapy/trunk/scrapy/utils/misc.py
==================
751a844e;Ismael Carnales;2009-02-05 12:14:49 +0000;updated tutorial to reflect project's structure change
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40820

==

scrapy/trunk/docs/intro/tutorial/tutorial1.rst
scrapy/trunk/docs/intro/tutorial/tutorial2.rst
scrapy/trunk/docs/intro/tutorial/tutorial3.rst
scrapy/trunk/docs/intro/tutorial/tutorial4.rst
==================
f7dac0e4;Daniel Grana;2009-02-05 12:12:15 +0000;Creates an usable project structure on startproject. closes #58 and closes #54
--HG--
rename : scrapy/trunk/scrapy/conf/project_template/__init__.py => scrapy/trunk/scrapy/templates/project/module/__init__.py
rename : scrapy/trunk/scrapy/conf/project_template/items.py => scrapy/trunk/scrapy/templates/project/module/items.py
rename : scrapy/trunk/scrapy/conf/project_template/scrapy_settings.py => scrapy/trunk/scrapy/templates/project/module/settings.py
rename : scrapy/trunk/scrapy/conf/project_template/spiders/__init__.py => scrapy/trunk/scrapy/templates/project/module/spiders/__init__.py
rename : scrapy/trunk/scrapy/conf/project_template/templates/spider_basic.tmpl => scrapy/trunk/scrapy/templates/project/module/templates/spider_basic.tmpl
rename : scrapy/trunk/scrapy/conf/project_template/templates/spider_crawl.tmpl => scrapy/trunk/scrapy/templates/project/module/templates/spider_crawl.tmpl
rename : scrapy/trunk/scrapy/conf/project_template/templates/spider_csvfeed.tmpl => scrapy/trunk/scrapy/templates/project/module/templates/spider_csvfeed.tmpl
rename : scrapy/trunk/scrapy/conf/project_template/templates/spider_xmlfeed.tmpl => scrapy/trunk/scrapy/templates/project/module/templates/spider_xmlfeed.tmpl
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40819

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
scrapy/trunk/scrapy/command/commands/genspider.py
scrapy/trunk/scrapy/conf/project_template/scrapy-ctl.py
scrapy/trunk/scrapy/templates/project/module/__init__.py
scrapy/trunk/scrapy/templates/project/module/items.py
scrapy/trunk/scrapy/templates/project/module/pipelines.py
scrapy/trunk/scrapy/templates/project/module/settings.py
scrapy/trunk/scrapy/templates/project/module/spiders/__init__.py
scrapy/trunk/scrapy/templates/project/module/templates/spider_basic.tmpl
scrapy/trunk/scrapy/templates/project/module/templates/spider_crawl.tmpl
scrapy/trunk/scrapy/templates/project/module/templates/spider_csvfeed.tmpl
scrapy/trunk/scrapy/templates/project/module/templates/spider_xmlfeed.tmpl
scrapy/trunk/scrapy/templates/project/root/scrapy-ctl.py
scrapy/trunk/scrapy/utils/misc.py
==================
bccef8a4;Ismael Carnales;2009-01-31 06:09:50 +0000;fixed basespider links in topics/spider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40818

==

scrapy/trunk/docs/topics/spiders.rst
==================
fa8ebd11;Ismael Carnales;2009-01-31 06:01:33 +0000;corrected naming and references in ref/spiders doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40817

==

scrapy/trunk/docs/ref/spiders.rst
scrapy/trunk/docs/topics/spiders.rst
==================
62206097;Pablo Hoffman;2009-01-30 23:20:49 +0000;added bin/runtests.sh script to run tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40816

==

scrapy/trunk/bin/runtests.sh
==================
20a61caa;Pablo Hoffman;2009-01-30 23:20:21 +0000;fixed some doc typos
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40815

==

scrapy/trunk/docs/ref/logging.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/docs/topics/item-pipeline.rst
==================
005a6422;Pablo Hoffman;2009-01-30 23:18:23 +0000;added SETTINGS_DISABLED environment variable to turn off custom settings (and only use Scrapy defaults)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40814

==

scrapy/trunk/scrapy/conf/__init__.py
==================
16efbf87;Pablo Hoffman;2009-01-30 22:33:50 +0000;added some references to documentation and fixed some doc typos (thanks Patrick)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40813

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/common.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/compression.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
scrapy/trunk/scrapy/contrib/spiders/crawl.py
scrapy/trunk/scrapy/contrib/spiders/feed.py
scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/spider/models.py
==================
c6722230;Pablo Hoffman;2009-01-30 21:53:40 +0000;splitted spiders doc from link extractor docs, moved the corresponding parts to ref and topics
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40812

==

scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/link-extractors.rst
scrapy/trunk/docs/ref/spiders.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/link-extractors.rst
scrapy/trunk/docs/topics/spiders.rst
==================
483ef3ba;Pablo Hoffman;2009-01-30 21:52:41 +0000;changed typo in Items docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40811

==

scrapy/trunk/docs/topics/items.rst
==================
a834eef6;Ismael Carnales;2009-01-30 19:24:43 +0000;added BaseSpider attributes and method references and metadata (from tutorial)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40810

==

scrapy/trunk/docs/topics/spiders.rst
==================
7e6c9c2e;Ismael Carnales;2009-01-30 19:14:16 +0000;formatting changes and references to spiders added in the tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40809

==

scrapy/trunk/docs/proposed/tutorial.rst
==================
2526e11b;Ismael Carnales;2009-01-30 19:12:09 +0000;changed formatting a little bit and added class references to spiders topic
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40808

==

scrapy/trunk/docs/topics/spiders.rst
==================
591a4a2b;Ismael Carnales;2009-01-30 14:45:52 +0000;added information on default item in new tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40807

==

scrapy/trunk/docs/proposed/tutorial.rst
==================
f27d07c1;Ismael Carnales;2009-01-30 14:26:40 +0000;added warning of spider naming in new tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40806

==

scrapy/trunk/docs/proposed/tutorial.rst
==================
3b012d39;Ismael Carnales;2009-01-30 13:15:50 +0000;modified default project template structure in proposed tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40805

==

scrapy/trunk/docs/proposed/tutorial.rst
==================
64875319;elpolilla;2009-01-30 13:05:52 +0000;Several corrections made to items and adaptors documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40804

==

scrapy/trunk/docs/topics/adaptors.rst
scrapy/trunk/docs/topics/items.rst
==================
d9a90a1f;Ismael Carnales;2009-01-30 11:29:55 +0000;added proposed documentation, moved tutorial there
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40803

==

scrapy/trunk/docs/index.rst
scrapy/trunk/docs/proposed/index.rst
scrapy/trunk/docs/proposed/tutorial.rst
==================
6cc806a8;elpolilla;2009-01-30 11:19:20 +0000;Added adaptors diagram svg to the repo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40802

==

scrapy/trunk/docs/topics/_images/adaptors_diagram.svg
==================
bcf6e547;Pablo Hoffman;2009-01-30 11:14:08 +0000;added one more case to responsetypes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40801

==

scrapy/trunk/scrapy/core/downloader/responsetypes/__init__.py
scrapy/trunk/scrapy/tests/test_responsetypes.py
==================
769519c2;elpolilla;2009-01-30 10:57:12 +0000;Added missing adaptors diagram to documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40800

==

scrapy/trunk/docs/topics/_images/adaptors_diagram.png
==================
fb13d3d8;Pablo Hoffman;2009-01-29 20:18:53 +0000;doc: added status argument to domain_closed signal
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40799

==

scrapy/trunk/docs/ref/signals.rst
==================
b3050ca0;Daniel Grana;2009-01-29 19:18:03 +0000;pipeline: remove open_domain/close_domain hooks, use domain_open and domain_closed signals instead. docs updated.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40798

==

scrapy/trunk/docs/topics/item-pipeline.rst
scrapy/trunk/scrapy/contrib/pipeline/media.py
scrapy/trunk/scrapy/item/pipeline.py
==================
73c92464;Pablo Hoffman;2009-01-29 18:52:46 +0000;bundled mime.types file with scrapy for platforms that have poor support for mime.types (windows), added from_args() convenience method to ResponseTypes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40797

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/downloader/responsetypes/__init__.py
scrapy/trunk/scrapy/core/downloader/responsetypes/mime.types
scrapy/trunk/scrapy/tests/test_responsetypes.py
==================
f4e6ed3c;Daniel Grana;2009-01-29 18:22:59 +0000;run without RobotTxtMiddleware by default and update docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40796

==

scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/scrapy/conf/default_settings.py
==================
e6375c6a;Ismael Carnales;2009-01-29 17:57:21 +0000;added some info on items pipeline on the tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40795

==

scrapy/trunk/docs/tutorial.rst
==================
9634af9a;elpolilla;2009-01-29 17:46:32 +0000;Updated adaptors and items documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40794

==

scrapy/trunk/docs/topics/adaptors.rst
scrapy/trunk/docs/topics/items.rst
==================
ff88171b;Ismael Carnales;2009-01-29 14:35:54 +0000;added items to tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40793

==

scrapy/trunk/docs/tutorial.rst
==================
04fc0471;Ismael Carnales;2009-01-29 12:29:28 +0000;first version of the new tutorial (work in progress)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40792

==

scrapy/trunk/docs/tutorial.rst
==================
3ca2187e;elpolilla;2009-01-29 02:21:08 +0000;Removed non-generic implementation of _add_single_attributes and modified test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40791

==

scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/tests/test_robustscrapeditem.py
==================
bc4fcbea;elpolilla;2009-01-28 11:45:39 +0000;Added response type recognition to local file urls
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40790

==

scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/downloader/responsetypes.py
==================
e9fbce4e;Andres Moreira;2009-01-27 17:58:51 +0000;Improved code of utils.markup functions.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40789

==

scrapy/trunk/scrapy/utils/markup.py
==================
c0601cd0;elpolilla;2009-01-27 14:05:22 +0000;Refactored remove_entities and fixed the hex entities bug (they werent recognised). Also, tests were added
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40788

==

scrapy/trunk/scrapy/tests/test_utils_markup.py
scrapy/trunk/scrapy/utils/markup.py
==================
c3d61dc9;Pablo Hoffman;2009-01-27 13:33:28 +0000;changing extension in test from csv to txt (not all systems support the text/csv mimetype)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40787

==

scrapy/trunk/scrapy/tests/test_responsetypes.py
==================
134b867a;Pablo Hoffman;2009-01-27 13:08:07 +0000;added support for unknown file extensions to ResponseTypes.from_filename
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40786

==

scrapy/trunk/scrapy/core/downloader/responsetypes.py
scrapy/trunk/scrapy/tests/test_responsetypes.py
==================
14e67d59;elpolilla;2009-01-27 12:35:09 +0000;Added test for encoding in csviter
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40785

==

scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample4.csv
scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample5.csv
scrapy/trunk/scrapy/tests/test_utils_iterators.py
==================
1e55e881;Pablo Hoffman;2009-01-27 12:18:23 +0000;fixed some typos in previous commit
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40784

==

scrapy/trunk/docs/ref/request-response.rst
==================
11a92361;Pablo Hoffman;2009-01-27 12:17:40 +0000;added example about creating Requests with cookies
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40783

==

scrapy/trunk/docs/ref/request-response.rst
==================
14ceca98;Pablo Hoffman;2009-01-27 12:10:49 +0000;added FormRequest example
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40782

==

scrapy/trunk/docs/ref/request-response.rst
==================
e25bfa5d;Pablo Hoffman;2009-01-27 11:27:09 +0000;added more cases to ResponseTypes, and tests for ResponseTypes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40781

==

scrapy/trunk/scrapy/core/downloader/responsetypes.py
scrapy/trunk/scrapy/tests/test_responsetypes.py
==================
b6246cbc;elpolilla;2009-01-27 11:10:42 +0000;Fixed encoding-related bug in csviter
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40780

==

scrapy/trunk/scrapy/utils/iterators.py
==================
4013497e;Pablo Hoffman;2009-01-26 23:42:51 +0000;more patches sent by Patrick
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40779

==

scrapy/trunk/docs/topics/adaptors.rst
scrapy/trunk/scrapy/conf/project_template/scrapy_settings.py
==================
c1a1b894;Pablo Hoffman;2009-01-26 23:38:21 +0000;some doc fixes suggested by Patrick Mézard
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40778

==

scrapy/trunk/docs/intro/tutorial/tutorial4.rst
scrapy/trunk/docs/topics/settings.rst
==================
57189e1b;Pablo Hoffman;2009-01-26 23:31:04 +0000;applied Patrick Mézard patch for loading local files
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40777

==

scrapy/trunk/scrapy/command/commands/shell.py
==================
ce1700dd;Pablo Hoffman;2009-01-26 23:28:19 +0000;added libxml2 installation steps for MacOSX (thanks Patrick Mézard)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40776

==

scrapy/trunk/docs/intro/install.rst
==================
279b9ac4;Pablo Hoffman;2009-01-26 23:22:53 +0000;updated adaptors docs to reflect its inestability and improved the ReST formatting (80 column lines, no ugly pipes at the beginnig of lines)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40775

==

scrapy/trunk/docs/misc/api-stability.rst
scrapy/trunk/docs/topics/adaptors.rst
==================
e8e87bcb;elpolilla;2009-01-26 16:20:58 +0000;Fixed small bug in adaptor pipelines that tried to work with None values
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40774

==

scrapy/trunk/scrapy/item/adaptors.py
==================
7ed88fd0;Pablo Hoffman;2009-01-26 15:36:53 +0000;added Content-Disposition encoding discovery to ResponseTypes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40773

==

scrapy/trunk/scrapy/core/downloader/responsetypes.py
==================
9de6ee51;elpolilla;2009-01-26 15:25:53 +0000;Added missing test for change in r769
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40772

==

scrapy/trunk/scrapy/tests/test_http_response.py
==================
91eff31f;elpolilla;2009-01-26 15:24:52 +0000;. Modified the default value of the BOT_NAME setting to the project's name . Modified spider templates to use the already-generated example item instead of a ScrapedItem
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40771

==

scrapy/trunk/scrapy/command/commands/genspider.py
scrapy/trunk/scrapy/conf/project_template/scrapy_settings.py
scrapy/trunk/scrapy/conf/project_template/templates/spider_crawl.tmpl
scrapy/trunk/scrapy/conf/project_template/templates/spider_csvfeed.tmpl
scrapy/trunk/scrapy/conf/project_template/templates/spider_xmlfeed.tmpl
==================
f63a6613;elpolilla;2009-01-26 15:03:47 +0000;Normalized the usage of ints for storing http status codes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40770

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/core/exceptions.py
scrapy/trunk/scrapy/http/response/__init__.py
==================
74661d54;elpolilla;2009-01-26 15:03:14 +0000;Added application/xml mimetype to the known response types
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40769

==

scrapy/trunk/scrapy/core/downloader/responsetypes.py
==================
b9d3a2cb;elpolilla;2009-01-26 12:15:31 +0000;Improved adaptors debugging in order to make it clearer for reading
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40768

==

scrapy/trunk/scrapy/item/adaptors.py
==================
bc4e80f6;Pablo Hoffman;2009-01-26 03:40:59 +0000;reverted to IO-blocking MailSender implementation (using standard smtplib) until we fix some problems with deferred left unexectuted when stopping the engine
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40767

==

scrapy/trunk/scrapy/mail/__init__.py
==================
5f0d5a16;Pablo Hoffman;2009-01-26 02:57:03 +0000;Big Response/Request refactoring:
- added Response subclasses: TextResponse, HtmlResponse, XmlResponse
- made Response.body a str
- added Response.body_as_unicode() method
- added encoding attribute for TextResponse and subclasses
- added headers_encoding() and body_encoding() to TextResponse and subclasses
- added ResponseTypes class to guess the Response class to use based on
  mimetype and other criteria

- added and improved several Request/Response tests
- updated request/response documetnation to reflect the changes

Another changes not related to encoding:

- added lixbml2debug for debugging libxml2 memory leaks, which can be enabled
  by a environment variable
- added memoizemethod decorator (implemented using descriptors) to cache the
  result of methods
- moved DecompressionMiddleware to contrib_exp

--HG--
rename : scrapy/trunk/scrapy/tests/test_spiders/testplugin.py => scrapy/trunk/scrapy/tests/test_spiders/testspider.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40766

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/compression.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/contrib/history/middleware.py
scrapy/trunk/scrapy/contrib/history/scheduler.py
scrapy/trunk/scrapy/contrib/pipeline/images.py
scrapy/trunk/scrapy/contrib/pipeline/s3images.py
scrapy/trunk/scrapy/contrib/response/soup.py
scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/__init__.py
scrapy/trunk/scrapy/contrib_exp/downloadermiddleware/decompression.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/downloader/responsetypes.py
scrapy/trunk/scrapy/http/__init__.py
scrapy/trunk/scrapy/http/request/__init__.py
scrapy/trunk/scrapy/http/request/form.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/http/response/__init__.py
scrapy/trunk/scrapy/http/response/html.py
scrapy/trunk/scrapy/http/response/text.py
scrapy/trunk/scrapy/http/response/xml.py
scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/replay/__init__.py
scrapy/trunk/scrapy/tests/test_adaptors.py
scrapy/trunk/scrapy/tests/test_contrib_response_soup.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_decompression.py
scrapy/trunk/scrapy/tests/test_downloadermiddleware_retry.py
scrapy/trunk/scrapy/tests/test_groupfilter.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_http_response.py
scrapy/trunk/scrapy/tests/test_libxml2.py
scrapy/trunk/scrapy/tests/test_link.py
scrapy/trunk/scrapy/tests/test_spiders/testspider.py
scrapy/trunk/scrapy/tests/test_utils_iterators.py
scrapy/trunk/scrapy/tests/test_utils_python.py
scrapy/trunk/scrapy/tests/test_utils_response.py
scrapy/trunk/scrapy/tests/test_xpath.py
scrapy/trunk/scrapy/tests/test_xpath_extension.py
scrapy/trunk/scrapy/utils/python.py
scrapy/trunk/scrapy/utils/response.py
scrapy/trunk/scrapy/utils/test.py
scrapy/trunk/scrapy/xpath/constructors.py
scrapy/trunk/scrapy/xpath/selector.py
==================
dbaf6027;elpolilla;2009-01-26 01:15:05 +0000;. Updated some adaptors docstrings . Turned Delist and Unquote adaptors into factory functions instead of classes . Updated tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40765

==

scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/contrib_exp/adaptors/__init__.py
scrapy/trunk/scrapy/contrib_exp/adaptors/markup.py
scrapy/trunk/scrapy/contrib_exp/adaptors/misc.py
scrapy/trunk/scrapy/tests/test_adaptors.py
scrapy/trunk/scrapy/tests/test_robustscrapeditem.py
==================
33df3c81;Pablo Hoffman;2009-01-24 16:59:08 +0000;explained what the heck is scrapy.contrib_exp
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40764

==

scrapy/trunk/scrapy/contrib_exp/__init__.py
==================
a07c9500;Daniel Grana;2009-01-23 03:42:05 +0000;duplicatesfilter: first version of configurable duplicate requests filtering middleware
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40763

==

scrapy/trunk/scrapy/conf/project_template/scrapy_settings.py
scrapy/trunk/scrapy/contrib/spidermiddleware/duplicatesfilter.py
==================
9209dbc8;elpolilla;2009-01-22 17:13:27 +0000;Fixed syntax error in test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40762

==

scrapy/trunk/scrapy/tests/test_robustscrapeditem.py
==================
f6021cad;elpolilla;2009-01-22 16:41:41 +0000;Several modifications done: . attribute method moved from ScrapedItem to RobustScrapedItem . this method was also drastically changed. now it accepts *args and runs the adaptor pipeline for each value . many adaptors were changed to work with single values instead of lists (due to the previous point's change) . ExtractImageLinks adaptor was modified to make use of the HTMLImageLinkExtractor . adaptors were moved from contrib to contrib_exp . tests were updated
--HG--
rename : scrapy/trunk/scrapy/contrib/adaptors/misc.py => scrapy/trunk/scrapy/contrib_exp/adaptors/misc.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40761

==

scrapy/trunk/scrapy/contrib/adaptorpipeline.py
scrapy/trunk/scrapy/contrib/adaptors/__init__.py
scrapy/trunk/scrapy/contrib/adaptors/extraction.py
scrapy/trunk/scrapy/contrib/adaptors/markup.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/contrib_exp/__init__.py
scrapy/trunk/scrapy/contrib_exp/adaptors/__init__.py
scrapy/trunk/scrapy/contrib_exp/adaptors/extraction.py
scrapy/trunk/scrapy/contrib_exp/adaptors/markup.py
scrapy/trunk/scrapy/contrib_exp/adaptors/misc.py
scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/tests/test_adaptors.py
scrapy/trunk/scrapy/tests/test_robustscrapeditem.py
scrapy/trunk/scrapy/tests/test_scrapeditem.py
scrapy/trunk/scrapy/tests/test_utils_misc.py
==================
4142fd0d;elpolilla;2009-01-22 16:40:01 +0000;Added get_base_url to utils.response and tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40760

==

scrapy/trunk/scrapy/tests/test_utils_response.py
scrapy/trunk/scrapy/utils/response.py
==================
86923cc6;elpolilla;2009-01-22 16:39:31 +0000;Changes in HTMLImageLinkExtractor: . Fixed little bug that triggered IndexErrors in some cases . Added support for receiving selectors instead of just raw xpath expressions . Re-enabled tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40759

==

scrapy/trunk/scrapy/contrib/link_extractors.py
scrapy/trunk/scrapy/tests/test_link.py
==================
eebc070f;Daniel Grana;2009-01-22 14:28:20 +0000;tutorial: fix reference to scrapy-ctl. contributed by Patrick Mezard <pmezard@gmail.com>
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40758

==

scrapy/trunk/docs/intro/tutorial/tutorial2.rst
==================
8ff4dc4d;Daniel Grana;2009-01-22 03:19:53 +0000;RetryMiddleware: added ConnectionLost to retried exceptions
twisted >8.0 has a ConnectionClosed exception parent of ConnectionLost
and ConnectionDone, but twisted 2.5 hasn't.

I add ConnectionLost until we can move forward to twisted >8.0

this is the docstring of ConnectionLost, hopes it is self explanatory:
    """Connection to the other side was lost in a non-clean fashion"""

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40757

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
==================
bef1fa96;Pablo Hoffman;2009-01-20 21:49:20 +0000;removed Request.append_callback() method (it was just an alias to Request.deferred.addCallback). refs #48
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40756

==

scrapy/trunk/scrapy/contrib/spiders/crawl.py
scrapy/trunk/scrapy/http/request.py
==================
677d0c36;Pablo Hoffman;2009-01-20 21:10:18 +0000;renamed Request url_encoding constructor argument to encoding. added Request.body tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40755

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
12d0bd4d;Pablo Hoffman;2009-01-20 21:00:56 +0000;added Content-Length header population to Common downloader middleware
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40754

==

scrapy/trunk/docs/ref/downloader-middleware.rst
scrapy/trunk/scrapy/contrib/downloadermiddleware/common.py
==================
1e002a0c;Ismael Carnales;2009-01-19 14:01:57 +0000;make the install scrapy code steps a list, so it doesn't show as sepparate points in the doc overview (we need an style guiide)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40753

==

scrapy/trunk/docs/intro/install.rst
==================
ddf03660;Ismael Carnales;2009-01-19 13:51:16 +0000;removed $ from commands in install it doesn't look so nice but it copy/paste compatible
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40752

==

scrapy/trunk/docs/intro/install.rst
==================
1cc95dc1;Ismael Carnales;2009-01-19 13:48:06 +0000;changed (and fixed) download links for windows libraries in install
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40751

==

scrapy/trunk/docs/intro/install.rst
==================
30e92856;Ismael Carnales;2009-01-19 13:37:07 +0000;corrected arch linux install information
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40750

==

scrapy/trunk/docs/intro/install.rst
==================
4018f07d;Pablo Hoffman;2009-01-19 03:14:23 +0000;minor update to topics/settings.rst
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40749

==

scrapy/trunk/docs/topics/settings.rst
==================
a29fed06;Daniel Grana;2009-01-19 00:35:28 +0000;docs: fix MailSender and Settings method references
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40748

==

scrapy/trunk/docs/ref/email.rst
scrapy/trunk/docs/topics/settings.rst
==================
3f13b388;Pablo Hoffman;2009-01-18 19:31:35 +0000;added additional test to ResponseSoup extension
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40747

==

scrapy/trunk/scrapy/tests/test_contrib_response_soup.py
==================
a413fc3b;Pablo Hoffman;2009-01-18 19:20:32 +0000;some minor performance improvements in downloader handlers, added scrapy.optional_features set
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40746

==

scrapy/trunk/scrapy/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
0c9f7257;Pablo Hoffman;2009-01-18 17:52:21 +0000;added Request.replace method, improved tests for replace/copy method in Request/Response classes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40745

==

scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_http_response.py
==================
314bbabb;Pablo Hoffman;2009-01-18 16:55:54 +0000;removed 'domain' from Request attributes and constructor arguments
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40744

==

scrapy/trunk/scrapy/core/manager.py
scrapy/trunk/scrapy/http/request.py
==================
d3c4d1f1;Pablo Hoffman;2009-01-18 16:38:01 +0000;removed domain argument from Response constructor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40743

==

scrapy/trunk/docs/ref/request-response.rst
==================
db91d268;Pablo Hoffman;2009-01-18 16:36:17 +0000;removed 'domain' argument from Response objects constructor. besides being a required first constructor argument, it wasn't actually needed and made the Response consturctor more complex
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40742

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/tests/test_adaptors.py
scrapy/trunk/scrapy/tests/test_contrib_response_soup.py
scrapy/trunk/scrapy/tests/test_engine.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_http_response.py
scrapy/trunk/scrapy/tests/test_libxml2.py
scrapy/trunk/scrapy/tests/test_link.py
scrapy/trunk/scrapy/tests/test_middleware_decompression.py
scrapy/trunk/scrapy/tests/test_middleware_retry.py
scrapy/trunk/scrapy/tests/test_utils_iterators.py
scrapy/trunk/scrapy/tests/test_utils_response.py
scrapy/trunk/scrapy/tests/test_xpath.py
scrapy/trunk/scrapy/tests/test_xpath_extension.py
scrapy/trunk/scrapy/xpath/selector.py
==================
654b49c8;Pablo Hoffman;2009-01-17 23:57:53 +0000;added meta argument to Request & Response constructors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40741

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_http_response.py
==================
8ecc6808;Pablo Hoffman;2009-01-17 23:09:53 +0000;removed Request.context attribute (use Request.meta instead)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40740

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/contrib/history/middleware.py
scrapy/trunk/scrapy/http/request.py
==================
7e640da4;Pablo Hoffman;2009-01-17 22:11:54 +0000;renamed to_string() Request and Response methods to httprepr(). removed __len__() from Request and Response
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40739

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/contrib/downloadermiddleware/stats.py
scrapy/trunk/scrapy/contrib/itemsampler.py
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_http_response.py
==================
5dc1e7e5;Pablo Hoffman;2009-01-17 21:05:08 +0000;updated request/response reference doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40738

==

scrapy/trunk/docs/ref/request-response.rst
==================
da6a24b6;Pablo Hoffman;2009-01-17 20:40:07 +0000;More Request/Response cleanup:
 * made status attribute an int
 * made engine use __str__ to display crawled requests
 * HTTP cache now inherits Response class to change __str__
 * added tests to check that the class is preserved on .copy() (for both Requests and Responses)
 * removed custom cached attribute (and passed to a Response.meta item)
 * removed some custom (and seldom used) methods from Response class: version(), info()
 * reinforced the privacy of the ResponseBody class, by renaming it to _ResponseBody and added a warning that it may be removed in the future
 * added tests for Request & Response to_string() methods
 * fixed minor (and harmless) bug in to_string() methods

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40737

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/debug.py
scrapy/trunk/scrapy/contrib/history/middleware.py
scrapy/trunk/scrapy/contrib/history/scheduler.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/http/__init__.py
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/replay/__init__.py
scrapy/trunk/scrapy/tests/test_adaptors.py
scrapy/trunk/scrapy/tests/test_engine.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_http_response.py
==================
b1745f49;Pablo Hoffman;2009-01-17 15:57:28 +0000;removed deprecated original_url attribute from Response objects (it can be accessed through Response.request.url)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40736

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/tests/test_http_response.py
==================
7b545381;Pablo Hoffman;2009-01-17 15:22:59 +0000;changed log message and increased log level, when spiders return objects which are not Request or ScrapedItem
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40735

==

scrapy/trunk/scrapy/core/engine.py
==================
6ba6238c;Pablo Hoffman;2009-01-15 03:24:48 +0000;Response class:  * added meta and cache attributes to Response class  * added tests for Response copy
Request class:
 * added meta attribute and renamed old _cache attribute to cache
 * moved depth and link_text to Request.meta
 * added tests for Request copy

* ResponseLibxml2 and ResponseSoup extensions now use Response.cache

Updated doc with changes

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40734

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/contrib/response/soup.py
scrapy/trunk/scrapy/contrib/spidermiddleware/depth.py
scrapy/trunk/scrapy/contrib/spiders/crawl.py
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_http_response.py
scrapy/trunk/scrapy/tests/test_utils_request.py
scrapy/trunk/scrapy/utils/request.py
scrapy/trunk/scrapy/xpath/extension.py
==================
d26a54f5;Pablo Hoffman;2009-01-15 03:06:00 +0000;added tests for ResponseSoup and ResponseLibxml2 extensions
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40733

==

scrapy/trunk/scrapy/tests/test_contrib_response_soup.py
scrapy/trunk/scrapy/tests/test_xpath_extension.py
==================
604af8e7;Pablo Hoffman;2009-01-15 00:20:24 +0000;doc; removed referer argument from Request constructor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40732

==

scrapy/trunk/docs/ref/request-response.rst
==================
2a7b41cd;Pablo Hoffman;2009-01-15 00:10:31 +0000;removed referer argument from Request constructor. refs #48
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40731

==

scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/tests/test_http_request.py
==================
9513b1f4;Daniel Grana;2009-01-14 23:59:45 +0000;Remove response referneces from pipelines. refs #51
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40730

==

scrapy/trunk/docs/topics/item-pipeline.rst
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/contrib/itemsampler.py
scrapy/trunk/scrapy/contrib/pipeline/media.py
scrapy/trunk/scrapy/contrib/pipeline/shoveitem.py
scrapy/trunk/scrapy/contrib/pipeline/show.py
scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/item/pipeline.py
==================
eef01a9f;Pablo Hoffman;2009-01-14 23:50:23 +0000;removed Request.method magic in Request constructor. refs #48
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40729

==

scrapy/trunk/docs/ref/request-response.rst
scrapy/trunk/scrapy/http/request.py
==================
ae95c1df;Pablo Hoffman;2009-01-14 23:31:24 +0000;removed unused (and broken) prepend_callback Request method
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40728

==

scrapy/trunk/scrapy/contrib/history/scheduler.py
scrapy/trunk/scrapy/http/request.py
==================
3f89fc10;Pablo Hoffman;2009-01-14 23:23:10 +0000;shortened some line widths
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40727

==

scrapy/trunk/scrapy/http/request.py
==================
1272b138;Pablo Hoffman;2009-01-14 22:02:58 +0000;moved HTTP auth functionality out of Request class and into scrapy.utils.request.request_authenticate function, added tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40726

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/tests/test_utils_request.py
scrapy/trunk/scrapy/utils/request.py
==================
8fc4719d;Andres Moreira;2009-01-14 18:59:52 +0000;Added dns cache support for the crawler, improving the performance of the page download because this reduce the dns lookups.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40725

==

scrapy/trunk/scrapy/core/downloader/dnscache.py
scrapy/trunk/scrapy/core/downloader/handlers.py
==================
7be6ff07;samus_;2009-01-14 12:12:37 +0000;typo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40724

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
baf9a8d8;samus_;2009-01-14 12:09:06 +0000;renamed expiration setting to the same used by the image pipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40723

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
0ea37f51;Pablo Hoffman;2009-01-14 01:17:40 +0000; * moved request fingerprinting from Request class to scrapy.utils.request - closes #50  * cleaned up fingerprint tests suite (only left relevant tests)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40722

==

scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
scrapy/trunk/scrapy/contrib/history/scheduler.py
scrapy/trunk/scrapy/contrib/pipeline/media.py
scrapy/trunk/scrapy/core/downloader/manager.py
scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/core/scheduler/schedulers.py
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/replay/__init__.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_utils_request.py
scrapy/trunk/scrapy/utils/request.py
==================
519458bd;Pablo Hoffman;2009-01-14 00:19:22 +0000;added documentation for settings: ENGINE_DEBUG, DOWNLOADER_DEBUG
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40721

==

scrapy/trunk/docs/ref/settings.rst
==================
64d1f67c;Pablo Hoffman;2009-01-13 21:47:49 +0000;decreased logging level of RequestLimitMiddleware to DEBUG
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40720

==

scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
==================
4ed811b4;Pablo Hoffman;2009-01-13 14:43:38 +0000;added DOWNLOAD_DELAY to default_settings and documentation, fixed some typo errors in settings reference
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40719

==

scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/scrapy/conf/default_settings.py
==================
0e78003c;Pablo Hoffman;2009-01-13 13:50:51 +0000;removed my email from CLOSEDOMAIN_NOTIFY setting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40718

==

scrapy/trunk/scrapy/conf/default_settings.py
==================
e316722b;Pablo Hoffman;2009-01-13 11:55:20 +0000;updated doc: ref/emails.rst and topics/downloader-middleware.rst
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40717

==

scrapy/trunk/docs/ref/email.rst
scrapy/trunk/docs/topics/downloader-middleware.rst
==================
468bfeb2;Pablo Hoffman;2009-01-13 10:10:19 +0000;removed unused imports
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40716

==

scrapy/trunk/scrapy/utils/datatypes.py
==================
95d99d51;Pablo Hoffman;2009-01-13 02:49:50 +0000;renamde old SchedulerStats web console module to ScheduleQueue and made it work with the new PriorityQueue
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40715

==

scrapy/trunk/docs/ref/extensions.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/webconsole/scheduler.py
==================
deb96052;Pablo Hoffman;2009-01-13 01:46:45 +0000;removed unused (Django) classes from scrapy.utils.datatypes: MergeDict, SortedDict, DotExpandedDict, FileDict. And also removed unused class gzStringIO
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40714

==

scrapy/trunk/scrapy/utils/datatypes.py
==================
ff637d9a;Pablo Hoffman;2009-01-13 01:37:49 +0000;added __len__ to PriorityQueue/Stack, and changed __iter__ implementation to return (item, priority) tuples, added more test cases
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40713

==

scrapy/trunk/scrapy/tests/test_utils_datatypes.py
scrapy/trunk/scrapy/utils/datatypes.py
==================
2434000c;Pablo Hoffman;2009-01-13 01:14:40 +0000; * ported PriorityQueue and PriorityStack to use heapq instead of queue.Queue +    bisect which was up to 5x slower!  * added test case for PriorityStack (only PriorityQueue had before)  * changed Priority{Stack,Queue} API to just push(), pop(), and made them    iterable
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40712

==

scrapy/trunk/scrapy/core/scheduler/schedulers.py
scrapy/trunk/scrapy/tests/test_utils_datatypes.py
scrapy/trunk/scrapy/utils/datatypes.py
==================
8b28d365;samus_;2009-01-12 22:43:10 +0000;removed extra return
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40711

==

scrapy/trunk/scrapy/spider/models.py
==================
eca60c7c;Andres Moreira;2009-01-12 17:18:54 +0000;Small change in canonicalize_url improved its performance a bit
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40710

==

scrapy/trunk/scrapy/utils/url.py
==================
30e44c9a;Pablo Hoffman;2009-01-12 00:53:37 +0000;added settings: REQUEST_HEADER_ACCEPT, REQUEST_HEADER_ACCEPT_LANGUAGE. started built-in downloader middleware reference
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40709

==

scrapy/trunk/docs/ref/downloader-middleware.rst
scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/common.py
==================
d0046196;Pablo Hoffman;2009-01-11 23:04:50 +0000;ported MailSender class to use twisted non-blocking IO
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40708

==

scrapy/trunk/docs/ref/email.rst
scrapy/trunk/scrapy/mail/__init__.py
==================
b0e37dc3;Pablo Hoffman;2009-01-11 21:27:38 +0000;renamed StackTraceDebug extension to StackTraceDump
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40707

==

scrapy/trunk/docs/ref/extensions.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/docs/topics/extensions.rst
scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/debug.py
scrapy/trunk/scrapy/log/__init__.py
==================
73074721;Pablo Hoffman;2009-01-11 20:04:13 +0000;improved settings doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40706

==

scrapy/trunk/docs/topics/settings.rst
==================
dfdc04c2;Pablo Hoffman;2009-01-11 19:49:11 +0000;some email doc improvments
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40705

==

scrapy/trunk/docs/ref/email.rst
scrapy/trunk/docs/ref/settings.rst
==================
09459ed7;Pablo Hoffman;2009-01-11 19:48:36 +0000;added logging doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40704

==

scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/logging.rst
==================
9e930703;Pablo Hoffman;2009-01-11 19:14:49 +0000;moved email doc to reference (instead of topics)
--HG--
rename : scrapy/trunk/docs/topics/email.rst => scrapy/trunk/docs/ref/email.rst
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40703

==

scrapy/trunk/docs/ref/email.rst
scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/scrapy/mail/__init__.py
==================
5c15def3;Pablo Hoffman;2009-01-11 19:11:17 +0000;added doc for scrapy.mail
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40702

==

scrapy/trunk/docs/topics/email.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/scrapy/mail/__init__.py
==================
bf0050c3;Pablo Hoffman;2009-01-11 06:34:38 +0000;added doc for extensions and web console (closes #29 and #33). also started stats doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40701

==

scrapy/trunk/docs/ref/extension-manager.rst
scrapy/trunk/docs/ref/extensions.rst
scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/docs/topics/extensions.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/stats.rst
scrapy/trunk/docs/topics/webconsole.rst
==================
300a0f49;Pablo Hoffman;2009-01-11 06:31:07 +0000;minor (and inoffensive) code improvements and fixes found while documenting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40700

==

scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/memdebug.py
scrapy/trunk/scrapy/contrib/memusage.py
scrapy/trunk/scrapy/contrib/response/soup.py
scrapy/trunk/scrapy/contrib/webconsole/livestats.py
scrapy/trunk/scrapy/contrib/webconsole/schedstats.py
scrapy/trunk/scrapy/contrib/webconsole/spiderctl.py
scrapy/trunk/scrapy/management/web.py
==================
7cfefc6e;Pablo Hoffman;2009-01-09 22:45:58 +0000;some minor doc improvements here and there
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40699

==

scrapy/trunk/docs/faq.rst
scrapy/trunk/docs/intro/index.rst
scrapy/trunk/docs/intro/overview.rst
scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/topics/index.rst
==================
45e812a8;Pablo Hoffman;2009-01-09 22:45:09 +0000;added misc section to doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40698

==

scrapy/trunk/docs/index.rst
scrapy/trunk/docs/misc/api-stability.rst
scrapy/trunk/docs/misc/index.rst
==================
0e6b518f;Pablo Hoffman;2009-01-09 21:18:41 +0000;added FAQ entry about Django
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40697

==

scrapy/trunk/docs/faq.rst
==================
71f7d62c;elpolilla;2009-01-09 17:35:04 +0000;Bugfix in AWSMiddleware regarding requests from local files
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40696

==

scrapy/trunk/scrapy/contrib/aws.py
==================
5fa10097;elpolilla;2009-01-09 13:45:11 +0000;Improved adaptors documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40695

==

scrapy/trunk/docs/topics/adaptors.rst
==================
2cfd292f;elpolilla;2009-01-09 10:49:48 +0000;Added needed conversion from unicode to string before using twisted's logging system because it may trigger encoding issues
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40694

==

scrapy/trunk/scrapy/log/__init__.py
==================
4c54305b;Pablo Hoffman;2009-01-09 10:35:14 +0000;added docstrings to unicode_to_str and str_to_unicode
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40693

==

scrapy/trunk/scrapy/utils/python.py
==================
8e38f70a;samus_;2009-01-09 01:33:12 +0000;small improvement to Response.__init__ testcase
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40692

==

scrapy/trunk/scrapy/tests/test_http_response.py
==================
d3ac5d5a;samus_;2009-01-09 00:45:12 +0000;added test for Response.__init__
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40691

==

scrapy/trunk/scrapy/tests/test_http_response.py
==================
8240fc48;samus_;2009-01-09 00:42:44 +0000;refactored ResponseBody's encoding test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40690

==

scrapy/trunk/scrapy/tests/test_http_response.py
==================
1feace1b;samus_;2009-01-08 18:29:56 +0000;a bit of performance
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40689

==

scrapy/trunk/scrapy/tests/test_middleware_decompression.py
==================
d0e5245f;samus_;2009-01-08 18:29:33 +0000;fixed bug
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40688

==

scrapy/trunk/scrapy/http/response.py
==================
c601bbb0;samus_;2009-01-08 16:08:04 +0000;fixed bug in copy method of Response (tests coming soon)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40687

==

scrapy/trunk/scrapy/http/response.py
==================
5cb9f344;elpolilla;2009-01-08 15:42:33 +0000;Changed method process_spider_output name to process_results in crawl and feed spiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40686

==

scrapy/trunk/scrapy/contrib/spiders/crawl.py
scrapy/trunk/scrapy/contrib/spiders/feed.py
==================
6568dc4f;Pablo Hoffman;2009-01-08 15:02:39 +0000;added custom CSS for scrapy doc with minor modifications (colors only)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40685

==

scrapy/trunk/docs/_static/scrapydoc.css
scrapy/trunk/docs/conf.py
==================
6420c407;Pablo Hoffman;2009-01-08 14:21:20 +0000;removed scrapyengine import from downoader code, minor improvements to docstrings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40684

==

scrapy/trunk/scrapy/core/downloader/manager.py
scrapy/trunk/scrapy/core/engine.py
==================
f39b7b50;elpolilla;2009-01-08 13:46:14 +0000;Disabled test until memory leak in libxml is fixed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40683

==

scrapy/trunk/scrapy/tests/test_link.py
==================
fc76af2e;Pablo Hoffman;2009-01-08 13:30:25 +0000;reverted r680 until we there are tests and documentation available about the change
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40682

==

scrapy/trunk/scrapy/link/__init__.py
==================
4a9a48a6;elpolilla;2009-01-08 11:05:15 +0000;. Added strip() to link texts in LinkExtractor in order to avoid extracting line breaks and such . Added test for restrict_xpaths in RegexLinkExtractor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40681

==

scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/tests/sample_data/link_extractor/regex_linkextractor.html
scrapy/trunk/scrapy/tests/test_link.py
==================
8278c0cf;elpolilla;2009-01-08 10:11:56 +0000;Changed process_results name in feed spiders to process_spider_output and moved its parameters to a more standard order
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40680

==

scrapy/trunk/scrapy/contrib/spiders/crawl.py
scrapy/trunk/scrapy/contrib/spiders/feed.py
==================
32d84232;Pablo Hoffman;2009-01-07 18:06:39 +0000;reverted r675 which broke precedence for environment variables
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40679

==

scrapy/trunk/scrapy/command/cmdline.py
==================
393cf349;Pablo Hoffman;2009-01-07 18:04:40 +0000;updated settings doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40678

==

scrapy/trunk/docs/topics/settings.rst
==================
382621b8;elpolilla;2009-01-07 17:39:09 +0000;Fixed bug in RegexLinkExtractor. Encoding was not being specified
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40677

==

scrapy/trunk/scrapy/link/extractors.py
==================
307f8b33;elpolilla;2009-01-07 17:31:06 +0000;. Modified loading of command-specific settings (were loaded as defaults, now as overrides) . Removed duplicated loading of extensions in shell command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40676

==

scrapy/trunk/scrapy/command/cmdline.py
scrapy/trunk/scrapy/command/commands/shell.py
==================
8029275c;elpolilla;2009-01-07 14:18:03 +0000;Removed non-scrapy import in shell command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40675

==

scrapy/trunk/scrapy/conf/commands/shell.py
==================
9884c209;Pablo Hoffman;2009-01-07 14:02:28 +0000;minor update to overview doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40674

==

scrapy/trunk/docs/intro/overview.rst
==================
e4852bca;elpolilla;2009-01-07 14:00:54 +0000;Modified extract adaptor to make use of "adaptor_args" (as it should), and added test for AdaptorPipes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40673

==

scrapy/trunk/scrapy/contrib/adaptors/extraction.py
scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/tests/test_adaptors.py
==================
41fbcbde;Pablo Hoffman;2009-01-07 12:56:40 +0000;minor corrections to overview doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40672

==

scrapy/trunk/docs/intro/overview.rst
==================
cd148c94;elpolilla;2009-01-07 12:48:15 +0000;Refactored extract adaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40671

==

scrapy/trunk/scrapy/contrib/adaptors/__init__.py
scrapy/trunk/scrapy/contrib/adaptors/extraction.py
scrapy/trunk/scrapy/tests/test_adaptors.py
==================
66852b82;elpolilla;2009-01-07 12:09:47 +0000;Small bugfix in selectors constructor regarding strings and unicodes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40670

==

scrapy/trunk/scrapy/xpath/selector.py
==================
2c2dc617;Pablo Hoffman;2009-01-07 03:59:39 +0000;somes fixes and updates to scrapy documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40669

==

scrapy/trunk/docs/faq.rst
scrapy/trunk/docs/index.rst
scrapy/trunk/docs/intro/tutorial/tutorial1.rst
scrapy/trunk/docs/intro/tutorial/tutorial2.rst
scrapy/trunk/docs/intro/tutorial/tutorial3.rst
scrapy/trunk/docs/intro/tutorial/tutorial4.rst
scrapy/trunk/docs/topics/item-pipeline.rst
==================
0319373c;Pablo Hoffman;2009-01-07 03:58:15 +0000;improved overview doc. closes #44
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40668

==

scrapy/trunk/docs/intro/overview.rst
==================
a155ad26;elpolilla;2009-01-07 03:18:18 +0000;Added documentation for Adaptors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40667

==

scrapy/trunk/docs/_static/items_adaptors-sample1.html
scrapy/trunk/docs/topics/adaptors.rst
scrapy/trunk/docs/topics/index.rst
==================
d1594df0;Pablo Hoffman;2009-01-07 01:02:38 +0000;made url_is_from_spider work for tuples in extra_domain_names
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40666

==

scrapy/trunk/scrapy/utils/url.py
==================
a2d19760;Pablo Hoffman;2009-01-06 23:07:29 +0000;doc: minor grammar correction
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40665

==

scrapy/trunk/docs/topics/architecture.rst
==================
abdf4dee;Pablo Hoffman;2009-01-06 23:05:04 +0000;added doc about scrapy architecture. closes #31
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40664

==

scrapy/trunk/docs/topics/_images/scrapy_architecture.odg
scrapy/trunk/docs/topics/_images/scrapy_architecture.png
scrapy/trunk/docs/topics/architecture.rst
scrapy/trunk/docs/topics/index.rst
==================
4286e5e4;olveyra;2009-01-06 19:43:58 +0000;fix to revision 660
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40663

==

scrapy/trunk/scrapy/contrib/spiders/crawl.py
==================
1d36c3f0;Pablo Hoffman;2009-01-06 17:34:14 +0000;updated robotstxt, spidermw and downloadermw docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40662

==

scrapy/trunk/docs/topics/downloader-middleware.rst
scrapy/trunk/docs/topics/robotstxt.rst
scrapy/trunk/docs/topics/spider-middleware.rst
==================
e9d050b9;Pablo Hoffman;2009-01-06 17:30:29 +0000;renamed spider middleware methods to more consistent ones: process_spider_input, process_spider_output, process_spider_exception
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40661

==

scrapy/trunk/scrapy/contrib/itemsampler.py
scrapy/trunk/scrapy/contrib/spidermiddleware/depth.py
scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
scrapy/trunk/scrapy/contrib/spidermiddleware/offsite.py
scrapy/trunk/scrapy/contrib/spidermiddleware/referer.py
scrapy/trunk/scrapy/contrib/spidermiddleware/restrict.py
scrapy/trunk/scrapy/contrib/spidermiddleware/urlfilter.py
scrapy/trunk/scrapy/contrib/spidermiddleware/urllength.py
scrapy/trunk/scrapy/contrib/spiders/crawl.py
scrapy/trunk/scrapy/spider/middleware.py
==================
cf34fd4c;Pablo Hoffman;2009-01-06 16:53:49 +0000;added spider middleware documentation. closes #28
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40660

==

scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/spider-middleware.rst
==================
7f7196c1;Pablo Hoffman;2009-01-06 16:44:06 +0000;removed unused import
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40659

==

scrapy/trunk/scrapy/spider/middleware.py
==================
5e636909;Pablo Hoffman;2009-01-06 16:42:59 +0000;added DEFAULT_SPIDER to default_settings and fixed formatting in DEFAULT_SPIDER setting documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40658

==

scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/scrapy/conf/default_settings.py
==================
c80fef7e;elpolilla;2009-01-06 16:08:03 +0000;Added the example project from the tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40657

==

scrapy/trunk/examples/google_bot/__init__.py
scrapy/trunk/examples/google_bot/items.py
scrapy/trunk/examples/google_bot/scrapy-ctl.py
scrapy/trunk/examples/google_bot/scrapy_settings.py
scrapy/trunk/examples/google_bot/spiders/__init__.py
scrapy/trunk/examples/google_bot/spiders/google_directory.py
scrapy/trunk/examples/google_bot/templates/spider_basic.tmpl
scrapy/trunk/examples/google_bot/templates/spider_crawl.tmpl
scrapy/trunk/examples/google_bot/templates/spider_csvfeed.tmpl
scrapy/trunk/examples/google_bot/templates/spider_xmlfeed.tmpl
==================
9d6defa6;Pablo Hoffman;2009-01-06 14:34:26 +0000;doc: fixed intro-install xref
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40656

==

scrapy/trunk/docs/intro/install.rst
scrapy/trunk/docs/intro/tutorial/tutorial1.rst
==================
9da90412;Pablo Hoffman;2009-01-06 00:19:51 +0000;updated INSTALL file to point to docs/intro/install. also, utf-8 default encoding is no longer required
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40655

==

scrapy/trunk/INSTALL
==================
3badafc8;Pablo Hoffman;2009-01-06 00:15:55 +0000;updated installation doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40654

==

scrapy/trunk/docs/intro/install.rst
==================
c9d91106;Pablo Hoffman;2009-01-06 00:15:30 +0000;updated documentation index
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40653

==

scrapy/trunk/docs/index.rst
==================
4df3118c;Pablo Hoffman;2009-01-05 23:49:06 +0000;added note to scrapy version
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40652

==

scrapy/trunk/scrapy/__init__.py
==================
b3c7203a;Pablo Hoffman;2009-01-05 23:29:25 +0000;updated some doc configuration - version, release and html_copy_source
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40651

==

scrapy/trunk/docs/conf.py
==================
9b857124;olveyra;2009-01-05 18:11:48 +0000;added DEFAULT_SPIDER setting help
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40650

==

scrapy/trunk/docs/ref/settings.rst
==================
111ba5d5;elpolilla;2009-01-05 16:55:20 +0000;Updated items documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40649

==

scrapy/trunk/docs/topics/items.rst
==================
f1962c1c;elpolilla;2009-01-05 16:54:54 +0000;. Moved init and repr methods from RobustScrapedItem to ScrapedItem . Refactored ScrapedItem's attribute method, added docstring and tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40648

==

scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/tests/test_scrapeditem.py
==================
3c4012f9;Pablo Hoffman;2009-01-05 03:37:06 +0000;updated scrapy version
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40647

==

scrapy/trunk/scrapy/__init__.py
==================
5c9c82d0;Pablo Hoffman;2009-01-05 02:49:23 +0000;some improvements to selectors doc structure, added literalincludes for sample1.html (to avoid duplicating the content), renamed that file and moved to _static (so it appears on built doc), moved comments out of source code snippets and into documentation text, and splitted them. converted to required '>>>' console format, and added proper highlighting hints
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40646

==

scrapy/trunk/docs/_static/selectors-sample1.html
scrapy/trunk/docs/topics/selectors.rst
==================
7ca989a7;Pablo Hoffman;2009-01-04 23:28:50 +0000;disabled docs app (redirecting to doc.scrapy.org instead)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40645

==

sites/scrapy.org/Makefile
sites/scrapy.org/scrapyorg/urls.py
sites/scrapy.org/templates/articles/doc.html
sites/scrapy.org/templates/articles/download.html
sites/scrapy.org/templates/header.html
==================
e61b5818;Pablo Hoffman;2009-01-04 19:03:15 +0000;fixed wrong xref name
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40644

==

scrapy/trunk/docs/topics/spiders.rst
==================
2ea63139;samus_;2009-01-04 18:23:12 +0000;reconfigured scrapy Response in order to disallow direct use of ResponseBody class that should be private
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40643

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/compression.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/decompression.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/tests/test_adaptors.py
scrapy/trunk/scrapy/tests/test_libxml2.py
scrapy/trunk/scrapy/tests/test_link.py
scrapy/trunk/scrapy/tests/test_middleware_decompression.py
==================
58e4cf74;elpolilla;2009-01-04 15:37:43 +0000;Added Items documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40642

==

scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/items.rst
==================
dc1a168d;elpolilla;2009-01-04 14:46:13 +0000;Fixed unquote adaptor's test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40641

==

scrapy/trunk/scrapy/tests/test_adaptors.py
==================
604c86b7;elpolilla;2009-01-04 14:25:15 +0000;Removed unappropiate unquote adaptor's default behaviour
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40640

==

scrapy/trunk/scrapy/contrib/adaptors/markup.py
==================
e4bfb27f;elpolilla;2009-01-04 10:50:14 +0000;Removed already-deprecated response decompression tool
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40639

==

scrapy/trunk/scrapy/utils/decompressor.py
==================
8d255f7b;Pablo Hoffman;2009-01-04 04:54:06 +0000;updated some docs paths
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40638

==

scrapy/trunk/scrapy/conf/default_settings.py
==================
ea439e4b;elpolilla;2009-01-04 01:15:08 +0000;Updated Selectors documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40637

==

scrapy/trunk/docs/topics/sample1.htm
scrapy/trunk/docs/topics/selectors.rst
==================
a5025899;elpolilla;2009-01-04 00:36:16 +0000;Updated Spiders documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40636

==

scrapy/trunk/docs/topics/spiders.rst
==================
f8f0db8b;Pablo Hoffman;2009-01-03 09:14:52 +0000;doc: several more improvements
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40635

==

scrapy/trunk/docs/faq.rst
scrapy/trunk/docs/intro/overview.rst
scrapy/trunk/docs/intro/tutorial/tutorial4.rst
scrapy/trunk/docs/ref/exceptions.rst
scrapy/trunk/docs/ref/signals.rst
scrapy/trunk/docs/topics/downloader-middleware.rst
scrapy/trunk/docs/topics/item-pipeline.rst
scrapy/trunk/docs/topics/robotstxt.rst
scrapy/trunk/docs/topics/selectors.rst
scrapy/trunk/docs/topics/settings.rst
scrapy/trunk/docs/topics/spiders.rst
==================
137429e5;Pablo Hoffman;2009-01-03 07:54:33 +0000;doc: added README
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40634

==

scrapy/trunk/docs/README
==================
16f9f5a9;Pablo Hoffman;2009-01-03 07:41:43 +0000;doc: added topic about robots.txt, added ROBOTSTXT_OBEY setting, added missing REQUESTS_PER_DOMAIN setting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40633

==

scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/robotstxt.rst
==================
b59acb18;Pablo Hoffman;2009-01-03 07:40:40 +0000;minor typo and grammar corrections to docs/faq
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40632

==

scrapy/trunk/docs/faq.rst
==================
4a3ba695;Pablo Hoffman;2009-01-03 07:36:35 +0000;updated default_settings with robots.txt related settings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40631

==

scrapy/trunk/scrapy/conf/default_settings.py
==================
e437ff67;Pablo Hoffman;2009-01-03 07:35:30 +0000;finished working version of robots.txt downloader middleware, and renamed the module/class
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40630

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/robotstxt.py
==================
8a404c44;Pablo Hoffman;2009-01-03 06:15:30 +0000;removed deprecated Request.__getitem__ method
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40629

==

scrapy/trunk/scrapy/http/request.py
==================
8d1d5102;Pablo Hoffman;2009-01-03 03:11:08 +0000;updated downloader-middleware to link to Request and Response classes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40628

==

scrapy/trunk/docs/topics/downloader-middleware.rst
==================
8b10d018;Pablo Hoffman;2009-01-03 03:10:14 +0000;added (incomplete) request-response doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40627

==

scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/request-response.rst
==================
44f6358a;Pablo Hoffman;2009-01-03 03:05:19 +0000;renamed itempipeline.rst to item-pipeline.rst
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40626

==

scrapy/trunk/docs/ref/exceptions.rst
scrapy/trunk/docs/ref/signals.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/item-pipeline.rst
scrapy/trunk/docs/topics/itempipeline.rst
==================
1a9845b3;Pablo Hoffman;2009-01-03 01:29:09 +0000;added documentation for downloader middleware. closes #27
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40625

==

scrapy/trunk/docs/topics/downloader-middleware.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/scrapy/core/downloader/middleware.py
==================
093c7e12;Pablo Hoffman;2009-01-03 01:25:03 +0000;docs: more updates to Makefile and conf.py
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40624

==

scrapy/trunk/docs/Makefile
scrapy/trunk/docs/conf.py
==================
14697b5f;Pablo Hoffman;2009-01-03 01:24:18 +0000;added FAQ to docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40623

==

scrapy/trunk/docs/faq.rst
scrapy/trunk/docs/index.rst
==================
d06fc991;Pablo Hoffman;2009-01-03 00:58:09 +0000;more stripping down of doc Makefile
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40622

==

scrapy/trunk/docs/Makefile
==================
144eaa64;Pablo Hoffman;2009-01-03 00:43:04 +0000;added stripped down version of Python documentation Makefile
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40621

==

scrapy/trunk/docs/Makefile
==================
541451af;Pablo Hoffman;2009-01-02 20:45:34 +0000;simplified obfuscated implementation of duplicated links removal and made it use scrapy.utils.python.unique function. also added missing 'unique' argument to docstring
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40620

==

scrapy/trunk/scrapy/link/__init__.py
==================
c69d94fb;Pablo Hoffman;2009-01-02 20:44:07 +0000;removed unused private variable
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40619

==

scrapy/trunk/scrapy/utils/python.py
==================
f8a6e2fc;Pablo Hoffman;2009-01-02 20:42:20 +0000;added key argument to unique function
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40618

==

scrapy/trunk/scrapy/utils/python.py
==================
e1c738a4;Pablo Hoffman;2009-01-02 20:17:40 +0000;minor text changes to home page
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40617

==

sites/scrapy.org/templates/articles/home.html
==================
aa927553;Pablo Hoffman;2009-01-02 20:07:24 +0000;changed scrapy.org title to include more key words
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40616

==

sites/scrapy.org/templates/base.html
==================
37189000;Pablo Hoffman;2009-01-02 20:06:17 +0000;removed ugly apostrophe
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40615

==

scrapy/trunk/docs/index.rst
==================
fc36ad00;Pablo Hoffman;2009-01-02 19:59:41 +0000;renamed ItemPipeline class to ItemPipelineManager to avoid confusions
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40614

==

scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/item/pipeline.py
==================
dd2f92f0;Pablo Hoffman;2009-01-02 19:55:22 +0000;added comment about new docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40613

==

scrapy/trunk/scrapy/core/exceptions.py
scrapy/trunk/scrapy/core/signals.py
==================
e95a28ef;Pablo Hoffman;2009-01-02 19:48:31 +0000;added documentation for item pipeline, signals and exceptions. changed scrapy version to 0.7 in sphinx conf. closes #26, #40, #41
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40612

==

scrapy/trunk/docs/_ext/scrapydocs.py
scrapy/trunk/docs/conf.py
scrapy/trunk/docs/ref/exceptions.rst
scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/docs/ref/signals.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/itempipeline.rst
==================
3789f064;Pablo Hoffman;2009-01-02 19:45:51 +0000;added -E to sphinx-build so source rst's are be always reloaded and warning messages printed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40611

==

sites/scrapy.org/Makefile
==================
47881c6e;elpolilla;2009-01-02 18:59:34 +0000;. Modified unicode conversion functions to accept the conversion encoding as a parameter . Modified safe_url_string to make use of this change
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40610

==

scrapy/trunk/scrapy/tests/test_utils_python.py
scrapy/trunk/scrapy/utils/python.py
scrapy/trunk/scrapy/utils/url.py
==================
63662ba6;elpolilla;2009-01-02 18:32:55 +0000;. Added tests for RegexLinkExtractor . Modified LinkExtractor in order to percent-encode urls using the response encoding . Improved LinkExtractors processing of unique links
--HG--
rename : scrapy/trunk/scrapy/tests/sample_data/image_linkextractor.html => scrapy/trunk/scrapy/tests/sample_data/link_extractor/image_linkextractor.html
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40609

==

scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/sample_data/link_extractor/image_linkextractor.html
scrapy/trunk/scrapy/tests/sample_data/link_extractor/linkextractor_latin1.html
scrapy/trunk/scrapy/tests/sample_data/link_extractor/linkextractor_noenc.html
scrapy/trunk/scrapy/tests/sample_data/link_extractor/regex_linkextractor.html
scrapy/trunk/scrapy/tests/test_link.py
==================
c791155a;elpolilla;2009-01-02 18:31:55 +0000;Modified url_safe_string in order to accept strings encoded in any encoding apart from unicode objects
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40608

==

scrapy/trunk/scrapy/utils/url.py
==================
95495f1d;Pablo Hoffman;2009-01-02 18:24:02 +0000;removed domain_initialized signal which was defined but never used
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40607

==

scrapy/trunk/scrapy/core/signals.py
==================
12b56a3e;Pablo Hoffman;2009-01-02 17:15:22 +0000;removed border-bottom on link hover which made trac behave strangly
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40606

==

sites/static.scrapy.org/css/trac.css
==================
f7e4b91f;Pablo Hoffman;2009-01-02 16:34:10 +0000;more rearrangements to scrapy doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40605

==

scrapy/trunk/docs/intro/index.rst
scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/topics/index.rst
==================
6a4a4a33;samus_;2009-01-02 16:28:05 +0000;created test for body_or_str (forgot to add the file to the repo at r601)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40604

==

scrapy/trunk/scrapy/tests/test_utils_response.py
==================
a0f2ce0b;Pablo Hoffman;2009-01-02 16:25:28 +0000;rearranged doc according to what we agreed on a meeting with elpolilla and ismael
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40603

==

scrapy/trunk/docs/index.rst
scrapy/trunk/docs/intro/index.rst
scrapy/trunk/docs/intro/install.rst
scrapy/trunk/docs/intro/overview.rst
scrapy/trunk/docs/intro/tutorial/index.rst
scrapy/trunk/docs/intro/tutorial/scrot1.png
scrapy/trunk/docs/intro/tutorial/scrot2.png
scrapy/trunk/docs/intro/tutorial/scrot3.png
scrapy/trunk/docs/intro/tutorial/tutorial1.rst
scrapy/trunk/docs/intro/tutorial/tutorial2.rst
scrapy/trunk/docs/intro/tutorial/tutorial3.rst
scrapy/trunk/docs/intro/tutorial/tutorial4.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/selectors.rst
scrapy/trunk/docs/topics/settings.rst
scrapy/trunk/docs/topics/spiders.rst
==================
d706182e;samus_;2009-01-02 16:21:28 +0000;created test for body_or_str and made small improvement to scrapy.http.response
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40602

==

scrapy/trunk/scrapy/http/response.py
==================
808923f5;Pablo Hoffman;2009-01-02 16:08:18 +0000;added topics section to docs, changed reference to ref
--HG--
rename : scrapy/trunk/docs/reference/index.rst => scrapy/trunk/docs/ref/index.rst
rename : scrapy/trunk/docs/reference/settings.rst => scrapy/trunk/docs/ref/settings.rst
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40601

==

scrapy/trunk/docs/index.rst
scrapy/trunk/docs/ref/index.rst
scrapy/trunk/docs/ref/settings.rst
scrapy/trunk/docs/topics/index.rst
scrapy/trunk/docs/topics/settings.rst
==================
c1edf0e3;samus_;2009-01-02 14:57:33 +0000;reverted generator approach because it conflicts with unique parameter plus fixed bug in canonicalize routine
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40600

==

scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_link.py
==================
e5a764cd;elpolilla;2009-01-02 14:06:51 +0000;. Modified LinkExtractors extract_links for being inconsistent. Moved extra parameters to the constructors. . Renamed ImageLinkExtractor to HtmlLinkExtractor and moved it to scrapy.contrib.link_extractors.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40599

==

scrapy/trunk/scrapy/contrib/link_extractors.py
scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_link.py
==================
2979521b;elpolilla;2009-01-02 13:07:18 +0000;Reverted change in r590 for inconsistency in the addition operation (doesnt work equally in both ways)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40598

==

scrapy/trunk/scrapy/tests/test_xpath.py
scrapy/trunk/scrapy/xpath/selector.py
==================
ebd5f465;samus_;2009-01-02 08:42:36 +0000;this changeset improves the extractors' implementation:
* moved LinkExtractor.extract_links to a private method and created wrapper in order to be able to work with text directly
* removed fugly new_response_from_xpaths from scrapy.utils.response and replaced it with a better internal algorithm
* moved former _normalize_input from scrapy.utils.iterators to scrapy.utils.response to fill the hole
* turned extractors' output lists into generators; this is safe because the result is always used in for..in constructs
* adapted test for generators (test should be rewritted anyways)

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40597

==

scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_link.py
scrapy/trunk/scrapy/utils/iterators.py
scrapy/trunk/scrapy/utils/response.py
==================
c9e48dc5;elpolilla;2009-01-02 04:12:59 +0000;Disabled ImageLinkExtractor test for triggering mysterious leaks in libxml2
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40596

==

scrapy/trunk/scrapy/tests/test_link.py
==================
e0cb3c1e;elpolilla;2009-01-02 02:36:27 +0000;Added test's missing sample file
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40595

==

scrapy/trunk/scrapy/tests/sample_data/image_linkextractor.html
==================
91a23e61;elpolilla;2009-01-02 02:34:44 +0000;Renamed LinkExtractors extract_urls method to extract_links
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40594

==

scrapy/trunk/scrapy/contrib/spiders/crawl.py
scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_link.py
scrapy/trunk/scrapy/tests/test_spiders/testplugin.py
==================
c82c799d;elpolilla;2009-01-02 02:25:17 +0000;Added ImageLinkExtractor's missing docstring
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40593

==

scrapy/trunk/scrapy/link/extractors.py
==================
5757e54a;elpolilla;2009-01-02 02:18:11 +0000;- Added repr method to Link objects - Added ImageLinkExtractor and tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40592

==

scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_link.py
==================
7bd73e0c;elpolilla;2008-12-31 13:23:25 +0000;Modified XPathSelectorLists: adding them should return a new XPathSelectorList
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40591

==

scrapy/trunk/scrapy/tests/test_xpath.py
scrapy/trunk/scrapy/xpath/selector.py
==================
99143ff3;olveyra;2008-12-30 19:38:15 +0000;doc string fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40590

==

scrapy/trunk/scrapy/link/extractors.py
==================
7e4c9200;Ismael Carnales;2008-12-30 15:04:59 +0000;corrected code blocks
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40589

==

scrapy/trunk/docs/reference/settings.rst
==================
1433af55;olveyra;2008-12-30 14:51:37 +0000;fix to commit (r586)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40588

==

scrapy/trunk/scrapy/spider/manager.py
==================
710247e0;olveyra;2008-12-30 13:49:00 +0000;Allow to load a default spider when no spider was found for a given url. Also a generic spider was added in contrib/spiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40587

==

scrapy/trunk/scrapy/conf/project_template/scrapy_settings.py
scrapy/trunk/scrapy/contrib/spiders/generic.py
scrapy/trunk/scrapy/spider/manager.py
==================
d0474095;Pablo Hoffman;2008-12-30 13:34:57 +0000;rearranged and sorted out default scrapy settings. closes #20
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40586

==

scrapy/trunk/scrapy/conf/__init__.py
scrapy/trunk/scrapy/conf/core_settings.py
scrapy/trunk/scrapy/conf/default_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
==================
1f247b1e;Pablo Hoffman;2008-12-30 13:28:36 +0000;added settings documentation topic, and completed available settings reference. closes #30
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40585

==

scrapy/trunk/docs/reference/settings.rst
scrapy/trunk/docs/topics/settings.rst
==================
af79bedf;olveyra;2008-12-30 13:04:06 +0000;Added doc line in RegexLinkExtractor for the case when no allow/deny argument is given
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40584

==

scrapy/trunk/scrapy/link/extractors.py
==================
8ef87660;Ismael Carnales;2008-12-30 11:27:19 +0000;the badge is back to green ... hulk is angry
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40583

==

sites/scrapy.org/templates/footer.html
==================
ad2c2368;Ismael Carnales;2008-12-30 11:25:42 +0000;using small gray badge
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40582

==

sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/footer.html
==================
c149e2de;Ismael Carnales;2008-12-30 11:16:32 +0000;removed menu from footer, added django badge
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40581

==

sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/footer.html
==================
c9491b60;Ismael Carnales;2008-12-30 10:56:15 +0000;replicating header menu in footer
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40580

==

sites/scrapy.org/templates/footer.html
==================
81fecc00;Ismael Carnales;2008-12-30 10:45:19 +0000;fixed settings indentation and added reference
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40579

==

scrapy/trunk/docs/reference/settings.rst
==================
36277f3a;Ismael Carnales;2008-12-29 19:02:56 +0000;changed settings from description unit to crossreference
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40578

==

scrapy/trunk/docs/_ext/scrapydocs.py
==================
5a038e7d;Ismael Carnales;2008-12-29 18:46:43 +0000;added docs breadrumb
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40577

==

sites/scrapy.org/templates/docs/doc.html
==================
e36f5624;Ismael Carnales;2008-12-29 18:35:13 +0000;fixed caps in news, reordered menu items
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40576

==

sites/scrapy.org/templates/header.html
==================
d619a11f;Ismael Carnales;2008-12-29 18:28:40 +0000;make sidebar bigger
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40575

==

sites/scrapy.org/static/style/style.css
==================
2f2c5cf1;Ismael Carnales;2008-12-29 18:27:16 +0000;removed django.contrib.comments requirement
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40574

==

sites/scrapy.org/scrapyorg/blog/models.py
sites/scrapy.org/scrapyorg/settings.py
sites/scrapy.org/templates/blog/post_detail.html
sites/scrapy.org/templates/header.html
==================
3d85932a;Ismael Carnales;2008-12-29 18:20:58 +0000;moved blog to news
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40573

==

sites/scrapy.org/scrapyorg/urls.py
==================
48682189;Ismael Carnales;2008-12-29 16:50:49 +0000;using a modified version of django simple blog
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40572

==

sites/scrapy.org/scrapyorg/blog/__init__.py
sites/scrapy.org/scrapyorg/blog/admin.py
sites/scrapy.org/scrapyorg/blog/feeds.py
sites/scrapy.org/scrapyorg/blog/managers.py
sites/scrapy.org/scrapyorg/blog/models.py
sites/scrapy.org/scrapyorg/blog/sitemap.py
sites/scrapy.org/scrapyorg/blog/templates/base.html
sites/scrapy.org/scrapyorg/blog/templates/blog/base_blog.html
sites/scrapy.org/scrapyorg/blog/templates/blog/category_detail.html
sites/scrapy.org/scrapyorg/blog/templates/blog/category_list.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_archive_day.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_archive_month.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_archive_year.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_detail.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_list.html
sites/scrapy.org/scrapyorg/blog/templates/blog/post_search.html
sites/scrapy.org/scrapyorg/blog/templates/feeds/posts_description.html
sites/scrapy.org/scrapyorg/blog/templates/feeds/posts_title.html
sites/scrapy.org/scrapyorg/blog/templates_backup/admin/blog/post/change_form.html
sites/scrapy.org/scrapyorg/blog/templates_backup/inlines/default.html
sites/scrapy.org/scrapyorg/blog/templatetags/__init__.py
sites/scrapy.org/scrapyorg/blog/templatetags/blog.py
sites/scrapy.org/scrapyorg/blog/tests.py
sites/scrapy.org/scrapyorg/blog/urls.py
sites/scrapy.org/scrapyorg/blog/views.py
sites/scrapy.org/scrapyorg/settings.py
sites/scrapy.org/scrapyorg/urls.py
sites/scrapy.org/templates/blog/base_blog.html
sites/scrapy.org/templates/blog/category_detail.html
sites/scrapy.org/templates/blog/category_list.html
sites/scrapy.org/templates/blog/post_archive_day.html
sites/scrapy.org/templates/blog/post_archive_month.html
sites/scrapy.org/templates/blog/post_archive_year.html
sites/scrapy.org/templates/blog/post_detail.html
sites/scrapy.org/templates/blog/post_list.html
sites/scrapy.org/templates/blog/post_search.html
==================
a5b609ac;Ismael Carnales;2008-12-29 16:13:19 +0000;moved blog templates to backup folder
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40571

==

sites/scrapy.org/templates/blog_back/entry_archive.html
sites/scrapy.org/templates/blog_back/entry_archive_day.html
sites/scrapy.org/templates/blog_back/entry_archive_month.html
sites/scrapy.org/templates/blog_back/entry_archive_year.html
sites/scrapy.org/templates/blog_back/entry_detail.html
==================
25a38e53;elpolilla;2008-12-29 15:54:16 +0000;Fixed minor encoding issues in adaptors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40570

==

scrapy/trunk/scrapy/contrib/adaptors/misc.py
==================
bbd2a9d6;elpolilla;2008-12-29 15:17:34 +0000;Fixed typo in test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40569

==

scrapy/trunk/scrapy/tests/test_adaptors.py
==================
5eb7e5ba;elpolilla;2008-12-29 15:10:21 +0000;Fixed lots of encoding issues, and improved some adaptors tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40568

==

scrapy/trunk/scrapy/contrib/adaptors/misc.py
scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-ascii.html
scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-cp1252.html
scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-latin1.html
scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-utf8-meta-latin1.html
scrapy/trunk/scrapy/tests/sample_data/adaptors/enc-utf8.html
scrapy/trunk/scrapy/tests/sample_data/adaptors/extr_unquoted.xml
scrapy/trunk/scrapy/tests/test_adaptors.py
scrapy/trunk/scrapy/tests/test_defaultencoding.py
scrapy/trunk/scrapy/utils/iterators.py
scrapy/trunk/scrapy/utils/url.py
scrapy/trunk/scrapy/xpath/selector.py
==================
fc3f66bd;Pablo Hoffman;2008-12-29 12:10:01 +0000;fixed grammar error
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40567

==

sites/scrapy.org/templates/articles/home.html
==================
b5a34dd2;Pablo Hoffman;2008-12-29 11:38:34 +0000;started writing settings documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40566

==

scrapy/trunk/docs/reference/settings.rst
==================
a593af5f;Pablo Hoffman;2008-12-28 08:45:27 +0000;fixed cyclic import between scrapy.core.engine and scrapy.utils.db
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40565

==

scrapy/trunk/scrapy/utils/db.py
==================
8a885e4d;Pablo Hoffman;2008-12-27 21:38:27 +0000;moved scrapy-docs svn:external where it belongs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40564

==
==================
06ad08c6;Pablo Hoffman;2008-12-27 21:32:18 +0000;moved dia diagram to docs/media
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40563

==

scrapy/trunk/docs/media/scrapy-architecture.dia
==================
7e5b85ca;Pablo Hoffman;2008-12-27 21:27:22 +0000;moved scrapy docs from website source to scrapy source, since it makes more sense there
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40562

==

scrapy/trunk/docs/_ext/scrapydocs.py
scrapy/trunk/docs/conf.py
scrapy/trunk/docs/index.rst
scrapy/trunk/docs/intro/index.rst
scrapy/trunk/docs/intro/install.rst
scrapy/trunk/docs/intro/overview/overview.rst
scrapy/trunk/docs/intro/overview/selectors.rst
scrapy/trunk/docs/intro/overview/spiders.rst
scrapy/trunk/docs/reference/index.rst
scrapy/trunk/docs/reference/settings.rst
scrapy/trunk/docs/tutorial/index.rst
scrapy/trunk/docs/tutorial/scrot1.png
scrapy/trunk/docs/tutorial/scrot2.png
scrapy/trunk/docs/tutorial/scrot3.png
scrapy/trunk/docs/tutorial/tutorial1.rst
scrapy/trunk/docs/tutorial/tutorial2.rst
scrapy/trunk/docs/tutorial/tutorial3.rst
scrapy/trunk/docs/tutorial/tutorial4.rst
sites/scrapy.org/Makefile
==================
97d47542;Pablo Hoffman;2008-12-27 21:20:29 +0000;moved docs to docs-old
--HG--
rename : scrapy/trunk/docs/scrapy-architecture.dia => scrapy/trunk/docs-old/scrapy-architecture.dia
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40561

==

scrapy/trunk/docs-old/scrapy-architecture.dia
==================
913c34a8;Pablo Hoffman;2008-12-27 19:57:10 +0000;added AUTHORS file
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40560

==

scrapy/trunk/AUTHORS
==================
77a99999;Pablo Hoffman;2008-12-27 19:16:12 +0000;improved text
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40559

==

sites/scrapy.org/templates/articles/home.html
==================
a617c2cb;Pablo Hoffman;2008-12-27 19:15:13 +0000;some updates to home and download page
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40558

==

sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/articles/download.html
sites/scrapy.org/templates/articles/home.html
==================
ed5e25c9;Pablo Hoffman;2008-12-27 18:21:37 +0000;removed tagline from scrapy logo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40557

==

sites/static.scrapy.org/logo.jpg
==================
f932a3d8;Pablo Hoffman;2008-12-27 17:37:05 +0000;added spider_exceptions to scrapy stats
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40556

==

scrapy/trunk/scrapy/core/engine.py
==================
6fa33f44;Pablo Hoffman;2008-12-27 02:06:05 +0000;fixed minor bug in scrapy manager
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40555

==

scrapy/trunk/scrapy/core/manager.py
==================
e89ad0be;Pablo Hoffman;2008-12-27 02:05:05 +0000;fixed minor bug in scrapy manager
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40554

==

scrapy/trunk/scrapy/core/manager.py
==================
9557e242;Pablo Hoffman;2008-12-27 01:07:29 +0000;added start_requests method to BaseSpider, made start_urls empty by default instead of a required attribute in every spider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40553

==

scrapy/trunk/scrapy/core/manager.py
scrapy/trunk/scrapy/spider/models.py
==================
5b159d0f;elpolilla;2008-12-26 18:53:15 +0000;- Improved unquote_markup by using generators instead of lists - Added possibility of specifying headers in items_to_csv
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40552

==

scrapy/trunk/scrapy/tests/test_utils_misc.py
scrapy/trunk/scrapy/utils/markup.py
scrapy/trunk/scrapy/utils/misc.py
==================
f59f1c8b;elpolilla;2008-12-26 16:10:03 +0000;Added items_to_csv function
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40551

==

scrapy/trunk/scrapy/tests/test_utils_misc.py
scrapy/trunk/scrapy/utils/misc.py
==================
c7332cd3;elpolilla;2008-12-26 14:03:45 +0000;Updated scrapy tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40550

==

sites/scrapy.org/docs/sources/tutorial/index.rst
sites/scrapy.org/docs/sources/tutorial/tutorial3.rst
sites/scrapy.org/docs/sources/tutorial/tutorial4.rst
==================
867ee20c;elpolilla;2008-12-26 12:21:53 +0000;Updated scrapy overview
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40549

==

sites/scrapy.org/docs/sources/intro/index.rst
sites/scrapy.org/docs/sources/intro/overview/overview.rst
sites/scrapy.org/docs/sources/intro/overview/selectors.rst
sites/scrapy.org/docs/sources/intro/overview/spiders.rst
sites/scrapy.org/docs/sources/tutorial/tutorial3.rst
==================
4ee36267;elpolilla;2008-12-26 11:51:09 +0000;Modified XMLFeedSpider in order to support parsing with HtmlXPathSelector
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40548

==

scrapy/trunk/scrapy/contrib/spiders/feed.py
==================
b9360f65;elpolilla;2008-12-24 14:14:03 +0000;Added tests for str_to_unicode and unicode_to_str
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40547

==

scrapy/trunk/scrapy/tests/test_utils_python.py
==================
86aa3bcb;elpolilla;2008-12-24 13:02:13 +0000;Added str_to_unicode and unicode_to_str functions, and used them in utils/markup
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40546

==

scrapy/trunk/scrapy/utils/markup.py
scrapy/trunk/scrapy/utils/python.py
==================
95ed5d86;elpolilla;2008-12-24 00:00:14 +0000;- Modified markup functions again; this time, in order to support utf-8 encoded strings (without interfering with unicode objects) - Reverted changes in tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40545

==

scrapy/trunk/scrapy/tests/test_utils_markup.py
scrapy/trunk/scrapy/utils/markup.py
==================
e2b08709;elpolilla;2008-12-23 23:27:53 +0000;Fixed markup tests. Those functions must always work with unicode objects.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40544

==

scrapy/trunk/scrapy/tests/test_utils_markup.py
==================
f4cecafc;elpolilla;2008-12-23 23:12:56 +0000;Removed some bogus decoding of strings in several markup-handling functions. Input must always be passed in a unicode object
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40543

==

scrapy/trunk/scrapy/utils/markup.py
==================
6d33e12c;Daniel Grana;2008-12-23 14:31:58 +0000;aws: sign requests if url hostname ends with s3.amazonaws.com common bucket suffix. This allows a spider to send requests to S3 with out need to sign it inside spider code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40542

==

scrapy/trunk/scrapy/contrib/aws.py
==================
0cd074c9;elpolilla;2008-12-23 14:21:46 +0000;Some changes made to shell command:  . Removed traces of the old decompressor tool  . Made the responses go through the downloader middlewares after being downloaded  . Added the command its own settings file
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40541

==

scrapy/trunk/scrapy/command/commands/shell.py
scrapy/trunk/scrapy/conf/commands/shell.py
==================
bd8bd25c;elpolilla;2008-12-23 01:37:32 +0000;Removed unuseful and noisy test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40540

==

scrapy/trunk/scrapy/tests/test_utils_iterators.py
==================
193fbfdc;elpolilla;2008-12-19 14:46:56 +0000;Updated scrapy's tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40539

==

sites/scrapy.org/docs/sources/tutorial/index.rst
sites/scrapy.org/docs/sources/tutorial/tutorial2.rst
sites/scrapy.org/docs/sources/tutorial/tutorial3.rst
==================
70af2e8e;elpolilla;2008-12-19 11:09:51 +0000;Modified Unquote adaptor to make use of the new unquote_markup function instead of remove_entities
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40538

==

scrapy/trunk/scrapy/contrib/adaptors/markup.py
==================
ac7ecb78;elpolilla;2008-12-19 10:16:58 +0000;Added adapt_response method to XMLFeedSpiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40537

==

scrapy/trunk/scrapy/contrib/spiders/feed.py
==================
9d76ff60;elpolilla;2008-12-19 10:16:31 +0000;Fixed bug in xmliter, which didnt add headers to the nodes it returned
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40536

==

scrapy/trunk/scrapy/tests/test_utils_iterators.py
scrapy/trunk/scrapy/utils/iterators.py
scrapy/trunk/scrapy/utils/python.py
==================
a98ba318;elpolilla;2008-12-18 16:49:09 +0000;Bugfix in parse command. Some options were not being processed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40535

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
cf8b5fae;Ismael Carnales;2008-12-18 16:22:09 +0000;massive rework of templates and styles
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40534

==

sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/base.html
sites/scrapy.org/templates/base_doc.html
sites/scrapy.org/templates/base_home.html
sites/scrapy.org/templates/footer.html
sites/scrapy.org/templates/header.html
==================
bda22a53;elpolilla;2008-12-18 16:12:49 +0000;Added more options to unquote_markup that are passed to remove_entities
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40533

==

scrapy/trunk/scrapy/utils/markup.py
==================
08150f5a;elpolilla;2008-12-18 16:03:46 +0000;Added "unquote_markup" function to scrapy.utils.markup
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40532

==

scrapy/trunk/scrapy/tests/test_utils_markup.py
scrapy/trunk/scrapy/utils/markup.py
==================
5b1aeac3;Ismael Carnales;2008-12-18 13:34:40 +0000;fixed typo in style
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40531

==

sites/scrapy.org/static/style/style.css
==================
2fab6549;Ismael Carnales;2008-12-18 13:33:21 +0000;make menu float in the right of logo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40530

==

sites/scrapy.org/static/style/style.css
==================
4fd712e1;Ismael Carnales;2008-12-18 13:06:13 +0000;added new logo, also make it clickable
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40529

==

sites/scrapy.org/static/images/logo.jpg
sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/header.html
==================
4856e2d6;Ezequiel Rivero;2008-12-18 10:36:21 +0000;fix of the footer.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40528

==

sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/base.html
==================
12471939;elpolilla;2008-12-17 17:43:20 +0000;Updated scrapy tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40527

==

sites/scrapy.org/docs/sources/tutorial/scrot1.png
sites/scrapy.org/docs/sources/tutorial/scrot2.png
sites/scrapy.org/docs/sources/tutorial/scrot3.png
sites/scrapy.org/docs/sources/tutorial/tutorial2.rst
==================
77009469;elpolilla;2008-12-17 16:40:29 +0000;Improved items set_adaptors method, and added a __repr__ method to AdaptorPipes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40526

==

scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
==================
4a16bbf7;Ismael Carnales;2008-12-16 19:01:50 +0000;more margin makes it more legible
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40525

==

sites/scrapy.org/static/style/style.css
==================
e7adff7a;Ismael Carnales;2008-12-16 19:00:24 +0000;removed footer margin
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40524

==

sites/scrapy.org/static/style/style.css
==================
8671c33e;Ismael Carnales;2008-12-16 18:59:18 +0000;now using left-aligned liquid layout
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40523

==

sites/scrapy.org/static/style/style.css
==================
570f49d4;Daniel Grana;2008-12-16 18:49:12 +0000;stats: limit the default number of stats history to 10
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40522

==

scrapy/trunk/scrapy/command/commands/stats.py
==================
7414e931;Ismael Carnales;2008-12-16 16:57:52 +0000;added breadcrumb navigation to docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40521

==

sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/docs/doc.html
==================
ed93eec3;Ismael Carnales;2008-12-16 16:55:29 +0000;removed border from last menu item
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40520

==

sites/scrapy.org/static/style/style.css
==================
f3d6d711;Ismael Carnales;2008-12-16 16:52:08 +0000;make home and download validate xhtml strict, watch out please
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40519

==

sites/scrapy.org/templates/articles/download.html
sites/scrapy.org/templates/articles/home.html
==================
a8b2f0c7;Ismael Carnales;2008-12-16 16:46:28 +0000;added charset
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40518

==

sites/scrapy.org/templates/base.html
==================
e3d1afe9;Ismael Carnales;2008-12-16 16:42:02 +0000;fixed html, is good to close the lis xD
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40517

==

sites/scrapy.org/templates/footer.html
sites/scrapy.org/templates/header.html
==================
58ce43c1;Ismael Carnales;2008-12-16 16:18:34 +0000;moved parents on top of prev/next links
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40516

==

sites/scrapy.org/templates/docs/doc.html
==================
89de849e;Ismael Carnales;2008-12-16 16:17:29 +0000;updated install link
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40515

==

sites/scrapy.org/templates/articles/download.html
==================
6766a396;Ismael Carnales;2008-12-16 16:14:15 +0000;added view to serve images
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40514

==

sites/scrapy.org/scrapyorg/docs/urls.py
sites/scrapy.org/scrapyorg/docs/views.py
==================
aab5a4a7;Ismael Carnales;2008-12-16 15:53:01 +0000;added links and reformated some texts
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40513

==

sites/scrapy.org/docs/sources/intro/install.rst
sites/scrapy.org/docs/sources/tutorial/tutorial1.rst
sites/scrapy.org/docs/sources/tutorial/tutorial2.rst
==================
e140b1e4;Ismael Carnales;2008-12-16 15:40:27 +0000;completed the install doc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40512

==

sites/scrapy.org/docs/sources/intro/install.rst
==================
a026e382;Ismael Carnales;2008-12-16 15:02:32 +0000;renamed intro to overview
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40511

==

sites/scrapy.org/docs/sources/intro/overview.rst
==================
e1ea75ba;Ismael Carnales;2008-12-16 15:01:26 +0000;archived old documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40510

==

sites/scrapy.org/docs/old/basics.rst
sites/scrapy.org/docs/old/tutorial/index.rst
sites/scrapy.org/docs/old/tutorial/tutorial1.rst
sites/scrapy.org/docs/old/tutorial/tutorial2.rst
sites/scrapy.org/docs/old/tutorial/tutorial3.rst
==================
99f956c1;Ismael Carnales;2008-12-16 15:00:35 +0000;making dir for old docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40509

==
==================
de003d15;Ismael Carnales;2008-12-16 14:59:38 +0000;renamed tutorial2 to tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40508

==

sites/scrapy.org/docs/sources/index.rst
sites/scrapy.org/docs/sources/tutorial/index.rst
sites/scrapy.org/docs/sources/tutorial/scrot1.png
sites/scrapy.org/docs/sources/tutorial/scrot2.png
sites/scrapy.org/docs/sources/tutorial/scrot3.png
sites/scrapy.org/docs/sources/tutorial/tutorial1.rst
sites/scrapy.org/docs/sources/tutorial/tutorial2.rst
==================
7f5117e3;Ismael Carnales;2008-12-16 14:58:52 +0000;reworking docs structure
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40507

==

sites/scrapy.org/docs/sources/index.rst
sites/scrapy.org/docs/sources/intro/index.rst
sites/scrapy.org/docs/sources/intro/install.rst
sites/scrapy.org/docs/sources/intro/overview.rst
sites/scrapy.org/docs/sources/tutorial_old/index.rst
sites/scrapy.org/docs/sources/tutorial_old/tutorial1.rst
sites/scrapy.org/docs/sources/tutorial_old/tutorial2.rst
sites/scrapy.org/docs/sources/tutorial_old/tutorial3.rst
==================
3e1eea8d;Ismael Carnales;2008-12-16 13:16:08 +0000;updated install with info for Arch Linux
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40506

==

scrapy/trunk/INSTALL
==================
4b2d29a6;Ismael Carnales;2008-12-16 11:58:24 +0000;renamed .static to _static
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40505

==

sites/scrapy.org/docs/sources/conf.py
==================
26c749b3;Ismael Carnales;2008-12-16 11:53:20 +0000;added extension for settings and basic skeleton of reference/settings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40504

==

sites/scrapy.org/docs/sources/_ext/scrapydocs.py
sites/scrapy.org/docs/sources/conf.py
sites/scrapy.org/docs/sources/index.rst
sites/scrapy.org/docs/sources/reference/index.rst
sites/scrapy.org/docs/sources/reference/settings.rst
==================
8d4a1e66;elpolilla;2008-12-16 11:46:19 +0000;Modified the new scrapy tutorial and added some images
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40503

==

sites/scrapy.org/docs/sources/tutorial2/scrot1.png
sites/scrapy.org/docs/sources/tutorial2/scrot2.png
sites/scrapy.org/docs/sources/tutorial2/scrot3.png
sites/scrapy.org/docs/sources/tutorial2/tutorial2.rst
==================
14b2a4ff;elpolilla;2008-12-16 00:39:48 +0000;Modified Scrapy tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40502

==

sites/scrapy.org/docs/sources/tutorial2/tutorial1.rst
sites/scrapy.org/docs/sources/tutorial2/tutorial2.rst
==================
f9931518;samus_;2008-12-15 17:08:57 +0000;restoring decompressor while errors are fixed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40501

==

scrapy/trunk/scrapy/utils/decompressor.py
==================
95c00c99;elpolilla;2008-12-15 15:06:52 +0000;Corrected syntax errors in templates
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40500

==

scrapy/trunk/scrapy/conf/project_template/templates/spider_crawl.tmpl
scrapy/trunk/scrapy/conf/project_template/templates/spider_csvfeed.tmpl
scrapy/trunk/scrapy/conf/project_template/templates/spider_xmlfeed.tmpl
==================
e5a476f9;Ismael Carnales;2008-12-15 14:30:25 +0000;fixed footer menu
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40499

==

sites/scrapy.org/static/style/style.css
==================
2e01fa16;elpolilla;2008-12-15 13:44:42 +0000;Added part of the new scrapy tutorial
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40498

==

sites/scrapy.org/docs/sources/index.rst
sites/scrapy.org/docs/sources/tutorial2/index.rst
sites/scrapy.org/docs/sources/tutorial2/tutorial1.rst
sites/scrapy.org/docs/sources/tutorial2/tutorial2.rst
==================
1cf569f8;elpolilla;2008-12-15 12:14:41 +0000;Reverting last change in scrapy-ctl script. PYTHONPATH should be set manually
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40497

==

scrapy/trunk/scrapy/conf/project_template/scrapy-ctl.py
==================
d72056c9;Pablo Hoffman;2008-12-15 12:02:16 +0000;removed incorrect text
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40496

==

sites/scrapy.org/templates/articles/community.html
==================
2d0cca53;elpolilla;2008-12-15 11:58:57 +0000;. Added path detection to scrapy-ctl script, which was giving problems with new projects . Corrected typo in CrawlSpiders template
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40495

==

scrapy/trunk/scrapy/conf/project_template/scrapy-ctl.py
scrapy/trunk/scrapy/conf/project_template/templates/spider_crawl.tmpl
==================
6b0e1f09;elpolilla;2008-12-15 02:29:47 +0000;. Replaced Decompressor tool by Decompression mmiddleware, including its tests . Removed references to Decompressor tool in FeedSpiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40494

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/decompression.py
scrapy/trunk/scrapy/contrib/spiders/feed.py
scrapy/trunk/scrapy/tests/test_middleware_decompression.py
==================
dcc34023;Pablo Hoffman;2008-12-14 06:29:19 +0000;scrapy.org: updated Home, added Download & Home articles. Updated footer & header
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40493

==

sites/scrapy.org/templates/articles/community.html
sites/scrapy.org/templates/articles/download.html
sites/scrapy.org/templates/articles/home.html
sites/scrapy.org/templates/footer.html
sites/scrapy.org/templates/header.html
==================
becf3bd7;Pablo Hoffman;2008-12-14 05:23:47 +0000;added BSD license
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40492

==

scrapy/trunk/LICENSE
==================
4599893f;Pablo Hoffman;2008-12-14 04:32:01 +0000;fixed bug in DownloaderStats middleware
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40491

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/stats.py
==================
1510efca;Pablo Hoffman;2008-12-14 04:01:54 +0000;Sorted out downloader-related stats:
 * added DownloaderStats (downloader middleware) to handle all downloader-related stats
 * removed downloader related stats from CoreStats
 * removed downloader exception stats from RetryMiddleware

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40490

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/stats.py
scrapy/trunk/scrapy/stats/corestats.py
==================
3d16160b;samus_;2008-12-14 01:49:59 +0000;adding RetryMiddleware errors to the stats
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40489

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
==================
bd4c106a;samus_;2008-12-12 21:26:00 +0000;* adjusted RETRY_TIMES setting and behaviour * refactored scrapy.contrib.downloadermiddleware.retry.RetryMiddleware * created test for it (scrapy.tests.test_middleware_retry.RetryTest) * updated docstring at scrapy.core.downloader.middleware.DownloaderMiddlewareManager
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40488

==

scrapy/trunk/scrapy/conf/core_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
scrapy/trunk/scrapy/core/downloader/middleware.py
scrapy/trunk/scrapy/tests/test_middleware_retry.py
==================
f7fce6cd;Ismael Carnales;2008-12-12 10:50:41 +0000;changed formatting of srapy intro
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40487

==

sites/scrapy.org/docs/sources/scrapy_intro.rst
==================
7efa85cc;elpolilla;2008-12-11 13:54:54 +0000;Added missing import and convenient check in ShoveItem pipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40486

==

scrapy/trunk/scrapy/contrib/pipeline/shoveitem.py
==================
4ec69bf1;elpolilla;2008-12-11 13:24:33 +0000;Added logging to the ShoveItem pipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40485

==

scrapy/trunk/scrapy/contrib/pipeline/shoveitem.py
==================
991fabb7;elpolilla;2008-12-10 16:48:02 +0000;Added response decompression to feed spiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40484

==

scrapy/trunk/scrapy/contrib/spiders/feed.py
==================
4d55a695;Pablo Hoffman;2008-12-10 01:39:32 +0000;removed obsolete dir
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40483

==
==================
4c0a4222;elpolilla;2008-12-08 16:33:11 +0000;Added some test cases to the ExtractImages adaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40482

==

scrapy/trunk/scrapy/tests/test_adaptors.py
==================
686ab9db;elpolilla;2008-12-08 13:45:21 +0000;Corrected error in CSVFeedSpiders template
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40481

==

scrapy/trunk/scrapy/conf/project_template/templates/spider_csvfeed.tmpl
==================
67706496;elpolilla;2008-12-08 13:42:25 +0000;Added template for CSVFeedSpiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40480

==

scrapy/trunk/scrapy/conf/project_template/templates/spider_csvfeed.tmpl
scrapy/trunk/scrapy/conf/project_template/templates/spider_xmlfeed.tmpl
==================
528d2391;elpolilla;2008-12-08 12:48:01 +0000;Fixed bug in images adaptor when a None value was received
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40479

==

scrapy/trunk/scrapy/contrib/adaptors/extraction.py
==================
29024d8a;Daniel Grana;2008-12-08 12:00:30 +0000;Fix a bug introduced by splitting s3 image uploading to use another downloader slot
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40478

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
fade1730;Daniel Grana;2008-12-08 12:00:02 +0000;Set Cache-Control header for Amazon S3 uploaded images to prevent browsers from requesting images everytime.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40477

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
b52f7726;elpolilla;2008-12-08 11:15:38 +0000;. Reverted change in r473. Now an error message is shown when no rules match the provided url . Modified print_results to make it show the callback from which items/links were extracted
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40476

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
2fe8afda;samus_;2008-12-07 02:56:07 +0000;adding support for dicts (because this is what MySQLdb *really* uses)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40475

==

scrapy/trunk/scrapy/tests/test_storedb.py
scrapy/trunk/scrapy/utils/db.py
==================
f373fc0f;elpolilla;2008-12-05 17:56:36 +0000;Modified parse command to make it default to "parse" method if no rules are found
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40474

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
aeb95200;elpolilla;2008-12-05 16:36:59 +0000;Modified parse command to accept multiple callbacks
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40473

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
aad2eae5;Daniel Grana;2008-12-04 18:52:03 +0000;S3 pipeline: add a custom method for requesting S3 requests downloads.
This helps split requests done to s3 from requests done to download
images from main spider domain.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40472

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
0ce417eb;elpolilla;2008-12-04 16:48:11 +0000;Corrected some error messages in order to comply with the conventions
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40471

==

scrapy/trunk/scrapy/command/commands/crawl.py
scrapy/trunk/scrapy/command/commands/parse.py
scrapy/trunk/scrapy/core/manager.py
==================
f18bce70;Daniel Grana;2008-12-04 02:10:56 +0000;core: allow engine download to be dinamically backouted to the double of the max_concurrent_requests for a domain
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40470

==

scrapy/trunk/scrapy/core/downloader/manager.py
scrapy/trunk/scrapy/core/engine.py
==================
72c978d8;Daniel Grana;2008-12-04 00:38:56 +0000;s3: sign requests in downloder middleware to avoid sending signed requests dated more than 15minutes ago
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40469

==

scrapy/trunk/scrapy/contrib/aws.py
scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
c7cb6c4e;elpolilla;2008-12-03 17:41:03 +0000;. Added --callback switch to crawl command . Adding again the method 'parse_start_urls' . Added --callback switch to parse command and removed extraction of links using rules
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40468

==

scrapy/trunk/scrapy/command/commands/crawl.py
scrapy/trunk/scrapy/command/commands/parse.py
scrapy/trunk/scrapy/contrib/spiders/crawl.py
==================
e030f384;elpolilla;2008-12-03 14:24:41 +0000;Fixed yet another bug in parse command that didnt extract links from all of the rules (just from the matching ones)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40467

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
242bd38b;elpolilla;2008-12-03 14:24:14 +0000;Fixed another bug in parse command. Only links from matching rules were being extracted
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40466

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
cc2a6994;elpolilla;2008-12-03 10:37:56 +0000;Fixed bug in parse command. Links from matching rules werent being extracted
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40465

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
f371c952;Daniel Grana;2008-12-02 18:10:24 +0000;s3: convert images to RGB prior to save as JPEG
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40464

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
977e13e3;elpolilla;2008-12-02 16:04:29 +0000;Fixed wrong help text in parse command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40463

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
ddda08ee;elpolilla;2008-12-02 15:19:15 +0000;Fixed some bugs in CrawlSpider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40462

==

scrapy/trunk/scrapy/contrib/spiders/crawl.py
==================
7ac8ae99;Daniel Grana;2008-12-02 13:45:35 +0000;Revert "add 505 and 403 to retry status codes due to amazon s3 random fails while uploading images"
This reverts changeset r457

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40461

==

scrapy/trunk/scrapy/conf/core_settings.py
==================
068d2278;elpolilla;2008-12-02 13:29:20 +0000;Removed silly bug from the previous revision
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40460

==

scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
==================
a4ba7b9d;elpolilla;2008-12-02 13:26:04 +0000;Added stripping of urls in LinkExtractor, and removed unnecesary check
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40459

==

scrapy/trunk/scrapy/link/extractors.py
==================
c22223be;Daniel Grana;2008-12-02 13:01:49 +0000;add 505 and 403 to retry status codes due to amazon s3 random fails while uploading images
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40458

==

scrapy/trunk/scrapy/conf/core_settings.py
==================
50379ee2;elpolilla;2008-12-02 12:51:32 +0000;Added LinkExtractor.matches test and fixed bug in that same method
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40457

==

scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_link.py
==================
c75ac38b;elpolilla;2008-12-02 12:20:55 +0000;Improved parse command and LinkExtractor's matches method
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40456

==

scrapy/trunk/scrapy/command/commands/parse.py
scrapy/trunk/scrapy/command/commands/parse_method.py
scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
==================
eff09f2f;elpolilla;2008-12-02 02:17:15 +0000;Added some missing postprocessing to items in parse command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40455

==

scrapy/trunk/scrapy/command/commands/parse_method.py
==================
3b7f282b;Daniel Grana;2008-12-01 18:44:04 +0000;fix missing import errors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40454

==

scrapy/trunk/scrapy/patches/monkeypatches.py
==================
dd37bb5a;Daniel Grana;2008-12-01 17:14:06 +0000;MONKEYPATCH: in twisted < 8.0.0, HTTPPageGetter class can not handle HEAD requests because of response empty body raising PartialDownloadError.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40453

==

scrapy/trunk/scrapy/patches/monkeypatches.py
==================
aa3ea811;elpolilla;2008-12-01 15:49:04 +0000;Fixed wrong error message in parse command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40452

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
0cff67b2;elpolilla;2008-12-01 15:44:50 +0000;Finished implementing new parse command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40451

==

scrapy/trunk/scrapy/command/commands/parse.py
scrapy/trunk/scrapy/command/commands/parse2.py
scrapy/trunk/scrapy/command/commands/parse_method.py
==================
8b372827;elpolilla;2008-12-01 02:59:34 +0000;Changed CrawlSpider's way of setting crawling rules
--HG--
rename : scrapy/trunk/scrapy/contrib/spiders2/crawl.py => scrapy/trunk/scrapy/contrib/spiders/crawl.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40450

==

scrapy/trunk/scrapy/conf/project_template/templates/spider_crawl.tmpl
scrapy/trunk/scrapy/contrib/adaptors/extraction.py
scrapy/trunk/scrapy/contrib/spiders.py
scrapy/trunk/scrapy/contrib/spiders/__init__.py
scrapy/trunk/scrapy/contrib/spiders/crawl.py
scrapy/trunk/scrapy/contrib/spiders/feed.py
scrapy/trunk/scrapy/contrib/spiders2/__init__.py
scrapy/trunk/scrapy/contrib/spiders2/feed.py
==================
7f05b923;Daniel Grana;2008-11-28 16:18:03 +0000;s3 images pipeline: dont include path prefix in key name
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40449

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
778b77f2;Pablo Hoffman;2008-11-28 01:58:49 +0000;added parse2 command (candidate to replace parse command)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40448

==

scrapy/trunk/scrapy/command/commands/parse2.py
==================
6d5a130b;Pablo Hoffman;2008-11-28 01:57:07 +0000;more refactoring to CrawlSpider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40447

==

scrapy/trunk/scrapy/contrib/spiders2/crawl.py
==================
1b92fef9;elpolilla;2008-11-27 15:44:29 +0000;Added scrapy intro RST
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40446

==

sites/scrapy.org/docs/sources/index.rst
sites/scrapy.org/docs/sources/scrapy_intro.rst
==================
142cd72f;Pablo Hoffman;2008-11-27 15:21:41 +0000;removed function check_valid_urlencode from scrapy.utils.url (it didn't fit there because it was too custom)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40445

==

scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
d865ca4e;Ismael Carnales;2008-11-27 14:54:42 +0000;removed unused and unneeded SITE_URL from localsettings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40444

==

sites/scrapy.org/scrapyorg/local_settings.py.template
==================
2f5cff0b;Ismael Carnales;2008-11-27 14:53:02 +0000;removed unneeded index view
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40443

==

sites/scrapy.org/scrapyorg/docs/urls.py
sites/scrapy.org/scrapyorg/docs/views.py
==================
9cc3b288;Ismael Carnales;2008-11-27 14:46:01 +0000;updated requirements
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40442

==

sites/scrapy.org/README
==================
7683eefc;Ismael Carnales;2008-11-27 14:43:36 +0000;add empty docs/pickle dir for pickled docs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40441

==
==================
dae37d3d;Ismael Carnales;2008-11-27 14:42:42 +0000;don't store pickled docs in SVN only the dir
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40440

==

sites/scrapy.org/docs/pickle/.doctrees/basics.doctree
sites/scrapy.org/docs/pickle/.doctrees/environment.pickle
sites/scrapy.org/docs/pickle/.doctrees/index.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/index.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/tutorial1.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/tutorial2.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/tutorial3.doctree
sites/scrapy.org/docs/pickle/basics.fpickle
sites/scrapy.org/docs/pickle/environment.pickle
sites/scrapy.org/docs/pickle/genindex.fpickle
sites/scrapy.org/docs/pickle/globalcontext.pickle
sites/scrapy.org/docs/pickle/index.fpickle
sites/scrapy.org/docs/pickle/last_build
sites/scrapy.org/docs/pickle/objects.inv
sites/scrapy.org/docs/pickle/search.fpickle
sites/scrapy.org/docs/pickle/searchindex.pickle
sites/scrapy.org/docs/pickle/tutorial/index.fpickle
sites/scrapy.org/docs/pickle/tutorial/tutorial1.fpickle
sites/scrapy.org/docs/pickle/tutorial/tutorial2.fpickle
sites/scrapy.org/docs/pickle/tutorial/tutorial3.fpickle
==================
9e43e69d;Ismael Carnales;2008-11-27 14:39:55 +0000;added Makefile for building docs and testing
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40439

==

sites/scrapy.org/Makefile
sites/scrapy.org/docs/pickle/.doctrees/basics.doctree
sites/scrapy.org/docs/pickle/.doctrees/environment.pickle
sites/scrapy.org/docs/pickle/.doctrees/index.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/index.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/tutorial1.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/tutorial2.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/tutorial3.doctree
sites/scrapy.org/docs/pickle/environment.pickle
sites/scrapy.org/docs/pickle/searchindex.pickle
==================
b714b5ab;elpolilla;2008-11-27 11:21:28 +0000;Added string cast in check_valid_urlencode to prevent urllib from failing
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40438

==

scrapy/trunk/scrapy/utils/url.py
==================
af842a3e;Pablo Hoffman;2008-11-26 22:10:06 +0000;added proper fix to canonicalize_url problem with unicode urls already percent-encoded
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40437

==

scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
8d08ab5f;samus_;2008-11-26 18:31:53 +0000;added excluded characters, also implemented dan's readability tips
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40436

==

scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
874331a5;Daniel Grana;2008-11-26 18:28:49 +0000;revert a testing less-than condition
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40435

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
ce172e85;Pablo Hoffman;2008-11-26 17:55:03 +0000;reverted wrong fix to canonicalize_url
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40434

==

scrapy/trunk/scrapy/utils/url.py
==================
0958eecf;elpolilla;2008-11-26 16:18:19 +0000;Modified canonicalize_url to make it always work with regular strings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40433

==

scrapy/trunk/scrapy/utils/url.py
==================
8eab5802;elpolilla;2008-11-26 16:09:39 +0000;Fixed bug in item.attribute
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40432

==

scrapy/trunk/scrapy/item/models.py
==================
40b3f06f;elpolilla;2008-11-26 14:48:07 +0000;Improved add parameter in item.attribute
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40431

==

scrapy/trunk/scrapy/item/models.py
==================
26b4be78;elpolilla;2008-11-26 13:12:20 +0000;Minor correction in docstring
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40430

==

scrapy/trunk/scrapy/contrib/spiders2/crawl.py
==================
04bd65de;elpolilla;2008-11-26 12:49:14 +0000;Added new crawling spider (with rules), but without replacing the previous one
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40429

==

scrapy/trunk/scrapy/contrib/item/__init__.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/contrib/spiders2.py
scrapy/trunk/scrapy/contrib/spiders2/__init__.py
scrapy/trunk/scrapy/contrib/spiders2/crawl.py
scrapy/trunk/scrapy/contrib/spiders2/feed.py
scrapy/trunk/scrapy/item/models.py
==================
fe49bc20;samus_;2008-11-26 12:05:31 +0000;improved check
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40428

==

scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
537a3457;Daniel Grana;2008-11-25 20:51:02 +0000;s3: put image size as metadata
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40427

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
664a7249;samus_;2008-11-25 18:49:17 +0000;improved url validation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40426

==

scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
89bd6ede;Ismael Carnales;2008-11-25 18:16:04 +0000;first commit of doc apps
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40425

==

sites/scrapy.org/docs/pickle/.doctrees/basics.doctree
sites/scrapy.org/docs/pickle/.doctrees/environment.pickle
sites/scrapy.org/docs/pickle/.doctrees/index.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/index.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/tutorial1.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/tutorial2.doctree
sites/scrapy.org/docs/pickle/.doctrees/tutorial/tutorial3.doctree
sites/scrapy.org/docs/pickle/basics.fpickle
sites/scrapy.org/docs/pickle/environment.pickle
sites/scrapy.org/docs/pickle/genindex.fpickle
sites/scrapy.org/docs/pickle/globalcontext.pickle
sites/scrapy.org/docs/pickle/index.fpickle
sites/scrapy.org/docs/pickle/last_build
sites/scrapy.org/docs/pickle/objects.inv
sites/scrapy.org/docs/pickle/search.fpickle
sites/scrapy.org/docs/pickle/searchindex.pickle
sites/scrapy.org/docs/pickle/tutorial/index.fpickle
sites/scrapy.org/docs/pickle/tutorial/tutorial1.fpickle
sites/scrapy.org/docs/pickle/tutorial/tutorial2.fpickle
sites/scrapy.org/docs/pickle/tutorial/tutorial3.fpickle
sites/scrapy.org/docs/sources/basics.rst
sites/scrapy.org/docs/sources/conf.py
sites/scrapy.org/docs/sources/index.rst
sites/scrapy.org/docs/sources/tutorial/index.rst
sites/scrapy.org/docs/sources/tutorial/tutorial1.rst
sites/scrapy.org/docs/sources/tutorial/tutorial2.rst
sites/scrapy.org/docs/sources/tutorial/tutorial3.rst
sites/scrapy.org/scrapyorg/docs/__init__.py
sites/scrapy.org/scrapyorg/docs/models.py
sites/scrapy.org/scrapyorg/docs/urls.py
sites/scrapy.org/scrapyorg/docs/views.py
sites/scrapy.org/scrapyorg/settings.py
sites/scrapy.org/scrapyorg/urls.py
sites/scrapy.org/static/style/pygments.css
sites/scrapy.org/templates/base_doc.html
sites/scrapy.org/templates/docs/doc.html
sites/scrapy.org/templates/header.html
==================
42411719;Ismael Carnales;2008-11-25 17:42:10 +0000;style h1s
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40424

==

sites/scrapy.org/static/style/style.css
==================
c61d0648;Daniel Grana;2008-11-25 17:17:25 +0000;use hashlib instead of deprecated md5 module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40423

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
81416c4d;Daniel Grana;2008-11-25 17:09:26 +0000;s3: add image md5 content checksum to image path
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40422

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
33b20be7;Pablo Hoffman;2008-11-25 17:06:36 +0000;cleanup handling of adaptor pipe debugging code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40421

==

scrapy/trunk/scrapy/item/adaptors.py
==================
e8df55d1;Ismael Carnales;2008-11-25 16:23:37 +0000;added header and footer templates
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40420

==

sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/base.html
sites/scrapy.org/templates/base_home.html
sites/scrapy.org/templates/footer.html
sites/scrapy.org/templates/header.html
==================
011adf4d;elpolilla;2008-11-25 15:27:04 +0000;Turned "strip_list" adaptor into "strip"
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40419

==

scrapy/trunk/scrapy/contrib/adaptors/__init__.py
scrapy/trunk/scrapy/contrib/adaptors/misc.py
scrapy/trunk/scrapy/tests/test_adaptors.py
==================
1a60f6c1;Daniel Grana;2008-11-25 13:44:06 +0000;comment default thumb sizes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40418

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
f61be3f0;Daniel Grana;2008-11-25 11:58:31 +0000;fix syntax typo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40417

==

scrapy/trunk/scrapy/contrib/aws.py
scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
072fed8d;Daniel Grana;2008-11-25 11:06:34 +0000;aws: request signing function and tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40416

==

scrapy/trunk/scrapy/contrib/aws.py
scrapy/trunk/scrapy/contrib/pipeline/s3images.py
scrapy/trunk/scrapy/tests/test_aws.py
==================
0fbb7579;Pablo Hoffman;2008-11-25 02:38:26 +0000;added new CrawlSpider that's gonna replace the old CrawlSpider soon
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40415

==

scrapy/trunk/scrapy/contrib/spiders2.py
==================
f558a49d;elpolilla;2008-11-25 01:41:22 +0000;Fixed ExtractImages adaptor, which wasnt looking for a base tag
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40414

==

scrapy/trunk/scrapy/contrib/adaptors/extraction.py
==================
5028146e;Pablo Hoffman;2008-11-25 00:39:11 +0000;added __slots__ to decrease memory footprint of Link objects
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40413

==

scrapy/trunk/scrapy/link/__init__.py
==================
a8903d58;elpolilla;2008-11-24 18:31:05 +0000;Changed deletion of _adaptor_dict attribute in parse command that could trigger exceptions
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40412

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
68e497e5;elpolilla;2008-11-24 13:09:08 +0000;Fixed some little bugs in adaptors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40411

==

scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
==================
3cbfb554;Ismael Carnales;2008-11-24 12:51:22 +0000;home must be the fist link in a left-to-right lecture world
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40410

==

sites/scrapy.org/templates/base_home.html
==================
859733d8;Ismael Carnales;2008-11-24 12:48:45 +0000;added link to insophia page
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40409

==

sites/scrapy.org/templates/base.html
==================
3dab0c12;Ismael Carnales;2008-11-24 12:40:59 +0000;use relative links for images
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40408

==

sites/scrapy.org/static/style/style.css
==================
e9e8fa00;elpolilla;2008-11-24 12:38:41 +0000;Added check to the previous commit, because it could have failed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40407

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
8f01a70e;elpolilla;2008-11-24 12:35:26 +0000;Removed ugly printing of adaptors dict in parse command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40406

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
82cf9111;elpolilla;2008-11-24 12:05:23 +0000;Added method for inserting adaptors into a pipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40405

==

scrapy/trunk/scrapy/item/models.py
==================
0f9eba8a;elpolilla;2008-11-24 11:28:18 +0000;Removed AdaptorDict and added AdaptorPipe, plus the adaptize helper
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40404

==

scrapy/trunk/scrapy/contrib/adaptors/markup.py
scrapy/trunk/scrapy/contrib/adaptors/misc.py
scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
==================
cbffced5;Daniel Grana;2008-11-24 10:59:59 +0000;add amamzon ws helper module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40403

==

scrapy/trunk/scrapy/contrib/aws.py
==================
2142d4f7;Daniel Grana;2008-11-24 10:19:26 +0000;s3 image pipeline: use scrapyengine for downloads
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40402

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
scrapy/trunk/scrapy/log/__init__.py
==================
c4434590;Daniel Grana;2008-11-24 10:18:55 +0000;images pipeline factorization
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40401

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
98bc8ec3;Daniel Grana;2008-11-24 10:18:27 +0000;spidermiddleware: remove not used "filter" hook
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40400

==

scrapy/trunk/scrapy/spider/middleware.py
==================
b56a5d93;Daniel Grana;2008-11-24 10:17:56 +0000;clean spidermiddleware callback/errback handling
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40399

==

scrapy/trunk/scrapy/spider/middleware.py
==================
c7b3fae9;Daniel Grana;2008-11-24 10:17:32 +0000;add basic spider template
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40398

==

scrapy/trunk/scrapy/conf/project_template/templates/spider_basic.tmpl
==================
0938984d;Daniel Grana;2008-11-24 10:17:02 +0000;media pipeline: no need for complex deferred execution
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40397

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
a6ff1653;Daniel Grana;2008-11-24 10:16:33 +0000;media pipeline: dont hide list of results for item_complete
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40396

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
5ccd4df0;Pablo Hoffman;2008-11-23 01:32:21 +0000;moved log method to BaseSpider, moved adapt_feed doc to docstring
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40395

==

scrapy/trunk/scrapy/contrib/spiders.py
scrapy/trunk/scrapy/spider/models.py
==================
d4040d73;samus_;2008-11-22 19:20:53 +0000;added docstring
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40394

==

scrapy/trunk/scrapy/utils/iterators.py
==================
1458686c;Daniel Grana;2008-11-21 10:37:32 +0000;media pipeline: support deferred execution of media_to_download hook
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40393

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
c15a24c2;elpolilla;2008-11-21 10:08:22 +0000;Added --force option switch to genspider command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40392

==

scrapy/trunk/scrapy/command/commands/genspider.py
==================
836c532e;samus_;2008-11-20 15:36:48 +0000;some cleanup to the identify mechanism
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40391

==

scrapy/trunk/scrapy/command/commands/parse.py
==================
17d45f52;elpolilla;2008-11-20 14:34:59 +0000;Added CSVFeedSpider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40390

==

scrapy/trunk/scrapy/contrib/spiders.py
==================
77a917df;elpolilla;2008-11-20 13:10:06 +0000;Modified FOLLOW_LINKS setting name to a more appropiate one
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40389

==

scrapy/trunk/scrapy/command/commands/crawl.py
scrapy/trunk/scrapy/contrib/spiders.py
==================
99c4c063;elpolilla;2008-11-20 12:10:36 +0000;Added --nofollow option switch to crawl command, and its functionality into CrawlSpiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40388

==

scrapy/trunk/scrapy/command/commands/crawl.py
scrapy/trunk/scrapy/contrib/spiders.py
==================
90fe6ef1;elpolilla;2008-11-19 12:29:04 +0000;Fixed bug that didnt show extracted links in new spiders parse command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40387

==

scrapy/trunk/scrapy/command/commands/parse.py
scrapy/trunk/scrapy/contrib/spiders.py
==================
56e3d5ae;Daniel Grana;2008-11-18 17:37:25 +0000;Revert "Modified image pipeline to make it able to manage 304 responses"
This reverts commit 3ff5303de7a3d2cffce0244b5bd9aa2b0f5c9c83.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40386

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
==================
d5469eab;elpolilla;2008-11-18 15:55:27 +0000;Modified image pipeline to make it able to manage 304 responses
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40385

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
==================
9a7b5a7c;elpolilla;2008-11-18 11:34:03 +0000;Improved genspider command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40384

==

scrapy/trunk/scrapy/command/commands/genspider.py
scrapy/trunk/scrapy/conf/project_template/templates/spider_crawl.tmpl
scrapy/trunk/scrapy/conf/project_template/templates/spider_xmlfeed.tmpl
==================
862def2d;Daniel Grana;2008-11-17 10:33:49 +0000;move teplate renderer function to utils package, it can be reused by genspider command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40383

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
scrapy/trunk/scrapy/utils/misc.py
==================
d6d32fa6;Daniel Grana;2008-11-17 10:33:15 +0000;substitute scrapy_settings template variables on startproject
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40382

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
==================
bddfbee0;elpolilla;2008-11-14 13:36:18 +0000;Fixed some unicode issues in adaptors, improved docstrings and a test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40381

==

scrapy/trunk/scrapy/contrib/adaptors/markup.py
scrapy/trunk/scrapy/contrib/adaptors/misc.py
scrapy/trunk/scrapy/tests/test_adaptors.py
==================
c209f214;elpolilla;2008-11-14 12:25:56 +0000;-Fixed bug in ExtractImages adaptor that made it fail if it received a string -Removed BasicSpider and it's guid generation method because it wasnt generic enough to be in the framework
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40380

==

scrapy/trunk/scrapy/contrib/adaptors/extraction.py
scrapy/trunk/scrapy/contrib/spiders.py
==================
f5eb71fb;elpolilla;2008-11-14 01:32:49 +0000;Fixed bug in url_query_cleaner that returned wrong parameters for urls with fragments and added test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40379

==

scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
79c9ac38;Pablo Hoffman;2008-11-13 15:50:27 +0000;updated scrapy.utils.misc.hash_values to drop usage of deprecated sha module in favor or hashlib, added tests to hash_values function
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40378

==

scrapy/trunk/scrapy/tests/test_utils_misc.py
scrapy/trunk/scrapy/utils/misc.py
==================
01b157d1;elpolilla;2008-11-13 12:27:36 +0000;Reverted delist adaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40377

==

scrapy/trunk/scrapy/contrib/adaptors/misc.py
==================
5f4053d9;elpolilla;2008-11-13 12:20:32 +0000;Reverted to revision 370
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40376

==

scrapy/trunk/scrapy/contrib/adaptors/__init__.py
scrapy/trunk/scrapy/contrib/adaptors/markup.py
scrapy/trunk/scrapy/contrib/item/__init__.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/item/__init__.py
scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/tests/test_adaptors.py
==================
fab0e693;elpolilla;2008-11-13 11:01:44 +0000;Removed unnecesary check in RobustScrapedItem's getattr
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40375

==

scrapy/trunk/scrapy/contrib/item/models.py
==================
4afa29b2;elpolilla;2008-11-13 10:46:43 +0000;Fixed adaptors test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40374

==

scrapy/trunk/scrapy/tests/test_adaptors.py
==================
4ef7c463;elpolilla;2008-11-13 10:35:24 +0000;Added ItemAttribute objects
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40373

==

scrapy/trunk/scrapy/contrib/item/__init__.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/item/__init__.py
scrapy/trunk/scrapy/item/models.py
==================
90d28bad;elpolilla;2008-11-13 10:13:11 +0000;Turned unquote adaptor into a function, and added adaptor factory
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40372

==

scrapy/trunk/scrapy/contrib/adaptors/__init__.py
scrapy/trunk/scrapy/contrib/adaptors/markup.py
==================
36080ada;elpolilla;2008-11-13 10:04:04 +0000;Added some missing docstrings to adaptors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40371

==

scrapy/trunk/scrapy/contrib/adaptors/misc.py
==================
323241b6;elpolilla;2008-11-11 12:51:39 +0000;Reverted changes in r368
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40370

==

scrapy/trunk/scrapy/contrib/spiders.py
==================
c5d13405;elpolilla;2008-11-10 15:30:45 +0000;Added possibility of checking whether a response should or shouldnt be parsed with the corresponding parse_suffix method (by defining check_suffix) in CrawlSpider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40369

==

scrapy/trunk/scrapy/contrib/spiders.py
==================
6db6b8c5;elpolilla;2008-11-10 12:26:11 +0000;GUID wasnt being set when calling a spider's parse_url method (from the parse command). Fixed that.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40368

==

scrapy/trunk/scrapy/contrib/spiders.py
==================
22d713bb;samus_;2008-11-08 13:34:02 +0000;seems scrapy uses a test spider (scrapy.tests.test_spiders.testplugin.TestSpider) moving the test to decobot
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40367

==

scrapy/trunk/scrapy/tests/test_load_spiders.py
==================
3e88890b;samus_;2008-11-08 12:26:54 +0000;added check for valid code on spiders
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40366

==

scrapy/trunk/scrapy/tests/test_load_spiders.py
==================
5e54ac52;Damian Canabal;2008-11-04 17:45:26 +0000;fixed new_response_from_xpaths function, unicode string was passed as body instead of ResponseBody object
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40365

==

scrapy/trunk/scrapy/utils/response.py
==================
a2461fbe;elpolilla;2008-11-04 14:06:28 +0000;Wrong attribute assignation fixed again
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40364

==

scrapy/trunk/scrapy/item/models.py
==================
224d3c51;elpolilla;2008-11-04 13:27:31 +0000;Bugfix in parse command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40363

==

scrapy/trunk/scrapy/command/commands/parse.py
scrapy/trunk/scrapy/contrib/spiders.py
==================
5bad7983;elpolilla;2008-11-04 11:26:23 +0000;Fixed bad checking while setting attributes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40362

==

scrapy/trunk/scrapy/item/models.py
==================
bd38a312;elpolilla;2008-11-04 10:57:59 +0000;- Fixed bug in attributes assignation (empty attributes being set) - Added GUID setting to FeedSpider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40361

==

scrapy/trunk/scrapy/contrib/spiders.py
scrapy/trunk/scrapy/item/models.py
==================
9b46c20d;samus_;2008-11-03 16:10:43 +0000;moved xpathselector_iternodes from scrapy.utils.xml to scrapy.utils.iterators and renamed it to "xmliter", also renamed csv_iter to csviter and added tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40360

==

scrapy/trunk/scrapy/contrib/spiders.py
scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample3.csv
scrapy/trunk/scrapy/tests/test_utils_iterators.py
scrapy/trunk/scrapy/tests/test_utils_xml.py
scrapy/trunk/scrapy/utils/iterators.py
scrapy/trunk/scrapy/utils/xml.py
==================
1ef65b97;elpolilla;2008-11-03 14:00:33 +0000;Fixed typo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40359

==

scrapy/trunk/scrapy/contrib/spiders.py
==================
1a45754c;elpolilla;2008-11-03 13:57:21 +0000;Removed an out-of-scrapy reference in the BasicSpider
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40358

==

scrapy/trunk/scrapy/contrib/spiders.py
==================
bc13a592;elpolilla;2008-11-03 12:28:00 +0000;Removed ugly loading of string codecs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40357

==

scrapy/trunk/scrapy/contrib/codecs/__init__.py
scrapy/trunk/scrapy/contrib/codecs/x_mac_roman.py
scrapy/trunk/scrapy/core/engine.py
==================
defcb451;elpolilla;2008-11-03 11:48:43 +0000;Implemented CrawlSpider and XMLFeedSpider classes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40356

==

scrapy/trunk/scrapy/command/commands/parse.py
scrapy/trunk/scrapy/contrib/spiders.py
==================
f2bab509;elpolilla;2008-11-03 11:02:58 +0000;- Fixed bad implementation of the SetGUIDPipeline - Modified item's attribute method to have an optional 'add' argument - Renamed normalize_urls adaptor to canonicalize_urls
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40355

==

scrapy/trunk/scrapy/contrib/adaptors/__init__.py
scrapy/trunk/scrapy/contrib/adaptors/misc.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/xpath/selector.py
==================
776818db;elpolilla;2008-11-03 10:43:40 +0000;Little change in test spider that broke the engine test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40354

==

scrapy/trunk/scrapy/tests/test_spiders/testplugin.py
==================
0574bbd4;elpolilla;2008-11-03 10:24:50 +0000;Added some improvements to LinkExtractor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40353

==

scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/link/extractors.py
scrapy/trunk/scrapy/tests/test_link.py
==================
6a2e288f;elpolilla;2008-10-31 11:52:35 +0000;Added support for x-mac-roman string codec
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40352

==

scrapy/trunk/scrapy/contrib/codecs/__init__.py
scrapy/trunk/scrapy/contrib/codecs/x_mac_roman.py
scrapy/trunk/scrapy/core/engine.py
==================
9882679b;elpolilla;2008-10-29 02:25:32 +0000;Bugfix in ExtractImages adaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40351

==

scrapy/trunk/scrapy/contrib/adaptors/extraction.py
==================
d61cd607;elpolilla;2008-10-29 01:35:23 +0000;Moved SetGUIDPipeline to contrib/item because it was unnecesary to put it on an exclusive module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40350

==

scrapy/trunk/scrapy/contrib/item/__init__.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/contrib/pipeline/setguid.py
==================
c73dc5ad;elpolilla;2008-10-29 01:28:04 +0000;Added normalize_urls adaptor, which was mentioned in the previous changeset, but not actually commited
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40349

==

scrapy/trunk/scrapy/contrib/adaptors/misc.py
==================
377bea49;elpolilla;2008-10-29 01:25:59 +0000;- Added SetGUIDPipeline and the guid generation helper for the BasicSpider - Fixed some issues with BasicSpider - Added a normalize_url adaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40348

==

scrapy/trunk/scrapy/contrib/adaptors/extraction.py
scrapy/trunk/scrapy/contrib/pipeline/setguid.py
scrapy/trunk/scrapy/contrib/spiders.py
scrapy/trunk/scrapy/utils/misc.py
==================
4288cb3f;elpolilla;2008-10-27 11:58:56 +0000;- Removed AdaptorFunc objects - Changed "AdaptorPipe" to "AdaptorDict" - Moved adaptors to contrib/adaptors - Fixed some tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40347

==

scrapy/trunk/scrapy/contrib/adaptors/__init__.py
scrapy/trunk/scrapy/contrib/adaptors/extraction.py
scrapy/trunk/scrapy/contrib/adaptors/markup.py
scrapy/trunk/scrapy/contrib/adaptors/misc.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/tests/test_adaptors.py
==================
ed98a842;Pablo Hoffman;2008-10-27 11:20:32 +0000;item sampler: added ITEMSAMPLER_MAX_RESPONSE_SIZE support, keeping only the first item scraped (in spidermiddleware)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40346

==

scrapy/trunk/scrapy/contrib/itemsampler.py
==================
1b4d4132;Pablo Hoffman;2008-10-27 03:39:11 +0000;added note for debian distros
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40345

==

scrapy/trunk/INSTALL
==================
f4dab4eb;Pablo Hoffman;2008-10-27 03:38:03 +0000;added ItemSamplerPipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40344

==

scrapy/trunk/scrapy/contrib/itemsampler.py
==================
968a55ea;Pablo Hoffman;2008-10-27 01:24:19 +0000;improved RequestLimitMiddleware to conform to better programming standards
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40343

==

scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
==================
23524ccc;Pablo Hoffman;2008-10-24 03:42:05 +0000;ScrapedItem cannot have a constructor that receives the adaptor_pipe. adaptor_pipe must be assigned by calling set_adaptors() from the outside (typically in a spider)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40342

==

scrapy/trunk/scrapy/item/models.py
==================
ebe847bc;elpolilla;2008-10-24 00:37:51 +0000;Activated adaptor pipeline creation at items __init__
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40341

==

scrapy/trunk/scrapy/item/models.py
==================
42e6ed74;elpolilla;2008-10-24 00:29:27 +0000;Modified some code to avoid problems with the _adaptor_pipe attribute and the replays, or with the item themselves
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40340

==

scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/item/__init__.py
scrapy/trunk/scrapy/replay/__init__.py
==================
06c25096;elpolilla;2008-10-24 00:20:14 +0000;Improved adaptors code and fixed some tests related with that
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40339

==

scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/tests/test_adaptors.py
==================
91ddfd6f;Pablo Hoffman;2008-10-23 12:44:24 +0000;removed debugging code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40338

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/manager.py
==================
ce3bbd1a;Pablo Hoffman;2008-10-23 12:43:31 +0000;enabled unsafeTracebacks to master for sending full tracebacks to workers, splitted master scheduled() method in 2 methods: schedule() and reschedule()
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40337

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/manager.py
==================
215151dd;Pablo Hoffman;2008-10-23 12:41:49 +0000;improved worker error logging for communication with master
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40336

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
==================
005044b0;Pablo Hoffman;2008-10-23 11:39:03 +0000;web console: added support for logging to a different file using WEBCONSOLE_LOGFILE setting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40335

==

scrapy/trunk/scrapy/management/web.py
==================
874ac0c2;Pablo Hoffman;2008-10-23 04:44:40 +0000;changes to logging and DEFAULT_PRIORITY removed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40334

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/manager.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/web.py
==================
52596f35;Pablo Hoffman;2008-10-23 04:43:41 +0000;some more fixes to cluster worker
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40333

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
==================
3e1ad8d6;Pablo Hoffman;2008-10-23 04:00:13 +0000;removed commas from log messages
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40332

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
==================
928112a9;Pablo Hoffman;2008-10-23 01:26:48 +0000;added ResponseCode class to contain all response codes, and other assorted code improvements
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40331

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/manager.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/web.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
==================
4b03435c;Pablo Hoffman;2008-10-23 01:15:37 +0000;enabled unsafeTracebacks in worker to send full tracebacks to master
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40330

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
==================
c913d6ff;Pablo Hoffman;2008-10-23 00:37:08 +0000;added generic pre-run hooks to cluster workers to deocuple pysvn from worker code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40329

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/hooks/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/hooks/svn.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
==================
f7275f6b;Pablo Hoffman;2008-10-22 17:23:30 +0000;made charset=utf8 by default in mysql_connect
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40328

==

scrapy/trunk/scrapy/utils/db.py
==================
57848d46;Pablo Hoffman;2008-10-22 17:14:07 +0000;updated test-worker script and moved to tools
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40327

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/tools/test-worker.py
==================
1c742607;Pablo Hoffman;2008-10-22 16:11:47 +0000;fixed bug with process manager status() method
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40326

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
==================
21c08e39;Pablo Hoffman;2008-10-22 15:20:12 +0000;added cluster master connection log message to cluster worker
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40325

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
==================
150f4ed8;Pablo Hoffman;2008-10-22 14:43:34 +0000;scrapy cluster: added missing docstrings to important methods, fixed some bugs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40324

==

scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/crawler/manager.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/manager.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/web.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
==================
5349030b;Pablo Hoffman;2008-10-22 13:44:02 +0000;creating cluster-refactor branch to fix several deficiences that the current cluster code has
--HG--
rename : scrapy/trunk/INSTALL => scrapy/branches/cluster-refactor/INSTALL
rename : scrapy/trunk/README => scrapy/branches/cluster-refactor/README
rename : scrapy/trunk/docs/scrapy-architecture.dia => scrapy/branches/cluster-refactor/docs/scrapy-architecture.dia
rename : scrapy/trunk/extras/sql/scraping.sql => scrapy/branches/cluster-refactor/extras/sql/scraping.sql
rename : scrapy/trunk/scrapy/__init__.py => scrapy/branches/cluster-refactor/scrapy/__init__.py
rename : scrapy/trunk/scrapy/bin/scrapy-admin.py => scrapy/branches/cluster-refactor/scrapy/bin/scrapy-admin.py
rename : scrapy/trunk/scrapy/command/__init__.py => scrapy/branches/cluster-refactor/scrapy/command/__init__.py
rename : scrapy/trunk/scrapy/command/cmdline.py => scrapy/branches/cluster-refactor/scrapy/command/cmdline.py
rename : scrapy/trunk/scrapy/command/commands/__init__.py => scrapy/branches/cluster-refactor/scrapy/command/commands/__init__.py
rename : scrapy/trunk/scrapy/command/commands/crawl.py => scrapy/branches/cluster-refactor/scrapy/command/commands/crawl.py
rename : scrapy/trunk/scrapy/command/commands/download.py => scrapy/branches/cluster-refactor/scrapy/command/commands/download.py
rename : scrapy/trunk/scrapy/command/commands/genspider.py => scrapy/branches/cluster-refactor/scrapy/command/commands/genspider.py
rename : scrapy/trunk/scrapy/command/commands/getattr.py => scrapy/branches/cluster-refactor/scrapy/command/commands/getattr.py
rename : scrapy/trunk/scrapy/command/commands/help.py => scrapy/branches/cluster-refactor/scrapy/command/commands/help.py
rename : scrapy/trunk/scrapy/command/commands/list.py => scrapy/branches/cluster-refactor/scrapy/command/commands/list.py
rename : scrapy/trunk/scrapy/command/commands/log.py => scrapy/branches/cluster-refactor/scrapy/command/commands/log.py
rename : scrapy/trunk/scrapy/command/commands/parse.py => scrapy/branches/cluster-refactor/scrapy/command/commands/parse.py
rename : scrapy/trunk/scrapy/command/commands/replay.py => scrapy/branches/cluster-refactor/scrapy/command/commands/replay.py
rename : scrapy/trunk/scrapy/command/commands/shell.py => scrapy/branches/cluster-refactor/scrapy/command/commands/shell.py
rename : scrapy/trunk/scrapy/command/commands/start.py => scrapy/branches/cluster-refactor/scrapy/command/commands/start.py
rename : scrapy/trunk/scrapy/command/commands/stats.py => scrapy/branches/cluster-refactor/scrapy/command/commands/stats.py
rename : scrapy/trunk/scrapy/command/models.py => scrapy/branches/cluster-refactor/scrapy/command/models.py
rename : scrapy/trunk/scrapy/conf/__init__.py => scrapy/branches/cluster-refactor/scrapy/conf/__init__.py
rename : scrapy/trunk/scrapy/conf/commands/__init__.py => scrapy/branches/cluster-refactor/scrapy/conf/commands/__init__.py
rename : scrapy/trunk/scrapy/conf/commands/crawl.py => scrapy/branches/cluster-refactor/scrapy/conf/commands/crawl.py
rename : scrapy/trunk/scrapy/conf/commands/help.py => scrapy/branches/cluster-refactor/scrapy/conf/commands/help.py
rename : scrapy/trunk/scrapy/conf/commands/list.py => scrapy/branches/cluster-refactor/scrapy/conf/commands/list.py
rename : scrapy/trunk/scrapy/conf/commands/log.py => scrapy/branches/cluster-refactor/scrapy/conf/commands/log.py
rename : scrapy/trunk/scrapy/conf/commands/scrape.py => scrapy/branches/cluster-refactor/scrapy/conf/commands/scrape.py
rename : scrapy/trunk/scrapy/conf/commands/stats.py => scrapy/branches/cluster-refactor/scrapy/conf/commands/stats.py
rename : scrapy/trunk/scrapy/conf/commands/test.py => scrapy/branches/cluster-refactor/scrapy/conf/commands/test.py
rename : scrapy/trunk/scrapy/conf/core_settings.py => scrapy/branches/cluster-refactor/scrapy/conf/core_settings.py
rename : scrapy/trunk/scrapy/conf/project_template/__init__.py => scrapy/branches/cluster-refactor/scrapy/conf/project_template/__init__.py
rename : scrapy/trunk/scrapy/conf/project_template/items.py => scrapy/branches/cluster-refactor/scrapy/conf/project_template/items.py
rename : scrapy/trunk/scrapy/conf/project_template/scrapy-ctl.py => scrapy/branches/cluster-refactor/scrapy/conf/project_template/scrapy-ctl.py
rename : scrapy/trunk/scrapy/conf/project_template/scrapy_settings.py => scrapy/branches/cluster-refactor/scrapy/conf/project_template/scrapy_settings.py
rename : scrapy/trunk/scrapy/conf/project_template/spiders/__init__.py => scrapy/branches/cluster-refactor/scrapy/conf/project_template/spiders/__init__.py
rename : scrapy/trunk/scrapy/contrib/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/__init__.py
rename : scrapy/trunk/scrapy/contrib/adaptorpipeline.py => scrapy/branches/cluster-refactor/scrapy/contrib/adaptorpipeline.py
rename : scrapy/trunk/scrapy/contrib/closedomain.py => scrapy/branches/cluster-refactor/scrapy/contrib/closedomain.py
rename : scrapy/trunk/scrapy/contrib/debug.py => scrapy/branches/cluster-refactor/scrapy/contrib/debug.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/__init__.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/cache.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/common.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/common.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/compression.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/compression.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/cookies.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/cookies.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/debug.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/debug.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/errorpages.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/errorpages.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/httpauth.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/httpauth.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/redirect.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/retry.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/robots.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/robots.py
rename : scrapy/trunk/scrapy/contrib/downloadermiddleware/useragent.py => scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/useragent.py
rename : scrapy/trunk/scrapy/contrib/groupsettings.py => scrapy/branches/cluster-refactor/scrapy/contrib/groupsettings.py
rename : scrapy/trunk/scrapy/contrib/history/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/history/__init__.py
rename : scrapy/trunk/scrapy/contrib/history/history.py => scrapy/branches/cluster-refactor/scrapy/contrib/history/history.py
rename : scrapy/trunk/scrapy/contrib/history/middleware.py => scrapy/branches/cluster-refactor/scrapy/contrib/history/middleware.py
rename : scrapy/trunk/scrapy/contrib/history/scheduler.py => scrapy/branches/cluster-refactor/scrapy/contrib/history/scheduler.py
rename : scrapy/trunk/scrapy/contrib/history/store.py => scrapy/branches/cluster-refactor/scrapy/contrib/history/store.py
rename : scrapy/trunk/scrapy/contrib/item/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/item/__init__.py
rename : scrapy/trunk/scrapy/contrib/item/models.py => scrapy/branches/cluster-refactor/scrapy/contrib/item/models.py
rename : scrapy/trunk/scrapy/contrib/memdebug.py => scrapy/branches/cluster-refactor/scrapy/contrib/memdebug.py
rename : scrapy/trunk/scrapy/contrib/memusage.py => scrapy/branches/cluster-refactor/scrapy/contrib/memusage.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/__init__.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/crawler/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/crawler/__init__.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/crawler/manager.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/crawler/manager.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/master/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/__init__.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/manager.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/master/web.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/web.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/ws_api.txt
rename : scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/worker/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/__init__.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
rename : scrapy/trunk/scrapy/contrib/pbcluster/worker/testworker.py => scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/testworker.py
rename : scrapy/trunk/scrapy/contrib/pipeline/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/__init__.py
rename : scrapy/trunk/scrapy/contrib/pipeline/images.py => scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/images.py
rename : scrapy/trunk/scrapy/contrib/pipeline/media.py => scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/media.py
rename : scrapy/trunk/scrapy/contrib/pipeline/s3images.py => scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/s3images.py
rename : scrapy/trunk/scrapy/contrib/pipeline/shoveitem.py => scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/shoveitem.py
rename : scrapy/trunk/scrapy/contrib/pipeline/show.py => scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/show.py
rename : scrapy/trunk/scrapy/contrib/prioritizers.py => scrapy/branches/cluster-refactor/scrapy/contrib/prioritizers.py
rename : scrapy/trunk/scrapy/contrib/response/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/response/__init__.py
rename : scrapy/trunk/scrapy/contrib/response/soup.py => scrapy/branches/cluster-refactor/scrapy/contrib/response/soup.py
rename : scrapy/trunk/scrapy/contrib/spider/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/spider/__init__.py
rename : scrapy/trunk/scrapy/contrib/spider/profiler.py => scrapy/branches/cluster-refactor/scrapy/contrib/spider/profiler.py
rename : scrapy/trunk/scrapy/contrib/spider/reloader.py => scrapy/branches/cluster-refactor/scrapy/contrib/spider/reloader.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/__init__.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/depth.py => scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/depth.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py => scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/limit.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/offsite.py => scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/offsite.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/referer.py => scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/referer.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/restrict.py => scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/restrict.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/urlfilter.py => scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/urlfilter.py
rename : scrapy/trunk/scrapy/contrib/spidermiddleware/urllength.py => scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/urllength.py
rename : scrapy/trunk/scrapy/contrib/spiders.py => scrapy/branches/cluster-refactor/scrapy/contrib/spiders.py
rename : scrapy/trunk/scrapy/contrib/web/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/web/__init__.py
rename : scrapy/trunk/scrapy/contrib/web/http.py => scrapy/branches/cluster-refactor/scrapy/contrib/web/http.py
rename : scrapy/trunk/scrapy/contrib/web/json.py => scrapy/branches/cluster-refactor/scrapy/contrib/web/json.py
rename : scrapy/trunk/scrapy/contrib/web/service.py => scrapy/branches/cluster-refactor/scrapy/contrib/web/service.py
rename : scrapy/trunk/scrapy/contrib/web/site.py => scrapy/branches/cluster-refactor/scrapy/contrib/web/site.py
rename : scrapy/trunk/scrapy/contrib/web/stats.py => scrapy/branches/cluster-refactor/scrapy/contrib/web/stats.py
rename : scrapy/trunk/scrapy/contrib/webconsole/__init__.py => scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/__init__.py
rename : scrapy/trunk/scrapy/contrib/webconsole/enginestatus.py => scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/enginestatus.py
rename : scrapy/trunk/scrapy/contrib/webconsole/livestats.py => scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/livestats.py
rename : scrapy/trunk/scrapy/contrib/webconsole/schedstats.py => scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/schedstats.py
rename : scrapy/trunk/scrapy/contrib/webconsole/spiderctl.py => scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/spiderctl.py
rename : scrapy/trunk/scrapy/contrib/webconsole/spiderstats.py => scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/spiderstats.py
rename : scrapy/trunk/scrapy/contrib/webconsole/stats.py => scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/stats.py
rename : scrapy/trunk/scrapy/core/__init__.py => scrapy/branches/cluster-refactor/scrapy/core/__init__.py
rename : scrapy/trunk/scrapy/core/downloader/__init__.py => scrapy/branches/cluster-refactor/scrapy/core/downloader/__init__.py
rename : scrapy/trunk/scrapy/core/downloader/handlers.py => scrapy/branches/cluster-refactor/scrapy/core/downloader/handlers.py
rename : scrapy/trunk/scrapy/core/downloader/manager.py => scrapy/branches/cluster-refactor/scrapy/core/downloader/manager.py
rename : scrapy/trunk/scrapy/core/downloader/middleware.py => scrapy/branches/cluster-refactor/scrapy/core/downloader/middleware.py
rename : scrapy/trunk/scrapy/core/engine.py => scrapy/branches/cluster-refactor/scrapy/core/engine.py
rename : scrapy/trunk/scrapy/core/exceptions.py => scrapy/branches/cluster-refactor/scrapy/core/exceptions.py
rename : scrapy/trunk/scrapy/core/manager.py => scrapy/branches/cluster-refactor/scrapy/core/manager.py
rename : scrapy/trunk/scrapy/core/prioritizers.py => scrapy/branches/cluster-refactor/scrapy/core/prioritizers.py
rename : scrapy/trunk/scrapy/core/scheduler/__init__.py => scrapy/branches/cluster-refactor/scrapy/core/scheduler/__init__.py
rename : scrapy/trunk/scrapy/core/scheduler/filter.py => scrapy/branches/cluster-refactor/scrapy/core/scheduler/filter.py
rename : scrapy/trunk/scrapy/core/scheduler/schedulers.py => scrapy/branches/cluster-refactor/scrapy/core/scheduler/schedulers.py
rename : scrapy/trunk/scrapy/core/scheduler/store.py => scrapy/branches/cluster-refactor/scrapy/core/scheduler/store.py
rename : scrapy/trunk/scrapy/core/signals.py => scrapy/branches/cluster-refactor/scrapy/core/signals.py
rename : scrapy/trunk/scrapy/extension/__init__.py => scrapy/branches/cluster-refactor/scrapy/extension/__init__.py
rename : scrapy/trunk/scrapy/fetcher/__init__.py => scrapy/branches/cluster-refactor/scrapy/fetcher/__init__.py
rename : scrapy/trunk/scrapy/http/__init__.py => scrapy/branches/cluster-refactor/scrapy/http/__init__.py
rename : scrapy/trunk/scrapy/http/headers.py => scrapy/branches/cluster-refactor/scrapy/http/headers.py
rename : scrapy/trunk/scrapy/http/request.py => scrapy/branches/cluster-refactor/scrapy/http/request.py
rename : scrapy/trunk/scrapy/http/response.py => scrapy/branches/cluster-refactor/scrapy/http/response.py
rename : scrapy/trunk/scrapy/http/url.py => scrapy/branches/cluster-refactor/scrapy/http/url.py
rename : scrapy/trunk/scrapy/item/__init__.py => scrapy/branches/cluster-refactor/scrapy/item/__init__.py
rename : scrapy/trunk/scrapy/item/adaptors.py => scrapy/branches/cluster-refactor/scrapy/item/adaptors.py
rename : scrapy/trunk/scrapy/item/models.py => scrapy/branches/cluster-refactor/scrapy/item/models.py
rename : scrapy/trunk/scrapy/item/pipeline.py => scrapy/branches/cluster-refactor/scrapy/item/pipeline.py
rename : scrapy/trunk/scrapy/link/__init__.py => scrapy/branches/cluster-refactor/scrapy/link/__init__.py
rename : scrapy/trunk/scrapy/link/extractors.py => scrapy/branches/cluster-refactor/scrapy/link/extractors.py
rename : scrapy/trunk/scrapy/log/__init__.py => scrapy/branches/cluster-refactor/scrapy/log/__init__.py
rename : scrapy/trunk/scrapy/mail/__init__.py => scrapy/branches/cluster-refactor/scrapy/mail/__init__.py
rename : scrapy/trunk/scrapy/management/__init__.py => scrapy/branches/cluster-refactor/scrapy/management/__init__.py
rename : scrapy/trunk/scrapy/management/telnet.py => scrapy/branches/cluster-refactor/scrapy/management/telnet.py
rename : scrapy/trunk/scrapy/management/web.py => scrapy/branches/cluster-refactor/scrapy/management/web.py
rename : scrapy/trunk/scrapy/patches/__init__.py => scrapy/branches/cluster-refactor/scrapy/patches/__init__.py
rename : scrapy/trunk/scrapy/patches/monkeypatches.py => scrapy/branches/cluster-refactor/scrapy/patches/monkeypatches.py
rename : scrapy/trunk/scrapy/replay/__init__.py => scrapy/branches/cluster-refactor/scrapy/replay/__init__.py
rename : scrapy/trunk/scrapy/spider/__init__.py => scrapy/branches/cluster-refactor/scrapy/spider/__init__.py
rename : scrapy/trunk/scrapy/spider/manager.py => scrapy/branches/cluster-refactor/scrapy/spider/manager.py
rename : scrapy/trunk/scrapy/spider/middleware.py => scrapy/branches/cluster-refactor/scrapy/spider/middleware.py
rename : scrapy/trunk/scrapy/spider/models.py => scrapy/branches/cluster-refactor/scrapy/spider/models.py
rename : scrapy/trunk/scrapy/stats/__init__.py => scrapy/branches/cluster-refactor/scrapy/stats/__init__.py
rename : scrapy/trunk/scrapy/stats/corestats.py => scrapy/branches/cluster-refactor/scrapy/stats/corestats.py
rename : scrapy/trunk/scrapy/stats/statscollector.py => scrapy/branches/cluster-refactor/scrapy/stats/statscollector.py
rename : scrapy/trunk/scrapy/store/__init__.py => scrapy/branches/cluster-refactor/scrapy/store/__init__.py
rename : scrapy/trunk/scrapy/store/db.py => scrapy/branches/cluster-refactor/scrapy/store/db.py
rename : scrapy/trunk/scrapy/tests/__init__.py => scrapy/branches/cluster-refactor/scrapy/tests/__init__.py
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.tar => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.tar
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.xml
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml.bz2 => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.xml.bz2
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml.gz => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.xml.gz
rename : scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.zip => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.zip
rename : scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample1.xml => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/feeds/feed-sample1.xml
rename : scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample2.xml => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/feeds/feed-sample2.xml
rename : scrapy/trunk/scrapy/tests/sample_data/test_site/index.html => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/test_site/index.html
rename : scrapy/trunk/scrapy/tests/sample_data/test_site/item1.html => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/test_site/item1.html
rename : scrapy/trunk/scrapy/tests/sample_data/test_site/item2.html => scrapy/branches/cluster-refactor/scrapy/tests/sample_data/test_site/item2.html
rename : scrapy/trunk/scrapy/tests/test_adaptors.py => scrapy/branches/cluster-refactor/scrapy/tests/test_adaptors.py
rename : scrapy/trunk/scrapy/tests/test_c14nurls.py => scrapy/branches/cluster-refactor/scrapy/tests/test_c14nurls.py
rename : scrapy/trunk/scrapy/tests/test_decompress.py => scrapy/branches/cluster-refactor/scrapy/tests/test_decompress.py
rename : scrapy/trunk/scrapy/tests/test_defaultencoding.py => scrapy/branches/cluster-refactor/scrapy/tests/test_defaultencoding.py
rename : scrapy/trunk/scrapy/tests/test_dependencies.py => scrapy/branches/cluster-refactor/scrapy/tests/test_dependencies.py
rename : scrapy/trunk/scrapy/tests/test_engine.py => scrapy/branches/cluster-refactor/scrapy/tests/test_engine.py
rename : scrapy/trunk/scrapy/tests/test_http_request.py => scrapy/branches/cluster-refactor/scrapy/tests/test_http_request.py
rename : scrapy/trunk/scrapy/tests/test_http_response.py => scrapy/branches/cluster-refactor/scrapy/tests/test_http_response.py
rename : scrapy/trunk/scrapy/tests/test_http_url.py => scrapy/branches/cluster-refactor/scrapy/tests/test_http_url.py
rename : scrapy/trunk/scrapy/tests/test_libxml2.py => scrapy/branches/cluster-refactor/scrapy/tests/test_libxml2.py
rename : scrapy/trunk/scrapy/tests/test_link.py => scrapy/branches/cluster-refactor/scrapy/tests/test_link.py
rename : scrapy/trunk/scrapy/tests/test_pipeline_images.py => scrapy/branches/cluster-refactor/scrapy/tests/test_pipeline_images.py
rename : scrapy/trunk/scrapy/tests/test_serialization.py => scrapy/branches/cluster-refactor/scrapy/tests/test_serialization.py
rename : scrapy/trunk/scrapy/tests/test_spidermonkey.py => scrapy/branches/cluster-refactor/scrapy/tests/test_spidermonkey.py
rename : scrapy/trunk/scrapy/tests/test_spiders/__init__.py => scrapy/branches/cluster-refactor/scrapy/tests/test_spiders/__init__.py
rename : scrapy/trunk/scrapy/tests/test_spiders/testplugin.py => scrapy/branches/cluster-refactor/scrapy/tests/test_spiders/testplugin.py
rename : scrapy/trunk/scrapy/tests/test_stats.py => scrapy/branches/cluster-refactor/scrapy/tests/test_stats.py
rename : scrapy/trunk/scrapy/tests/test_storedb.py => scrapy/branches/cluster-refactor/scrapy/tests/test_storedb.py
rename : scrapy/trunk/scrapy/tests/test_utils_datatypes.py => scrapy/branches/cluster-refactor/scrapy/tests/test_utils_datatypes.py
rename : scrapy/trunk/scrapy/tests/test_utils_markup.py => scrapy/branches/cluster-refactor/scrapy/tests/test_utils_markup.py
rename : scrapy/trunk/scrapy/tests/test_utils_url.py => scrapy/branches/cluster-refactor/scrapy/tests/test_utils_url.py
rename : scrapy/trunk/scrapy/tests/test_utils_xml.py => scrapy/branches/cluster-refactor/scrapy/tests/test_utils_xml.py
rename : scrapy/trunk/scrapy/tests/test_xpath.py => scrapy/branches/cluster-refactor/scrapy/tests/test_xpath.py
rename : scrapy/trunk/scrapy/utils/__init__.py => scrapy/branches/cluster-refactor/scrapy/utils/__init__.py
rename : scrapy/trunk/scrapy/utils/c14n.py => scrapy/branches/cluster-refactor/scrapy/utils/c14n.py
rename : scrapy/trunk/scrapy/utils/datatypes.py => scrapy/branches/cluster-refactor/scrapy/utils/datatypes.py
rename : scrapy/trunk/scrapy/utils/db.py => scrapy/branches/cluster-refactor/scrapy/utils/db.py
rename : scrapy/trunk/scrapy/utils/decompressor.py => scrapy/branches/cluster-refactor/scrapy/utils/decompressor.py
rename : scrapy/trunk/scrapy/utils/defer.py => scrapy/branches/cluster-refactor/scrapy/utils/defer.py
rename : scrapy/trunk/scrapy/utils/display.py => scrapy/branches/cluster-refactor/scrapy/utils/display.py
rename : scrapy/trunk/scrapy/utils/iterators.py => scrapy/branches/cluster-refactor/scrapy/utils/iterators.py
rename : scrapy/trunk/scrapy/utils/markup.py => scrapy/branches/cluster-refactor/scrapy/utils/markup.py
rename : scrapy/trunk/scrapy/utils/misc.py => scrapy/branches/cluster-refactor/scrapy/utils/misc.py
rename : scrapy/trunk/scrapy/utils/python.py => scrapy/branches/cluster-refactor/scrapy/utils/python.py
rename : scrapy/trunk/scrapy/utils/response.py => scrapy/branches/cluster-refactor/scrapy/utils/response.py
rename : scrapy/trunk/scrapy/utils/serialization.py => scrapy/branches/cluster-refactor/scrapy/utils/serialization.py
rename : scrapy/trunk/scrapy/utils/url.py => scrapy/branches/cluster-refactor/scrapy/utils/url.py
rename : scrapy/trunk/scrapy/utils/xml.py => scrapy/branches/cluster-refactor/scrapy/utils/xml.py
rename : scrapy/trunk/scrapy/xlib/BeautifulSoup.py => scrapy/branches/cluster-refactor/scrapy/xlib/BeautifulSoup.py
rename : scrapy/trunk/scrapy/xlib/__init__.py => scrapy/branches/cluster-refactor/scrapy/xlib/__init__.py
rename : scrapy/trunk/scrapy/xlib/lrucache.py => scrapy/branches/cluster-refactor/scrapy/xlib/lrucache.py
rename : scrapy/trunk/scrapy/xlib/lsprofcalltree.py => scrapy/branches/cluster-refactor/scrapy/xlib/lsprofcalltree.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/__init__.py => scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/__init__.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/dispatcher.py => scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/dispatcher.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/errors.py => scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/errors.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/license.txt => scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/license.txt
rename : scrapy/trunk/scrapy/xlib/pydispatch/robust.py => scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/robust.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/robustapply.py => scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/robustapply.py
rename : scrapy/trunk/scrapy/xlib/pydispatch/saferef.py => scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/saferef.py
rename : scrapy/trunk/scrapy/xlib/spidermonkey/INSTALL.scrapy => scrapy/branches/cluster-refactor/scrapy/xlib/spidermonkey/INSTALL.scrapy
rename : scrapy/trunk/scrapy/xlib/spidermonkey/__init__.py => scrapy/branches/cluster-refactor/scrapy/xlib/spidermonkey/__init__.py
rename : scrapy/trunk/scrapy/xlib/spidermonkey/sm_settings.py => scrapy/branches/cluster-refactor/scrapy/xlib/spidermonkey/sm_settings.py
rename : scrapy/trunk/scrapy/xlib/spidermonkey/spidermonkey.py => scrapy/branches/cluster-refactor/scrapy/xlib/spidermonkey/spidermonkey.py
rename : scrapy/trunk/scrapy/xpath/__init__.py => scrapy/branches/cluster-refactor/scrapy/xpath/__init__.py
rename : scrapy/trunk/scrapy/xpath/constructors.py => scrapy/branches/cluster-refactor/scrapy/xpath/constructors.py
rename : scrapy/trunk/scrapy/xpath/document.py => scrapy/branches/cluster-refactor/scrapy/xpath/document.py
rename : scrapy/trunk/scrapy/xpath/extension.py => scrapy/branches/cluster-refactor/scrapy/xpath/extension.py
rename : scrapy/trunk/scrapy/xpath/selector.py => scrapy/branches/cluster-refactor/scrapy/xpath/selector.py
rename : scrapy/trunk/scrapy/xpath/types.py => scrapy/branches/cluster-refactor/scrapy/xpath/types.py
rename : scrapy/trunk/scripts/rpm-install.sh => scrapy/branches/cluster-refactor/scripts/rpm-install.sh
rename : scrapy/trunk/setup.cfg => scrapy/branches/cluster-refactor/setup.cfg
rename : scrapy/trunk/setup.py => scrapy/branches/cluster-refactor/setup.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40323

==

scrapy/branches/cluster-refactor/INSTALL
scrapy/branches/cluster-refactor/README
scrapy/branches/cluster-refactor/docs/scrapy-architecture.dia
scrapy/branches/cluster-refactor/extras/sql/scraping.sql
scrapy/branches/cluster-refactor/scrapy/__init__.py
scrapy/branches/cluster-refactor/scrapy/bin/scrapy-admin.py
scrapy/branches/cluster-refactor/scrapy/command/__init__.py
scrapy/branches/cluster-refactor/scrapy/command/cmdline.py
scrapy/branches/cluster-refactor/scrapy/command/commands/__init__.py
scrapy/branches/cluster-refactor/scrapy/command/commands/crawl.py
scrapy/branches/cluster-refactor/scrapy/command/commands/download.py
scrapy/branches/cluster-refactor/scrapy/command/commands/genspider.py
scrapy/branches/cluster-refactor/scrapy/command/commands/getattr.py
scrapy/branches/cluster-refactor/scrapy/command/commands/help.py
scrapy/branches/cluster-refactor/scrapy/command/commands/list.py
scrapy/branches/cluster-refactor/scrapy/command/commands/log.py
scrapy/branches/cluster-refactor/scrapy/command/commands/parse.py
scrapy/branches/cluster-refactor/scrapy/command/commands/replay.py
scrapy/branches/cluster-refactor/scrapy/command/commands/shell.py
scrapy/branches/cluster-refactor/scrapy/command/commands/start.py
scrapy/branches/cluster-refactor/scrapy/command/commands/stats.py
scrapy/branches/cluster-refactor/scrapy/command/models.py
scrapy/branches/cluster-refactor/scrapy/conf/__init__.py
scrapy/branches/cluster-refactor/scrapy/conf/commands/__init__.py
scrapy/branches/cluster-refactor/scrapy/conf/commands/crawl.py
scrapy/branches/cluster-refactor/scrapy/conf/commands/help.py
scrapy/branches/cluster-refactor/scrapy/conf/commands/list.py
scrapy/branches/cluster-refactor/scrapy/conf/commands/log.py
scrapy/branches/cluster-refactor/scrapy/conf/commands/scrape.py
scrapy/branches/cluster-refactor/scrapy/conf/commands/stats.py
scrapy/branches/cluster-refactor/scrapy/conf/commands/test.py
scrapy/branches/cluster-refactor/scrapy/conf/core_settings.py
scrapy/branches/cluster-refactor/scrapy/conf/project_template/__init__.py
scrapy/branches/cluster-refactor/scrapy/conf/project_template/items.py
scrapy/branches/cluster-refactor/scrapy/conf/project_template/scrapy-ctl.py
scrapy/branches/cluster-refactor/scrapy/conf/project_template/scrapy_settings.py
scrapy/branches/cluster-refactor/scrapy/conf/project_template/spiders/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/adaptorpipeline.py
scrapy/branches/cluster-refactor/scrapy/contrib/closedomain.py
scrapy/branches/cluster-refactor/scrapy/contrib/debug.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/cache.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/common.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/compression.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/cookies.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/debug.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/errorpages.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/retry.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/robots.py
scrapy/branches/cluster-refactor/scrapy/contrib/downloadermiddleware/useragent.py
scrapy/branches/cluster-refactor/scrapy/contrib/groupsettings.py
scrapy/branches/cluster-refactor/scrapy/contrib/history/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/history/history.py
scrapy/branches/cluster-refactor/scrapy/contrib/history/middleware.py
scrapy/branches/cluster-refactor/scrapy/contrib/history/scheduler.py
scrapy/branches/cluster-refactor/scrapy/contrib/history/store.py
scrapy/branches/cluster-refactor/scrapy/contrib/item/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/item/models.py
scrapy/branches/cluster-refactor/scrapy/contrib/memdebug.py
scrapy/branches/cluster-refactor/scrapy/contrib/memusage.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/crawler/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/crawler/manager.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/manager.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/web.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/master/ws_api.txt
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/manager.py
scrapy/branches/cluster-refactor/scrapy/contrib/pbcluster/worker/testworker.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/images.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/media.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/s3images.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/shoveitem.py
scrapy/branches/cluster-refactor/scrapy/contrib/pipeline/show.py
scrapy/branches/cluster-refactor/scrapy/contrib/prioritizers.py
scrapy/branches/cluster-refactor/scrapy/contrib/response/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/response/soup.py
scrapy/branches/cluster-refactor/scrapy/contrib/spider/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/spider/profiler.py
scrapy/branches/cluster-refactor/scrapy/contrib/spider/reloader.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/depth.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/limit.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/offsite.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/referer.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/restrict.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/urlfilter.py
scrapy/branches/cluster-refactor/scrapy/contrib/spidermiddleware/urllength.py
scrapy/branches/cluster-refactor/scrapy/contrib/spiders.py
scrapy/branches/cluster-refactor/scrapy/contrib/web/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/web/http.py
scrapy/branches/cluster-refactor/scrapy/contrib/web/json.py
scrapy/branches/cluster-refactor/scrapy/contrib/web/service.py
scrapy/branches/cluster-refactor/scrapy/contrib/web/site.py
scrapy/branches/cluster-refactor/scrapy/contrib/web/stats.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/__init__.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/enginestatus.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/livestats.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/schedstats.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/spiderctl.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/spiderstats.py
scrapy/branches/cluster-refactor/scrapy/contrib/webconsole/stats.py
scrapy/branches/cluster-refactor/scrapy/core/__init__.py
scrapy/branches/cluster-refactor/scrapy/core/downloader/__init__.py
scrapy/branches/cluster-refactor/scrapy/core/downloader/handlers.py
scrapy/branches/cluster-refactor/scrapy/core/downloader/manager.py
scrapy/branches/cluster-refactor/scrapy/core/downloader/middleware.py
scrapy/branches/cluster-refactor/scrapy/core/engine.py
scrapy/branches/cluster-refactor/scrapy/core/exceptions.py
scrapy/branches/cluster-refactor/scrapy/core/manager.py
scrapy/branches/cluster-refactor/scrapy/core/prioritizers.py
scrapy/branches/cluster-refactor/scrapy/core/scheduler/__init__.py
scrapy/branches/cluster-refactor/scrapy/core/scheduler/filter.py
scrapy/branches/cluster-refactor/scrapy/core/scheduler/schedulers.py
scrapy/branches/cluster-refactor/scrapy/core/scheduler/store.py
scrapy/branches/cluster-refactor/scrapy/core/signals.py
scrapy/branches/cluster-refactor/scrapy/extension/__init__.py
scrapy/branches/cluster-refactor/scrapy/fetcher/__init__.py
scrapy/branches/cluster-refactor/scrapy/http/__init__.py
scrapy/branches/cluster-refactor/scrapy/http/headers.py
scrapy/branches/cluster-refactor/scrapy/http/request.py
scrapy/branches/cluster-refactor/scrapy/http/response.py
scrapy/branches/cluster-refactor/scrapy/http/url.py
scrapy/branches/cluster-refactor/scrapy/item/__init__.py
scrapy/branches/cluster-refactor/scrapy/item/adaptors.py
scrapy/branches/cluster-refactor/scrapy/item/models.py
scrapy/branches/cluster-refactor/scrapy/item/pipeline.py
scrapy/branches/cluster-refactor/scrapy/link/__init__.py
scrapy/branches/cluster-refactor/scrapy/link/extractors.py
scrapy/branches/cluster-refactor/scrapy/log/__init__.py
scrapy/branches/cluster-refactor/scrapy/mail/__init__.py
scrapy/branches/cluster-refactor/scrapy/management/__init__.py
scrapy/branches/cluster-refactor/scrapy/management/telnet.py
scrapy/branches/cluster-refactor/scrapy/management/web.py
scrapy/branches/cluster-refactor/scrapy/patches/__init__.py
scrapy/branches/cluster-refactor/scrapy/patches/monkeypatches.py
scrapy/branches/cluster-refactor/scrapy/replay/__init__.py
scrapy/branches/cluster-refactor/scrapy/spider/__init__.py
scrapy/branches/cluster-refactor/scrapy/spider/manager.py
scrapy/branches/cluster-refactor/scrapy/spider/middleware.py
scrapy/branches/cluster-refactor/scrapy/spider/models.py
scrapy/branches/cluster-refactor/scrapy/stats/__init__.py
scrapy/branches/cluster-refactor/scrapy/stats/corestats.py
scrapy/branches/cluster-refactor/scrapy/stats/statscollector.py
scrapy/branches/cluster-refactor/scrapy/store/__init__.py
scrapy/branches/cluster-refactor/scrapy/store/db.py
scrapy/branches/cluster-refactor/scrapy/tests/__init__.py
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.tar
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.xml
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.xml.bz2
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.xml.gz
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/compressed/feed-sample1.zip
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/feeds/feed-sample1.xml
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/feeds/feed-sample2.xml
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/test_site/index.html
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/test_site/item1.html
scrapy/branches/cluster-refactor/scrapy/tests/sample_data/test_site/item2.html
scrapy/branches/cluster-refactor/scrapy/tests/test_adaptors.py
scrapy/branches/cluster-refactor/scrapy/tests/test_c14nurls.py
scrapy/branches/cluster-refactor/scrapy/tests/test_decompress.py
scrapy/branches/cluster-refactor/scrapy/tests/test_defaultencoding.py
scrapy/branches/cluster-refactor/scrapy/tests/test_dependencies.py
scrapy/branches/cluster-refactor/scrapy/tests/test_engine.py
scrapy/branches/cluster-refactor/scrapy/tests/test_http_request.py
scrapy/branches/cluster-refactor/scrapy/tests/test_http_response.py
scrapy/branches/cluster-refactor/scrapy/tests/test_http_url.py
scrapy/branches/cluster-refactor/scrapy/tests/test_libxml2.py
scrapy/branches/cluster-refactor/scrapy/tests/test_link.py
scrapy/branches/cluster-refactor/scrapy/tests/test_pipeline_images.py
scrapy/branches/cluster-refactor/scrapy/tests/test_serialization.py
scrapy/branches/cluster-refactor/scrapy/tests/test_spidermonkey.py
scrapy/branches/cluster-refactor/scrapy/tests/test_spiders/__init__.py
scrapy/branches/cluster-refactor/scrapy/tests/test_spiders/testplugin.py
scrapy/branches/cluster-refactor/scrapy/tests/test_stats.py
scrapy/branches/cluster-refactor/scrapy/tests/test_storedb.py
scrapy/branches/cluster-refactor/scrapy/tests/test_utils_datatypes.py
scrapy/branches/cluster-refactor/scrapy/tests/test_utils_markup.py
scrapy/branches/cluster-refactor/scrapy/tests/test_utils_url.py
scrapy/branches/cluster-refactor/scrapy/tests/test_utils_xml.py
scrapy/branches/cluster-refactor/scrapy/tests/test_xpath.py
scrapy/branches/cluster-refactor/scrapy/utils/__init__.py
scrapy/branches/cluster-refactor/scrapy/utils/c14n.py
scrapy/branches/cluster-refactor/scrapy/utils/datatypes.py
scrapy/branches/cluster-refactor/scrapy/utils/db.py
scrapy/branches/cluster-refactor/scrapy/utils/decompressor.py
scrapy/branches/cluster-refactor/scrapy/utils/defer.py
scrapy/branches/cluster-refactor/scrapy/utils/display.py
scrapy/branches/cluster-refactor/scrapy/utils/iterators.py
scrapy/branches/cluster-refactor/scrapy/utils/markup.py
scrapy/branches/cluster-refactor/scrapy/utils/misc.py
scrapy/branches/cluster-refactor/scrapy/utils/python.py
scrapy/branches/cluster-refactor/scrapy/utils/response.py
scrapy/branches/cluster-refactor/scrapy/utils/serialization.py
scrapy/branches/cluster-refactor/scrapy/utils/url.py
scrapy/branches/cluster-refactor/scrapy/utils/xml.py
scrapy/branches/cluster-refactor/scrapy/xlib/BeautifulSoup.py
scrapy/branches/cluster-refactor/scrapy/xlib/__init__.py
scrapy/branches/cluster-refactor/scrapy/xlib/lrucache.py
scrapy/branches/cluster-refactor/scrapy/xlib/lsprofcalltree.py
scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/__init__.py
scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/dispatcher.py
scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/errors.py
scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/license.txt
scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/robust.py
scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/robustapply.py
scrapy/branches/cluster-refactor/scrapy/xlib/pydispatch/saferef.py
scrapy/branches/cluster-refactor/scrapy/xlib/spidermonkey/INSTALL.scrapy
scrapy/branches/cluster-refactor/scrapy/xlib/spidermonkey/__init__.py
scrapy/branches/cluster-refactor/scrapy/xlib/spidermonkey/sm_settings.py
scrapy/branches/cluster-refactor/scrapy/xlib/spidermonkey/spidermonkey.py
scrapy/branches/cluster-refactor/scrapy/xpath/__init__.py
scrapy/branches/cluster-refactor/scrapy/xpath/constructors.py
scrapy/branches/cluster-refactor/scrapy/xpath/document.py
scrapy/branches/cluster-refactor/scrapy/xpath/extension.py
scrapy/branches/cluster-refactor/scrapy/xpath/selector.py
scrapy/branches/cluster-refactor/scrapy/xpath/types.py
scrapy/branches/cluster-refactor/scripts/rpm-install.sh
scrapy/branches/cluster-refactor/setup.cfg
scrapy/branches/cluster-refactor/setup.py
==================
00f28e3e;Pablo Hoffman;2008-10-22 13:13:58 +0000;using cPickle instead of pickle
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40322

==

scrapy/trunk/scrapy/conf/__init__.py
scrapy/trunk/scrapy/store/db.py
==================
52ee3781;Pablo Hoffman;2008-10-21 00:42:25 +0000;cleaned some code for code reusage
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40321

==

scrapy/trunk/scrapy/contrib/web/json.py
scrapy/trunk/scrapy/contrib/web/service.py
==================
4ede33a4;elpolilla;2008-10-20 13:35:23 +0000;Fixed some bugs in the single attributes pipeline generator
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40320

==

scrapy/trunk/scrapy/item/adaptors.py
==================
5fddea58;samus_;2008-10-17 21:53:40 +0000;created csv iterator to replace CSVParser iteration facilities
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40319

==

scrapy/trunk/scrapy/utils/iterators.py
==================
1146e180;Pablo Hoffman;2008-10-17 14:54:36 +0000;added S3ImagesPipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40318

==

scrapy/trunk/scrapy/contrib/pipeline/s3images.py
==================
125414c1;elpolilla;2008-10-16 14:42:51 +0000;Added some basic tests for the ImagePipeline (although there are a few missing yet)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40317

==

scrapy/trunk/scrapy/tests/test_pipeline_images.py
==================
3433272d;elpolilla;2008-10-16 13:29:23 +0000;- Added adaptors tests - Fixed some small bugs on a few adaptors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40316

==

scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/tests/test_adaptors.py
==================
0ed5978a;elpolilla;2008-10-13 14:30:51 +0000;Improved adaptors functionality: - Added many basic adaptors (like extract, extract_links, regex, etc.) - Added some basic pipelines (for single data, lists, urls, etc.) - Now XPathSelectors store the response with which they were created (if any)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40315

==

scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/xpath/selector.py
==================
e6f73c3d;olveyra;2008-10-09 18:59:32 +0000;removed rulengine and simpage code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40314

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/histogram.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/tagdepth.py
scrapy/trunk/scrapy/contrib/rulengine/__init__.py
scrapy/trunk/scrapy/contrib/rulengine/exceptions.py
scrapy/trunk/scrapy/contrib/rulengine/pipeline.py
scrapy/trunk/scrapy/contrib/rulengine/responseWrapper.py
==================
e9f39133;Pablo Hoffman;2008-10-07 14:31:24 +0000;changed TEST_DB setting to TEST_SCRAPING_DB
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40313

==

scrapy/trunk/scrapy/tests/test_storedb.py
==================
498cd3a3;Daniel Grana;2008-10-07 13:07:36 +0000;oops, missing import
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40312

==

scrapy/trunk/scrapy/tests/test_storedb.py
==================
0ae4a19e;Daniel Grana;2008-10-07 13:01:32 +0000;remove hardcoded user/password for testing storedb
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40311

==

scrapy/trunk/scrapy/tests/test_storedb.py
==================
fc782d5e;elpolilla;2008-10-06 17:12:33 +0000;Modified ItemDeltas to work with RobustScrapedItems instead of ScrapedItems
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40310

==

scrapy/trunk/scrapy/contrib/item/__init__.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/item/models.py
==================
05f4a26c;Andres Moreira;2008-10-06 11:58:11 +0000;Fixed bug for unicode support.The empty string ('') in some platforms is decoding as ascii, independently of the default encoding of python, changed to u''.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40309

==

scrapy/trunk/scrapy/utils/markup.py
==================
a309dfeb;elpolilla;2008-10-06 10:14:52 +0000;Added ItemDelta objects and modified replays to make use of them
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40308

==

scrapy/trunk/scrapy/command/commands/replay.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/item/models.py
==================
88597e3a;Pablo Hoffman;2008-10-06 03:23:28 +0000;removed unneeded DEFAULT_DATA_ENCODING and commented COMMANDS_MODULE in project template
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40307

==

scrapy/trunk/scrapy/conf/project_template/scrapy_settings.py
==================
d6cbaab6;Pablo Hoffman;2008-10-06 03:22:05 +0000;added setadaptors method to ScrapedItem, removed incorrect constructor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40306

==

scrapy/trunk/scrapy/item/models.py
==================
9c19316d;Pablo Hoffman;2008-10-06 02:36:39 +0000;removed unused imports and minor bug fix to media/image pipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40305

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
c7436480;samus_;2008-10-05 18:32:39 +0000;removing utf-16 xpathselector_iternodes testcase since the problem comes from UnicodeDammit's conversion meaning that the results of the test are misleading
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40304

==

scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample3.xml
scrapy/trunk/scrapy/tests/test_utils_xml.py
==================
8f80603a;Pablo Hoffman;2008-10-05 07:57:51 +0000;added RegexLinkExtractor in new scrapy.link.extractors module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40303

==

scrapy/trunk/scrapy/link/extractors.py
==================
c68c478a;Pablo Hoffman;2008-10-05 07:45:03 +0000;added scrapy.contrib.spiders module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40302

==

scrapy/trunk/scrapy/contrib/spiders.py
==================
7b2317d9;Pablo Hoffman;2008-10-05 07:39:26 +0000;added scrapy.utils.response module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40301

==

scrapy/trunk/scrapy/utils/response.py
==================
24df5d16;Pablo Hoffman;2008-10-05 07:37:21 +0000;improved scrapy-admin.py script and default project template
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40300

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
scrapy/trunk/scrapy/conf/project_template/__init__.py
scrapy/trunk/scrapy/conf/project_template/items.py
scrapy/trunk/scrapy/conf/project_template/scrapy-ctl.py
scrapy/trunk/scrapy/conf/project_template/scrapy_settings.py
scrapy/trunk/scrapy/conf/project_template/spiders/__init__.py
scrapy/trunk/scrapy/templates/scrapy-ctl.tmpl
==================
8dc46c16;Pablo Hoffman;2008-10-05 07:35:58 +0000;removed old comment
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40299

==

scrapy/trunk/scrapy/spider/models.py
==================
acebe63d;Pablo Hoffman;2008-10-05 06:58:39 +0000;added __nonzero__ method to XPathSelector
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40298

==

scrapy/trunk/scrapy/xpath/selector.py
==================
ac4688da;Damian Canabal;2008-10-03 19:50:26 +0000;added NotSupported Exception
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40297

==

scrapy/trunk/scrapy/core/exceptions.py
==================
768a31a4;Andres Moreira;2008-10-03 14:37:25 +0000;Added test for utils/markup.py. Added support to unicode to the new markup functions. Changed some comments.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40296

==

scrapy/trunk/scrapy/tests/test_utils_markup.py
scrapy/trunk/scrapy/utils/markup.py
==================
453714b2;Andres Moreira;2008-10-03 11:57:51 +0000;Added new functions to parse html.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40295

==

scrapy/trunk/scrapy/utils/markup.py
==================
71c3cea1;Pablo Hoffman;2008-10-03 04:14:07 +0000;added another test for safe_url_string function
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40294

==

scrapy/trunk/scrapy/tests/test_utils_url.py
==================
e447044f;olveyra;2008-10-02 22:41:51 +0000;reverted an experimental code that should have been commited
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40293

==

scrapy/trunk/scrapy/core/manager.py
==================
1f4e484a;olveyra;2008-10-02 20:39:36 +0000;added DOWNLOAD_DELAY comment in settings template
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40292

==

scrapy/trunk/scrapy/templates/settings.tmpl
==================
58a419f4;olveyra;2008-10-02 19:59:51 +0000;added support for global DOWNLOAD_DELAY setting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40291

==

scrapy/trunk/scrapy/core/downloader/manager.py
==================
3ec47301;olveyra;2008-10-02 19:22:34 +0000;allow to directly specify which domain corresponds to a given request
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40290

==

scrapy/trunk/scrapy/core/manager.py
scrapy/trunk/scrapy/http/request.py
==================
98f3314b;Pablo Hoffman;2008-09-30 19:57:05 +0000;simplified test without loosing functionality
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40289

==

scrapy/trunk/scrapy/tests/test_utils_url.py
==================
9ba4573b;olveyra;2008-09-30 19:24:24 +0000;added test for r284
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40288

==

scrapy/trunk/scrapy/tests/test_utils_url.py
==================
c755f5a5;olveyra;2008-09-30 16:56:12 +0000;better management of some redirection loops.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40287

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
==================
433f35b4;olveyra;2008-09-30 16:19:20 +0000;small fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40286

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
==================
a38c72bb;olveyra;2008-09-30 14:15:23 +0000;safe_url_string should not escape unreserved marks (see RFC 2396, sec 2.3)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40285

==

scrapy/trunk/scrapy/utils/url.py
==================
3f32bae4;olveyra;2008-09-30 13:44:11 +0000;- copied original request to response.request in get_url method - deleted unused comment
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40284

==

scrapy/trunk/scrapy/command/commands/shell.py
==================
3ae4d62f;elpolilla;2008-09-29 18:14:28 +0000;- Added the posibility of knowing the decompressed response's format, in the decompression tool
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40283

==

scrapy/trunk/scrapy/utils/decompressor.py
==================
f8f2f3a5;Damian Canabal;2008-09-29 13:21:35 +0000;rolled back public ent_re to private and added a function has_entities instead
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40282

==

scrapy/trunk/scrapy/utils/markup.py
==================
ad00d5e6;Damian Canabal;2008-09-29 12:52:54 +0000;changed private html entity regex to public
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40281

==

scrapy/trunk/scrapy/utils/markup.py
==================
c07937c4;samus_;2008-09-25 12:49:19 +0000;added comment
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40280

==

scrapy/trunk/scrapy/http/response.py
==================
c4aa1e7e;samus_;2008-09-25 12:45:43 +0000;small fix to the regex
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40279

==

scrapy/trunk/scrapy/http/response.py
==================
555cb094;Daniel Grana;2008-09-25 12:22:31 +0000;images: use brief exception logging
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40278

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
==================
c73cbdd9;olveyra;2008-09-25 02:14:02 +0000;allow to override item class adaptor in constructor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40277

==

scrapy/trunk/scrapy/item/models.py
==================
79485ceb;samus_;2008-09-24 18:19:19 +0000;added support for xml-declared encodings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40276

==

scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/utils/misc.py
==================
a4b709e0;Damian Canabal;2008-09-24 12:40:55 +0000;added test for remove entities
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40275

==

scrapy/trunk/scrapy/tests/test_utils_markup.py
==================
4e7e539b;Damian Canabal;2008-09-24 12:25:10 +0000;html entities regexp improvement
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40274

==

scrapy/trunk/scrapy/utils/markup.py
==================
79be2ca9;Pablo Hoffman;2008-09-23 22:18:20 +0000;moved scrapy.core.log module to scrapy.log
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40273

==

scrapy/trunk/scrapy/command/cmdline.py
scrapy/trunk/scrapy/contrib/closedomain.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/debug.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/robots.py
scrapy/trunk/scrapy/contrib/history/middleware.py
scrapy/trunk/scrapy/contrib/history/scheduler.py
scrapy/trunk/scrapy/contrib/history/store.py
scrapy/trunk/scrapy/contrib/memusage.py
scrapy/trunk/scrapy/contrib/pbcluster/crawler/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
scrapy/trunk/scrapy/contrib/pipeline/images.py
scrapy/trunk/scrapy/contrib/pipeline/media.py
scrapy/trunk/scrapy/contrib/pipeline/show.py
scrapy/trunk/scrapy/contrib/rulengine/__init__.py
scrapy/trunk/scrapy/contrib/rulengine/pipeline.py
scrapy/trunk/scrapy/contrib/spider/reloader.py
scrapy/trunk/scrapy/contrib/spidermiddleware/depth.py
scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
scrapy/trunk/scrapy/contrib/spidermiddleware/offsite.py
scrapy/trunk/scrapy/contrib/spidermiddleware/referer.py
scrapy/trunk/scrapy/contrib/spidermiddleware/urllength.py
scrapy/trunk/scrapy/core/downloader/manager.py
scrapy/trunk/scrapy/core/downloader/middleware.py
scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/core/manager.py
scrapy/trunk/scrapy/core/scheduler/schedulers.py
scrapy/trunk/scrapy/core/signals.py
scrapy/trunk/scrapy/extension/__init__.py
scrapy/trunk/scrapy/item/pipeline.py
scrapy/trunk/scrapy/log/__init__.py
scrapy/trunk/scrapy/mail/__init__.py
scrapy/trunk/scrapy/replay/__init__.py
scrapy/trunk/scrapy/spider/manager.py
scrapy/trunk/scrapy/spider/middleware.py
scrapy/trunk/scrapy/stats/statscollector.py
scrapy/trunk/scrapy/utils/db.py
==================
fbec2b3a;Pablo Hoffman;2008-09-23 21:52:05 +0000;moved scrapy.core.mail module to scrapy.mail
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40272

==

scrapy/trunk/scrapy/contrib/closedomain.py
scrapy/trunk/scrapy/contrib/memdebug.py
scrapy/trunk/scrapy/contrib/memusage.py
scrapy/trunk/scrapy/mail/__init__.py
==================
cb8e0d9b;Pablo Hoffman;2008-09-23 21:48:48 +0000;added scrapy.utils.defer, moved deferred functions from scrapy.utils.misc to that module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40271

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
scrapy/trunk/scrapy/contrib/web/json.py
scrapy/trunk/scrapy/contrib/web/site.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/downloader/manager.py
scrapy/trunk/scrapy/core/downloader/middleware.py
scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/core/manager.py
scrapy/trunk/scrapy/core/scheduler/schedulers.py
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/item/pipeline.py
scrapy/trunk/scrapy/spider/middleware.py
scrapy/trunk/scrapy/utils/defer.py
scrapy/trunk/scrapy/utils/misc.py
==================
6637d8cf;Pablo Hoffman;2008-09-23 21:34:05 +0000;removed location_str function incorrectly added to this module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40270

==

scrapy/trunk/scrapy/utils/misc.py
==================
dbfc6341;samus_;2008-09-23 20:36:32 +0000;removed duplicated function convert_entity from scrapy.utils.misc
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40269

==

scrapy/trunk/scrapy/utils/misc.py
==================
4842fe06;german;2008-09-22 18:04:30 +0000;removed unquote_html
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40268

==

scrapy/trunk/scrapy/utils/misc.py
==================
2b6ed80a;Matias Aguirre;2008-09-19 20:00:08 +0000;Change site-media with static in css file
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40267

==

sites/scrapy.org/static/style/style.css
==================
e985b6c3;Matias Aguirre;2008-09-19 19:57:45 +0000;Comment blog templatetags calls
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40266

==

sites/scrapy.org/templates/base_home.html
==================
d3f66b7d;Matias Aguirre;2008-09-19 19:53:57 +0000;Remove blog url an installed app setting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40265

==

sites/scrapy.org/scrapyorg/settings.py
sites/scrapy.org/scrapyorg/urls.py
==================
bd28045b;Matias Aguirre;2008-09-19 19:19:28 +0000;Remove blog application which is not django 1.0
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40264

==

sites/scrapy.org/scrapyorg/blog/__init__.py
sites/scrapy.org/scrapyorg/blog/feeds.py
sites/scrapy.org/scrapyorg/blog/models.py
sites/scrapy.org/scrapyorg/blog/templatetags/__init__.py
sites/scrapy.org/scrapyorg/blog/templatetags/lastblogentry.py
sites/scrapy.org/scrapyorg/blog/urls.py
==================
4d388c94;Matias Aguirre;2008-09-19 19:17:41 +0000;Django 1.0 support over download application
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40263

==

sites/scrapy.org/scrapyorg/download/admin.py
sites/scrapy.org/scrapyorg/download/models.py
sites/scrapy.org/scrapyorg/urls.py
==================
62975817;Daniel Grana;2008-09-19 16:57:57 +0000;remove decobot reference and fix test_plugin
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40262

==

scrapy/trunk/scrapy/tests/test_spiders/testplugin.py
==================
baabdb00;Daniel Grana;2008-09-19 16:57:21 +0000;remove decobot reference
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40261

==

scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
==================
d87f979d;Daniel Grana;2008-09-19 15:21:47 +0000;grrr.. stupid bugfix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40260

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
c05dcdab;eduardo;2008-09-19 14:11:14 +0000;removed references to python2.5
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40259

==

scrapy/trunk/scripts/rpm-install.sh
scrapy/trunk/setup.cfg
==================
ddd7393a;olveyra;2008-09-19 12:50:19 +0000;reverted changeset 254
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40258

==

scrapy/trunk/scrapy/core/downloader/manager.py
==================
33246085;olveyra;2008-09-18 20:19:26 +0000;ouch! reverted a failed commit and now yes, removed an unneeded None
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40257

==

scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/downloader/manager.py
==================
133e9242;olveyra;2008-09-18 20:13:31 +0000;removed unneeded None
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40256

==

scrapy/trunk/scrapy/core/downloader/handlers.py
==================
6ce7ae4d;olveyra;2008-09-18 20:11:30 +0000;allow to set download delay as a scrapy setting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40255

==

scrapy/trunk/scrapy/core/downloader/manager.py
==================
cfb56e39;eduardo;2008-09-18 19:21:40 +0000;bump version
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40254

==

scrapy/trunk/setup.py
==================
c6d4a37a;eduardo;2008-09-18 17:48:35 +0000;include templates
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40253

==

scrapy/trunk/setup.py
==================
818d9baf;Daniel Grana;2008-09-18 16:08:33 +0000;new setup.py
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40252

==

scrapy/trunk/setup.py
==================
a85e5305;eduardo;2008-09-18 14:58:43 +0000;in the way of setuptooling
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40251

==

scrapy/trunk/scripts/rpm-install.sh
scrapy/trunk/setup.cfg
scrapy/trunk/setup.py
==================
93c31385;Daniel Grana;2008-09-17 12:34:48 +0000;use request.deferred for cached valued too
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40250

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
6f2d3619;Daniel Grana;2008-09-16 23:40:48 +0000;media: use deferred of request to allow adding callback from get_media_requests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40249

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
7932a8a5;Daniel Grana;2008-09-16 23:40:06 +0000;add image pipeline that stores and can thumbs images in different sizes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40248

==

scrapy/trunk/scrapy/contrib/pipeline/images.py
==================
4807f2eb;Daniel Grana;2008-09-16 23:39:26 +0000;move media_to_download hook to allow caching and prevent downloading
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40247

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
5048491f;Daniel Grana;2008-09-16 19:31:25 +0000;mediapipeline: change cache variable by domaininfo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40246

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
41a4f22c;Daniel Grana;2008-09-16 14:03:39 +0000;messy typo adding errback
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40245

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
e0d90f9d;anibal;2008-09-16 11:56:15 +0000;Scrapy architecture diagram 1st version, dia source
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40244

==

scrapy/trunk/docs/scrapy-architecture.dia
==================
0a7a5e5b;Pablo Hoffman;2008-09-16 11:30:22 +0000;added docs dir, guess for what? :)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40243

==
==================
b57148df;Pablo Hoffman;2008-09-15 15:37:44 +0000;renamed scrapy.lib to scrapy.xlib
--HG--
rename : scrapy/trunk/scrapy/lib/BeautifulSoup.py => scrapy/trunk/scrapy/xlib/BeautifulSoup.py
rename : scrapy/trunk/scrapy/lib/__init__.py => scrapy/trunk/scrapy/xlib/__init__.py
rename : scrapy/trunk/scrapy/lib/lrucache.py => scrapy/trunk/scrapy/xlib/lrucache.py
rename : scrapy/trunk/scrapy/lib/lsprofcalltree.py => scrapy/trunk/scrapy/xlib/lsprofcalltree.py
rename : scrapy/trunk/scrapy/lib/pydispatch/__init__.py => scrapy/trunk/scrapy/xlib/pydispatch/__init__.py
rename : scrapy/trunk/scrapy/lib/pydispatch/dispatcher.py => scrapy/trunk/scrapy/xlib/pydispatch/dispatcher.py
rename : scrapy/trunk/scrapy/lib/pydispatch/errors.py => scrapy/trunk/scrapy/xlib/pydispatch/errors.py
rename : scrapy/trunk/scrapy/lib/pydispatch/license.txt => scrapy/trunk/scrapy/xlib/pydispatch/license.txt
rename : scrapy/trunk/scrapy/lib/pydispatch/robust.py => scrapy/trunk/scrapy/xlib/pydispatch/robust.py
rename : scrapy/trunk/scrapy/lib/pydispatch/robustapply.py => scrapy/trunk/scrapy/xlib/pydispatch/robustapply.py
rename : scrapy/trunk/scrapy/lib/pydispatch/saferef.py => scrapy/trunk/scrapy/xlib/pydispatch/saferef.py
rename : scrapy/trunk/scrapy/lib/spidermonkey/INSTALL.scrapy => scrapy/trunk/scrapy/xlib/spidermonkey/INSTALL.scrapy
rename : scrapy/trunk/scrapy/lib/spidermonkey/__init__.py => scrapy/trunk/scrapy/xlib/spidermonkey/__init__.py
rename : scrapy/trunk/scrapy/lib/spidermonkey/sm_settings.py => scrapy/trunk/scrapy/xlib/spidermonkey/sm_settings.py
rename : scrapy/trunk/scrapy/lib/spidermonkey/spidermonkey.py => scrapy/trunk/scrapy/xlib/spidermonkey/spidermonkey.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40242

==

scrapy/trunk/scrapy/__init__.py
scrapy/trunk/scrapy/xlib/BeautifulSoup.py
scrapy/trunk/scrapy/xlib/__init__.py
scrapy/trunk/scrapy/xlib/lrucache.py
scrapy/trunk/scrapy/xlib/lsprofcalltree.py
scrapy/trunk/scrapy/xlib/pydispatch/__init__.py
scrapy/trunk/scrapy/xlib/pydispatch/dispatcher.py
scrapy/trunk/scrapy/xlib/pydispatch/errors.py
scrapy/trunk/scrapy/xlib/pydispatch/license.txt
scrapy/trunk/scrapy/xlib/pydispatch/robust.py
scrapy/trunk/scrapy/xlib/pydispatch/robustapply.py
scrapy/trunk/scrapy/xlib/pydispatch/saferef.py
scrapy/trunk/scrapy/xlib/spidermonkey/INSTALL.scrapy
scrapy/trunk/scrapy/xlib/spidermonkey/__init__.py
scrapy/trunk/scrapy/xlib/spidermonkey/sm_settings.py
scrapy/trunk/scrapy/xlib/spidermonkey/spidermonkey.py
==================
2cb300b9;Pablo Hoffman;2008-09-15 15:29:12 +0000;removed simplejson from scrapy code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40241

==

scrapy/trunk/INSTALL
scrapy/trunk/scrapy/lib/simplejson/__init__.py
scrapy/trunk/scrapy/lib/simplejson/_speedups.c
scrapy/trunk/scrapy/lib/simplejson/decoder.py
scrapy/trunk/scrapy/lib/simplejson/encoder.py
scrapy/trunk/scrapy/lib/simplejson/jsonfilter.py
scrapy/trunk/scrapy/lib/simplejson/scanner.py
scrapy/trunk/scrapy/lib/simplejson/tests/__init__.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_attacks.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_dump.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_fail.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_indent.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_pass1.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_pass2.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_pass3.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_recursion.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_separators.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_unicode.py
==================
08feb4df;Daniel Grana;2008-09-15 13:55:23 +0000;ername methods and enforce extraction of Request objects as item media to download
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40240

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
0090fcb0;Pablo Hoffman;2008-09-15 13:08:44 +0000;improved fix to support IE7 (thanks bill\!)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40239

==

sites/static.scrapy.org/css/trac.css
==================
d7a88e8d;Pablo Hoffman;2008-09-15 12:58:19 +0000;fixed hack for IE6
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40238

==

sites/static.scrapy.org/css/trac.css
==================
31d3b2cf;Pablo Hoffman;2008-09-15 12:56:31 +0000;added hack for IE6
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40237

==

sites/static.scrapy.org/css/trac.css
==================
49447623;Daniel Grana;2008-09-15 12:46:34 +0000;move bugtraps to avoid silence of bugs in media_downloaded or media_failed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40236

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
ca695c8c;Daniel Grana;2008-09-15 08:57:51 +0000;small bugfix and add bugtraps
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40235

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
6407a744;Daniel Grana;2008-09-15 08:27:15 +0000;remove item.image_urls from get_urls_from_item
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40234

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
af0808be;Daniel Grana;2008-09-15 07:08:27 +0000;add info object to public methods
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40233

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
4263c3a2;Daniel Grana;2008-09-15 06:01:40 +0000;Adds docstrings to public methods, remove unused imports, normalize urls to requests.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40232

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
31e497e5;Daniel Grana;2008-09-15 04:33:40 +0000;add media_to_download hook support, and return cached result if available
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40231

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
scrapy/trunk/scrapy/utils/misc.py
==================
df2f4b21;olveyra;2008-09-15 01:23:10 +0000;removed reference to guid (decobot specific) attribute in item pipeline logs
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40230

==

scrapy/trunk/scrapy/item/pipeline.py
==================
3803f676;Daniel Grana;2008-09-12 21:55:14 +0000;mediamiddleware: bugfixes and remove prints
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40229

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
2fd5cf64;olveyra;2008-09-12 20:48:48 +0000;- Support for not output in cluster status - schedule option by default does not have output
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40228

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
==================
d612701b;Daniel Grana;2008-09-12 19:58:45 +0000;add media pipeline skeleton
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40227

==

scrapy/trunk/scrapy/contrib/pipeline/media.py
==================
2dc20bb5;Andres Moreira;2008-09-11 16:35:50 +0000;Fixed condition of new option --quiet.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40226

==

scrapy/trunk/scrapy/command/commands/replay.py
==================
4cffc039;olveyra;2008-09-11 15:33:35 +0000;- leave in adaptors.py only the elemental adaptors pipeline code. - moved to contrib/adaptorpipeline the advanced adaptors pipeline code.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40225

==

scrapy/trunk/scrapy/contrib/adaptorpipeline.py
scrapy/trunk/scrapy/item/adaptors.py
==================
23814537;Andres Moreira;2008-09-11 14:59:16 +0000;Fixed bug in the total items count. Added new option --quiet to the action diff. This option doesn't show the report if there aren't differences.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40224

==

scrapy/trunk/scrapy/command/commands/replay.py
==================
2b6bcd61;elpolilla;2008-09-11 14:50:15 +0000;Small piece of code moved for not complying with conventions
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40223

==

scrapy/trunk/scrapy/tests/test_xpath.py
==================
06964cf3;elpolilla;2008-09-11 12:13:33 +0000;some small semantics errors fixed in xpath test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40222

==

scrapy/trunk/scrapy/tests/test_xpath.py
==================
d8b7f41e;elpolilla;2008-09-11 11:14:44 +0000;implemented extract_unquote method over xpath selectors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40221

==

scrapy/trunk/scrapy/tests/test_xpath.py
scrapy/trunk/scrapy/xpath/selector.py
==================
da7b8796;olveyra;2008-09-10 14:06:28 +0000;- AdaptorPipe compilation feature to resolve the problem of efficience and mantain the simplicity of the actual pipeline definition approach (for people that prefer to bore with lots of lines to define and edit a pipeline, they can edit directly the compiled version)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40220

==

scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
==================
789d8d35;elpolilla;2008-09-10 02:49:05 +0000;bugfix in decompressor tool
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40219

==

scrapy/trunk/scrapy/utils/decompressor.py
==================
ec710702;olveyra;2008-09-09 15:05:42 +0000;Added getd command, similar to get but first decompress the response. Based on decompressor tool.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40218

==

scrapy/trunk/scrapy/command/commands/shell.py
==================
543b9de9;elpolilla;2008-09-09 14:12:57 +0000;pylinted decompressor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40217

==

scrapy/trunk/scrapy/utils/decompressor.py
==================
b363f908;elpolilla;2008-09-09 14:10:15 +0000;decompressor tool improved
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40216

==

scrapy/trunk/scrapy/utils/decompressor.py
==================
98ac66f8;anibal;2008-09-09 14:10:00 +0000;Added more flexibility to childclasses who override gespider command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40215

==

scrapy/trunk/scrapy/command/commands/genspider.py
==================
eddc7b76;elpolilla;2008-09-09 13:02:49 +0000;added sample data for decompression tool's test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40214

==

scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.tar
scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml
scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml.bz2
scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.xml.gz
scrapy/trunk/scrapy/tests/sample_data/compressed/feed-sample1.zip
==================
7df63477;elpolilla;2008-09-09 12:56:01 +0000;added response decompression tool
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40213

==

scrapy/trunk/scrapy/tests/test_decompress.py
scrapy/trunk/scrapy/utils/decompressor.py
==================
3a298180;olveyra;2008-09-08 12:06:53 +0000;minor code fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40212

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
3fe36e77;olveyra;2008-09-06 17:03:47 +0000;Removed PRIORITY constants, added DEFAULT_PRIORITY setting
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40211

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
==================
8b09be86;olveyra;2008-09-05 21:51:53 +0000;adaptors with generic matching function
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40210

==

scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
==================
09b11a3a;Andres Moreira;2008-09-05 14:45:24 +0000;Added an histogram plot to simpages group to the report. Added quantities of html elements to symbol of the simhash. Now is more effective.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40209

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/histogram.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/tagdepth.py
==================
c2af3124;olveyra;2008-09-04 19:50:25 +0000;- added negative attribute name match
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40208

==

scrapy/trunk/scrapy/item/adaptors.py
==================
4e61f057;olveyra;2008-09-04 19:33:36 +0000;second security fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40207

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
51bdd694;olveyra;2008-09-04 19:11:53 +0000;- removed contrib/adaptors.py - display adaptor name when an exception raises inside the adaptor pipeline - add debug parameter to item attribute method to display input/output of each adaptor
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40206

==

scrapy/trunk/scrapy/contrib/adaptors.py
scrapy/trunk/scrapy/item/adaptors.py
==================
daf51203;olveyra;2008-09-04 18:15:45 +0000;security fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40205

==

scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
==================
f4f9626c;Andres Moreira;2008-09-03 19:11:52 +0000;Remove old code.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40204

==

scrapy/trunk/scrapy/contrib/rulengine/pipeline.py
==================
3cb1ab87;Andres Moreira;2008-09-03 19:06:34 +0000;Add rule engine to the framework. Rules are executed in a pipeline.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40203

==

scrapy/trunk/scrapy/contrib/rulengine/__init__.py
scrapy/trunk/scrapy/contrib/rulengine/exceptions.py
scrapy/trunk/scrapy/contrib/rulengine/pipeline.py
scrapy/trunk/scrapy/contrib/rulengine/responseWrapper.py
==================
1fa947dd;olveyra;2008-09-03 13:53:28 +0000;- Improved attribute name checks - added support to tuple definition of pipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40202

==

scrapy/trunk/scrapy/item/adaptors.py
==================
82a9fa9f;olveyra;2008-09-02 18:52:04 +0000;more efficient name attribute check in adaptors pipeline
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40201

==

scrapy/trunk/scrapy/item/adaptors.py
==================
6b16ee5e;olveyra;2008-09-02 17:39:22 +0000;- assure deferred_degenerate will take an iterable (bug raised when no spider middleware is enabled)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40200

==

scrapy/trunk/scrapy/utils/misc.py
==================
f54ba9f7;olveyra;2008-09-02 15:41:22 +0000;removed unused import
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40199

==

scrapy/trunk/scrapy/command/commands/shell.py
==================
972896cd;olveyra;2008-09-02 15:20:16 +0000;removed canonicalize from get function in shell
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40198

==

scrapy/trunk/scrapy/command/commands/shell.py
==================
2a30073e;olveyra;2008-09-02 14:12:17 +0000;fix get function (strip and canonicalize url)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40197

==

scrapy/trunk/scrapy/command/commands/shell.py
==================
7913a862;olveyra;2008-09-02 12:38:59 +0000;updated settings template
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40196

==

scrapy/trunk/scrapy/templates/settings.tmpl
==================
472a0de1;olveyra;2008-09-01 20:06:10 +0000;- Fixes in adaptors code, after testing - added attrs_list param to insertadaptor method
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40195

==

scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
==================
41fa9880;Pablo Hoffman;2008-09-01 19:28:30 +0000;removed unneeded exception code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40194

==

scrapy/trunk/scrapy/item/adaptors.py
==================
a88fb416;Pablo Hoffman;2008-09-01 04:28:18 +0000;changed Referer middleware class name
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40193

==

scrapy/trunk/scrapy/contrib/spidermiddleware/referer.py
==================
037e6c21;Pablo Hoffman;2008-09-01 04:18:12 +0000;improved SpiderMiddleware's docstrings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40192

==

scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
scrapy/trunk/scrapy/contrib/spidermiddleware/offsite.py
scrapy/trunk/scrapy/contrib/spidermiddleware/referer.py
scrapy/trunk/scrapy/contrib/spidermiddleware/restrict.py
scrapy/trunk/scrapy/contrib/spidermiddleware/urllength.py
==================
c9cafd5c;Pablo Hoffman;2008-09-01 04:16:51 +0000;added UrlFilterMiddleware
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40191

==

scrapy/trunk/scrapy/contrib/spidermiddleware/urlfilter.py
==================
d7d94482;Pablo Hoffman;2008-09-01 04:09:51 +0000;added update_fingerprint method to Request
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40190

==

scrapy/trunk/scrapy/http/request.py
==================
96d24c76;Pablo Hoffman;2008-09-01 03:34:53 +0000;fixed some documentation errors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40189

==

scrapy/trunk/scrapy/utils/url.py
==================
29c3715c;Pablo Hoffman;2008-09-01 03:33:18 +0000;changed remove_fragments argument to keep_fragments, for consistency with the other canonicalize_url arguments
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40188

==

scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
30803b9e;Pablo Hoffman;2008-09-01 03:31:11 +0000;added canonicalize_url function to scrapy.utils.url, along with a complete suite of tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40187

==

scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
34355048;Pablo Hoffman;2008-09-01 01:19:32 +0000;some functions were added to scrapy.utils.url without following our policies for adding tests (to scrapy.tests) and documentation (as docstrings). fixed that.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40186

==

scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/utils/url.py
==================
f3013bb9;olveyra;2008-08-31 00:25:13 +0000;Improved Adaptors code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40185

==

scrapy/trunk/scrapy/item/adaptors.py
scrapy/trunk/scrapy/item/models.py
==================
0e6562cb;olveyra;2008-08-27 17:37:32 +0000;moved some url utils from decobot to scrapy
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40184

==

scrapy/trunk/scrapy/utils/url.py
==================
9164150b;olveyra;2008-08-27 17:21:12 +0000;- avoid to raise an exception when no arg is given to replay command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40183

==

scrapy/trunk/scrapy/command/commands/replay.py
==================
b11b84ff;olveyra;2008-08-27 13:52:45 +0000;- moved scrape command to shell - fixes - get and scrapehelp functions added as ipython magic commands
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40182

==

scrapy/trunk/scrapy/command/commands/shell.py
scrapy/trunk/scrapy/contrib/webconsole/livestats.py
==================
bfe6168f;Pablo Hoffman;2008-08-25 00:00:14 +0000;cleaned up simpages code a bit, added some documentation
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40181

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/tagdepth.py
==================
eee86b98;Pablo Hoffman;2008-08-24 19:10:27 +0000;added prototype page similarity code, to detect different layouts
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40180

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/simpages/metrics/tagdepth.py
==================
397d3ff2;olveyra;2008-08-23 18:21:47 +0000;Added a synchronous get method which also updates console user namespace.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40179

==

scrapy/trunk/scrapy/command/commands/scrape.py
==================
e83dcb58;olveyra;2008-08-22 13:38:29 +0000;allow to use scrape command without an url
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40178

==

scrapy/trunk/scrapy/command/commands/scrape.py
==================
77053113;olveyra;2008-08-21 17:12:32 +0000;reverted clean_markup code movement
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40177

==

scrapy/trunk/scrapy/contrib/adaptors.py
scrapy/trunk/scrapy/utils/markup.py
==================
a2bd70ba;olveyra;2008-08-21 15:07:55 +0000;moved clean_markup to scrapy.utils.markup
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40176

==

scrapy/trunk/scrapy/contrib/adaptors.py
scrapy/trunk/scrapy/utils/markup.py
==================
643ea99f;olveyra;2008-08-20 12:52:31 +0000;fixed a clean code movement error: forget to apply remove tags when text does not contains cdata
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40175

==

scrapy/trunk/scrapy/contrib/adaptors.py
==================
1c8c73eb;Pablo Hoffman;2008-08-19 19:52:31 +0000;added some validation to new spider module names
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40174

==

scrapy/trunk/scrapy/command/commands/genspider.py
==================
17dec39c;olveyra;2008-08-19 13:42:32 +0000;removed temporal fix in 171
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40173

==

scrapy/trunk/scrapy/contrib/adaptors.py
==================
0f49c7c0;olveyra;2008-08-18 15:53:53 +0000;temporal fix to avoid exceptions before commit in decobot
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40172

==

scrapy/trunk/scrapy/contrib/adaptors.py
==================
5b3662ee;olveyra;2008-08-18 15:18:40 +0000;- Added generic clean adaptors - removed attribute name from adaptor function method (adaptors should not nor need to know attribute names)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40171

==

scrapy/trunk/scrapy/contrib/adaptors.py
scrapy/trunk/scrapy/item/models.py
==================
8877426a;olveyra;2008-08-15 17:04:36 +0000;minor fixes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40170

==

scrapy/trunk/scrapy/contrib/adaptors.py
scrapy/trunk/scrapy/item/models.py
==================
801b804a;Andres Moreira;2008-08-15 14:59:48 +0000;Added support to replay update to crawl again all the pages downloaded in the replay file.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40169

==

scrapy/trunk/scrapy/command/cmdline.py
scrapy/trunk/scrapy/command/commands/replay.py
scrapy/trunk/scrapy/replay/__init__.py
==================
9b0dd66e;olveyra;2008-08-15 12:35:09 +0000;improved explanation comment of the RequestLimitMiddleware
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40168

==

scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
==================
ee59bd87;Andres Moreira;2008-08-14 12:23:37 +0000;Changed messages of downloaded respones to received respones.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40167

==

scrapy/trunk/scrapy/command/commands/replay.py
==================
cdd88956;Andres Moreira;2008-08-14 12:22:07 +0000;The response downloadeds are manage by a new signal, response_received and I changed the methods associated that. Changed the method response_download to response_received. Added code to support the update in response_received.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40166

==

scrapy/trunk/scrapy/replay/__init__.py
==================
d95e5423;anibal;2008-08-14 11:53:29 +0000;ignoring temp directories for spider tests
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40165

==
==================
3975bf95;Pablo Hoffman;2008-08-14 09:57:17 +0000;added response_received signal
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40164

==

scrapy/trunk/scrapy/core/downloader/middleware.py
scrapy/trunk/scrapy/core/signals.py
==================
632b975c;olveyra;2008-08-14 01:13:14 +0000;import fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40163

==

scrapy/trunk/scrapy/contrib/adaptors.py
==================
280ad944;Pablo Hoffman;2008-08-13 21:06:49 +0000;changed setting default value
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40162

==

scrapy/trunk/scrapy/templates/settings.tmpl
==================
8e72e4e6;olveyra;2008-08-13 19:49:25 +0000;- Introduction of class BaseAdaptor - Contrib Adaptors - location_str moved from decobot to scrapy - Added setting DEFAULT_DATA_ENCODING
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40161

==

scrapy/trunk/scrapy/contrib/adaptors.py
scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/templates/settings.tmpl
scrapy/trunk/scrapy/utils/misc.py
==================
3a018cad;olveyra;2008-08-12 17:55:54 +0000;avoid trying to stop a not running task (this bug caused stalled processes in production servers)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40160

==

scrapy/trunk/scrapy/core/engine.py
==================
d0f12be4;olveyra;2008-08-12 16:18:03 +0000;removed a bad character from comment that caused an encoding error
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40159

==

scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
==================
baf32540;anibal;2008-08-12 15:59:05 +0000;we should add some svn hook to use pylint before commit :)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40158

==

scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
==================
e3f70a81;olveyra;2008-08-12 15:13:48 +0000;commented debug lines in last commit
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40157

==

scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
==================
a690d33f;olveyra;2008-08-12 15:11:15 +0000;added scheduler request queue limit for spiders (spider middleware)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40156

==

scrapy/trunk/scrapy/contrib/spidermiddleware/limit.py
scrapy/trunk/scrapy/templates/settings.tmpl
==================
290702d9;olveyra;2008-08-09 02:01:41 +0000;Cluster crawler fixes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40155

==

scrapy/trunk/scrapy/contrib/pbcluster/__init__.py
scrapy/trunk/scrapy/contrib/pbcluster/crawler/__init__.py
scrapy/trunk/scrapy/contrib/pbcluster/crawler/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
5b4d9f8f;olveyra;2008-08-08 17:16:27 +0000;fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40154

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
29cd1bc3;olveyra;2008-08-08 16:57:33 +0000;Added pb-capable crawler. The idea is to improve cluster performance adding communication between crawler and master. At the momento, a remote stop method to the crawler was added to sustitute the previous stop based on kernel signal. Further will add monitoring functionality, because the processes are very silent, mainly when unavailable report is not issued, and offen happens lots of thing that nobody realize on if some fortuite events wouldn't happent
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40153

==

scrapy/trunk/scrapy/contrib/pbcluster/crawler/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
6cfbe78d;olveyra;2008-08-07 16:01:25 +0000;Added a periodic ping to maintain mysql connection active
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40152

==

scrapy/trunk/scrapy/templates/settings.tmpl
scrapy/trunk/scrapy/utils/db.py
==================
4606b7f9;olveyra;2008-08-07 12:26:43 +0000;deleting old cluster branch
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40151

==

scrapy/trunk/scrapy/contrib/cluster/__init__.py
scrapy/trunk/scrapy/contrib/cluster/master/__init__.py
scrapy/trunk/scrapy/contrib/cluster/master/manager.py
scrapy/trunk/scrapy/contrib/cluster/master/web.py
scrapy/trunk/scrapy/contrib/cluster/worker/__init__.py
scrapy/trunk/scrapy/contrib/cluster/worker/manager.py
scrapy/trunk/scrapy/contrib/cluster/worker/web.py
==================
59d6e925;olveyra;2008-08-07 11:59:44 +0000;upss...removing a print...
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40150

==

scrapy/trunk/scrapy/utils/db.py
==================
3f7100fe;olveyra;2008-08-07 11:56:12 +0000;improved last change to left definitively there
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40149

==

scrapy/trunk/scrapy/utils/db.py
==================
6b890c1b;olveyra;2008-08-07 11:49:00 +0000;added a log to see if db settings are really being passed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40148

==

scrapy/trunk/scrapy/utils/db.py
==================
246bdedc;olveyra;2008-08-05 18:32:03 +0000;fixed a get setting in UrlToGuidService
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40147

==

scrapy/trunk/scrapy/contrib/web/service.py
==================
22eb48da;olveyra;2008-08-05 16:51:12 +0000;added MYSQL_CONNECTION_SETTINGS settings
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40146

==

scrapy/trunk/scrapy/templates/settings.tmpl
scrapy/trunk/scrapy/utils/db.py
==================
388f7641;olveyra;2008-08-05 12:05:28 +0000;reverted last change. Seems this options is available only in very recent versions of mysql-python
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40145

==

scrapy/trunk/scrapy/utils/db.py
==================
7fc59232;olveyra;2008-08-05 11:41:49 +0000;add reconnect=1 parameter to mysql_connect in order to reconnect after a large inactivity period
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40144

==

scrapy/trunk/scrapy/utils/db.py
==================
7a195a97;olveyra;2008-08-01 18:13:07 +0000;allow usage of integer "dont_filter", meaning number of times dont_filter will apply when redirecting.
Under this scheme, dont_filter=True is the same as dont_filter=1
and (convenient?) dont filter <= 0 means dont_filter = True forever

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40143

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
==================
3badb39e;elpolilla;2008-07-31 23:08:54 +0000;removed report feature for not being generic
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40142

==

scrapy/trunk/scrapy/command/commands/crawl.py
scrapy/trunk/scrapy/report/__init__.py
==================
380a65e7;samus_;2008-07-31 17:59:35 +0000;fix for the replays and cache timeout
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40141

==

scrapy/trunk/scrapy/replay/__init__.py
==================
0f65d2f2;elpolilla;2008-07-31 15:42:50 +0000;total of variants added to the report feature
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40140

==

scrapy/trunk/scrapy/report/__init__.py
==================
f9253843;Matias Aguirre;2008-07-30 23:47:28 +0000;Adding missing templates
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40139

==

sites/scrapy.org/templates/articles/home.html
sites/scrapy.org/templates/home.html
==================
f955c969;elpolilla;2008-07-30 16:01:28 +0000;smallest change ever in the reports, but improves the act of reading them
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40138

==

scrapy/trunk/scrapy/report/__init__.py
==================
c7620056;elpolilla;2008-07-30 11:20:22 +0000;bugfix in scraping report
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40137

==

scrapy/trunk/scrapy/report/__init__.py
==================
7b0877c5;Matias Aguirre;2008-07-29 13:54:20 +0000;Changes:     * Simplify article app, it isn't necessary to save them       in db, instead this tool should render static templates       directly based in the url.       Example: if the url is "/article/today" it will look for       the template "articles/today.html" in articles templates       directory. This app is configured to handle any url, so       it will render an url like "/about" (if there isn't other       url defined to handle "about" before article definition),       and in this case will try to render the template       "article.html" in articles templates dir
    * Removed models, not necessary now

    * Removed templatetags, not necessary now

    * Removed flatpages middleware ??

    * Added url to articles app, this will used as a last case
      to handle undefined urls.

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40136

==

sites/scrapy.org/scrapyorg/article/models.py
sites/scrapy.org/scrapyorg/article/templatetags/__init__.py
sites/scrapy.org/scrapyorg/article/templatetags/article_tags.py
sites/scrapy.org/scrapyorg/article/urls.py
sites/scrapy.org/scrapyorg/article/views.py
sites/scrapy.org/scrapyorg/settings.py
sites/scrapy.org/scrapyorg/urls.py
==================
28bb53fa;Daniel Grana;2008-07-29 12:27:55 +0000;process result's items using generators to give pipeline a chance to consume while parsing new items
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40135

==

scrapy/trunk/scrapy/contrib/spidermiddleware/depth.py
scrapy/trunk/scrapy/contrib/spidermiddleware/offsite.py
scrapy/trunk/scrapy/contrib/spidermiddleware/referer.py
scrapy/trunk/scrapy/contrib/spidermiddleware/restrict.py
scrapy/trunk/scrapy/contrib/spidermiddleware/urllength.py
scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/spider/middleware.py
scrapy/trunk/scrapy/utils/misc.py
==================
640e8b91;elpolilla;2008-07-29 01:14:01 +0000;scrapy report util improved
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40134

==

scrapy/trunk/scrapy/command/commands/crawl.py
scrapy/trunk/scrapy/report/__init__.py
==================
02b87f7d;olveyra;2008-07-28 22:29:55 +0000;in settings template, set DEFAULT_ITEM_CLASS to scrapy.item.ScrapedItem to enable console
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40133

==

scrapy/trunk/scrapy/templates/settings.tmpl
==================
1cbfe461;olveyra;2008-07-28 22:11:19 +0000;disabled webconsole by default
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40132

==

scrapy/trunk/scrapy/templates/settings.tmpl
==================
ea9571aa;elpolilla;2008-07-28 13:01:34 +0000;--report option modified (i had forgotten to report the variants)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40131

==

scrapy/trunk/scrapy/report/__init__.py
==================
f86324fa;elpolilla;2008-07-28 12:42:00 +0000;--report option added to crawl command
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40130

==

scrapy/trunk/scrapy/command/commands/crawl.py
scrapy/trunk/scrapy/report/__init__.py
==================
4b2e20ab;Pablo Hoffman;2008-07-28 04:15:51 +0000;added scrapy.utils.markup module
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40129

==

scrapy/trunk/scrapy/tests/test_utils_markup.py
scrapy/trunk/scrapy/utils/markup.py
==================
c9c624dd;olveyra;2008-07-27 22:00:08 +0000;minor adjustments
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40128

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
scrapy/trunk/scrapy/templates/settings.tmpl
==================
86c7f37d;olveyra;2008-07-27 16:11:23 +0000;moved options nocache and nopipeline from decobot to scrapy
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40127

==

scrapy/trunk/scrapy/command/commands/crawl.py
==================
b59f62dc;olveyra;2008-07-27 14:54:11 +0000;Added function convert_entity from decobot.utils.text_extraction (to complete and fix revision 124)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40126

==

scrapy/trunk/scrapy/utils/misc.py
==================
1e2ddb47;olveyra;2008-07-27 02:49:20 +0000;remove wrong import from decobot and added unquote_html
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40125

==

scrapy/trunk/scrapy/utils/misc.py
==================
137ec643;olveyra;2008-07-27 02:23:14 +0000;minor adjustments and some fixes, readded scrapy-admin.py with execution permission
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40124

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
scrapy/trunk/scrapy/templates/scrapy-ctl.tmpl
==================
b851ec5f;olveyra;2008-07-27 01:38:53 +0000;deleted scrapy-admin to commit again with execution access
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40123

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
==================
fbb5860f;samus_;2008-07-26 15:51:39 +0000;re-enabling replays with the new mechanism
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40122

==

scrapy/trunk/scrapy/replay/__init__.py
==================
bc00f8cc;olveyra;2008-07-25 22:42:57 +0000;re-reverted commit 119 back again to 118. The code removed is confusing.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40121

==

scrapy/trunk/scrapy/conf/__init__.py
==================
67ee6bff;Pablo Hoffman;2008-07-25 21:28:49 +0000;restored code removed in r118. there's nothing wrong with that code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40120

==

scrapy/trunk/scrapy/conf/__init__.py
==================
c97c495d;olveyra;2008-07-25 19:40:43 +0000;removed code that generates confusing and mistaken import error message when the import error raises inside scrapy_settings.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40119

==

scrapy/trunk/scrapy/conf/__init__.py
==================
0bb68f34;samus_;2008-07-25 19:26:46 +0000;forgot to import sys module :P
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40118

==

scrapy/trunk/scrapy/replay/__init__.py
==================
8e18ecd5;olveyra;2008-07-25 19:11:01 +0000;first version of scrapy-admin
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40117

==

scrapy/trunk/scrapy/bin/scrapy-admin.py
scrapy/trunk/scrapy/templates/scrapy-ctl.tmpl
scrapy/trunk/scrapy/templates/settings.tmpl
==================
bd7c80ed;samus_;2008-07-25 18:50:45 +0000;adding new replay method (beta)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40116

==

scrapy/trunk/scrapy/replay/__init__.py
==================
22e3d3a0;Matias Aguirre;2008-07-25 17:36:34 +0000;Add save_on_top to admin sections
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40115

==

sites/scrapy.org/scrapyorg/article/models.py
sites/scrapy.org/scrapyorg/download/models.py
==================
e4212065;Matias Aguirre;2008-07-25 16:59:27 +0000;Add publish field
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40114

==

sites/scrapy.org/scrapyorg/article/models.py
sites/scrapy.org/scrapyorg/article/templatetags/article_tags.py
sites/scrapy.org/scrapyorg/article/urls.py
sites/scrapy.org/scrapyorg/article/views.py
==================
9f8ce8f1;Matias Aguirre;2008-07-25 16:59:00 +0000;Add bool icon for public field in admin
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40113

==

sites/scrapy.org/scrapyorg/download/models.py
==================
baee62cf;Matias Aguirre;2008-07-25 15:38:11 +0000;Change positions urls in download and article applications, this are like admin urls now and the views are decorated to force a staff user check before
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40112

==

sites/scrapy.org/scrapyorg/article/models.py
sites/scrapy.org/scrapyorg/article/views.py
sites/scrapy.org/scrapyorg/download/models.py
sites/scrapy.org/scrapyorg/download/urls.py
sites/scrapy.org/scrapyorg/download/views.py
sites/scrapy.org/scrapyorg/urls.py
==================
fd4aab5f;Matias Aguirre;2008-07-25 15:35:11 +0000;Force all textareas to be 30 rows height
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40111

==

sites/scrapy.org/templates/admin/base_site.html
==================
80a99dde;Matias Aguirre;2008-07-25 15:23:59 +0000;Adding missing template sections
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40110

==

sites/scrapy.org/templates/admin/base_site.html
==================
4c193f47;Matias Aguirre;2008-07-25 15:19:16 +0000;Adding if clause that will display blog entries box only if there are any entry to list
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40109

==

sites/scrapy.org/templates/base_home.html
==================
56e110af;Matias Aguirre;2008-07-25 15:17:43 +0000;Override admin base template with a custom one that has some JS to resize textaeras, useful when editing an article
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40108

==

sites/scrapy.org/templates/admin/base_site.html
==================
ee8d9a59;Matias Aguirre;2008-07-25 15:16:37 +0000;Adding nav and footer links statically instead of use the removed links application
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40107

==

sites/scrapy.org/templates/base_home.html
==================
202e08a9;Matias Aguirre;2008-07-25 15:11:56 +0000;Removing flatpages from applications list, this isn't used
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40106

==

sites/scrapy.org/scrapyorg/settings.py
==================
d4337610;Matias Aguirre;2008-07-25 15:10:41 +0000;Removing link application, was too much overkill to the functionality needed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40105

==

sites/scrapy.org/scrapyorg/link/__init__.py
sites/scrapy.org/scrapyorg/link/models.py
sites/scrapy.org/scrapyorg/link/templatetags/__init__.py
sites/scrapy.org/scrapyorg/link/templatetags/link_tags.py
sites/scrapy.org/scrapyorg/link/urls.py
sites/scrapy.org/scrapyorg/link/views.py
sites/scrapy.org/scrapyorg/settings.py
sites/scrapy.org/scrapyorg/urls.py
==================
9dd144f4;Pablo Hoffman;2008-07-25 13:42:40 +0000;removed parent attribute from Response class
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40104

==

scrapy/trunk/scrapy/command/commands/scrape.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/contrib/history/middleware.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/http/response.py
==================
f3f34d08;olveyra;2008-07-24 15:18:29 +0000;- added basic statistics (needs to be improved) - node remotion when connection lost event
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40103

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
e86ee647;samus_;2008-07-24 01:52:28 +0000;small improvements to the cache
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40102

==

scrapy/trunk/scrapy/conf/core_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
==================
8b8e3e75;olveyra;2008-07-23 19:23:47 +0000;fixed a bug in which pending list remains stalled because not proper clean out of loading list
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40101

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
0dffb68e;olveyra;2008-07-23 19:13:39 +0000;not update nodes after scheduling, to avoid enter in a loop
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%40100

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
b5b79042;olveyra;2008-07-23 17:15:16 +0000;- added worker to master notifications. - deleted statistics code. will change approach
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4099

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
980369ba;olveyra;2008-07-23 12:32:38 +0000;changed default webservice port to connect on to 8060
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4098

==

scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
==================
3a06868c;olveyra;2008-07-23 12:21:05 +0000;deleted date folder from log path
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4097

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
7e32fe10;Pablo Hoffman;2008-07-23 03:13:26 +0000;do not hide svn errors
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4096

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
8a0fdaa8;Pablo Hoffman;2008-07-22 23:13:08 +0000;logfiles are now appendable instead of truncable
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4095

==

scrapy/trunk/scrapy/core/log.py
==================
a7301cc9;samus_;2008-07-22 18:38:02 +0000;implemented __getslice__ for the XPathSelectorList, still broken when using step-slices
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4094

==

scrapy/trunk/scrapy/xpath/selector.py
==================
a27b085c;olveyra;2008-07-22 17:56:04 +0000;fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4093

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
5e2db86c;samus_;2008-07-22 17:53:37 +0000;fixed pickle
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4092

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
==================
7f62faea;olveyra;2008-07-22 17:21:55 +0000;Added cluster statistics report
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4091

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/testworker.py
==================
85a45146;samus_;2008-07-22 16:48:10 +0000;reverted wrong XPathSelector commit
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4090

==

scrapy/trunk/scrapy/xpath/selector.py
==================
e8b5a07a;samus_;2008-07-22 16:44:30 +0000;cPickle as pickle
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4089

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/xpath/selector.py
==================
30202c54;samus_;2008-07-22 16:27:52 +0000;ís_cached fix2
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4088

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
==================
e7fbaa50;samus_;2008-07-22 16:12:42 +0000;reverted wrong XPathSelector commit
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4087

==

scrapy/trunk/scrapy/xpath/selector.py
==================
c9851d8e;samus_;2008-07-22 16:11:57 +0000;ís_cached fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4086

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/xpath/selector.py
==================
5778ecf1;samus_;2008-07-22 14:19:41 +0000;small fix for string representation of XPathSelector when the node is not an xml object
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4085

==

scrapy/trunk/scrapy/xpath/selector.py
==================
97b2e7df;samus_;2008-07-22 11:51:53 +0000;added pickled_meta to avoid using eval
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4084

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
==================
76a9d2da;samus_;2008-07-22 11:33:05 +0000;migrated all sha to hashlib
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4083

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/contrib/history/middleware.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/contrib/web/service.py
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/http/response.py
==================
ce905ce7;olveyra;2008-07-21 19:14:37 +0000;- code fixes - fix when rescheduling with a new priority - added freeslots to status_as_dict - remove a domain from loading list only when reported as running in some node.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4082

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
9c345016;samus_;2008-07-21 14:07:57 +0000;added INFO message
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4081

==

scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
==================
d2121141;samus_;2008-07-21 13:23:23 +0000;implemented CACHE2_EXPIRATION_SECS and migrated sha to hashlib
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4080

==

scrapy/trunk/scrapy/conf/core_settings.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/http/request.py
==================
b45d87d0;Pablo Hoffman;2008-07-18 01:51:49 +0000;removed duplicated code
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4079

==

scrapy/trunk/scrapy/command/commands/__init__.py
==================
cdb3b025;olveyra;2008-07-17 19:20:10 +0000;fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4078

==

scrapy/trunk/scrapy/command/models.py
==================
7c1ebfd1;olveyra;2008-07-17 19:06:03 +0000;option help fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4077

==

scrapy/trunk/scrapy/command/models.py
==================
d765b133;olveyra;2008-07-17 19:00:05 +0000;- --default-spider option gives the default spider (old --spider option) - --spider option now forces to use the given spider domain when arguments are urls
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4076

==

scrapy/trunk/scrapy/command/models.py
scrapy/trunk/scrapy/spider/manager.py
==================
abde0e5f;olveyra;2008-07-17 18:15:46 +0000;readed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4075

==

scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
==================
fb43b935;olveyra;2008-07-17 18:14:52 +0000;deleted
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4074

==

scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
==================
6f028cc3;olveyra;2008-07-17 18:09:32 +0000;moved cluster-ctl script to scrapy branch
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4073

==

scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib/pbcluster/tools/scrapy-cluster-ctl.py
==================
f515942f;olveyra;2008-07-17 15:41:15 +0000;- added verbosity levels - now log paths includes a folder named by the date, so it is easier to mantain logs in server
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4072

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
5403fd3d;olveyra;2008-07-16 19:17:46 +0000;- added disable_node and enable_node functions - removed unused imports - autoreload of lost nodes - some code improvements and fixes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4071

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt
==================
8150fd6a;Ezequiel Rivero;2008-07-16 17:50:58 +0000;size fix for menu in trac
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4070

==

sites/static.scrapy.org/css/trac.css
==================
e8eab24d;olveyra;2008-07-16 12:09:42 +0000;don't update status in run callback, so to avoid lots of bouncing domains. The domains will be loaded softly on each node update
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4069

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
338a485b;olveyra;2008-07-16 11:20:53 +0000;- load only one domain per node (and load the following when the run callback is executed). This way, we avoid to load lot of domains that will bounce. Also, we mix up better the domains between available nodes.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4068

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
ace6e3c4;olveyra;2008-07-15 18:53:37 +0000;- Reschedule a domain that is already running or loading in some node - No schedule a domain that is already scheduled
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4067

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
==================
69d1c576;olveyra;2008-07-15 18:06:14 +0000;small fix and pepocho fix
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4066

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
e71aa06f;olveyra;2008-07-15 12:11:32 +0000;Check the node will not run a domain that is already running
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4065

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
2b6189a3;olveyra;2008-07-14 14:10:26 +0000;renamed setting SCRAPY_PICKLED_SETTINGS to SCRAPY_PICKLED_SETTINGS_TO_OVERRIDE
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4064

==

scrapy/trunk/scrapy/conf/__init__.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
11bc122a;olveyra;2008-07-14 13:39:58 +0000;pickled settings must go in overrides settings not default, because of precedence
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4063

==

scrapy/trunk/scrapy/conf/__init__.py
==================
49175d19;Pablo Hoffman;2008-07-14 13:31:00 +0000;added new test case for xpathselector_iternodes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4062

==

scrapy/trunk/scrapy/tests/test_utils_xml.py
scrapy/trunk/scrapy/utils/xml.py
==================
28b5bb32;Pablo Hoffman;2008-07-14 13:22:05 +0000;added utf-16 (and other encodings) support to xpathselector_iternodes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4061

==

scrapy/trunk/scrapy/tests/test_utils_xml.py
scrapy/trunk/scrapy/utils/xml.py
==================
90e93a76;Pablo Hoffman;2008-07-14 13:18:58 +0000;imports should be at module's top
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4060

==

scrapy/trunk/scrapy/extension/__init__.py
==================
9b3c3c14;olveyra;2008-07-14 12:42:58 +0000;logs extensions NotConfigured exception message
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4059

==

scrapy/trunk/scrapy/extension/__init__.py
==================
377e17b7;olveyra;2008-07-14 12:35:46 +0000;More data in log message
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4058

==

scrapy/trunk/scrapy/contrib/webconsole/spiderstats.py
==================
a4cfea54;olveyra;2008-07-11 19:34:39 +0000;fixed env name
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4057

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
1eb583a3;olveyra;2008-07-11 19:31:08 +0000;added log msg
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4056

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
ba0f87ed;olveyra;2008-07-11 18:27:19 +0000;changed CLUSTER_WORKER_LOGDIR to CLUSTER_LOGDIR
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4055

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
585f35fb;olveyra;2008-07-11 16:21:23 +0000;Cluster Master improvements:
- rescheduling now goes with original priority decreased by one
- Added GLOBAL_CLUSTER_SETTINGS
- Added PB remote method load_node so the worker also can initiate a
connection

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4054

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
0c35b7ed;olveyra;2008-07-11 16:08:28 +0000;Now worker pass settings to process via SCRAPY_PICKLED_SETTINGS
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4053

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
8ea2dc94;olveyra;2008-07-11 16:05:20 +0000;renamed pickled data
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4052

==

scrapy/trunk/scrapy/conf/__init__.py
==================
94993b76;olveyra;2008-07-11 15:59:08 +0000;added SCRAPY_PICKLED_DEFAULT_SETTINGS, a string to pass by environment setting an arbitrary set of settings via "pickle" python module.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4051

==

scrapy/trunk/scrapy/conf/__init__.py
==================
c97e7d0d;Daniel Grana;2008-07-08 19:48:12 +0000;show if crawled pages are cached or live versions
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4050

==

scrapy/trunk/scrapy/core/engine.py
==================
805eeec8;olveyra;2008-07-08 18:08:20 +0000;deleted unneeded log
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4049

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
fc4e0eaa;olveyra;2008-07-08 18:03:20 +0000;fix a bug with rescheduling a domain when no free slot are in worker (a domain was passed instead of a list, and that raises the one-letter domains bug), also reschedule with priority=0)
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4048

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
863d94ad;olveyra;2008-07-07 18:00:35 +0000;added CLUSTER_MASTER_CACHEFILE setting, changed SVN_WORKDIR to CLUSTER_WORKER_SVNWORKDIR
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4047

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
e78f7a93;olveyra;2008-07-07 17:51:09 +0000;better way to stop engine with process signals
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4046

==

scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/core/manager.py
==================
648b312b;Pablo Hoffman;2008-07-07 17:37:55 +0000;engine.stop() is now always executed when reactor stops
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4045

==

scrapy/trunk/scrapy/core/engine.py
==================
6bdbcd81;olveyra;2008-07-04 19:02:19 +0000;pep8 pal pablo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4044

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
1d876db8;olveyra;2008-07-04 18:59:36 +0000;pass to crawl process the correct python path
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4043

==

scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
6bbbb0c1;olveyra;2008-07-04 13:23:21 +0000;master logs response from worker.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4042

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
e11d824e;olveyra;2008-07-04 13:22:27 +0000;added --pidfile option
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4041

==

scrapy/trunk/scrapy/command/models.py
==================
23b34084;olveyra;2008-07-02 19:42:36 +0000;- added svn update support - removed passing of env variables - added automatic group settings load
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4040

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
8344819a;olveyra;2008-07-02 15:07:29 +0000;added persistence of pending list in master
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4039

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
9c713529;olveyra;2008-07-01 15:28:07 +0000;fix and webservice api doc update
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4038

==

scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt
==================
74ef3ab5;olveyra;2008-07-01 15:17:00 +0000;added environment options
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4037

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
d2684dc1;olveyra;2008-07-01 13:17:23 +0000;Ok, first functional version of pbcluster
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4036

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/master/ws_api.txt
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
==================
d993f493;Pablo Hoffman;2008-07-01 02:21:12 +0000;some improvments to XPathSelectors:
- x() method now returns the same XPathSelector type of its parent
- added tests to check this
- added tests to verify that XML and HTML XPathSelector behave differently when
  parsing some non trivial markup

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4035

==

scrapy/trunk/scrapy/tests/test_xpath.py
scrapy/trunk/scrapy/xpath/selector.py
==================
1f7f0d09;Pablo Hoffman;2008-06-30 17:20:56 +0000;replaced XMLNodeIterator with xpathselector_iternodes
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4034

==

scrapy/trunk/scrapy/tests/test_utils_xml.py
scrapy/trunk/scrapy/tests/test_xpath.py
scrapy/trunk/scrapy/utils/xml.py
scrapy/trunk/scrapy/xpath/__init__.py
scrapy/trunk/scrapy/xpath/iterator.py
==================
3ee14952;Ezequiel Rivero;2008-06-30 15:07:27 +0000;css styling changes.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4033

==

sites/static.scrapy.org/css/trac.css
==================
8a81fe82;olveyra;2008-06-30 14:24:49 +0000;deleted prints
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4032

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
==================
53838d6a;olveyra;2008-06-30 14:20:27 +0000;pbcluster commit
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4031

==

scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/testworker.py
==================
4caadf6b;Pablo Hoffman;2008-06-29 06:08:48 +0000;added (yet another) xml node iterator based entirely in regex
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4030

==

scrapy/trunk/scrapy/xpath/iterator.py
==================
f9fc8a1b;Pablo Hoffman;2008-06-29 05:34:28 +0000;exported XmlXPathSelector and HtmlXPathSelector in scrapy.xpath, changed scrape command to instantiate those
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4029

==

scrapy/trunk/scrapy/command/commands/scrape.py
scrapy/trunk/scrapy/xpath/__init__.py
==================
6cc91df9;Pablo Hoffman;2008-06-29 05:20:31 +0000;some improvements to XPathSelector and friends
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4028

==

scrapy/trunk/scrapy/tests/test_xpath.py
scrapy/trunk/scrapy/xpath/constructors.py
scrapy/trunk/scrapy/xpath/iterator.py
scrapy/trunk/scrapy/xpath/selector.py
==================
9cf83faf;Pablo Hoffman;2008-06-29 01:10:44 +0000;moved outside scrapy
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4027

==

scrapy/trunk/scrapy/tests/sample_data/link_extraction/extract_urls.html
==================
1638ef2b;Pablo Hoffman;2008-06-29 01:08:23 +0000;removed link_extraction and text_extraction modules test
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4026

==

scrapy/trunk/scrapy/tests/test_link_extraction.py
scrapy/trunk/scrapy/tests/test_text_extraction.py
==================
83dcf8af;Pablo Hoffman;2008-06-28 23:37:28 +0000;commited initial scrapy code, taken from the old repo at r31560
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4025

==

scrapy/trunk/INSTALL
scrapy/trunk/README
scrapy/trunk/extras/sql/scraping.sql
scrapy/trunk/scrapy/__init__.py
scrapy/trunk/scrapy/command/__init__.py
scrapy/trunk/scrapy/command/cmdline.py
scrapy/trunk/scrapy/command/commands/__init__.py
scrapy/trunk/scrapy/command/commands/crawl.py
scrapy/trunk/scrapy/command/commands/download.py
scrapy/trunk/scrapy/command/commands/genspider.py
scrapy/trunk/scrapy/command/commands/getattr.py
scrapy/trunk/scrapy/command/commands/help.py
scrapy/trunk/scrapy/command/commands/list.py
scrapy/trunk/scrapy/command/commands/log.py
scrapy/trunk/scrapy/command/commands/parse.py
scrapy/trunk/scrapy/command/commands/replay.py
scrapy/trunk/scrapy/command/commands/scrape.py
scrapy/trunk/scrapy/command/commands/start.py
scrapy/trunk/scrapy/command/commands/stats.py
scrapy/trunk/scrapy/command/models.py
scrapy/trunk/scrapy/conf/__init__.py
scrapy/trunk/scrapy/conf/commands/__init__.py
scrapy/trunk/scrapy/conf/commands/crawl.py
scrapy/trunk/scrapy/conf/commands/help.py
scrapy/trunk/scrapy/conf/commands/list.py
scrapy/trunk/scrapy/conf/commands/log.py
scrapy/trunk/scrapy/conf/commands/scrape.py
scrapy/trunk/scrapy/conf/commands/stats.py
scrapy/trunk/scrapy/conf/commands/test.py
scrapy/trunk/scrapy/conf/core_settings.py
scrapy/trunk/scrapy/contrib/__init__.py
scrapy/trunk/scrapy/contrib/closedomain.py
scrapy/trunk/scrapy/contrib/cluster/__init__.py
scrapy/trunk/scrapy/contrib/cluster/master/__init__.py
scrapy/trunk/scrapy/contrib/cluster/master/manager.py
scrapy/trunk/scrapy/contrib/cluster/master/web.py
scrapy/trunk/scrapy/contrib/cluster/worker/__init__.py
scrapy/trunk/scrapy/contrib/cluster/worker/manager.py
scrapy/trunk/scrapy/contrib/cluster/worker/web.py
scrapy/trunk/scrapy/contrib/debug.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/__init__.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/cache.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/common.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/compression.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/cookies.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/debug.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/errorpages.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/httpauth.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/redirect.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/retry.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/robots.py
scrapy/trunk/scrapy/contrib/downloadermiddleware/useragent.py
scrapy/trunk/scrapy/contrib/groupsettings.py
scrapy/trunk/scrapy/contrib/history/__init__.py
scrapy/trunk/scrapy/contrib/history/history.py
scrapy/trunk/scrapy/contrib/history/middleware.py
scrapy/trunk/scrapy/contrib/history/scheduler.py
scrapy/trunk/scrapy/contrib/history/store.py
scrapy/trunk/scrapy/contrib/item/__init__.py
scrapy/trunk/scrapy/contrib/item/models.py
scrapy/trunk/scrapy/contrib/memdebug.py
scrapy/trunk/scrapy/contrib/memusage.py
scrapy/trunk/scrapy/contrib/pbcluster/__init__.py
scrapy/trunk/scrapy/contrib/pbcluster/master/__init__.py
scrapy/trunk/scrapy/contrib/pbcluster/master/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/master/web.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/__init__.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/manager.py
scrapy/trunk/scrapy/contrib/pbcluster/worker/testworker.py
scrapy/trunk/scrapy/contrib/pipeline/__init__.py
scrapy/trunk/scrapy/contrib/pipeline/shoveitem.py
scrapy/trunk/scrapy/contrib/pipeline/show.py
scrapy/trunk/scrapy/contrib/prioritizers.py
scrapy/trunk/scrapy/contrib/response/__init__.py
scrapy/trunk/scrapy/contrib/response/soup.py
scrapy/trunk/scrapy/contrib/spider/__init__.py
scrapy/trunk/scrapy/contrib/spider/profiler.py
scrapy/trunk/scrapy/contrib/spider/reloader.py
scrapy/trunk/scrapy/contrib/spidermiddleware/__init__.py
scrapy/trunk/scrapy/contrib/spidermiddleware/depth.py
scrapy/trunk/scrapy/contrib/spidermiddleware/offsite.py
scrapy/trunk/scrapy/contrib/spidermiddleware/referer.py
scrapy/trunk/scrapy/contrib/spidermiddleware/restrict.py
scrapy/trunk/scrapy/contrib/spidermiddleware/urllength.py
scrapy/trunk/scrapy/contrib/web/__init__.py
scrapy/trunk/scrapy/contrib/web/http.py
scrapy/trunk/scrapy/contrib/web/json.py
scrapy/trunk/scrapy/contrib/web/service.py
scrapy/trunk/scrapy/contrib/web/site.py
scrapy/trunk/scrapy/contrib/web/stats.py
scrapy/trunk/scrapy/contrib/webconsole/__init__.py
scrapy/trunk/scrapy/contrib/webconsole/enginestatus.py
scrapy/trunk/scrapy/contrib/webconsole/livestats.py
scrapy/trunk/scrapy/contrib/webconsole/schedstats.py
scrapy/trunk/scrapy/contrib/webconsole/spiderctl.py
scrapy/trunk/scrapy/contrib/webconsole/spiderstats.py
scrapy/trunk/scrapy/contrib/webconsole/stats.py
scrapy/trunk/scrapy/core/__init__.py
scrapy/trunk/scrapy/core/downloader/__init__.py
scrapy/trunk/scrapy/core/downloader/handlers.py
scrapy/trunk/scrapy/core/downloader/manager.py
scrapy/trunk/scrapy/core/downloader/middleware.py
scrapy/trunk/scrapy/core/engine.py
scrapy/trunk/scrapy/core/exceptions.py
scrapy/trunk/scrapy/core/log.py
scrapy/trunk/scrapy/core/mail.py
scrapy/trunk/scrapy/core/manager.py
scrapy/trunk/scrapy/core/prioritizers.py
scrapy/trunk/scrapy/core/scheduler/__init__.py
scrapy/trunk/scrapy/core/scheduler/filter.py
scrapy/trunk/scrapy/core/scheduler/schedulers.py
scrapy/trunk/scrapy/core/scheduler/store.py
scrapy/trunk/scrapy/core/signals.py
scrapy/trunk/scrapy/extension/__init__.py
scrapy/trunk/scrapy/fetcher/__init__.py
scrapy/trunk/scrapy/http/__init__.py
scrapy/trunk/scrapy/http/headers.py
scrapy/trunk/scrapy/http/request.py
scrapy/trunk/scrapy/http/response.py
scrapy/trunk/scrapy/http/url.py
scrapy/trunk/scrapy/item/__init__.py
scrapy/trunk/scrapy/item/models.py
scrapy/trunk/scrapy/item/pipeline.py
scrapy/trunk/scrapy/lib/BeautifulSoup.py
scrapy/trunk/scrapy/lib/__init__.py
scrapy/trunk/scrapy/lib/lrucache.py
scrapy/trunk/scrapy/lib/lsprofcalltree.py
scrapy/trunk/scrapy/lib/pydispatch/__init__.py
scrapy/trunk/scrapy/lib/pydispatch/dispatcher.py
scrapy/trunk/scrapy/lib/pydispatch/errors.py
scrapy/trunk/scrapy/lib/pydispatch/license.txt
scrapy/trunk/scrapy/lib/pydispatch/robust.py
scrapy/trunk/scrapy/lib/pydispatch/robustapply.py
scrapy/trunk/scrapy/lib/pydispatch/saferef.py
scrapy/trunk/scrapy/lib/simplejson/__init__.py
scrapy/trunk/scrapy/lib/simplejson/_speedups.c
scrapy/trunk/scrapy/lib/simplejson/decoder.py
scrapy/trunk/scrapy/lib/simplejson/encoder.py
scrapy/trunk/scrapy/lib/simplejson/jsonfilter.py
scrapy/trunk/scrapy/lib/simplejson/scanner.py
scrapy/trunk/scrapy/lib/simplejson/tests/__init__.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_attacks.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_dump.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_fail.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_indent.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_pass1.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_pass2.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_pass3.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_recursion.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_separators.py
scrapy/trunk/scrapy/lib/simplejson/tests/test_unicode.py
scrapy/trunk/scrapy/lib/spidermonkey/INSTALL.scrapy
scrapy/trunk/scrapy/lib/spidermonkey/__init__.py
scrapy/trunk/scrapy/lib/spidermonkey/sm_settings.py
scrapy/trunk/scrapy/lib/spidermonkey/spidermonkey.py
scrapy/trunk/scrapy/link/__init__.py
scrapy/trunk/scrapy/management/__init__.py
scrapy/trunk/scrapy/management/telnet.py
scrapy/trunk/scrapy/management/web.py
scrapy/trunk/scrapy/patches/__init__.py
scrapy/trunk/scrapy/patches/monkeypatches.py
scrapy/trunk/scrapy/replay/__init__.py
scrapy/trunk/scrapy/spider/__init__.py
scrapy/trunk/scrapy/spider/manager.py
scrapy/trunk/scrapy/spider/middleware.py
scrapy/trunk/scrapy/spider/models.py
scrapy/trunk/scrapy/stats/__init__.py
scrapy/trunk/scrapy/stats/corestats.py
scrapy/trunk/scrapy/stats/statscollector.py
scrapy/trunk/scrapy/store/__init__.py
scrapy/trunk/scrapy/store/db.py
scrapy/trunk/scrapy/tests/__init__.py
scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample1.xml
scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample2.xml
scrapy/trunk/scrapy/tests/sample_data/feeds/feed-sample3.xml
scrapy/trunk/scrapy/tests/sample_data/link_extraction/extract_urls.html
scrapy/trunk/scrapy/tests/sample_data/test_site/index.html
scrapy/trunk/scrapy/tests/sample_data/test_site/item1.html
scrapy/trunk/scrapy/tests/sample_data/test_site/item2.html
scrapy/trunk/scrapy/tests/test_c14nurls.py
scrapy/trunk/scrapy/tests/test_defaultencoding.py
scrapy/trunk/scrapy/tests/test_dependencies.py
scrapy/trunk/scrapy/tests/test_engine.py
scrapy/trunk/scrapy/tests/test_http_request.py
scrapy/trunk/scrapy/tests/test_http_response.py
scrapy/trunk/scrapy/tests/test_http_url.py
scrapy/trunk/scrapy/tests/test_libxml2.py
scrapy/trunk/scrapy/tests/test_link.py
scrapy/trunk/scrapy/tests/test_link_extraction.py
scrapy/trunk/scrapy/tests/test_serialization.py
scrapy/trunk/scrapy/tests/test_spidermonkey.py
scrapy/trunk/scrapy/tests/test_spiders/__init__.py
scrapy/trunk/scrapy/tests/test_spiders/testplugin.py
scrapy/trunk/scrapy/tests/test_stats.py
scrapy/trunk/scrapy/tests/test_storedb.py
scrapy/trunk/scrapy/tests/test_text_extraction.py
scrapy/trunk/scrapy/tests/test_utils_datatypes.py
scrapy/trunk/scrapy/tests/test_utils_url.py
scrapy/trunk/scrapy/tests/test_xpath.py
scrapy/trunk/scrapy/utils/__init__.py
scrapy/trunk/scrapy/utils/c14n.py
scrapy/trunk/scrapy/utils/datatypes.py
scrapy/trunk/scrapy/utils/db.py
scrapy/trunk/scrapy/utils/display.py
scrapy/trunk/scrapy/utils/misc.py
scrapy/trunk/scrapy/utils/python.py
scrapy/trunk/scrapy/utils/serialization.py
scrapy/trunk/scrapy/utils/url.py
scrapy/trunk/scrapy/xpath/__init__.py
scrapy/trunk/scrapy/xpath/constructors.py
scrapy/trunk/scrapy/xpath/document.py
scrapy/trunk/scrapy/xpath/extension.py
scrapy/trunk/scrapy/xpath/iterator.py
scrapy/trunk/scrapy/xpath/selector.py
scrapy/trunk/scrapy/xpath/types.py
==================
37ca8701;Pablo Hoffman;2008-06-28 22:57:47 +0000;removed unused dir dev.scrapy.org
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4024

==
==================
72949991;Pablo Hoffman;2008-06-28 22:56:32 +0000;moved dev.scrapy.org/htdocs to static.scrapy.org
--HG--
rename : sites/dev.scrapy.org/htdocs/asc.png => sites/static.scrapy.org/asc.png
rename : sites/dev.scrapy.org/htdocs/attachment.png => sites/static.scrapy.org/attachment.png
rename : sites/dev.scrapy.org/htdocs/changeset.png => sites/static.scrapy.org/changeset.png
rename : sites/dev.scrapy.org/htdocs/closedticket.png => sites/static.scrapy.org/closedticket.png
rename : sites/dev.scrapy.org/htdocs/collapsed.png => sites/static.scrapy.org/collapsed.png
rename : sites/dev.scrapy.org/htdocs/css/about.css => sites/static.scrapy.org/css/about.css
rename : sites/dev.scrapy.org/htdocs/css/admin.css => sites/static.scrapy.org/css/admin.css
rename : sites/dev.scrapy.org/htdocs/css/browser.css => sites/static.scrapy.org/css/browser.css
rename : sites/dev.scrapy.org/htdocs/css/changeset.css => sites/static.scrapy.org/css/changeset.css
rename : sites/dev.scrapy.org/htdocs/css/code.css => sites/static.scrapy.org/css/code.css
rename : sites/dev.scrapy.org/htdocs/css/diff.css => sites/static.scrapy.org/css/diff.css
rename : sites/dev.scrapy.org/htdocs/css/prefs.css => sites/static.scrapy.org/css/prefs.css
rename : sites/dev.scrapy.org/htdocs/css/report.css => sites/static.scrapy.org/css/report.css
rename : sites/dev.scrapy.org/htdocs/css/roadmap.css => sites/static.scrapy.org/css/roadmap.css
rename : sites/dev.scrapy.org/htdocs/css/search.css => sites/static.scrapy.org/css/search.css
rename : sites/dev.scrapy.org/htdocs/css/ticket.css => sites/static.scrapy.org/css/ticket.css
rename : sites/dev.scrapy.org/htdocs/css/timeline.css => sites/static.scrapy.org/css/timeline.css
rename : sites/dev.scrapy.org/htdocs/css/trac-0.11rc2.css.diff => sites/static.scrapy.org/css/trac-0.11rc2.css.diff
rename : sites/dev.scrapy.org/htdocs/css/trac.css => sites/static.scrapy.org/css/trac.css
rename : sites/dev.scrapy.org/htdocs/css/wiki.css => sites/static.scrapy.org/css/wiki.css
rename : sites/dev.scrapy.org/htdocs/desc.png => sites/static.scrapy.org/desc.png
rename : sites/dev.scrapy.org/htdocs/dots.gif => sites/static.scrapy.org/dots.gif
rename : sites/dev.scrapy.org/htdocs/draft.png => sites/static.scrapy.org/draft.png
rename : sites/dev.scrapy.org/htdocs/edit_toolbar.png => sites/static.scrapy.org/edit_toolbar.png
rename : sites/dev.scrapy.org/htdocs/editedticket.png => sites/static.scrapy.org/editedticket.png
rename : sites/dev.scrapy.org/htdocs/envelope.png => sites/static.scrapy.org/envelope.png
rename : sites/dev.scrapy.org/htdocs/expanded.png => sites/static.scrapy.org/expanded.png
rename : sites/dev.scrapy.org/htdocs/expander_normal.png => sites/static.scrapy.org/expander_normal.png
rename : sites/dev.scrapy.org/htdocs/expander_normal_hover.png => sites/static.scrapy.org/expander_normal_hover.png
rename : sites/dev.scrapy.org/htdocs/expander_open.png => sites/static.scrapy.org/expander_open.png
rename : sites/dev.scrapy.org/htdocs/expander_open_hover.png => sites/static.scrapy.org/expander_open_hover.png
rename : sites/dev.scrapy.org/htdocs/extlink.gif => sites/static.scrapy.org/extlink.gif
rename : sites/dev.scrapy.org/htdocs/feed.png => sites/static.scrapy.org/feed.png
rename : sites/dev.scrapy.org/htdocs/file.png => sites/static.scrapy.org/file.png
rename : sites/dev.scrapy.org/htdocs/folder.png => sites/static.scrapy.org/folder.png
rename : sites/dev.scrapy.org/htdocs/guide/basic-workflow.png => sites/static.scrapy.org/guide/basic-workflow.png
rename : sites/dev.scrapy.org/htdocs/guide/original-workflow.png => sites/static.scrapy.org/guide/original-workflow.png
rename : sites/dev.scrapy.org/htdocs/ics.png => sites/static.scrapy.org/ics.png
rename : sites/dev.scrapy.org/htdocs/imggrid.png => sites/static.scrapy.org/imggrid.png
rename : sites/dev.scrapy.org/htdocs/js/blame.js => sites/static.scrapy.org/js/blame.js
rename : sites/dev.scrapy.org/htdocs/js/diff.js => sites/static.scrapy.org/js/diff.js
rename : sites/dev.scrapy.org/htdocs/js/expand_dir.js => sites/static.scrapy.org/js/expand_dir.js
rename : sites/dev.scrapy.org/htdocs/js/folding.js => sites/static.scrapy.org/js/folding.js
rename : sites/dev.scrapy.org/htdocs/js/ie_pre7_hacks.js => sites/static.scrapy.org/js/ie_pre7_hacks.js
rename : sites/dev.scrapy.org/htdocs/js/jquery.js => sites/static.scrapy.org/js/jquery.js
rename : sites/dev.scrapy.org/htdocs/js/keyboard_nav.js => sites/static.scrapy.org/js/keyboard_nav.js
rename : sites/dev.scrapy.org/htdocs/js/noconflict.js => sites/static.scrapy.org/js/noconflict.js
rename : sites/dev.scrapy.org/htdocs/js/query.js => sites/static.scrapy.org/js/query.js
rename : sites/dev.scrapy.org/htdocs/js/search.js => sites/static.scrapy.org/js/search.js
rename : sites/dev.scrapy.org/htdocs/js/suggest.js => sites/static.scrapy.org/js/suggest.js
rename : sites/dev.scrapy.org/htdocs/js/trac.js => sites/static.scrapy.org/js/trac.js
rename : sites/dev.scrapy.org/htdocs/js/wikitoolbar.js => sites/static.scrapy.org/js/wikitoolbar.js
rename : sites/dev.scrapy.org/htdocs/loading.gif => sites/static.scrapy.org/loading.gif
rename : sites/dev.scrapy.org/htdocs/lock-locked.png => sites/static.scrapy.org/lock-locked.png
rename : sites/dev.scrapy.org/htdocs/logo.jpg => sites/static.scrapy.org/logo.jpg
rename : sites/dev.scrapy.org/htdocs/main-bg.jpg => sites/static.scrapy.org/main-bg.jpg
rename : sites/dev.scrapy.org/htdocs/milestone.png => sites/static.scrapy.org/milestone.png
rename : sites/dev.scrapy.org/htdocs/newticket.png => sites/static.scrapy.org/newticket.png
rename : sites/dev.scrapy.org/htdocs/parent.png => sites/static.scrapy.org/parent.png
rename : sites/dev.scrapy.org/htdocs/python.png => sites/static.scrapy.org/python.png
rename : sites/dev.scrapy.org/htdocs/topbar_gradient.png => sites/static.scrapy.org/topbar_gradient.png
rename : sites/dev.scrapy.org/htdocs/topbar_gradient2.png => sites/static.scrapy.org/topbar_gradient2.png
rename : sites/dev.scrapy.org/htdocs/trac.ico => sites/static.scrapy.org/trac.ico
rename : sites/dev.scrapy.org/htdocs/trac_banner.png => sites/static.scrapy.org/trac_banner.png
rename : sites/dev.scrapy.org/htdocs/trac_logo_mini.png => sites/static.scrapy.org/trac_logo_mini.png
rename : sites/dev.scrapy.org/htdocs/vgradient.png => sites/static.scrapy.org/vgradient.png
rename : sites/dev.scrapy.org/htdocs/wiki.png => sites/static.scrapy.org/wiki.png
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4023

==

sites/dev.scrapy.org/conf/trac-0.11rc2.ini.diff
sites/dev.scrapy.org/conf/trac.ini
sites/static.scrapy.org/asc.png
sites/static.scrapy.org/attachment.png
sites/static.scrapy.org/changeset.png
sites/static.scrapy.org/closedticket.png
sites/static.scrapy.org/collapsed.png
sites/static.scrapy.org/css/about.css
sites/static.scrapy.org/css/admin.css
sites/static.scrapy.org/css/browser.css
sites/static.scrapy.org/css/changeset.css
sites/static.scrapy.org/css/code.css
sites/static.scrapy.org/css/diff.css
sites/static.scrapy.org/css/prefs.css
sites/static.scrapy.org/css/report.css
sites/static.scrapy.org/css/roadmap.css
sites/static.scrapy.org/css/search.css
sites/static.scrapy.org/css/ticket.css
sites/static.scrapy.org/css/timeline.css
sites/static.scrapy.org/css/trac-0.11rc2.css.diff
sites/static.scrapy.org/css/trac.css
sites/static.scrapy.org/css/wiki.css
sites/static.scrapy.org/desc.png
sites/static.scrapy.org/dots.gif
sites/static.scrapy.org/draft.png
sites/static.scrapy.org/edit_toolbar.png
sites/static.scrapy.org/editedticket.png
sites/static.scrapy.org/envelope.png
sites/static.scrapy.org/expanded.png
sites/static.scrapy.org/expander_normal.png
sites/static.scrapy.org/expander_normal_hover.png
sites/static.scrapy.org/expander_open.png
sites/static.scrapy.org/expander_open_hover.png
sites/static.scrapy.org/extlink.gif
sites/static.scrapy.org/feed.png
sites/static.scrapy.org/file.png
sites/static.scrapy.org/folder.png
sites/static.scrapy.org/guide/basic-workflow.png
sites/static.scrapy.org/guide/original-workflow.png
sites/static.scrapy.org/ics.png
sites/static.scrapy.org/imggrid.png
sites/static.scrapy.org/js/blame.js
sites/static.scrapy.org/js/diff.js
sites/static.scrapy.org/js/expand_dir.js
sites/static.scrapy.org/js/folding.js
sites/static.scrapy.org/js/ie_pre7_hacks.js
sites/static.scrapy.org/js/jquery.js
sites/static.scrapy.org/js/keyboard_nav.js
sites/static.scrapy.org/js/noconflict.js
sites/static.scrapy.org/js/query.js
sites/static.scrapy.org/js/search.js
sites/static.scrapy.org/js/suggest.js
sites/static.scrapy.org/js/trac.js
sites/static.scrapy.org/js/wikitoolbar.js
sites/static.scrapy.org/loading.gif
sites/static.scrapy.org/lock-locked.png
sites/static.scrapy.org/logo.jpg
sites/static.scrapy.org/main-bg.jpg
sites/static.scrapy.org/milestone.png
sites/static.scrapy.org/newticket.png
sites/static.scrapy.org/parent.png
sites/static.scrapy.org/python.png
sites/static.scrapy.org/topbar_gradient.png
sites/static.scrapy.org/topbar_gradient2.png
sites/static.scrapy.org/trac.ico
sites/static.scrapy.org/trac_banner.png
sites/static.scrapy.org/trac_logo_mini.png
sites/static.scrapy.org/vgradient.png
sites/static.scrapy.org/wiki.png
==================
ebb4b978;Pablo Hoffman;2008-06-28 22:49:48 +0000;removed executable bit from logo.jpg
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4022

==

sites/dev.scrapy.org/htdocs/logo.jpg
==================
c382eb2d;Pablo Hoffman;2008-06-28 22:49:01 +0000;commited entire static.scrapy.org tree
--HG--
rename : sites/dev.scrapy.org/htdocs/images/logo.jpg => sites/dev.scrapy.org/htdocs/logo.jpg
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4021

==

sites/dev.scrapy.org/htdocs/asc.png
sites/dev.scrapy.org/htdocs/attachment.png
sites/dev.scrapy.org/htdocs/changeset.png
sites/dev.scrapy.org/htdocs/closedticket.png
sites/dev.scrapy.org/htdocs/collapsed.png
sites/dev.scrapy.org/htdocs/css/trac.css
sites/dev.scrapy.org/htdocs/desc.png
sites/dev.scrapy.org/htdocs/dots.gif
sites/dev.scrapy.org/htdocs/draft.png
sites/dev.scrapy.org/htdocs/edit_toolbar.png
sites/dev.scrapy.org/htdocs/editedticket.png
sites/dev.scrapy.org/htdocs/envelope.png
sites/dev.scrapy.org/htdocs/expanded.png
sites/dev.scrapy.org/htdocs/expander_normal.png
sites/dev.scrapy.org/htdocs/expander_normal_hover.png
sites/dev.scrapy.org/htdocs/expander_open.png
sites/dev.scrapy.org/htdocs/expander_open_hover.png
sites/dev.scrapy.org/htdocs/extlink.gif
sites/dev.scrapy.org/htdocs/feed.png
sites/dev.scrapy.org/htdocs/file.png
sites/dev.scrapy.org/htdocs/folder.png
sites/dev.scrapy.org/htdocs/guide/basic-workflow.png
sites/dev.scrapy.org/htdocs/guide/original-workflow.png
sites/dev.scrapy.org/htdocs/ics.png
sites/dev.scrapy.org/htdocs/imggrid.png
sites/dev.scrapy.org/htdocs/js/blame.js
sites/dev.scrapy.org/htdocs/js/diff.js
sites/dev.scrapy.org/htdocs/js/expand_dir.js
sites/dev.scrapy.org/htdocs/js/folding.js
sites/dev.scrapy.org/htdocs/js/ie_pre7_hacks.js
sites/dev.scrapy.org/htdocs/js/jquery.js
sites/dev.scrapy.org/htdocs/js/keyboard_nav.js
sites/dev.scrapy.org/htdocs/js/noconflict.js
sites/dev.scrapy.org/htdocs/js/query.js
sites/dev.scrapy.org/htdocs/js/search.js
sites/dev.scrapy.org/htdocs/js/suggest.js
sites/dev.scrapy.org/htdocs/js/trac.js
sites/dev.scrapy.org/htdocs/js/wikitoolbar.js
sites/dev.scrapy.org/htdocs/loading.gif
sites/dev.scrapy.org/htdocs/lock-locked.png
sites/dev.scrapy.org/htdocs/logo.jpg
sites/dev.scrapy.org/htdocs/main-bg.jpg
sites/dev.scrapy.org/htdocs/milestone.png
sites/dev.scrapy.org/htdocs/newticket.png
sites/dev.scrapy.org/htdocs/parent.png
sites/dev.scrapy.org/htdocs/python.png
sites/dev.scrapy.org/htdocs/topbar_gradient.png
sites/dev.scrapy.org/htdocs/topbar_gradient2.png
sites/dev.scrapy.org/htdocs/trac.ico
sites/dev.scrapy.org/htdocs/trac_banner.png
sites/dev.scrapy.org/htdocs/trac_logo_mini.png
sites/dev.scrapy.org/htdocs/vgradient.png
sites/dev.scrapy.org/htdocs/wiki.png
==================
b63cda56;Pablo Hoffman;2008-06-28 22:02:49 +0000;added scrapy logo
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4020

==

sites/dev.scrapy.org/htdocs/images/logo.jpg
==================
46300ec5;Daniel Grana;2008-06-27 19:20:32 +0000;move module imports
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4019

==

sites/scrapy.org/scrapyorg/article/templatetags/article_tags.py
sites/scrapy.org/scrapyorg/article/urls.py
sites/scrapy.org/scrapyorg/article/views.py
sites/scrapy.org/scrapyorg/blog/templatetags/lastblogentry.py
sites/scrapy.org/scrapyorg/blog/urls.py
sites/scrapy.org/scrapyorg/download/templatetags/download_tags.py
sites/scrapy.org/scrapyorg/download/urls.py
sites/scrapy.org/scrapyorg/download/views.py
sites/scrapy.org/scrapyorg/link/templatetags/link_tags.py
sites/scrapy.org/scrapyorg/link/urls.py
sites/scrapy.org/scrapyorg/link/views.py
sites/scrapy.org/scrapyorg/local_settings.py.template
sites/scrapy.org/scrapyorg/settings.py
sites/scrapy.org/scrapyorg/urls.py
==================
1f5bb2a7;Daniel Grana;2008-06-27 17:36:56 +0000;remove apps and move README
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4018

==

sites/scrapy.org/README
sites/scrapy.org/scrapyorg/apps/__init__.py
==================
40c9d60d;Daniel Grana;2008-06-27 17:32:27 +0000;big move move
--HG--
rename : sites/scrapy.org/scrapyorg/apps/article/__init__.py => sites/scrapy.org/scrapyorg/article/__init__.py
rename : sites/scrapy.org/scrapyorg/apps/article/models.py => sites/scrapy.org/scrapyorg/article/models.py
rename : sites/scrapy.org/scrapyorg/apps/article/templatetags/__init__.py => sites/scrapy.org/scrapyorg/article/templatetags/__init__.py
rename : sites/scrapy.org/scrapyorg/apps/article/templatetags/article_tags.py => sites/scrapy.org/scrapyorg/article/templatetags/article_tags.py
rename : sites/scrapy.org/scrapyorg/apps/article/urls.py => sites/scrapy.org/scrapyorg/article/urls.py
rename : sites/scrapy.org/scrapyorg/apps/article/views.py => sites/scrapy.org/scrapyorg/article/views.py
rename : sites/scrapy.org/scrapyorg/apps/blog/__init__.py => sites/scrapy.org/scrapyorg/blog/__init__.py
rename : sites/scrapy.org/scrapyorg/apps/blog/feeds.py => sites/scrapy.org/scrapyorg/blog/feeds.py
rename : sites/scrapy.org/scrapyorg/apps/blog/models.py => sites/scrapy.org/scrapyorg/blog/models.py
rename : sites/scrapy.org/scrapyorg/apps/blog/templatetags/__init__.py => sites/scrapy.org/scrapyorg/blog/templatetags/__init__.py
rename : sites/scrapy.org/scrapyorg/apps/blog/templatetags/lastblogentry.py => sites/scrapy.org/scrapyorg/blog/templatetags/lastblogentry.py
rename : sites/scrapy.org/scrapyorg/apps/blog/urls.py => sites/scrapy.org/scrapyorg/blog/urls.py
rename : sites/scrapy.org/scrapyorg/apps/download/__init__.py => sites/scrapy.org/scrapyorg/download/__init__.py
rename : sites/scrapy.org/scrapyorg/apps/download/models.py => sites/scrapy.org/scrapyorg/download/models.py
rename : sites/scrapy.org/scrapyorg/apps/download/templatetags/__init__.py => sites/scrapy.org/scrapyorg/download/templatetags/__init__.py
rename : sites/scrapy.org/scrapyorg/apps/download/templatetags/download_tags.py => sites/scrapy.org/scrapyorg/download/templatetags/download_tags.py
rename : sites/scrapy.org/scrapyorg/apps/download/urls.py => sites/scrapy.org/scrapyorg/download/urls.py
rename : sites/scrapy.org/scrapyorg/apps/download/views.py => sites/scrapy.org/scrapyorg/download/views.py
rename : sites/scrapy.org/scrapyorg/apps/link/__init__.py => sites/scrapy.org/scrapyorg/link/__init__.py
rename : sites/scrapy.org/scrapyorg/apps/link/models.py => sites/scrapy.org/scrapyorg/link/models.py
rename : sites/scrapy.org/scrapyorg/apps/link/templatetags/__init__.py => sites/scrapy.org/scrapyorg/link/templatetags/__init__.py
rename : sites/scrapy.org/scrapyorg/apps/link/templatetags/link_tags.py => sites/scrapy.org/scrapyorg/link/templatetags/link_tags.py
rename : sites/scrapy.org/scrapyorg/apps/link/urls.py => sites/scrapy.org/scrapyorg/link/urls.py
rename : sites/scrapy.org/scrapyorg/apps/link/views.py => sites/scrapy.org/scrapyorg/link/views.py
rename : sites/scrapy.org/scrapyorg/static/images/box-borders-bottom.gif => sites/scrapy.org/static/images/box-borders-bottom.gif
rename : sites/scrapy.org/scrapyorg/static/images/box-borders-bottom.png => sites/scrapy.org/static/images/box-borders-bottom.png
rename : sites/scrapy.org/scrapyorg/static/images/box-borders-top.png => sites/scrapy.org/static/images/box-borders-top.png
rename : sites/scrapy.org/scrapyorg/static/images/footer-bg.jpg => sites/scrapy.org/static/images/footer-bg.jpg
rename : sites/scrapy.org/scrapyorg/static/images/icon-arrow.gif => sites/scrapy.org/static/images/icon-arrow.gif
rename : sites/scrapy.org/scrapyorg/static/images/icon-author.gif => sites/scrapy.org/static/images/icon-author.gif
rename : sites/scrapy.org/scrapyorg/static/images/logo.jpg => sites/scrapy.org/static/images/logo.jpg
rename : sites/scrapy.org/scrapyorg/static/images/main-bg.jpg => sites/scrapy.org/static/images/main-bg.jpg
rename : sites/scrapy.org/scrapyorg/static/style/style.css => sites/scrapy.org/static/style/style.css
rename : sites/scrapy.org/scrapyorg/templates/base.html => sites/scrapy.org/templates/base.html
rename : sites/scrapy.org/scrapyorg/templates/base_home.html => sites/scrapy.org/templates/base_home.html
rename : sites/scrapy.org/scrapyorg/templates/base_weblog.html => sites/scrapy.org/templates/base_weblog.html
rename : sites/scrapy.org/scrapyorg/templates/blog/entry_archive.html => sites/scrapy.org/templates/blog/entry_archive.html
rename : sites/scrapy.org/scrapyorg/templates/blog/entry_archive_day.html => sites/scrapy.org/templates/blog/entry_archive_day.html
rename : sites/scrapy.org/scrapyorg/templates/blog/entry_archive_month.html => sites/scrapy.org/templates/blog/entry_archive_month.html
rename : sites/scrapy.org/scrapyorg/templates/blog/entry_archive_year.html => sites/scrapy.org/templates/blog/entry_archive_year.html
rename : sites/scrapy.org/scrapyorg/templates/blog/entry_detail.html => sites/scrapy.org/templates/blog/entry_detail.html
rename : sites/scrapy.org/scrapyorg/templates/home.html => sites/scrapy.org/templates/home.html
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4017

==

sites/scrapy.org/scrapyorg/article/__init__.py
sites/scrapy.org/scrapyorg/article/models.py
sites/scrapy.org/scrapyorg/article/templatetags/__init__.py
sites/scrapy.org/scrapyorg/article/templatetags/article_tags.py
sites/scrapy.org/scrapyorg/article/urls.py
sites/scrapy.org/scrapyorg/article/views.py
sites/scrapy.org/scrapyorg/blog/__init__.py
sites/scrapy.org/scrapyorg/blog/feeds.py
sites/scrapy.org/scrapyorg/blog/models.py
sites/scrapy.org/scrapyorg/blog/templatetags/__init__.py
sites/scrapy.org/scrapyorg/blog/templatetags/lastblogentry.py
sites/scrapy.org/scrapyorg/blog/urls.py
sites/scrapy.org/scrapyorg/download/__init__.py
sites/scrapy.org/scrapyorg/download/models.py
sites/scrapy.org/scrapyorg/download/templatetags/__init__.py
sites/scrapy.org/scrapyorg/download/templatetags/download_tags.py
sites/scrapy.org/scrapyorg/download/urls.py
sites/scrapy.org/scrapyorg/download/views.py
sites/scrapy.org/scrapyorg/link/__init__.py
sites/scrapy.org/scrapyorg/link/models.py
sites/scrapy.org/scrapyorg/link/templatetags/__init__.py
sites/scrapy.org/scrapyorg/link/templatetags/link_tags.py
sites/scrapy.org/scrapyorg/link/urls.py
sites/scrapy.org/scrapyorg/link/views.py
sites/scrapy.org/static/images/box-borders-bottom.gif
sites/scrapy.org/static/images/box-borders-bottom.png
sites/scrapy.org/static/images/box-borders-top.png
sites/scrapy.org/static/images/footer-bg.jpg
sites/scrapy.org/static/images/icon-arrow.gif
sites/scrapy.org/static/images/icon-author.gif
sites/scrapy.org/static/images/logo.jpg
sites/scrapy.org/static/images/main-bg.jpg
sites/scrapy.org/static/style/style.css
sites/scrapy.org/templates/base.html
sites/scrapy.org/templates/base_home.html
sites/scrapy.org/templates/base_weblog.html
sites/scrapy.org/templates/blog/entry_archive.html
sites/scrapy.org/templates/blog/entry_archive_day.html
sites/scrapy.org/templates/blog/entry_archive_month.html
sites/scrapy.org/templates/blog/entry_archive_year.html
sites/scrapy.org/templates/blog/entry_detail.html
sites/scrapy.org/templates/home.html
==================
7cf813f5;Daniel Grana;2008-06-27 17:30:19 +0000;mv scrapy_site scrapyorg
--HG--
rename : sites/scrapy.org/scrapy_site/README => sites/scrapy.org/scrapyorg/README
rename : sites/scrapy.org/scrapy_site/__init__.py => sites/scrapy.org/scrapyorg/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/__init__.py => sites/scrapy.org/scrapyorg/apps/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/article/__init__.py => sites/scrapy.org/scrapyorg/apps/article/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/article/models.py => sites/scrapy.org/scrapyorg/apps/article/models.py
rename : sites/scrapy.org/scrapy_site/apps/article/templatetags/__init__.py => sites/scrapy.org/scrapyorg/apps/article/templatetags/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/article/templatetags/article_tags.py => sites/scrapy.org/scrapyorg/apps/article/templatetags/article_tags.py
rename : sites/scrapy.org/scrapy_site/apps/article/urls.py => sites/scrapy.org/scrapyorg/apps/article/urls.py
rename : sites/scrapy.org/scrapy_site/apps/article/views.py => sites/scrapy.org/scrapyorg/apps/article/views.py
rename : sites/scrapy.org/scrapy_site/apps/blog/__init__.py => sites/scrapy.org/scrapyorg/apps/blog/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/blog/feeds.py => sites/scrapy.org/scrapyorg/apps/blog/feeds.py
rename : sites/scrapy.org/scrapy_site/apps/blog/models.py => sites/scrapy.org/scrapyorg/apps/blog/models.py
rename : sites/scrapy.org/scrapy_site/apps/blog/templatetags/__init__.py => sites/scrapy.org/scrapyorg/apps/blog/templatetags/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/blog/templatetags/lastblogentry.py => sites/scrapy.org/scrapyorg/apps/blog/templatetags/lastblogentry.py
rename : sites/scrapy.org/scrapy_site/apps/blog/urls.py => sites/scrapy.org/scrapyorg/apps/blog/urls.py
rename : sites/scrapy.org/scrapy_site/apps/download/__init__.py => sites/scrapy.org/scrapyorg/apps/download/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/download/models.py => sites/scrapy.org/scrapyorg/apps/download/models.py
rename : sites/scrapy.org/scrapy_site/apps/download/templatetags/__init__.py => sites/scrapy.org/scrapyorg/apps/download/templatetags/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/download/templatetags/download_tags.py => sites/scrapy.org/scrapyorg/apps/download/templatetags/download_tags.py
rename : sites/scrapy.org/scrapy_site/apps/download/urls.py => sites/scrapy.org/scrapyorg/apps/download/urls.py
rename : sites/scrapy.org/scrapy_site/apps/download/views.py => sites/scrapy.org/scrapyorg/apps/download/views.py
rename : sites/scrapy.org/scrapy_site/apps/link/__init__.py => sites/scrapy.org/scrapyorg/apps/link/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/link/models.py => sites/scrapy.org/scrapyorg/apps/link/models.py
rename : sites/scrapy.org/scrapy_site/apps/link/templatetags/__init__.py => sites/scrapy.org/scrapyorg/apps/link/templatetags/__init__.py
rename : sites/scrapy.org/scrapy_site/apps/link/templatetags/link_tags.py => sites/scrapy.org/scrapyorg/apps/link/templatetags/link_tags.py
rename : sites/scrapy.org/scrapy_site/apps/link/urls.py => sites/scrapy.org/scrapyorg/apps/link/urls.py
rename : sites/scrapy.org/scrapy_site/apps/link/views.py => sites/scrapy.org/scrapyorg/apps/link/views.py
rename : sites/scrapy.org/scrapy_site/lib/__init__.py => sites/scrapy.org/scrapyorg/lib/__init__.py
rename : sites/scrapy.org/scrapy_site/lib/templatetags.py => sites/scrapy.org/scrapyorg/lib/templatetags.py
rename : sites/scrapy.org/scrapy_site/local_settings.py.template => sites/scrapy.org/scrapyorg/local_settings.py.template
rename : sites/scrapy.org/scrapy_site/manage.py => sites/scrapy.org/scrapyorg/manage.py
rename : sites/scrapy.org/scrapy_site/settings.py => sites/scrapy.org/scrapyorg/settings.py
rename : sites/scrapy.org/scrapy_site/static/images/box-borders-bottom.gif => sites/scrapy.org/scrapyorg/static/images/box-borders-bottom.gif
rename : sites/scrapy.org/scrapy_site/static/images/box-borders-bottom.png => sites/scrapy.org/scrapyorg/static/images/box-borders-bottom.png
rename : sites/scrapy.org/scrapy_site/static/images/box-borders-top.png => sites/scrapy.org/scrapyorg/static/images/box-borders-top.png
rename : sites/scrapy.org/scrapy_site/static/images/footer-bg.jpg => sites/scrapy.org/scrapyorg/static/images/footer-bg.jpg
rename : sites/scrapy.org/scrapy_site/static/images/icon-arrow.gif => sites/scrapy.org/scrapyorg/static/images/icon-arrow.gif
rename : sites/scrapy.org/scrapy_site/static/images/icon-author.gif => sites/scrapy.org/scrapyorg/static/images/icon-author.gif
rename : sites/scrapy.org/scrapy_site/static/images/logo.jpg => sites/scrapy.org/scrapyorg/static/images/logo.jpg
rename : sites/scrapy.org/scrapy_site/static/images/main-bg.jpg => sites/scrapy.org/scrapyorg/static/images/main-bg.jpg
rename : sites/scrapy.org/scrapy_site/static/style/style.css => sites/scrapy.org/scrapyorg/static/style/style.css
rename : sites/scrapy.org/scrapy_site/templates/base.html => sites/scrapy.org/scrapyorg/templates/base.html
rename : sites/scrapy.org/scrapy_site/templates/base_home.html => sites/scrapy.org/scrapyorg/templates/base_home.html
rename : sites/scrapy.org/scrapy_site/templates/base_weblog.html => sites/scrapy.org/scrapyorg/templates/base_weblog.html
rename : sites/scrapy.org/scrapy_site/templates/blog/entry_archive.html => sites/scrapy.org/scrapyorg/templates/blog/entry_archive.html
rename : sites/scrapy.org/scrapy_site/templates/blog/entry_archive_day.html => sites/scrapy.org/scrapyorg/templates/blog/entry_archive_day.html
rename : sites/scrapy.org/scrapy_site/templates/blog/entry_archive_month.html => sites/scrapy.org/scrapyorg/templates/blog/entry_archive_month.html
rename : sites/scrapy.org/scrapy_site/templates/blog/entry_archive_year.html => sites/scrapy.org/scrapyorg/templates/blog/entry_archive_year.html
rename : sites/scrapy.org/scrapy_site/templates/blog/entry_detail.html => sites/scrapy.org/scrapyorg/templates/blog/entry_detail.html
rename : sites/scrapy.org/scrapy_site/templates/home.html => sites/scrapy.org/scrapyorg/templates/home.html
rename : sites/scrapy.org/scrapy_site/urls.py => sites/scrapy.org/scrapyorg/urls.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4016

==

sites/scrapy.org/scrapyorg/README
sites/scrapy.org/scrapyorg/__init__.py
sites/scrapy.org/scrapyorg/apps/__init__.py
sites/scrapy.org/scrapyorg/apps/article/__init__.py
sites/scrapy.org/scrapyorg/apps/article/models.py
sites/scrapy.org/scrapyorg/apps/article/templatetags/__init__.py
sites/scrapy.org/scrapyorg/apps/article/templatetags/article_tags.py
sites/scrapy.org/scrapyorg/apps/article/urls.py
sites/scrapy.org/scrapyorg/apps/article/views.py
sites/scrapy.org/scrapyorg/apps/blog/__init__.py
sites/scrapy.org/scrapyorg/apps/blog/feeds.py
sites/scrapy.org/scrapyorg/apps/blog/models.py
sites/scrapy.org/scrapyorg/apps/blog/templatetags/__init__.py
sites/scrapy.org/scrapyorg/apps/blog/templatetags/lastblogentry.py
sites/scrapy.org/scrapyorg/apps/blog/urls.py
sites/scrapy.org/scrapyorg/apps/download/__init__.py
sites/scrapy.org/scrapyorg/apps/download/models.py
sites/scrapy.org/scrapyorg/apps/download/templatetags/__init__.py
sites/scrapy.org/scrapyorg/apps/download/templatetags/download_tags.py
sites/scrapy.org/scrapyorg/apps/download/urls.py
sites/scrapy.org/scrapyorg/apps/download/views.py
sites/scrapy.org/scrapyorg/apps/link/__init__.py
sites/scrapy.org/scrapyorg/apps/link/models.py
sites/scrapy.org/scrapyorg/apps/link/templatetags/__init__.py
sites/scrapy.org/scrapyorg/apps/link/templatetags/link_tags.py
sites/scrapy.org/scrapyorg/apps/link/urls.py
sites/scrapy.org/scrapyorg/apps/link/views.py
sites/scrapy.org/scrapyorg/lib/__init__.py
sites/scrapy.org/scrapyorg/lib/templatetags.py
sites/scrapy.org/scrapyorg/local_settings.py.template
sites/scrapy.org/scrapyorg/manage.py
sites/scrapy.org/scrapyorg/settings.py
sites/scrapy.org/scrapyorg/static/images/box-borders-bottom.gif
sites/scrapy.org/scrapyorg/static/images/box-borders-bottom.png
sites/scrapy.org/scrapyorg/static/images/box-borders-top.png
sites/scrapy.org/scrapyorg/static/images/footer-bg.jpg
sites/scrapy.org/scrapyorg/static/images/icon-arrow.gif
sites/scrapy.org/scrapyorg/static/images/icon-author.gif
sites/scrapy.org/scrapyorg/static/images/logo.jpg
sites/scrapy.org/scrapyorg/static/images/main-bg.jpg
sites/scrapy.org/scrapyorg/static/style/style.css
sites/scrapy.org/scrapyorg/templates/base.html
sites/scrapy.org/scrapyorg/templates/base_home.html
sites/scrapy.org/scrapyorg/templates/base_weblog.html
sites/scrapy.org/scrapyorg/templates/blog/entry_archive.html
sites/scrapy.org/scrapyorg/templates/blog/entry_archive_day.html
sites/scrapy.org/scrapyorg/templates/blog/entry_archive_month.html
sites/scrapy.org/scrapyorg/templates/blog/entry_archive_year.html
sites/scrapy.org/scrapyorg/templates/blog/entry_detail.html
sites/scrapy.org/scrapyorg/templates/home.html
sites/scrapy.org/scrapyorg/urls.py
==================
9767f190;Ezequiel Rivero;2008-06-27 17:10:06 +0000;styling changes for trac.css.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4015

==

sites/dev.scrapy.org/htdocs/css/changeset.css
sites/dev.scrapy.org/htdocs/css/trac.css
==================
b029be10;anibal;2008-06-27 11:40:06 +0000;adding all the css
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4014

==

sites/dev.scrapy.org/htdocs/css/about.css
sites/dev.scrapy.org/htdocs/css/admin.css
sites/dev.scrapy.org/htdocs/css/browser.css
sites/dev.scrapy.org/htdocs/css/changeset.css
sites/dev.scrapy.org/htdocs/css/code.css
sites/dev.scrapy.org/htdocs/css/diff.css
sites/dev.scrapy.org/htdocs/css/prefs.css
sites/dev.scrapy.org/htdocs/css/report.css
sites/dev.scrapy.org/htdocs/css/roadmap.css
sites/dev.scrapy.org/htdocs/css/search.css
sites/dev.scrapy.org/htdocs/css/ticket.css
sites/dev.scrapy.org/htdocs/css/timeline.css
sites/dev.scrapy.org/htdocs/css/wiki.css
==================
8c3cdbbb;Matias Aguirre;2008-06-27 04:00:57 +0000;Added accessors to Link attributes in GroupLink model
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4013

==

sites/scrapy.org/scrapy_site/apps/link/models.py
==================
5ac926c5;Matias Aguirre;2008-06-27 03:08:01 +0000;Rename site directory because djang crashed with 'site' name, maybe because his site application
--HG--
rename : sites/scrapy.org/site/README => sites/scrapy.org/scrapy_site/README
rename : sites/scrapy.org/site/__init__.py => sites/scrapy.org/scrapy_site/__init__.py
rename : sites/scrapy.org/site/apps/__init__.py => sites/scrapy.org/scrapy_site/apps/__init__.py
rename : sites/scrapy.org/site/apps/article/__init__.py => sites/scrapy.org/scrapy_site/apps/article/__init__.py
rename : sites/scrapy.org/site/apps/article/models.py => sites/scrapy.org/scrapy_site/apps/article/models.py
rename : sites/scrapy.org/site/apps/article/templatetags/__init__.py => sites/scrapy.org/scrapy_site/apps/article/templatetags/__init__.py
rename : sites/scrapy.org/site/apps/article/templatetags/article_tags.py => sites/scrapy.org/scrapy_site/apps/article/templatetags/article_tags.py
rename : sites/scrapy.org/site/apps/article/urls.py => sites/scrapy.org/scrapy_site/apps/article/urls.py
rename : sites/scrapy.org/site/apps/article/views.py => sites/scrapy.org/scrapy_site/apps/article/views.py
rename : sites/scrapy.org/site/apps/blog/__init__.py => sites/scrapy.org/scrapy_site/apps/blog/__init__.py
rename : sites/scrapy.org/site/apps/blog/feeds.py => sites/scrapy.org/scrapy_site/apps/blog/feeds.py
rename : sites/scrapy.org/site/apps/blog/models.py => sites/scrapy.org/scrapy_site/apps/blog/models.py
rename : sites/scrapy.org/site/apps/blog/templatetags/__init__.py => sites/scrapy.org/scrapy_site/apps/blog/templatetags/__init__.py
rename : sites/scrapy.org/site/apps/blog/templatetags/lastblogentry.py => sites/scrapy.org/scrapy_site/apps/blog/templatetags/lastblogentry.py
rename : sites/scrapy.org/site/apps/blog/urls.py => sites/scrapy.org/scrapy_site/apps/blog/urls.py
rename : sites/scrapy.org/site/apps/download/__init__.py => sites/scrapy.org/scrapy_site/apps/download/__init__.py
rename : sites/scrapy.org/site/apps/download/models.py => sites/scrapy.org/scrapy_site/apps/download/models.py
rename : sites/scrapy.org/site/apps/download/templatetags/__init__.py => sites/scrapy.org/scrapy_site/apps/download/templatetags/__init__.py
rename : sites/scrapy.org/site/apps/download/templatetags/download_tags.py => sites/scrapy.org/scrapy_site/apps/download/templatetags/download_tags.py
rename : sites/scrapy.org/site/apps/download/urls.py => sites/scrapy.org/scrapy_site/apps/download/urls.py
rename : sites/scrapy.org/site/apps/download/views.py => sites/scrapy.org/scrapy_site/apps/download/views.py
rename : sites/scrapy.org/site/apps/link/__init__.py => sites/scrapy.org/scrapy_site/apps/link/__init__.py
rename : sites/scrapy.org/site/apps/link/models.py => sites/scrapy.org/scrapy_site/apps/link/models.py
rename : sites/scrapy.org/site/apps/link/templatetags/__init__.py => sites/scrapy.org/scrapy_site/apps/link/templatetags/__init__.py
rename : sites/scrapy.org/site/apps/link/templatetags/link_tags.py => sites/scrapy.org/scrapy_site/apps/link/templatetags/link_tags.py
rename : sites/scrapy.org/site/apps/link/urls.py => sites/scrapy.org/scrapy_site/apps/link/urls.py
rename : sites/scrapy.org/site/apps/link/views.py => sites/scrapy.org/scrapy_site/apps/link/views.py
rename : sites/scrapy.org/site/lib/__init__.py => sites/scrapy.org/scrapy_site/lib/__init__.py
rename : sites/scrapy.org/site/lib/templatetags.py => sites/scrapy.org/scrapy_site/lib/templatetags.py
rename : sites/scrapy.org/site/local_settings.py.template => sites/scrapy.org/scrapy_site/local_settings.py.template
rename : sites/scrapy.org/site/manage.py => sites/scrapy.org/scrapy_site/manage.py
rename : sites/scrapy.org/site/settings.py => sites/scrapy.org/scrapy_site/settings.py
rename : sites/scrapy.org/site/static/images/box-borders-bottom.gif => sites/scrapy.org/scrapy_site/static/images/box-borders-bottom.gif
rename : sites/scrapy.org/site/static/images/box-borders-bottom.png => sites/scrapy.org/scrapy_site/static/images/box-borders-bottom.png
rename : sites/scrapy.org/site/static/images/box-borders-top.png => sites/scrapy.org/scrapy_site/static/images/box-borders-top.png
rename : sites/scrapy.org/site/static/images/footer-bg.jpg => sites/scrapy.org/scrapy_site/static/images/footer-bg.jpg
rename : sites/scrapy.org/site/static/images/icon-arrow.gif => sites/scrapy.org/scrapy_site/static/images/icon-arrow.gif
rename : sites/scrapy.org/site/static/images/icon-author.gif => sites/scrapy.org/scrapy_site/static/images/icon-author.gif
rename : sites/scrapy.org/site/static/images/logo.jpg => sites/scrapy.org/scrapy_site/static/images/logo.jpg
rename : sites/scrapy.org/site/static/images/main-bg.jpg => sites/scrapy.org/scrapy_site/static/images/main-bg.jpg
rename : sites/scrapy.org/site/static/style/style.css => sites/scrapy.org/scrapy_site/static/style/style.css
rename : sites/scrapy.org/site/templates/base.html => sites/scrapy.org/scrapy_site/templates/base.html
rename : sites/scrapy.org/site/templates/base_home.html => sites/scrapy.org/scrapy_site/templates/base_home.html
rename : sites/scrapy.org/site/templates/base_weblog.html => sites/scrapy.org/scrapy_site/templates/base_weblog.html
rename : sites/scrapy.org/site/templates/blog/entry_archive.html => sites/scrapy.org/scrapy_site/templates/blog/entry_archive.html
rename : sites/scrapy.org/site/templates/blog/entry_archive_day.html => sites/scrapy.org/scrapy_site/templates/blog/entry_archive_day.html
rename : sites/scrapy.org/site/templates/blog/entry_archive_month.html => sites/scrapy.org/scrapy_site/templates/blog/entry_archive_month.html
rename : sites/scrapy.org/site/templates/blog/entry_archive_year.html => sites/scrapy.org/scrapy_site/templates/blog/entry_archive_year.html
rename : sites/scrapy.org/site/templates/blog/entry_detail.html => sites/scrapy.org/scrapy_site/templates/blog/entry_detail.html
rename : sites/scrapy.org/site/templates/home.html => sites/scrapy.org/scrapy_site/templates/home.html
rename : sites/scrapy.org/site/urls.py => sites/scrapy.org/scrapy_site/urls.py
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4012

==

sites/scrapy.org/scrapy_site/README
sites/scrapy.org/scrapy_site/__init__.py
sites/scrapy.org/scrapy_site/apps/__init__.py
sites/scrapy.org/scrapy_site/apps/article/__init__.py
sites/scrapy.org/scrapy_site/apps/article/models.py
sites/scrapy.org/scrapy_site/apps/article/templatetags/__init__.py
sites/scrapy.org/scrapy_site/apps/article/templatetags/article_tags.py
sites/scrapy.org/scrapy_site/apps/article/urls.py
sites/scrapy.org/scrapy_site/apps/article/views.py
sites/scrapy.org/scrapy_site/apps/blog/__init__.py
sites/scrapy.org/scrapy_site/apps/blog/feeds.py
sites/scrapy.org/scrapy_site/apps/blog/models.py
sites/scrapy.org/scrapy_site/apps/blog/templatetags/__init__.py
sites/scrapy.org/scrapy_site/apps/blog/templatetags/lastblogentry.py
sites/scrapy.org/scrapy_site/apps/blog/urls.py
sites/scrapy.org/scrapy_site/apps/download/__init__.py
sites/scrapy.org/scrapy_site/apps/download/models.py
sites/scrapy.org/scrapy_site/apps/download/templatetags/__init__.py
sites/scrapy.org/scrapy_site/apps/download/templatetags/download_tags.py
sites/scrapy.org/scrapy_site/apps/download/urls.py
sites/scrapy.org/scrapy_site/apps/download/views.py
sites/scrapy.org/scrapy_site/apps/link/__init__.py
sites/scrapy.org/scrapy_site/apps/link/models.py
sites/scrapy.org/scrapy_site/apps/link/templatetags/__init__.py
sites/scrapy.org/scrapy_site/apps/link/templatetags/link_tags.py
sites/scrapy.org/scrapy_site/apps/link/urls.py
sites/scrapy.org/scrapy_site/apps/link/views.py
sites/scrapy.org/scrapy_site/lib/__init__.py
sites/scrapy.org/scrapy_site/lib/templatetags.py
sites/scrapy.org/scrapy_site/local_settings.py.template
sites/scrapy.org/scrapy_site/manage.py
sites/scrapy.org/scrapy_site/settings.py
sites/scrapy.org/scrapy_site/static/images/box-borders-bottom.gif
sites/scrapy.org/scrapy_site/static/images/box-borders-bottom.png
sites/scrapy.org/scrapy_site/static/images/box-borders-top.png
sites/scrapy.org/scrapy_site/static/images/footer-bg.jpg
sites/scrapy.org/scrapy_site/static/images/icon-arrow.gif
sites/scrapy.org/scrapy_site/static/images/icon-author.gif
sites/scrapy.org/scrapy_site/static/images/logo.jpg
sites/scrapy.org/scrapy_site/static/images/main-bg.jpg
sites/scrapy.org/scrapy_site/static/style/style.css
sites/scrapy.org/scrapy_site/templates/base.html
sites/scrapy.org/scrapy_site/templates/base_home.html
sites/scrapy.org/scrapy_site/templates/base_weblog.html
sites/scrapy.org/scrapy_site/templates/blog/entry_archive.html
sites/scrapy.org/scrapy_site/templates/blog/entry_archive_day.html
sites/scrapy.org/scrapy_site/templates/blog/entry_archive_month.html
sites/scrapy.org/scrapy_site/templates/blog/entry_archive_year.html
sites/scrapy.org/scrapy_site/templates/blog/entry_detail.html
sites/scrapy.org/scrapy_site/templates/home.html
sites/scrapy.org/scrapy_site/urls.py
==================
6ced1f4e;Matias Aguirre;2008-06-27 02:41:04 +0000;Override the correct block, some content from base template was being removed
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4011

==

sites/scrapy.org/site/templates/home.html
==================
f91f0733;Matias Aguirre;2008-06-27 02:40:11 +0000;Add blog templatetag call to retrieve last two post and display in homepage
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%4010

==

sites/scrapy.org/site/templates/base_home.html
==================
b5fe9653;Matias Aguirre;2008-06-27 02:16:00 +0000;Add link url to access position inc/dec views
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%409

==

sites/scrapy.org/site/urls.py
==================
06effebd;Matias Aguirre;2008-06-27 02:10:11 +0000;Rename 'order' field to 'position'
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%408

==

sites/scrapy.org/site/apps/article/models.py
sites/scrapy.org/site/apps/article/urls.py
sites/scrapy.org/site/apps/article/views.py
==================
87b97f07;Matias Aguirre;2008-06-27 02:09:23 +0000;Fix import in templatetag
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%407

==

sites/scrapy.org/site/apps/blog/templatetags/lastblogentry.py
==================
a5aa40c2;Matias Aguirre;2008-06-27 02:07:53 +0000;Added implicit NxN relation between Links and Groups because an order was needed. Added views to inc/dec the position value. This is used for link ordering.
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%406

==

sites/scrapy.org/site/apps/link/models.py
sites/scrapy.org/site/apps/link/templatetags/link_tags.py
sites/scrapy.org/site/apps/link/urls.py
sites/scrapy.org/site/apps/link/views.py
==================
9fa14def;anibal;2008-06-26 16:01:39 +0000; * trac.ini and trac.css added  * both with a diff file (if you want to see only the things I change on default trac-0.11rc2 installation-initenv files)  * images were not commited because they should be taken from Scrapy site or taken and tuned by ezequiel  * if custom images are made for this trac, they should be placed under htdocs/
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%405

==

sites/dev.scrapy.org/conf/trac-0.11rc2.ini.diff
sites/dev.scrapy.org/conf/trac.ini
sites/dev.scrapy.org/htdocs/css/trac-0.11rc2.css.diff
sites/dev.scrapy.org/htdocs/css/trac.css
==================
b4ea1c3a;Pablo Hoffman;2008-06-26 14:59:36 +0000;renamed code.scrapy.org to dev.scrapy.org
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%404

==
==================
468c0d38;Matias Aguirre;2008-06-26 14:36:58 +0000;Django site project. Apps installed:     * Article       This is a simple "article" application with ReST support. Instances could       be marked as "main" and a templatetag retrieve them.
    * Blog
      Django blog application, needs a better integration yet.

    * Download
      Little application to manage "download" links

    * Link
      Little application to manage links (like those displayed on top and in the
      footer)

--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%403

==

sites/scrapy.org/site/README
sites/scrapy.org/site/__init__.py
sites/scrapy.org/site/apps/__init__.py
sites/scrapy.org/site/apps/article/__init__.py
sites/scrapy.org/site/apps/article/models.py
sites/scrapy.org/site/apps/article/templatetags/__init__.py
sites/scrapy.org/site/apps/article/templatetags/article_tags.py
sites/scrapy.org/site/apps/article/urls.py
sites/scrapy.org/site/apps/article/views.py
sites/scrapy.org/site/apps/blog/__init__.py
sites/scrapy.org/site/apps/blog/feeds.py
sites/scrapy.org/site/apps/blog/models.py
sites/scrapy.org/site/apps/blog/templatetags/__init__.py
sites/scrapy.org/site/apps/blog/templatetags/lastblogentry.py
sites/scrapy.org/site/apps/blog/urls.py
sites/scrapy.org/site/apps/download/__init__.py
sites/scrapy.org/site/apps/download/models.py
sites/scrapy.org/site/apps/download/templatetags/__init__.py
sites/scrapy.org/site/apps/download/templatetags/download_tags.py
sites/scrapy.org/site/apps/download/urls.py
sites/scrapy.org/site/apps/download/views.py
sites/scrapy.org/site/apps/link/__init__.py
sites/scrapy.org/site/apps/link/models.py
sites/scrapy.org/site/apps/link/templatetags/__init__.py
sites/scrapy.org/site/apps/link/templatetags/link_tags.py
sites/scrapy.org/site/apps/link/views.py
sites/scrapy.org/site/lib/__init__.py
sites/scrapy.org/site/lib/templatetags.py
sites/scrapy.org/site/local_settings.py.template
sites/scrapy.org/site/manage.py
sites/scrapy.org/site/settings.py
sites/scrapy.org/site/static/images/box-borders-bottom.gif
sites/scrapy.org/site/static/images/box-borders-bottom.png
sites/scrapy.org/site/static/images/box-borders-top.png
sites/scrapy.org/site/static/images/footer-bg.jpg
sites/scrapy.org/site/static/images/icon-arrow.gif
sites/scrapy.org/site/static/images/icon-author.gif
sites/scrapy.org/site/static/images/logo.jpg
sites/scrapy.org/site/static/images/main-bg.jpg
sites/scrapy.org/site/static/style/style.css
sites/scrapy.org/site/templates/base.html
sites/scrapy.org/site/templates/base_home.html
sites/scrapy.org/site/templates/base_weblog.html
sites/scrapy.org/site/templates/blog/entry_archive.html
sites/scrapy.org/site/templates/blog/entry_archive_day.html
sites/scrapy.org/site/templates/blog/entry_archive_month.html
sites/scrapy.org/site/templates/blog/entry_archive_year.html
sites/scrapy.org/site/templates/blog/entry_detail.html
sites/scrapy.org/site/templates/home.html
sites/scrapy.org/site/urls.py
==================
0ae2f10e;Pablo Hoffman;2008-06-26 13:44:50 +0000;commited initial skeleton of scrapy svn
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%402

==
==================
5c13be38;Daniel Grana;2009-05-04 18:16:20 +0000;dummy file to shift a revision
--HG--
extra : convert_revision : svn%3Ab85faa78-f9eb-468e-a121-7cced6da292c%401

==

.hgignore
